nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=6.25e-05 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter10_learnrate0.000125_tr0.8691_cv1.9306 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter11 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975047
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.2475, max 7.77538, mean -0.00464958, stddev 0.983373, skewness 0.0162194, kurtosis 1.92828 ) 
[1] output of <AffineTransform> ( min -28.3877, max 24.4242, mean -3.31575, stddev 3.83673, skewness 0.133089, kurtosis 1.27629 ) 
[2] output of <Sigmoid> ( min 4.69225e-13, max 1, mean 0.19899, stddev 0.30602, skewness 1.55503, kurtosis 0.998399 ) 
[3] output of <AffineTransform> ( min -27.8396, max 15.4206, mean -3.94204, stddev 2.68536, skewness -0.0800811, kurtosis 2.20085 ) 
[4] output of <Sigmoid> ( min 8.11706e-13, max 1, mean 0.0990121, stddev 0.190707, skewness 2.88111, kurtosis 8.26781 ) 
[5] output of <AffineTransform> ( min -14.3656, max 10.6851, mean -3.10739, stddev 1.96461, skewness 0.558824, kurtosis 2.31687 ) 
[6] output of <Sigmoid> ( min 5.7692e-07, max 0.999977, mean 0.113244, stddev 0.187422, skewness 2.75849, kurtosis 7.75533 ) 
[7] output of <AffineTransform> ( min -23.6174, max 16.3518, mean -2.80892, stddev 2.27862, skewness 0.574899, kurtosis 2.87747 ) 
[8] output of <Sigmoid> ( min 5.53487e-11, max 1, mean 0.152683, stddev 0.231767, skewness 2.094, kurtosis 3.69162 ) 
[9] output of <AffineTransform> ( min -16.0037, max 17.2098, mean -2.81081, stddev 2.85027, skewness 1.31806, kurtosis 2.56572 ) 
[10] output of <Sigmoid> ( min 1.12122e-07, max 1, mean 0.179307, stddev 0.291589, skewness 1.76048, kurtosis 1.74314 ) 
[11] output of <AffineTransform> ( min -30.7739, max 20.7913, mean -3.56463, stddev 3.56971, skewness 1.03633, kurtosis 3.21898 ) 
[12] output of <Sigmoid> ( min 4.31602e-14, max 1, mean 0.153231, stddev 0.296916, skewness 2.00663, kurtosis 2.50211 ) 
[13] output of <AffineTransform> ( min -13.7528, max 21.4923, mean -0.0091424, stddev 3.46739, skewness 0.542778, kurtosis 0.996247 ) 
[14] output of <Softmax> ( min 2.77589e-15, max 0.999896, mean 0.000624927, stddev 0.0178693, skewness 40.8283, kurtosis 1822.63 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.603969, max 0.92424, mean -0.000347009, stddev 0.0471565, skewness 0.0539251, kurtosis 14.2057 ) 
[1] diff-output of <AffineTransform> ( min -0.300558, max 0.220301, mean 1.74317e-06, stddev 0.00980651, skewness 0.00716357, kurtosis 54.9776 ) 
[2] diff-output of <Sigmoid> ( min -1.29694, max 1.18557, mean -0.000172257, stddev 0.0874734, skewness -0.0386298, kurtosis 12.2033 ) 
[3] diff-output of <AffineTransform> ( min -0.380585, max 0.294333, mean 3.54819e-05, stddev 0.0108725, skewness -0.155664, kurtosis 77.4041 ) 
[4] diff-output of <Sigmoid> ( min -1.5968, max 1.57075, mean 8.32533e-05, stddev 0.114396, skewness -0.033962, kurtosis 12.9197 ) 
[5] diff-output of <AffineTransform> ( min -0.298438, max 0.298025, mean 3.18202e-05, stddev 0.0111179, skewness 0.21762, kurtosis 60.5495 ) 
[6] diff-output of <Sigmoid> ( min -2.2104, max 2.10359, mean 0.000223648, stddev 0.0963374, skewness -0.0604112, kurtosis 15.8126 ) 
[7] diff-output of <AffineTransform> ( min -0.238373, max 0.198639, mean 1.63099e-05, stddev 0.00917967, skewness 0.0656164, kurtosis 45.0262 ) 
[8] diff-output of <Sigmoid> ( min -1.1725, max 1.1357, mean -9.16071e-05, stddev 0.0680451, skewness -0.0602121, kurtosis 13.9421 ) 
[9] diff-output of <AffineTransform> ( min -0.179806, max 0.191784, mean 1.52702e-05, stddev 0.00680402, skewness -0.128526, kurtosis 52.6883 ) 
[10] diff-output of <Sigmoid> ( min -0.846326, max 0.859493, mean 8.07353e-05, stddev 0.0516233, skewness -0.048771, kurtosis 16.9783 ) 
[11] diff-output of <AffineTransform> ( min -0.263825, max 0.218095, mean 1.55114e-05, stddev 0.0077162, skewness -0.345, kurtosis 70.6996 ) 
[12] diff-output of <Sigmoid> ( min -2.26827, max 1.5839, mean 9.44376e-06, stddev 0.0813931, skewness -0.0647883, kurtosis 11.9468 ) 
[13] diff-output of <AffineTransform> ( min -0.999957, max 0.897816, mean -7.38539e-09, stddev 0.0158246, skewness -27.3444, kurtosis 2162.86 ) 
[14] diff-output of <Softmax> ( min -0.999957, max 0.897816, mean -7.38539e-09, stddev 0.0158246, skewness -27.3444, kurtosis 2162.86 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.48463, max 1.20502, mean -0.00303816, stddev 0.151086, skewness -0.0218114, kurtosis 1.77771 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.543111, max 0.557461, mean 0.000446246, stddev 0.153665, skewness -0.168542, kurtosis 0.881299 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.751497, max 0.82272, mean 0.00169626, stddev 0.0623379, skewness 0.180044, kurtosis 6.17262 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.723991, max 0.871444, mean 0.00908335, stddev 0.173009, skewness 0.418342, kurtosis 2.13578 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.647238, max 0.747509, mean 0.000854848, stddev 0.0380323, skewness 0.28735, kurtosis 12.1949 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.620296, max 1.01675, mean 0.00814605, stddev 0.183657, skewness 0.38259, kurtosis 2.93928 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.464397, max 0.56924, mean 0.000510136, stddev 0.0315817, skewness 0.265481, kurtosis 11.1697 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.607854, max 0.692373, mean 0.00417533, stddev 0.146297, skewness 0.310514, kurtosis 2.73356 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.453727, max 0.34712, mean 0.000632122, stddev 0.0298388, skewness -0.0925728, kurtosis 8.43684 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.624463, max 0.505406, mean 0.00390916, stddev 0.109308, skewness -0.168833, kurtosis 3.39096 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.465725, max 0.496433, mean 0.000831896, stddev 0.0414467, skewness 0.00680995, kurtosis 8.89122 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.573066, max 0.639338, mean 0.00397091, stddev 0.126337, skewness 0.00469982, kurtosis 2.56615 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -4.17176, max 2.57944, mean -2.5755e-08, stddev 0.0881571, skewness -5.41129, kurtosis 123.561 ) , lr-coef 1, max-norm 0
  bias_grad ( min -4.14351, max 2.45638, mean -6.85453e-09, stddev 0.278329, skewness -2.95822, kurtosis 42.7211 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 338432 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.50193, max 6.77601, mean -0.00405738, stddev 0.997423, skewness -0.00626004, kurtosis 2.0657 ) 
[1] output of <AffineTransform> ( min -29.7325, max 21.2829, mean -3.30544, stddev 3.86766, skewness 0.109583, kurtosis 1.26004 ) 
[2] output of <Sigmoid> ( min 1.22272e-13, max 1, mean 0.200872, stddev 0.307579, skewness 1.54006, kurtosis 0.944492 ) 
[3] output of <AffineTransform> ( min -33.3181, max 16.8083, mean -3.95429, stddev 2.71446, skewness -0.120661, kurtosis 2.27905 ) 
[4] output of <Sigmoid> ( min 3.38931e-15, max 1, mean 0.0997087, stddev 0.192599, skewness 2.86896, kurtosis 8.14582 ) 
[5] output of <AffineTransform> ( min -13.9945, max 12.1468, mean -3.10517, stddev 1.98778, skewness 0.550065, kurtosis 2.28974 ) 
[6] output of <Sigmoid> ( min 8.36104e-07, max 0.999995, mean 0.114777, stddev 0.190243, skewness 2.72318, kurtosis 7.46651 ) 
[7] output of <AffineTransform> ( min -23.6566, max 15.6336, mean -2.80623, stddev 2.31301, skewness 0.542072, kurtosis 2.7589 ) 
[8] output of <Sigmoid> ( min 5.32207e-11, max 1, mean 0.155174, stddev 0.235217, skewness 2.05539, kurtosis 3.47922 ) 
[9] output of <AffineTransform> ( min -16.6773, max 17.8726, mean -2.79995, stddev 2.89473, skewness 1.31569, kurtosis 2.5616 ) 
[10] output of <Sigmoid> ( min 5.71636e-08, max 1, mean 0.181522, stddev 0.294478, skewness 1.74034, kurtosis 1.65431 ) 
[11] output of <AffineTransform> ( min -29.9742, max 19.2793, mean -3.55379, stddev 3.60753, skewness 1.02948, kurtosis 3.15685 ) 
[12] output of <Sigmoid> ( min 9.60225e-14, max 1, mean 0.155838, stddev 0.299947, skewness 1.97269, kurtosis 2.34978 ) 
[13] output of <AffineTransform> ( min -14.454, max 22.157, mean -0.0135986, stddev 3.51886, skewness 0.515531, kurtosis 0.904467 ) 
[14] output of <Softmax> ( min 5.09515e-15, max 0.995331, mean 0.000624927, stddev 0.0183411, skewness 41.5489, kurtosis 1874.33 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.03009, max 1.70599, mean -0.00058182, stddev 0.0441438, skewness 0.706808, kurtosis 50.6059 ) 
[1] diff-output of <AffineTransform> ( min -0.303408, max 0.316086, mean -6.08618e-06, stddev 0.00875248, skewness 0.0298045, kurtosis 69.0049 ) 
[2] diff-output of <Sigmoid> ( min -1.35808, max 1.48836, mean 0.000108183, stddev 0.0773002, skewness 0.00352046, kurtosis 12.89 ) 
[3] diff-output of <AffineTransform> ( min -0.282251, max 0.229724, mean -3.87472e-05, stddev 0.00953248, skewness -0.528992, kurtosis 68.6141 ) 
[4] diff-output of <Sigmoid> ( min -1.44281, max 1.32389, mean 0.000215919, stddev 0.100922, skewness -0.0155545, kurtosis 10.3163 ) 
[5] diff-output of <AffineTransform> ( min -0.287493, max 0.263366, mean -6.42762e-05, stddev 0.00978399, skewness -0.425685, kurtosis 52.5701 ) 
[6] diff-output of <Sigmoid> ( min -1.33406, max 1.6044, mean -0.000308427, stddev 0.0854839, skewness -0.0760485, kurtosis 11.358 ) 
[7] diff-output of <AffineTransform> ( min -0.215902, max 0.195973, mean -4.57357e-05, stddev 0.00814129, skewness -0.314312, kurtosis 40.2203 ) 
[8] diff-output of <Sigmoid> ( min -1.04042, max 1.00155, mean -0.000171996, stddev 0.0603773, skewness -0.0661233, kurtosis 11.6394 ) 
[9] diff-output of <AffineTransform> ( min -0.128676, max 0.14417, mean -3.69411e-05, stddev 0.00603614, skewness -0.214627, kurtosis 41.1013 ) 
[10] diff-output of <Sigmoid> ( min -0.731166, max 0.650917, mean 4.06074e-05, stddev 0.0460113, skewness -0.135792, kurtosis 14.0353 ) 
[11] diff-output of <AffineTransform> ( min -0.194813, max 0.213397, mean -3.3312e-05, stddev 0.00690937, skewness -0.283143, kurtosis 57.2176 ) 
[12] diff-output of <Sigmoid> ( min -1.04794, max 1.35721, mean -0.000378677, stddev 0.073116, skewness -0.147947, kurtosis 8.27698 ) 
[13] diff-output of <AffineTransform> ( min -0.999471, max 0.826097, mean -5.59143e-09, stddev 0.0146925, skewness -30.8442, kurtosis 2449.87 ) 
[14] diff-output of <Softmax> ( min -0.999471, max 0.826097, mean -5.59143e-09, stddev 0.0146925, skewness -30.8442, kurtosis 2449.87 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.60367, max 1.58873, mean -0.00035614, stddev 0.13988, skewness 0.00280454, kurtosis 3.0042 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.716621, max 1.06834, mean -0.00155807, stddev 0.170628, skewness 0.168185, kurtosis 2.1242 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.915788, max 0.649515, mean -0.00185178, stddev 0.0596915, skewness -0.28712, kurtosis 7.15042 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.07701, max 0.691362, mean -0.00991931, stddev 0.179908, skewness -0.301101, kurtosis 2.81997 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.697287, max 0.666531, mean -0.00174095, stddev 0.0373514, skewness -0.516807, kurtosis 14.1926 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.974678, max 0.812146, mean -0.0164548, stddev 0.194834, skewness -0.424756, kurtosis 3.08716 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.601285, max 0.603439, mean -0.00131459, stddev 0.0318917, skewness -0.268995, kurtosis 11.0442 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.767017, max 0.718493, mean -0.0117083, stddev 0.161714, skewness -0.119019, kurtosis 2.57669 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.361868, max 0.378043, mean -0.00146637, stddev 0.0295216, skewness -0.429912, kurtosis 8.19922 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.541539, max 0.409558, mean -0.0094569, stddev 0.114364, skewness -0.46294, kurtosis 3.05617 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.467986, max 0.379817, mean -0.00130804, stddev 0.0402827, skewness -0.41358, kurtosis 8.01284 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.496132, max 0.450086, mean -0.0085279, stddev 0.124906, skewness -0.336067, kurtosis 1.74021 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.32895, max 1.6462, mean 5.044e-09, stddev 0.080204, skewness -4.85431, kurtosis 83.6186 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.29467, max 1.64631, mean -5.96046e-09, stddev 0.235271, skewness -1.86092, kurtosis 13.6179 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0778833 min, processing 72422.9 frames per sec; i/o time 5.00387%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14106 318 182 101 16 23 147 394 174 74 294 47 870 141 67 129 255 114 165 74 149 213 181 183 408 103 94 245 56 199 233 219 209 78 485 234 501 261 303 129 32 34 202 163 535 145 178 160 16656 5473 1407 385 440 102 243 122 303 118 380 0 107 271 58 97 93 86 243 57 294 191 144 415 282 143 874 110 864 152 49 13 569 154 448 222 342 20 710 155 141 68 76 139 255 166 278 70 165 257 182 92 99 60 29 327 272 85 199 196 15 111 124 263 142 460 128 77 124 98 17 288 88 277 175 145 85 235 203 106 16 130 103 96 261 105 225 47 654 102 126 63 230 68 627 94 106 150 211 42 124 289 144 100 161 98 300 136 229 44 206 11 193 224 432 114 59 162 165 82 201 60 143 259 59 211 112 0 74 325 188 0 308 89 60 48 267 60 114 213 217 233 69 84 34 171 117 241 110 199 148 224 208 100 318 174 185 100 39 85 279 178 263 182 189 160 112 158 150 96 122 83 71 465 110 243 156 322 191 131 401 380 136 112 84 62 69 94 171 202 164 237 323 105 117 1041 218 21 103 173 175 146 274 69 106 143 83 59 358 320 29 312 180 310 237 470 549 136 85 158 80 245 175 26 156 156 198 132 23 84 27 70 350 301 265 162 4 208 159 83 111 119 62 231 365 304 54 85 79 76 168 163 124 705 189 106 48 121 19 123 117 137 169 141 132 456 113 108 147 127 25 491 355 389 168 188 199 87 83 96 64 68 88 197 54 111 190 205 366 44 139 111 166 116 142 17 246 129 132 136 118 101 283 141 319 231 267 110 156 104 38 203 22 154 518 287 30 115 144 23 375 214 888 167 91 50 151 941 147 529 88 198 86 42 20 103 215 7 131 37 106 81 22 12 221 160 126 219 148 121 262 96 292 133 232 397 251 83 68 117 120 105 280 174 760 20 61 190 113 277 70 233 90 65 10 85 200 246 146 190 262 32 169 140 133 203 48 20 191 113 261 70 14 67 149 131 195 140 173 225 118 142 479 20 65 121 644 103 272 567 0 296 110 125 160 72 193 209 23 154 136 123 42 101 71 350 71 132 225 118 52 133 131 151 84 16 351 136 37 102 80 155 336 499 610 12 156 207 219 45 193 336 298 26 79 88 241 108 284 67 113 217 108 268 207 177 338 0 305 120 149 24 75 211 69 271 255 39 24 38 172 143 166 104 74 156 223 90 72 29 82 110 165 110 21 127 56 70 231 501 270 74 7 137 123 314 232 395 203 187 41 160 122 17 81 166 128 40 126 167 271 254 173 133 146 338 236 381 113 188 153 16 31 122 164 152 22 403 94 16 266 540 9 424 185 271 152 51 169 517 345 194 95 131 53 165 217 206 266 69 37 89 10 229 185 91 95 46 196 393 238 61 98 65 90 158 275 81 102 141 157 238 200 153 34 93 114 536 130 350 119 108 80 155 62 182 91 71 357 98 68 287 22 338 165 148 65 150 43 19 475 257 27 112 101 300 81 75 49 62 166 121 115 96 155 149 114 163 60 77 150 33 195 123 137 225 13 96 1 371 772 359 185 304 20 19 266 123 818 63 1086 46 67 11 30 81 10 43 201 243 244 188 190 152 28 79 20 11 286 81 50 67 51 394 74 59 133 106 100 187 12 118 214 93 178 180 230 63 181 177 200 223 108 128 194 131 308 105 338 145 9 47 366 206 283 41 270 145 334 161 60 200 224 66 501 255 295 186 156 187 52 224 200 154 11 230 236 109 237 192 144 232 96 14 257 201 241 13 135 54 40 360 65 120 202 78 92 300 194 309 191 175 92 336 191 76 30 198 155 34 242 103 151 159 81 34 239 79 193 187 894 389 136 108 191 100 92 356 115 212 250 415 139 101 304 13 96 177 271 105 284 17 199 129 1 184 412 238 105 621 144 87 465 395 487 106 311 221 12 120 85 137 17 153 113 92 58 238 214 264 478 417 92 505 132 126 271 46 78 163 182 80 434 59 158 155 94 295 460 167 110 239 370 337 231 178 243 94 209 244 6 572 148 133 853 101 140 298 137 110 210 495 597 87 244 98 307 351 125 50 122 130 203 116 71 317 281 439 117 229 237 160 74 14 68 0 179 352 232 39 133 161 95 239 159 52 55 475 149 208 139 238 143 13 107 166 174 77 63 265 134 130 27 75 250 167 217 98 105 107 7 35 22 33 161 244 236 88 96 74 173 431 163 277 184 154 69 301 65 155 55 235 28 214 170 218 43 55 187 121 171 187 83 253 141 91 98 50 139 63 314 513 250 377 20 20 151 50 93 210 102 8 75 294 127 188 138 219 387 206 58 42 144 160 500 297 122 109 157 150 293 122 184 135 454 256 639 430 514 276 260 11 205 603 30 294 400 314 275 1369 13 135 174 545 623 167 212 18 228 189 8 269 378 188 368 54 407 110 66 152 72 182 17 70 15 364 187 435 117 417 215 453 278 238 307 229 170 222 514 1659 385 27 29 135 197 165 95 257 265 225 234 324 927 460 300 79 209 290 73 105 104 301 57 72 71 288 277 257 196 163 88 149 159 249 147 133 209 222 383 280 233 81 385 205 66 221 90 97 206 21 51 102 157 112 55 247 289 199 94 253 66 209 60 71 91 216 394 303 128 297 867 202 154 463 68 187 379 101 293 182 46 44 166 97 74 114 137 135 144 261 159 184 429 65 188 148 128 153 25 51 234 276 278 124 105 40 231 49 271 475 138 472 70 108 64 340 343 67 57 83 126 354 312 217 173 1139 101 283 121 161 41 25 133 75 25 152 172 146 145 67 68 173 860 150 185 54 238 244 264 142 245 359 64 188 236 440 467 176 100 111 397 181 34 127 285 168 80 217 39 170 96 409 264 27 293 60 89 290 93 158 44 360 209 393 470 276 215 186 17 107 387 87 199 486 200 364 92 208 98 45 112 198 200 51 75 73 84 123 256 497 140 236 327 93 108 130 82 201 557 166 152 149 89 177 110 106 78 340 468 258 114 99 72 272 150 361 278 295 290 28 136 365 263 133 172 27 246 193 368 212 124 30 441 21 75 76 130 112 227 87 275 45 268 77 220 120 69 290 57 21 181 188 104 237 443 402 322 50 177 99 344 374 167 607 329 146 320 241 58 191 64 178 543 113 28 155 219 163 210 154 367 176 195 1 841 138 164 67 156 162 210 126 393 144 100 416 188 132 120 202 89 151 241 532 67 245 136 522 206 63 792 272 178 150 161 82 451 1062 108 97 108 446 279 270 318 355 93 76 348 328 313 159 58 10 183 270 82 159 405 105 236 115 193 135 71 309 426 85 360 345 394 142 119 508 112 227 186 277 383 158 183 201 169 192 413 353 368 174 165 139 218 129 84 185 106 167 149 106 202 192 52 277 184 277 122 323 139 144 176 143 106 132 12 86 245 122 119 225 70 210 189 188 218 55 279 22 282 149 868 210 123 114 155 211 47 194 250 216 147 82 225 171 95 173 158 351 748 556 143 154 463 220 173 181 206 19 145 407 56 190 265 144 349 166 273 170 313 198 110 79 89 397 68 641 130 53 377 240 109 206 175 235 18 281 141 48 200 153 232 127 223 530 843 47 63 163 102 29 37 47 20 181 ]
@@@ Loss per-class: [ 0.363041 1.09031 0.609885 1.04159 1.04372 1.43402 1.43972 0.549667 0.719562 1.34222 0.349883 1.7965 0.40556 0.735336 2.03159 0.723832 0.809325 0.763019 0.989561 1.38076 0.704967 0.645619 0.943826 0.948318 1.17237 0.612194 1.33226 0.541834 1.21127 0.521748 1.16646 0.68831 0.908046 0.937185 0.402407 0.369606 0.260191 0.173898 0.501496 1.14839 1.26105 0.576626 0.536017 0.816327 0.291369 0.659858 0.721613 0.812676 0.282698 0.554912 0.659741 0.45824 0.31771 1.97068 0.743417 1.06374 0.484017 0.825938 0.868064 0 0.91765 0.590947 2.51174 1.03225 1.16155 0.972465 0.654041 0.701865 0.771752 0.471177 1.01103 0.6945 0.586731 0.362689 0.315512 1.59006 0.226134 0.773054 0.819514 2.28232 0.864525 0.561074 0.536307 0.804836 0.789782 0.728879 0.778568 0.759106 0.776062 0.793008 1.092 0.473176 0.408579 1.28164 0.650106 1.53409 1.32375 0.705745 0.569654 0.701361 0.594243 0.969447 1.22437 0.454205 0.746637 0.577985 0.820971 0.528047 2.12697 0.611263 0.822752 0.351795 1.27204 0.43283 1.89001 0.970087 1.36906 0.657772 1.16124 0.804983 0.920146 0.655031 0.990593 1.08376 0.45864 0.70079 0.965357 0.747127 1.3943 0.991066 1.43675 0.694168 1.05376 1.18515 1.05542 0.785877 0.519876 1.17171 1.24273 1.09152 0.945307 1.15777 0.451143 1.60873 0.795805 0.794281 0.936433 0.809371 0.772024 0.731759 0.544992 0.793753 1.14947 0.700138 0.686665 0.570583 0.529881 1.12269 0.537554 1.02971 0.541074 0.521538 0.922357 1.03742 1.10042 1.33024 1.1715 1.22149 1.35396 0.751481 0.530085 0.627595 0.716192 0.986703 0.753602 0 1.31417 0.798896 0.482543 0 1.31986 0.736525 0.563657 0.978899 1.08221 1.02185 0.508561 1.10174 0.982213 0.194282 0.839261 1.23867 0.799158 0.5355 0.92571 0.66418 0.79539 1.06484 0.73406 0.622222 1.08371 1.70287 0.477331 1.34156 0.989948 0.762662 1.10759 1.02114 0.995009 0.52098 0.701173 0.934628 0.73113 0.489679 1.24462 0.547591 1.84736 1.12258 0.984936 0.995422 1.0476 0.889462 1.15987 1.10122 0.495227 0.644098 1.18992 0.648767 0.451027 0.454112 0.761082 0.715416 1.73136 0.534281 0.412896 1.633 0.959072 0.752164 0.91261 0.801827 1.31869 0.68499 0.497126 0.492026 0.461522 5.97412 2.19321 1.09768 2.02753 1.69276 1.02288 0.834095 0.977149 1.21784 1.10744 0.9709 0.937844 0.759648 0.781554 0.350403 0.27488 1.17086 1.53568 0.459018 0.520348 0.604255 0.492547 0.954854 1.03543 0.684499 0.852072 0.613371 1.10372 0.787953 2.00795 1.51363 0.504054 1.48255 1.09378 0.86455 0.518969 1.24766 1.42471 0.552667 4.07368 1.32964 0.803504 1.46129 0.906398 0.653993 0.923158 0.900954 0.648899 0.778654 1.48005 1.10684 1.01526 1.01155 0.741561 0.395881 0.842886 0.634757 1.10543 1.01423 1.07177 1.30134 1.40795 2.70437 0.933537 0.676895 0.516986 1.28001 0.733891 1.04468 1.31475 0.624728 1.07504 1.15048 0.901667 0.912495 0.517523 0.404123 0.636729 0.871663 0.697522 0.70918 0.948819 0.632568 1.33058 1.02671 0.731179 0.57033 1.41547 0.628065 0.630301 0.762717 0.722739 1.85728 1.26924 1.35516 0.506509 0.980059 0.643396 1.87949 0.645823 1.48924 1.49668 0.753843 1.65844 1.17039 0.801344 0.445926 0.859012 0.615204 0.821691 0.806016 0.450398 0.687999 1.14391 1.01688 1.41005 1.11334 0.506714 0.985479 0.953504 0.678223 1.90527 1.87157 1.01276 0.597902 0.6894 0.762308 1.03147 0.906764 1.19744 0.577158 1.22027 0.491795 2.29133 0.978534 1.55297 0.459803 0.926581 0.680622 1.41593 4.32326 1.10949 0.760122 0.58763 1.47707 1.46692 1.23287 0.844266 1.17995 0.488881 0.465336 0.568521 1.12479 1.84787 0.580366 0.659656 0.96939 0.734372 0.75191 1.06056 2.02272 0.770041 1.15689 0.939556 0.928554 1.54334 0.843238 0.529188 0.895516 0.898155 1.62643 0.780029 1.56518 1.09284 0.47031 0.818244 1.47573 1.95858 1.42903 0.929326 0.799598 0.613008 1.03784 1.35278 1.40744 1.24044 0.868367 2.14082 0.939453 1.21876 1.75016 1.0154 0.481092 0.763865 1.05956 1.1513 0.691247 1.55041 0.63534 0.802879 0.838041 1.50304 1.0564 1.13054 0.610774 0.733849 1.1533 1.01595 0.693325 0.531241 1.59666 0.534552 0.467869 0 1.1459 0.873848 0.988825 0.796069 1.25575 0.803521 0.900393 0.616954 0.719505 0.853523 0.728951 2.04373 1.3743 1.1346 0.625159 1.20614 0.954133 1.08097 0.967308 0.775484 0.731637 0.888371 0.593225 1.43173 1.56269 0.327599 1.52842 1.28541 1.85324 0.944522 1.16726 1.23143 0.499417 0.540133 2.0139 0.382842 1.33451 1.13704 1.52912 1.81326 1.37705 0.999459 0.954233 0.559569 0.836562 0.999673 0.584287 0.77481 1.50884 1.21671 0.970118 0.829696 0.876137 1.28757 1.63917 0.841064 0 0.820162 2.21662 0.618392 0.801615 1.23255 0.774466 0.74388 0.912587 0.391164 1.11527 0.737516 0.837859 1.01951 1.05219 1.1325 1.05856 1.08402 1.9392 1.18037 0.512001 0.746873 0.792157 1.43968 0.7625 0.733829 1.47362 1.52615 0.958962 1.17981 0.626852 1.02171 0.65481 1.11667 1.38459 3.0062 1.47354 0.734852 0.798922 0.795038 0.354023 0.788341 1.46811 1.52073 0.907258 0.499671 1.16365 0.916217 0.891161 1.2047 1.07377 0.934157 0.589682 0.83989 0.869734 1.03007 1.05111 0.722367 0.503999 0.780163 1.16521 1.58433 0.738268 1.34555 2.91435 0.805768 0.743764 0.510034 0.436989 1.25318 0.368361 1.25966 1.46138 0.793962 1.14649 1.9995 0.667683 0.526354 1.30726 0.547874 1.72934 0.722841 0.871462 0.862307 1.10387 0.598365 0.88424 1.17491 1.2975 1.19087 0.799594 1.01216 1.08012 1.31461 0.78398 2.17824 0.901337 1.14197 0.924263 1.18665 1.91578 1.07683 0.621549 0.849714 0.774201 1.15189 1.04894 0.994511 0.827473 0.670309 1.51693 1.20554 1.43826 0.611109 1.2101 1.28903 0.961065 1.21862 1.10675 0.869176 0.5222 1.02193 1.10411 1.19863 1.51686 0.520277 0.537404 2.22199 0.994834 1.52799 1.62511 0.721847 1.13465 1.62402 0.651104 1.27642 0.90873 0.72196 1.19006 0.984686 1.54439 1.52301 1.62602 1.15361 1.06906 0.50813 0.82605 0.830662 0.731513 1.47869 1.11422 1.78173 1.0403 0.833181 1.20317 0.527043 1.02092 0.868057 0.861958 2.18385 1.52527 0.877322 0.792999 1.36975 0.819935 0.537071 1.33092 1.27897 0.682085 3.1264 1.78106 10.9499 1.4265 0.495994 0.291503 0.51555 1.097 1.55932 1.86567 0.924563 0.769055 0.869928 0.569673 0.586811 1.30175 1.44262 2.9158 1.12264 1.20933 3.22441 1.53495 0.875055 1.15127 1.05302 0.494038 0.413393 1.55246 2.30067 1.08975 1.13604 2.84817 1.09086 0.876099 0.751902 1.93267 1.18781 0.814421 3.25349 1.18805 0.605202 1.4765 1.46586 0.506872 1.93032 0.840794 0.583399 1.64081 1.36451 0.895577 1.17234 1.0208 1.40319 0.833287 1.02839 1.01916 0.555013 1.09594 0.970492 2.10631 0.743538 0.895932 0.756457 0.512042 1.53855 1.04177 0.758374 0.746587 1.01991 0.801669 1.29941 0.847458 0.777147 1.24131 1.00204 0.550979 1.06302 1.451 0.659148 0.858758 1.26285 1.35547 0.61085 0.648316 1.14 1.29666 1.21722 0.811259 2.31788 0.73383 0.85207 0.983718 0.987361 1.30432 1.19121 0.538353 0.787187 1.38145 0.720246 0.659183 0.79852 0.6196 1.21321 1.65736 1.78499 0.730715 0.728266 1.36834 1.2192 1.72039 1.56826 0.855346 0.405113 0.582406 1.0733 0.708668 1.40715 0.801837 0.611878 0.887619 0.877548 0.38606 0.73202 1.00875 1.19824 1.25362 1.07672 1.16717 0.600252 1.35133 0.986752 1.36241 0.854185 1.10545 1.0322 0.441012 1.17057 1.25494 1.19675 1.61886 1.66618 0.938592 0.728174 0.705804 0.493344 0.511279 1.09941 1.44455 1.11804 1.84932 1.10214 0.989431 0.931818 1.27942 0.768884 1.27465 0.737691 1.414 8.3309 0.803096 0.613776 0.601696 1.41763 0.562466 1.22846 1.21591 0.447744 0.817372 0.595508 0.876754 0.926878 0.753816 1.6233 1.35565 1.11646 0.836595 2.23007 0.679373 0.999439 1.76624 1.06812 0.683453 2.78768 0.635213 0.505019 0.520517 1.28226 0.861587 1.11114 0.947124 1.34827 1.28698 1.26812 0.878248 1.14057 1.67463 0.798294 0.584977 0.887004 0.892034 1.15809 0.626358 1.09999 1.3429 0.989672 0.526851 0.486229 0.628652 0.699058 0.555653 0.583029 0.792413 0.765135 1.24418 2.40041 0.54521 0.713514 1.28032 0.581404 0.741317 1.00494 0.796421 1.05247 0.881324 0.49176 0.76421 0.876473 1.49403 0.711699 1.24317 1.05288 0.800934 1.21219 1.79345 1.36528 1.39486 0.400379 0.984532 1.04173 0.998088 1.5907 0.662618 1.51044 1.75692 1.12991 1.27367 0.862667 1.71955 1.30041 0 1.30746 0.637722 0.669534 0.644272 1.07901 0.714717 0.866225 0.60057 1.27974 2.33987 2.27253 0.648726 1.64442 0.733519 1.98607 0.914745 1.12074 1.62131 1.4477 0.892103 1.25074 1.73617 1.32204 0.836228 1.38849 0.902542 0.844799 1.69204 0.670382 1.38581 1.28251 1.11139 0.827816 0.909956 3.30718 1.394 0.812239 0.790881 0.945892 0.846475 0.736085 1.2614 1.04426 1.66745 1.04636 0.739051 0.906605 0.466354 1.39966 1.29666 1.06392 1.00886 0.965353 1.12433 0.943457 0.886507 1.26642 1.04804 0.555064 0.654851 2.09839 1.62966 1.41106 0.881581 1.38582 1.39108 1.16144 1.06202 0.965679 1.31013 0.575578 1.2774 2.42905 3.23055 0.901548 0.792932 1.35424 1.00457 1.23258 1.74471 0.903674 2.78743 1.29408 1.06417 1.39474 0.79997 1.19017 0.92563 1.3072 1.07261 1.32956 0.574983 1.18605 0.515592 1.63088 2.37075 1.50908 3.17595 0.783148 0.723561 1.21428 1.21379 0.951007 0.840145 0.56645 0.869718 0.950346 1.17673 0.530044 0.625797 1.35318 1.17511 1.21094 1.30268 0.701361 1.34181 0.850293 0.536135 2.01793 1.18789 1.29554 0.480249 0.821892 0.641783 2.07566 1.15087 0.790671 1.09359 0.553293 0.758514 0.882942 2.34682 0.796864 1.83937 1.71401 0.43085 0.581958 1.99566 0.661393 1.14737 1.40416 0.621606 1.30721 0.721289 1.54833 1.78714 1.19244 1.61508 0.612667 0.378934 0.815855 0.683446 1.25197 0.653525 1.38459 0.645363 0.587093 0.864782 0.987063 1.04119 2.15099 0.713845 0.742428 0.627411 0.761726 1.74576 1.07406 1.06729 0.923601 0.69976 1.40976 1.57906 0.953702 1.07987 1.03212 0.9253 0.475055 1.00729 0.92908 1.76411 1.19732 0.932169 1.09533 0.660129 1.22515 0.999874 1.266 0.647623 0.803332 1.31533 1.09485 1.40941 1.36552 2.17214 0.927998 0.913962 1.65257 0.557884 0.857307 1.75601 1.82597 1.46128 0.7466 0.736217 0.829811 0.964557 0.934089 1.0191 1.35035 0.608 1.45521 0.390297 0.802719 1.76563 2.79889 2.59369 1.13158 1.89529 1.11149 0.925994 0.819489 1.69189 0.917824 1.38348 0.773586 1.90399 1.3183 0.576845 1.26602 0.474066 0.884295 0.978357 1.61867 0.453474 0.755449 1.14423 0.922431 0.536308 0.978594 0.863745 0.933449 1.49618 1.31294 0.996175 1.47914 1.36945 0.636642 0.717743 1.23759 1.21009 1.03269 1.07186 0.99645 0.730723 1.1799 1.74824 0.679825 1.13223 1.22831 1.15094 1.20412 0.841039 1.14589 1.78684 1.39382 0.891666 0.849758 0.826982 0.907961 1.11225 1.1397 0.990792 1.18497 0.651223 1.67015 0.59864 0.840256 0.555708 1.10835 0.857301 1.64349 1.74425 1.28476 1.82282 0.836012 0.839116 1.00524 1.27279 1.69732 0.810881 0.723249 0.478081 0.860875 0.895575 0.851372 1.1011 1.28928 1.64424 1.35484 1.19545 1.45144 0.718606 0.507218 1.06495 1.18926 0.841957 0.492793 1.01605 0.770755 1.14415 1.11895 0.68547 0.482571 1.81476 0.893277 1.42527 3.72858 0.607034 1.10883 0.956804 0.983836 1.26471 1.07005 0.854138 1.11702 1.05135 1.62781 1.36805 0.666915 1.03645 1.13621 0.502376 1.5651 0.989573 1.26451 0.551102 1.42961 0.867454 0.479484 0.975401 1.23925 0.631925 1.42833 0.861741 1.31196 0.570578 0.692712 0.854808 0.858611 0.625843 1.1222 1.58772 1.06074 1.57936 1.05546 1.18406 1.35656 0.702647 1.00094 0.846671 1.59154 0.955109 1.05055 0.773521 1.31406 1.15487 1.00032 1.78312 1.27097 1.53451 1.70398 1.17196 0.810835 0.689733 0.83174 1.4075 0.861739 1.24804 0.916394 0.991243 1.54116 1.26854 0.846564 0.864274 1.28514 1.2478 1.43438 2.15156 0.856135 1.98299 0.890373 0.639767 1.01204 0.906387 1.28579 0.931894 1.23963 0.409212 1.77541 0.778024 0.98022 0.779886 0.354633 1.63449 1.10597 0.566976 2.03479 1.16 2.30922 1.45446 1.41719 1.31706 1.3821 0.959435 1.50934 1.13237 0.935781 0.997572 0.763634 1.04381 1.91155 1.62388 0.823929 1.13761 1.05417 3.82592 0.70186 1.27667 1.37045 2.56331 1.63924 1.29912 0.597544 1.6465 0.763051 0.748909 1.56079 0.985639 1.42884 1.10324 1.28959 1.04449 1.38069 0.95063 0.530389 1.26982 0.920611 0.574203 0.84151 1.23905 1.89666 0.852474 0.910126 1.03913 1.31694 0.883683 0.557317 2.22446 1.48327 1.34012 1.02811 0.42806 1.20194 0.77046 0.99877 1.00758 1.05347 9.28097 0.792065 1.10369 0.56969 0.740243 1.38726 1.02587 0.680965 0.715474 1.09962 1.04285 1.53393 0.40589 0.947752 1.15478 1.42993 1.2314 1.84872 0.908844 1.00159 1.0648 0.709902 0.879539 1.63499 0.970465 1.27155 0.777248 0.674179 1.0284 1.74439 0.854004 1.01526 1.4039 0.49101 0.399682 1.10774 1.24844 1.18817 1.02149 0.784298 1.0569 0.795673 1.45953 1.69965 1.64676 0.810391 0.938317 0.924609 0.821439 1.36452 2.16554 0.634884 0.437592 1.19609 1.08289 0.675562 2.20022 0.539671 0.938301 2.51994 0.911681 1.63772 0.488289 0.399144 1.16651 1.04023 0.986811 1.10158 1.30161 0.731776 0.791069 1.45555 1.45386 1.38741 1.35224 1.27851 1.61538 1.25544 1.27599 0.957794 1.32718 1.13946 0.583514 1.17654 0.720964 1.17846 1.32344 0.729237 0.598033 1.2767 1.25427 1.57271 2.16571 1.03453 1.08728 0.699756 0.900459 1.44907 1.70148 1.6414 0.605196 1.10672 0.81132 1.54867 1.35036 0.945687 0.632311 1.36109 0.84331 1.8845 0.996104 0.7766 0.958412 1.00878 1.26976 1.86986 0.799926 1.28658 1.2079 0.647858 0.361364 0.716374 2.67015 0.947653 1.10181 0.43134 1.36318 1.30956 1.14598 0.783801 0.98141 2.29355 1.16872 0.96208 1.06907 0.909478 1.05457 1.05965 0.89955 1.64966 1.02584 1.53672 0.83761 0.977803 0.676179 1.73144 1.23495 0.814748 0.836457 0.872809 0.976821 1.20513 0.900064 1.12786 1.25149 1.05044 0.934077 1.11819 1.47341 0.856993 0.916329 0.531776 0.897007 1.87003 0.75394 1.60866 1.41997 1.42845 0.310822 1.17629 0.882572 0.828985 1.59265 1.24201 0.987502 0.818287 0.649555 0.837459 1.38506 1.0871 0.96264 0.80332 0.895739 0.8646 0.731482 0.579848 1.84032 1.04586 0.438839 0.921561 2.35478 1.1136 0.847192 1.83281 3.54883 3.57179 1.13913 1.73725 2.06336 ]
@@@ Frame-accuracy per-class: [ 86.1305 72.2135 85.4795 73.8916 72.7273 68.0851 54.2373 83.1432 78.51 44.2953 90.6621 44.2105 88.2252 81.2721 28.1481 80.3089 77.1037 79.476 76.1329 59.0604 76.9231 82.904 74.9311 73.0245 64.6267 86.9565 53.9683 82.2811 60.177 87.7193 62.5268 78.3599 78.7589 73.8854 90.0103 89.9787 94.7159 96.3671 86.6557 68.7259 70.7692 89.8551 85.4321 72.7829 93.5574 85.9107 75.6303 79.7508 91.0876 81.7393 78.7211 89.2348 92.168 28.2927 80.4928 75.102 88.9621 74.2616 79.1064 0 68.8372 84.7145 20.5128 75.8974 62.0321 73.9884 83.7782 71.3043 83.5314 87.7285 71.9723 79.9037 85.3097 87.108 92.167 50.6787 92.8861 78.0328 72.7273 29.6296 74.2757 86.0841 84.9498 78.6517 78.8321 92.6829 76.2843 77.1704 77.7385 78.8321 60.1307 88.172 88.454 63.0631 82.9443 56.7376 59.2145 75.7282 84.9315 83.2432 80.402 69.4215 57.6271 87.9389 80 78.3626 81.203 85.4962 45.1613 81.6143 73.0924 90.3226 58.2456 90.3366 42.0233 76.129 61.0442 82.2335 85.7143 74.87 77.9661 80 71.2251 65.2921 86.5497 78.9809 72.7273 79.8122 72.7273 70.4981 56.0386 79.7927 69.2161 69.1943 69.6231 82.1053 86.4782 72.1951 61.6601 67.7165 75.4881 55.4745 88.2869 53.9683 78.8732 77.0764 74.7045 65.8824 78.7149 80.829 86.5052 83.5821 69.3498 81.2183 82.1963 81.3187 85.4031 69.6629 82.8087 60.8696 87.3385 84.1871 73.526 71.6157 65.5462 57.2308 68.2779 64.2424 66.005 77.686 85.0174 86.3198 77.3109 78.487 76.4444 0 67.1141 76.1905 86.4721 0 61.2642 80.4469 85.9504 72.1649 71.028 74.3802 82.0961 62.7635 70.3448 95.5032 76.259 72.1893 89.8551 81.6327 75.7447 84.058 82.3529 63.6591 79.4613 83.2962 65.2278 40.796 86.6562 63.0372 72.7763 75.6219 73.4177 66.6667 71.5564 91.3165 81.2144 71.7808 81.2665 86.6044 64.8889 85.8044 48.505 70.4663 72.6531 77.8443 76.9231 74.1139 68.7783 66.5298 85.623 83.7209 68.4073 86.692 86.4259 86.2024 80.5861 85.3333 47.3373 88 90.6475 46.5608 69.9708 78.5185 75.9878 76.6316 57.8053 80.5687 85.9574 85.7417 89.2449 0 26.087 63.9769 34.7578 53.9249 69.2168 69.0647 76.0563 61.324 67.0659 67.2269 72.2455 80.1872 84.7458 93.12 92.5208 61.5137 59.7895 89.0542 85.3503 82.0513 90.0585 81.388 65.8385 80.2444 76.9231 83.0189 71.5655 76.0383 42.8212 57.3585 85.1064 41.4201 72.7273 76.5957 86.4479 62.0232 62.5235 86.7692 0 58.0336 82.1317 50.2994 78.9238 86.1925 76.8 77.3218 84.2681 80.4598 55.0459 73.6842 64.1509 66.6667 80.1187 88.0734 73.8956 81.3607 75.9894 65.7277 51.5464 59.2593 61.5385 29.1498 78.2979 85.0909 85.5457 64.311 76.2264 64.8412 56.3877 79.2627 72.5424 63.5294 78.4314 74.4659 86.3572 91.1425 81.8991 79.0451 81.7043 78.8571 75.4491 90.1554 62.0155 65.6934 81.3559 86.0759 60.5505 86.0987 81.8898 79.8054 77.7626 44.9438 68.1004 57.3991 87.0871 72.103 84.2105 51.4286 85.1927 54.8263 49.8113 79.1209 51.4768 69.9507 80.4233 87.6325 76.9953 80.7775 76.6355 70.5882 88.1789 81.3397 62.3377 75.6757 62.2222 71.8447 87.3674 69.5652 81.9672 83.1169 40.1384 55.3191 71.3715 87.1795 83.1739 80 75.4098 71.2871 66.6667 82.8465 58.3051 89.1407 29.3785 76.0705 64.7399 89.4118 92.6829 90.8213 60.3248 0 67.6806 77.3333 86.385 58.8957 75.5556 64 73.5892 67.9128 88.5375 87.4715 84.1751 73.251 46.0952 88.0829 80.3419 75.6554 77.8495 79.7484 69.1849 32.3353 72.9927 74.0426 76.3485 69.1943 43.4938 74.4986 86.259 82.9268 79.6748 54.0682 81.9383 55.4955 65.2482 87.3662 78.453 59.542 28.5714 53.8012 74.813 73.8337 83.959 68.2415 63.2381 49.2308 61.9469 70.4626 38.2022 70.7617 59.7938 73.1707 69.4517 85.4626 82.9828 69.5035 75.8621 75.5556 55.5184 83.6502 75.7033 82.5623 57.0605 67.8492 60.7595 78.5965 78.6236 82.9268 64.1221 82.3045 87.1994 55.0725 84.7706 89.8678 0 66.7791 77.8281 74.9004 78.5047 70.3448 77.0026 77.327 85.1064 79.6117 74.7253 84.2105 25.8824 55.1724 76.9231 84.4508 71.3287 76.9811 68.2927 76.7932 85.7143 82.397 79.8479 85.8086 54.4379 54.5455 94.7368 52.7473 74.6667 44.878 75.7764 67.5241 59.1382 86.0861 86.8141 56 91.3738 60.7229 67.426 39.5604 38.2429 56.7608 71.3568 75.4717 84.2767 81.3559 71.2215 82.0276 79.0861 47.4074 66.9604 69.8851 70.0461 74.4879 61.6867 57.4648 78.2866 0 73.3224 35.6846 84.9498 73.4694 68.8742 78.487 84.8921 74.7698 90.0196 60.7595 77.551 85.7143 73.6232 71.777 63.0631 67.9426 75.1678 44.7284 65.7718 85.0829 84.1379 77.9661 42.4242 77.8281 77.3414 52.4887 65.1163 77.6471 56.6372 86.5248 71.2743 83.9482 68.3919 61.745 0 50.1818 83.4008 79.4913 76.9892 89.7598 77.1499 50.6667 48.1928 80.3738 86.5306 62.8571 76.0736 73.8739 64.5914 66.6667 64.8221 82.3881 76.2431 78.5855 74.3516 67.4157 85.3242 86.5583 79.4926 69.7248 55.5066 75.3316 60.5863 6.06061 76.1905 79.1837 86.9301 85.9016 75.5556 92.689 63.4921 72.7273 77.6735 69.1952 10.5263 82.2144 85.7143 62.6151 85.9016 64.0777 78.4661 76.715 72.3589 65.8098 85.8639 74.5247 63.5514 64.0483 63.4483 76.9976 69.0432 71.9424 69.3333 80.4469 0 71.8954 67.9245 76.5027 68.0628 32.2581 66.1578 81.3215 74.6331 74.7967 70.0508 73.2824 74.0331 75.7098 82.7586 55.2147 61.4634 56.5371 81.9048 69.1824 63.8404 75.57 57.971 65.2406 74.2358 86.3001 72.0307 67.3324 64.4351 57.1429 86.9565 86.8167 32 66.3014 61.2022 54.5455 82.2378 67.0051 55.4745 85.2174 66.6667 73.5598 75.5287 52.5253 70.229 49.1694 62.069 51.2821 67.9285 76.1165 94.5455 70.2222 76.8473 78.8686 56.4417 79.4702 48.4848 72 78.0781 57.6132 83.9827 75.6477 70.0965 75.5853 39.3013 59.9388 74.3802 80 52.4917 80.597 85.9335 66.3968 63.2727 83.3703 0 48.7047 0 60.5653 85.5663 93.185 86.7925 65.0246 48.7805 20.5128 74.2964 76.9231 73.7935 83.4646 86.2402 64.5161 68.1481 0 68.8525 74.8466 0 39.0805 71.9603 68.1725 72.3926 87.5332 89.7638 53.7705 35.0877 74.2138 82.9268 0 70.8551 78.5276 89.1089 53.3333 66.0194 80.1014 26.8456 67.2269 84.6442 54.4601 56.7164 88 0 76.7932 87.1795 53.4759 64.4258 79.2244 68.5466 74.0157 61.157 79.4366 64.3392 68.0089 83.871 76.2646 70.9512 38.7833 78.7682 74.8815 82.127 89.3471 63.1579 84.2105 83.4925 77.4818 72.3104 86.747 58.0407 79.7251 77.429 47.0588 66.1157 87.7805 66.3697 58.6466 82.7517 78.2779 64.9746 47.7212 81.1502 83.2 62.8571 59.6882 62.3441 80.2589 43.4783 81.5618 75.2643 74.8858 69.4737 63.8961 67.8201 87.3118 80.829 62.069 79.2233 83.871 79.089 88.8889 59.0406 47.7064 56.7901 78.5021 82.4427 58.9212 63.2099 43.3121 49.7297 74.5424 89.4602 81.4216 68.9295 80.9117 59.4595 76.6716 83.5509 73.2026 88.5246 92.1914 82.3151 75.3623 66.8041 66.6667 75.2475 71.4734 84.6626 66.6667 76.8267 60.3774 79.0698 76.8 65.8468 86.2644 66.6667 65.4378 65.2742 48.7562 54.0541 74.0533 78.7879 79.0588 86.6267 88.0866 69.5341 56.1576 65.6814 29.6296 70.4663 77.7465 75.8748 55.9242 75.9227 85.7143 80.2005 56.3707 0 75.3388 87.0303 80.5031 55.9242 84.9558 65.0519 72 85.4995 75.8534 83.4872 75.1174 69.0209 78.1038 16 57.2614 64.3275 80 40 79.4788 69.6035 57.2973 76.9231 81.761 27.972 80.9074 89.4462 84.0719 43.2432 76.36 70.1887 71.9368 63.3517 47.3118 66.242 80.7339 65.7534 44.7205 77.3303 82.3529 73.817 77.1704 75.1323 78.8494 67.5353 65.6716 70.5882 86.4301 85.5601 85.3333 79.0497 84.0336 80.4928 74.0741 77.8043 65.0307 0 86.6376 78.1145 62.9213 85.2958 84.7291 73.3096 78.392 72.7273 69.6833 87.886 81.1302 76.1506 51.4286 82.2086 56.8528 71.5447 76.2447 67.7291 43.5644 64.4898 54.4061 88.4521 71.2446 69.9301 72.4409 47.2469 86.0068 49.3617 46.6231 69.4737 66.0436 83.2215 13.7931 70.073 0 60.1671 81.4184 83.4409 83.5443 75.6554 79.8762 75.3927 81.4196 67.7116 32.381 30.6306 83.0705 56.8562 74.8201 37.276 76.3103 72.4739 37.037 56.7442 69.0691 61.3181 42.5806 61.4173 81.7326 61.71 76.6284 83.6364 52.9801 85.0299 56.1194 58.3908 64.9746 72.9858 76.2791 26.6667 59.1549 75.5556 86.5672 75.5418 75.6646 79.9154 63.2768 72.5389 48.3221 72.0461 83.6616 82.5688 89.009 63.9566 64.0777 70.5036 68.6567 68.7023 65.5949 73.8739 69.2144 45.614 68.0653 83.2845 76.4302 45.977 57.6577 62.4 74.0741 67.0554 63.4667 63.4731 66.2722 76.3251 63.388 82.2335 59.4059 45.1613 12.5984 75.3577 78.481 58.2834 72.5828 68.2927 43.9024 77.2277 7.92079 59.893 69.8337 59.5122 70.5882 67.5497 78.438 69.8039 72.679 61.3718 88.3827 67.871 84.7458 49.5726 25.8824 57.4394 19.9377 79.3207 82.6891 61.2245 63.9269 73.6508 75.0831 86.201 68.5714 75.3388 70.1107 86.4686 81.4815 56.7631 62.9501 68.0272 64.7378 79.0787 69.5652 74.4526 86.3297 55.7377 63.1579 64.1698 87.1224 75.4991 83.096 22.2222 64.9446 81.3754 63.6114 81.7963 81.194 74.8235 37.8378 73.523 53.8259 35.2941 92.0223 87.4505 41.3793 84.1248 82.5688 58.1595 83.2579 66.1654 87.8689 55.1724 46.5753 68.5714 58.156 83.871 89.7119 80 83.3525 67.234 78.8024 59.8608 83.3517 87.2531 77.1488 72.5203 68.4096 46.9208 79.1011 79.8834 82.8563 80.6744 50.9091 64.4068 71.5867 79.4937 82.1752 52.356 58.6408 71.1864 69.6231 70.7889 78.2743 86.5768 72.3127 71.5474 46.5409 63.4845 76.0757 73.4694 83.4123 64.1148 69.9834 59.1304 82.7586 71.3287 63.7782 74.2342 59.4175 67.6845 44.0367 79.096 75.5853 52.6646 84.1683 81.3559 50.1873 52.506 58.427 83.1812 76.6488 78.8009 65.0307 74.1894 68.6131 54.1353 82.167 58.5635 91.2821 76.9976 27.907 19.4175 33.1707 60.9524 45.3333 68.4685 74.7475 76.3385 42.1053 77.2487 64.2998 76.6917 54.8926 61.157 96.5035 63.388 87.7598 73.7643 71.1697 45.1362 86.7227 77.2334 69.6296 75.0809 87.1629 65.6934 68.2667 71.1462 61.0837 63.7138 68.4932 53.7634 67.4157 80.4805 78.9744 55.0336 62.8821 70.5455 68.6347 72.6644 80.3059 62.6959 46.0705 79.1618 73.2824 62.069 73.4007 59.144 80.7818 62.7451 42.7184 60.1279 77.0344 79.7127 79.5181 81.5166 71.6049 66.0907 68.6869 66.6667 83.9117 47.6534 85.7143 80.8511 86.6359 69.7674 73.7151 53.2751 38.5185 71.3043 41.9162 79.0514 73.3427 71.68 62.5287 57.6369 57.7446 86.6995 88.1834 75.7202 74.9226 79.5181 66.6667 72.6592 52.9801 54.902 69.5082 55.6522 83.959 84.5361 60.7407 58.3942 73.7752 87.6235 75.7475 80.8625 66.055 60.7966 73.2106 88.8469 54.0351 75.7637 58.1363 26.3566 85.4111 69.3446 70.6016 72.5134 58.3569 72.6368 81.6143 61.1321 69.9725 57.971 59.6078 80.9107 66.4688 68.323 89.1954 48.1013 70.9677 55.9585 87.4237 57.4669 76.3636 88.586 77.686 59.2179 82.9604 65.2406 79.4953 69.6629 84.6047 83.5322 76.493 78.0021 82.0976 61.2529 50.9383 74.2857 63.2558 70.4516 69.7143 61.6541 78.7256 75.3117 78.4636 48.6486 66.1871 78.1726 83.5165 64 73.5516 71.3217 46.6019 60.9272 55.7823 46.1538 72.8745 76.8031 82.6131 81.8505 59.6195 77.5573 63.1016 70.9677 68.1992 63.0303 66.5012 72.6457 78.0781 66.2295 64.214 62.5698 31.5493 79.638 45.0704 73.8854 86.3436 69.7972 71.5667 64.6288 73.3668 55.1724 88.8073 51.1628 82.7109 75.763 77.8342 93.2874 45.614 65.2015 85.6361 42.8843 73.4082 38.2609 69.0909 68.1542 58.3979 60.2442 73.8824 53.012 78.6885 76.3307 79.0698 82.1192 75.817 48.2759 56.8889 76.4835 74.2857 72.5953 15.3846 78.2123 69.6774 62.1315 29.8755 44.6043 60.241 90.4348 55.814 76.0331 80.1061 44.9761 78.3158 61.5558 67.0807 60.155 63.3663 55.7746 77.3869 84.7605 61.6822 77.0149 83.6214 76.783 64.8464 44.9298 78.2609 73.5043 71.0183 69.7674 76.7507 83.5327 37.0044 38.5965 58.5209 78.3599 91.7431 67.9335 80.2589 72.6531 73.6544 71.6113 0 72.4896 64.2599 86.3222 81.4815 60.7029 73.2308 84.0855 80.6324 73.1893 68.5121 49.7512 87.395 74.8011 70.1887 63.9004 66.6667 53.6313 79.868 72.4638 66.6667 81.4815 74.9491 60.8059 72.5359 58.5956 74.0157 82.0189 72.2936 50.4202 80.3987 70.5882 71.5152 85.9358 91.2941 67.2811 64.6154 69.1244 73.9082 79.7853 75.0462 76.6091 56.2588 64.1711 44.4444 79.1966 75.4947 73.0463 74.6082 49.5726 19.0476 82.2888 91.6821 69.0909 72.7273 84.3403 36.019 85.8351 75.3247 36.6925 73.0627 44.7552 90.1454 89.5662 73.6842 74.0638 70.6223 69.2015 69.4737 83.682 79.4494 56 63.7363 57.9088 62.3423 67.0143 51.735 65.3951 58.5608 73.7463 63.3766 69.8912 83.7341 64.8575 78.51 72.5076 77.4194 83.2952 81.0811 65.0888 66.3073 44.1315 49.5522 72.9097 70.4225 83.4568 77.4026 49.5238 51.5315 61.7886 88.2883 64.4898 77.898 56.6308 61.5917 63.4561 84.3206 65.7277 78.4906 24 73.9884 78.2077 76.7347 75.3138 61.1973 55.3191 75.0594 58.5752 61.5385 76.8879 90.0901 80.5009 4.44444 74.3363 65.5518 88.198 66.0333 70.4453 64.6288 81.0289 73.2861 33.6842 66.838 73.4531 69.2841 73.2203 72.7273 73.1707 77.551 59.6859 69.1643 52.9968 79.3741 70.6747 82.3001 47.3868 64.0777 79.1802 74.8299 76.6571 79.3388 68.2809 82.0513 74.2268 63.5583 65.4867 76.1155 72.693 60.8997 76.681 78.6787 86.6545 78.0059 44.3381 78.0856 47.9638 62.8931 63.6872 89.0566 56.9343 72.3305 82.7586 59.8131 67.8146 71.9335 76.7123 83.7772 78.0627 63.6943 59.4595 74.9556 75.6184 78.3505 79.3017 77.5244 87.3118 53.3333 72.4832 86.3336 69.3539 25.2632 70.8661 76.4526 39.0244 3.38983 10.6667 80 48.7805 43.5262 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 0.864348 (Xent), [AvgXent: 0.864348, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 75.7204% <<

