nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.004 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter03_learnrate0.008_tr1.3399_cv2.2283 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter05 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975062
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.2475, max 7.77538, mean -0.00464958, stddev 0.983373, skewness 0.0162194, kurtosis 1.92828 ) 
[1] output of <AffineTransform> ( min -28.2023, max 21.7695, mean -3.28609, stddev 3.71516, skewness 0.156913, kurtosis 1.39952 ) 
[2] output of <Sigmoid> ( min 5.64812e-13, max 1, mean 0.193596, stddev 0.30046, skewness 1.60836, kurtosis 1.19873 ) 
[3] output of <AffineTransform> ( min -29.4657, max 16.2737, mean -4.01821, stddev 2.7741, skewness -0.0355755, kurtosis 2.4601 ) 
[4] output of <Sigmoid> ( min 1.59672e-13, max 1, mean 0.0988107, stddev 0.195953, skewness 2.90452, kurtosis 8.25238 ) 
[5] output of <AffineTransform> ( min -15.1931, max 11.6232, mean -3.21109, stddev 2.01661, skewness 0.632869, kurtosis 2.50027 ) 
[6] output of <Sigmoid> ( min 2.52183e-07, max 0.999991, mean 0.109219, stddev 0.190241, skewness 2.84203, kurtosis 8.1035 ) 
[7] output of <AffineTransform> ( min -23.7975, max 15.985, mean -2.97385, stddev 2.28183, skewness 0.61939, kurtosis 3.23422 ) 
[8] output of <Sigmoid> ( min 4.62232e-11, max 1, mean 0.139054, stddev 0.225584, skewness 2.29115, kurtosis 4.60343 ) 
[9] output of <AffineTransform> ( min -16.5928, max 16.8006, mean -2.93561, stddev 2.75771, skewness 1.39577, kurtosis 2.97885 ) 
[10] output of <Sigmoid> ( min 6.22075e-08, max 1, mean 0.164333, stddev 0.28052, skewness 1.92564, kurtosis 2.40323 ) 
[11] output of <AffineTransform> ( min -32.1376, max 19.0679, mean -3.68332, stddev 3.38845, skewness 1.00739, kurtosis 3.46523 ) 
[12] output of <Sigmoid> ( min 1.10357e-14, max 1, mean 0.140415, stddev 0.283323, skewness 2.16746, kurtosis 3.23377 ) 
[13] output of <AffineTransform> ( min -12.5821, max 20.1727, mean -0.00744548, stddev 3.15134, skewness 0.603926, kurtosis 1.1439 ) 
[14] output of <Softmax> ( min 7.27244e-14, max 0.997729, mean 0.000624902, stddev 0.016293, skewness 41.1699, kurtosis 1922.06 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.829166, max 1.1867, mean -0.000101746, stddev 0.0477076, skewness 0.174574, kurtosis 17.3423 ) 
[1] diff-output of <AffineTransform> ( min -0.304955, max 0.27424, mean 5.0096e-05, stddev 0.00907984, skewness 0.474107, kurtosis 58.3661 ) 
[2] diff-output of <Sigmoid> ( min -1.32318, max 1.30153, mean 8.9797e-05, stddev 0.0795198, skewness 0.165654, kurtosis 11.1355 ) 
[3] diff-output of <AffineTransform> ( min -0.248441, max 0.321451, mean 5.52419e-05, stddev 0.00986306, skewness 0.44697, kurtosis 66.1948 ) 
[4] diff-output of <Sigmoid> ( min -1.5056, max 1.33111, mean -0.000175743, stddev 0.102274, skewness -0.0125979, kurtosis 8.37409 ) 
[5] diff-output of <AffineTransform> ( min -0.244767, max 0.258984, mean 8.62501e-05, stddev 0.0102546, skewness 0.434426, kurtosis 50.0575 ) 
[6] diff-output of <Sigmoid> ( min -1.2947, max 1.52573, mean 0.000562883, stddev 0.0902392, skewness 0.0730319, kurtosis 9.74257 ) 
[7] diff-output of <AffineTransform> ( min -0.173273, max 0.288919, mean 6.34328e-05, stddev 0.00894383, skewness 0.455257, kurtosis 41.1651 ) 
[8] diff-output of <Sigmoid> ( min -0.795152, max 1.16631, mean 0.000244054, stddev 0.069442, skewness 0.0268628, kurtosis 9.32172 ) 
[9] diff-output of <AffineTransform> ( min -0.18844, max 0.18835, mean 4.85971e-05, stddev 0.0070798, skewness 0.0869514, kurtosis 43.5503 ) 
[10] diff-output of <Sigmoid> ( min -0.839505, max 0.93358, mean 0.000185326, stddev 0.0547379, skewness -0.0360384, kurtosis 12.2592 ) 
[11] diff-output of <AffineTransform> ( min -0.327696, max 0.212116, mean 7.44913e-05, stddev 0.00834032, skewness -0.144672, kurtosis 59.6604 ) 
[12] diff-output of <Sigmoid> ( min -1.79539, max 1.15654, mean 0.000877987, stddev 0.0911463, skewness -0.0686267, kurtosis 5.22124 ) 
[13] diff-output of <AffineTransform> ( min -0.99996, max 0.894756, mean -8.13685e-09, stddev 0.0190536, skewness -25.8817, kurtosis 1699.17 ) 
[14] diff-output of <Softmax> ( min -0.99996, max 0.894756, mean -8.13685e-09, stddev 0.0190536, skewness -25.8817, kurtosis 1699.17 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.22818, max 1.52512, mean -0.00130199, stddev 0.140249, skewness -0.0032997, kurtosis 2.3832 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.634737, max 0.554115, mean 0.0128245, stddev 0.15409, skewness -0.0219375, kurtosis 1.06491 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.839618, max 0.990373, mean 0.00253943, stddev 0.056581, skewness 0.130854, kurtosis 7.54608 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.799298, max 1.09353, mean 0.0141419, stddev 0.164077, skewness 0.164073, kurtosis 3.26809 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.590141, max 0.733056, mean 0.00217221, stddev 0.0360485, skewness 0.461146, kurtosis 12.2484 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.644441, max 0.987564, mean 0.02208, stddev 0.170413, skewness 0.367976, kurtosis 2.32418 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.56745, max 0.490037, mean 0.00178256, stddev 0.0321648, skewness 0.377881, kurtosis 10.5442 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.628775, max 0.855135, mean 0.0162388, stddev 0.153471, skewness 0.203522, kurtosis 2.28457 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.426691, max 0.395512, mean 0.0016974, stddev 0.0308344, skewness 0.286588, kurtosis 8.74676 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.425886, max 0.563617, mean 0.0124407, stddev 0.120127, skewness 0.318459, kurtosis 2.53983 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.493667, max 0.541298, mean 0.00333421, stddev 0.0426951, skewness 0.449603, kurtosis 8.21192 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.529591, max 0.480652, mean 0.0190697, stddev 0.12755, skewness 0.215136, kurtosis 2.04145 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -3.52163, max 2.29394, mean -8.33163e-08, stddev 0.10324, skewness -4.96023, kurtosis 89.2252 ) , lr-coef 1, max-norm 0
  bias_grad ( min -3.45862, max 1.82094, mean -7.89762e-09, stddev 0.33663, skewness -2.18837, kurtosis 16.7355 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 338432 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.50193, max 6.77601, mean -0.00405738, stddev 0.997423, skewness -0.00626004, kurtosis 2.0657 ) 
[1] output of <AffineTransform> ( min -30.6329, max 19.786, mean -3.29356, stddev 3.81848, skewness 0.119996, kurtosis 1.34268 ) 
[2] output of <Sigmoid> ( min 4.9693e-14, max 1, mean 0.198262, stddev 0.305049, skewness 1.56564, kurtosis 1.03797 ) 
[3] output of <AffineTransform> ( min -33.9243, max 16.5883, mean -3.99839, stddev 2.77586, skewness -0.0912527, kurtosis 2.40293 ) 
[4] output of <Sigmoid> ( min 1.84873e-15, max 1, mean 0.100197, stddev 0.196579, skewness 2.86405, kurtosis 8.00413 ) 
[5] output of <AffineTransform> ( min -14.9022, max 12.5248, mean -3.16484, stddev 2.02427, skewness 0.584186, kurtosis 2.34854 ) 
[6] output of <Sigmoid> ( min 3.37323e-07, max 0.999996, mean 0.112872, stddev 0.192467, skewness 2.75732, kurtosis 7.56814 ) 
[7] output of <AffineTransform> ( min -23.6053, max 15.9668, mean -2.88623, stddev 2.32481, skewness 0.569225, kurtosis 2.88704 ) 
[8] output of <Sigmoid> ( min 5.60192e-11, max 1, mean 0.149081, stddev 0.233384, skewness 2.13745, kurtosis 3.82941 ) 
[9] output of <AffineTransform> ( min -16.6557, max 16.8, mean -2.85341, stddev 2.86751, skewness 1.34331, kurtosis 2.69432 ) 
[10] output of <Sigmoid> ( min 5.84121e-08, max 1, mean 0.175688, stddev 0.290869, skewness 1.80002, kurtosis 1.8769 ) 
[11] output of <AffineTransform> ( min -30.3428, max 19.5512, mean -3.60217, stddev 3.54335, skewness 1.01473, kurtosis 3.21004 ) 
[12] output of <Sigmoid> ( min 6.64155e-14, max 1, mean 0.15119, stddev 0.295524, skewness 2.02758, kurtosis 2.58478 ) 
[13] output of <AffineTransform> ( min -13.777, max 20.1528, mean -0.0133875, stddev 3.38498, skewness 0.526407, kurtosis 0.93639 ) 
[14] output of <Softmax> ( min 1.07848e-14, max 0.992875, mean 0.000624918, stddev 0.0183264, skewness 41.2385, kurtosis 1835.51 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.94544, max 0.791466, mean -0.00047832, stddev 0.0378302, skewness -1.64864, kurtosis 92.3215 ) 
[1] diff-output of <AffineTransform> ( min -0.584559, max 0.2107, mean -7.1307e-06, stddev 0.00719344, skewness -2.10304, kurtosis 237.864 ) 
[2] diff-output of <Sigmoid> ( min -2.34594, max 1.19841, mean -0.000202406, stddev 0.0632158, skewness -0.539529, kurtosis 32.4789 ) 
[3] diff-output of <AffineTransform> ( min -0.389741, max 0.403364, mean -3.52023e-05, stddev 0.00779473, skewness -0.135216, kurtosis 142.547 ) 
[4] diff-output of <Sigmoid> ( min -2.03351, max 1.70619, mean 0.000164625, stddev 0.0819483, skewness -0.037633, kurtosis 16.4242 ) 
[5] diff-output of <AffineTransform> ( min -0.435306, max 0.231302, mean -6.34727e-05, stddev 0.0080958, skewness -0.903092, kurtosis 95.6205 ) 
[6] diff-output of <Sigmoid> ( min -1.79385, max 1.13018, mean -0.000323546, stddev 0.0714738, skewness -0.105394, kurtosis 14.89 ) 
[7] diff-output of <AffineTransform> ( min -0.159234, max 0.223969, mean -4.99094e-05, stddev 0.00697611, skewness 0.0664892, kurtosis 53.6398 ) 
[8] diff-output of <Sigmoid> ( min -0.918507, max 0.895877, mean -0.000251008, stddev 0.0532178, skewness -0.0264725, kurtosis 13.1623 ) 
[9] diff-output of <AffineTransform> ( min -0.132378, max 0.128291, mean -3.46211e-05, stddev 0.00539852, skewness -0.287314, kurtosis 47.9799 ) 
[10] diff-output of <Sigmoid> ( min -0.780957, max 0.630185, mean -3.3674e-05, stddev 0.041944, skewness -0.120531, kurtosis 16.1731 ) 
[11] diff-output of <AffineTransform> ( min -0.193544, max 0.214568, mean -2.22866e-05, stddev 0.00639767, skewness -0.297031, kurtosis 62.834 ) 
[12] diff-output of <Sigmoid> ( min -1.00102, max 0.882061, mean -8.99016e-05, stddev 0.0692322, skewness -0.0999282, kurtosis 7.21379 ) 
[13] diff-output of <AffineTransform> ( min -0.999919, max 0.859543, mean -6.07339e-09, stddev 0.0143201, skewness -32.577, kurtosis 2581.07 ) 
[14] diff-output of <Softmax> ( min -0.999919, max 0.859543, mean -6.07339e-09, stddev 0.0143201, skewness -32.577, kurtosis 2581.07 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -2.25369, max 2.84107, mean -0.000662213, stddev 0.113909, skewness 0.0589384, kurtosis 8.04578 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.481401, max 0.526732, mean -0.00182547, stddev 0.122537, skewness 0.169993, kurtosis 0.652376 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.680641, max 0.836549, mean -0.00192809, stddev 0.0464687, skewness 0.0843473, kurtosis 9.23122 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.625657, max 0.730649, mean -0.00901178, stddev 0.133103, skewness 0.153396, kurtosis 2.28087 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.573531, max 0.5492, mean -0.00175276, stddev 0.0306155, skewness -0.428205, kurtosis 14.8358 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.728164, max 0.718967, mean -0.016249, stddev 0.151163, skewness -0.0472155, kurtosis 2.17764 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.433962, max 0.601691, mean -0.00145037, stddev 0.0265317, skewness -0.00883198, kurtosis 11.3953 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.556762, max 0.54182, mean -0.0127768, stddev 0.129755, skewness 0.0773261, kurtosis 2.30897 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.32215, max 0.288496, mean -0.00132562, stddev 0.0250148, skewness -0.245928, kurtosis 8.76561 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.598882, max 0.459661, mean -0.00886302, stddev 0.095288, skewness -0.404465, kurtosis 4.3706 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.468676, max 0.356831, mean -0.00073756, stddev 0.035662, skewness -0.242203, kurtosis 8.0687 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.425117, max 0.462127, mean -0.00570536, stddev 0.107961, skewness -0.127619, kurtosis 1.91464 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -1.68863, max 1.23808, mean -1.70474e-08, stddev 0.0770985, skewness -5.13065, kurtosis 79.2983 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.67204, max 1.24029, mean -3.57628e-09, stddev 0.226099, skewness -1.86263, kurtosis 10.2149 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0779254 min, processing 72383.8 frames per sec; i/o time 5.15964%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14106 318 182 101 16 23 147 394 174 74 294 47 870 141 67 129 255 114 165 74 149 213 181 183 408 103 94 245 56 199 233 219 209 78 485 234 501 261 303 129 32 34 202 163 535 145 178 160 16656 5473 1407 385 440 102 243 122 303 118 380 0 107 271 58 97 93 86 243 57 294 191 144 415 282 143 874 110 864 152 49 13 569 154 448 222 342 20 710 155 141 68 76 139 255 166 278 70 165 257 182 92 99 60 29 327 272 85 199 196 15 111 124 263 142 460 128 77 124 98 17 288 88 277 175 145 85 235 203 106 16 130 103 96 261 105 225 47 654 102 126 63 230 68 627 94 106 150 211 42 124 289 144 100 161 98 300 136 229 44 206 11 193 224 432 114 59 162 165 82 201 60 143 259 59 211 112 0 74 325 188 0 308 89 60 48 267 60 114 213 217 233 69 84 34 171 117 241 110 199 148 224 208 100 318 174 185 100 39 85 279 178 263 182 189 160 112 158 150 96 122 83 71 465 110 243 156 322 191 131 401 380 136 112 84 62 69 94 171 202 164 237 323 105 117 1041 218 21 103 173 175 146 274 69 106 143 83 59 358 320 29 312 180 310 237 470 549 136 85 158 80 245 175 26 156 156 198 132 23 84 27 70 350 301 265 162 4 208 159 83 111 119 62 231 365 304 54 85 79 76 168 163 124 705 189 106 48 121 19 123 117 137 169 141 132 456 113 108 147 127 25 491 355 389 168 188 199 87 83 96 64 68 88 197 54 111 190 205 366 44 139 111 166 116 142 17 246 129 132 136 118 101 283 141 319 231 267 110 156 104 38 203 22 154 518 287 30 115 144 23 375 214 888 167 91 50 151 941 147 529 88 198 86 42 20 103 215 7 131 37 106 81 22 12 221 160 126 219 148 121 262 96 292 133 232 397 251 83 68 117 120 105 280 174 760 20 61 190 113 277 70 233 90 65 10 85 200 246 146 190 262 32 169 140 133 203 48 20 191 113 261 70 14 67 149 131 195 140 173 225 118 142 479 20 65 121 644 103 272 567 0 296 110 125 160 72 193 209 23 154 136 123 42 101 71 350 71 132 225 118 52 133 131 151 84 16 351 136 37 102 80 155 336 499 610 12 156 207 219 45 193 336 298 26 79 88 241 108 284 67 113 217 108 268 207 177 338 0 305 120 149 24 75 211 69 271 255 39 24 38 172 143 166 104 74 156 223 90 72 29 82 110 165 110 21 127 56 70 231 501 270 74 7 137 123 314 232 395 203 187 41 160 122 17 81 166 128 40 126 167 271 254 173 133 146 338 236 381 113 188 153 16 31 122 164 152 22 403 94 16 266 540 9 424 185 271 152 51 169 517 345 194 95 131 53 165 217 206 266 69 37 89 10 229 185 91 95 46 196 393 238 61 98 65 90 158 275 81 102 141 157 238 200 153 34 93 114 536 130 350 119 108 80 155 62 182 91 71 357 98 68 287 22 338 165 148 65 150 43 19 475 257 27 112 101 300 81 75 49 62 166 121 115 96 155 149 114 163 60 77 150 33 195 123 137 225 13 96 1 371 772 359 185 304 20 19 266 123 818 63 1086 46 67 11 30 81 10 43 201 243 244 188 190 152 28 79 20 11 286 81 50 67 51 394 74 59 133 106 100 187 12 118 214 93 178 180 230 63 181 177 200 223 108 128 194 131 308 105 338 145 9 47 366 206 283 41 270 145 334 161 60 200 224 66 501 255 295 186 156 187 52 224 200 154 11 230 236 109 237 192 144 232 96 14 257 201 241 13 135 54 40 360 65 120 202 78 92 300 194 309 191 175 92 336 191 76 30 198 155 34 242 103 151 159 81 34 239 79 193 187 894 389 136 108 191 100 92 356 115 212 250 415 139 101 304 13 96 177 271 105 284 17 199 129 1 184 412 238 105 621 144 87 465 395 487 106 311 221 12 120 85 137 17 153 113 92 58 238 214 264 478 417 92 505 132 126 271 46 78 163 182 80 434 59 158 155 94 295 460 167 110 239 370 337 231 178 243 94 209 244 6 572 148 133 853 101 140 298 137 110 210 495 597 87 244 98 307 351 125 50 122 130 203 116 71 317 281 439 117 229 237 160 74 14 68 0 179 352 232 39 133 161 95 239 159 52 55 475 149 208 139 238 143 13 107 166 174 77 63 265 134 130 27 75 250 167 217 98 105 107 7 35 22 33 161 244 236 88 96 74 173 431 163 277 184 154 69 301 65 155 55 235 28 214 170 218 43 55 187 121 171 187 83 253 141 91 98 50 139 63 314 513 250 377 20 20 151 50 93 210 102 8 75 294 127 188 138 219 387 206 58 42 144 160 500 297 122 109 157 150 293 122 184 135 454 256 639 430 514 276 260 11 205 603 30 294 400 314 275 1369 13 135 174 545 623 167 212 18 228 189 8 269 378 188 368 54 407 110 66 152 72 182 17 70 15 364 187 435 117 417 215 453 278 238 307 229 170 222 514 1659 385 27 29 135 197 165 95 257 265 225 234 324 927 460 300 79 209 290 73 105 104 301 57 72 71 288 277 257 196 163 88 149 159 249 147 133 209 222 383 280 233 81 385 205 66 221 90 97 206 21 51 102 157 112 55 247 289 199 94 253 66 209 60 71 91 216 394 303 128 297 867 202 154 463 68 187 379 101 293 182 46 44 166 97 74 114 137 135 144 261 159 184 429 65 188 148 128 153 25 51 234 276 278 124 105 40 231 49 271 475 138 472 70 108 64 340 343 67 57 83 126 354 312 217 173 1139 101 283 121 161 41 25 133 75 25 152 172 146 145 67 68 173 860 150 185 54 238 244 264 142 245 359 64 188 236 440 467 176 100 111 397 181 34 127 285 168 80 217 39 170 96 409 264 27 293 60 89 290 93 158 44 360 209 393 470 276 215 186 17 107 387 87 199 486 200 364 92 208 98 45 112 198 200 51 75 73 84 123 256 497 140 236 327 93 108 130 82 201 557 166 152 149 89 177 110 106 78 340 468 258 114 99 72 272 150 361 278 295 290 28 136 365 263 133 172 27 246 193 368 212 124 30 441 21 75 76 130 112 227 87 275 45 268 77 220 120 69 290 57 21 181 188 104 237 443 402 322 50 177 99 344 374 167 607 329 146 320 241 58 191 64 178 543 113 28 155 219 163 210 154 367 176 195 1 841 138 164 67 156 162 210 126 393 144 100 416 188 132 120 202 89 151 241 532 67 245 136 522 206 63 792 272 178 150 161 82 451 1062 108 97 108 446 279 270 318 355 93 76 348 328 313 159 58 10 183 270 82 159 405 105 236 115 193 135 71 309 426 85 360 345 394 142 119 508 112 227 186 277 383 158 183 201 169 192 413 353 368 174 165 139 218 129 84 185 106 167 149 106 202 192 52 277 184 277 122 323 139 144 176 143 106 132 12 86 245 122 119 225 70 210 189 188 218 55 279 22 282 149 868 210 123 114 155 211 47 194 250 216 147 82 225 171 95 173 158 351 748 556 143 154 463 220 173 181 206 19 145 407 56 190 265 144 349 166 273 170 313 198 110 79 89 397 68 641 130 53 377 240 109 206 175 235 18 281 141 48 200 153 232 127 223 530 843 47 63 163 102 29 37 47 20 181 ]
@@@ Loss per-class: [ 0.464803 1.38686 0.736167 1.27317 1.66042 1.9318 1.83385 0.732427 0.956762 1.73658 0.45672 2.22561 0.580779 0.877947 2.29623 0.910791 1.01427 0.99099 1.22834 1.55706 0.933096 0.893704 1.09875 1.18997 1.44636 0.88043 1.63673 0.720898 1.42139 0.727906 1.47482 0.908023 1.17309 1.23432 0.511097 0.528127 0.35436 0.252806 0.740908 1.50803 1.5318 0.671136 0.716408 1.10538 0.386914 0.865428 0.951741 1.11644 0.346459 0.772242 0.790256 0.601253 0.406681 2.15217 0.893202 1.27135 0.681464 1.07813 1.03033 0 1.21276 0.767286 2.95655 1.36264 1.5571 1.04904 0.854528 0.937125 0.952199 0.659853 1.2333 0.942782 0.758965 0.552664 0.414871 1.96298 0.279545 1.12007 1.05983 2.3431 0.977174 0.721212 0.631441 0.914188 0.945539 0.966036 0.977358 0.932462 0.969958 1.00416 1.26138 0.656957 0.582852 1.53955 0.843888 1.81838 1.61586 0.799509 0.784561 1.04255 0.764834 1.24561 1.56124 0.648391 1.00407 0.690385 1.09255 0.681197 2.63915 0.690619 1.00496 0.476569 1.63659 0.553638 2.28308 1.31811 1.65457 0.93999 1.47657 1.02872 1.26468 0.875737 1.19036 1.24872 0.608156 0.87817 1.19912 0.975118 2.01053 1.31135 1.80888 0.975121 1.30612 1.51934 1.34073 1.01702 0.625623 1.46263 1.67682 1.34337 1.32663 1.55059 0.573576 2.00028 1.01717 1.09708 1.19004 1.10742 1.04097 0.873288 0.777468 1.01896 1.36019 0.898535 0.937835 0.753139 0.701422 1.514 0.658004 1.57962 0.759204 0.684329 1.19877 1.28555 1.38607 1.5552 1.45452 1.44817 1.55943 0.92166 0.672364 0.87534 1.00062 1.29947 1.03384 0 1.56884 0.991585 0.633016 0 1.66338 0.912214 0.790616 1.21093 1.34265 1.20757 0.646129 1.41462 1.25786 0.233749 1.1135 1.43914 1.01494 0.682322 1.28431 0.824825 0.9348 1.41269 0.992423 0.807793 1.37621 2.0731 0.589581 1.65724 1.35512 0.920636 1.50505 1.39276 1.19294 0.726338 0.981657 1.19409 1.01261 0.691969 1.64577 0.719553 2.23052 1.36756 1.26961 1.25641 1.47274 1.18182 1.44794 1.42342 0.733512 0.779225 1.44935 0.902078 0.61761 0.58089 1.06336 0.759529 2.17224 0.782722 0.508148 2.03795 1.21276 0.910745 1.22317 1.04777 1.62491 0.953356 0.665652 0.650474 0.65309 6.16532 2.61027 1.48325 2.4302 2.12612 1.31457 1.24904 1.18989 1.45209 1.40586 1.38138 1.10077 0.941268 1.13453 0.502825 0.358944 1.42775 1.92991 0.604976 0.733115 0.856238 0.757481 1.18776 1.3322 0.908104 1.10944 0.605683 1.29894 0.926194 2.49093 1.80381 0.871222 1.73023 1.19868 1.11073 0.63935 1.63704 1.88152 0.691174 5.7019 1.66972 1.0442 1.81988 1.20073 0.887957 1.22964 1.12582 0.83294 1.05013 1.96976 1.33848 1.25743 1.11362 0.976278 0.465861 1.10306 0.783956 1.47367 1.31648 1.16974 1.61199 2.00065 3.10883 1.15958 0.933562 0.688292 1.56335 1.05175 1.31675 1.68553 0.801759 1.34133 1.41352 1.33935 1.2092 0.722917 0.570627 0.839386 1.19739 0.924919 1.03178 1.13457 0.849114 1.57753 1.41237 0.939777 0.677042 1.6528 0.815401 0.914075 0.88386 0.902273 2.0123 1.56171 1.70351 0.715969 1.23328 0.846331 3.04452 0.906215 1.85561 1.94695 0.969251 2.03871 1.52613 0.884049 0.5481 1.06196 0.780963 1.01155 1.12125 0.533326 0.866374 1.51846 1.3526 1.7944 1.33341 0.677469 1.20985 1.09102 1.03948 2.37851 2.56815 1.29472 0.808908 0.905448 1.01169 1.24209 1.24423 1.47074 0.746515 1.42281 0.567376 2.74516 1.23095 1.95747 0.527601 1.27263 0.812418 1.79627 5.38189 1.44785 1.09413 0.732396 1.78696 2.13576 1.86852 1.03979 1.41214 0.684372 0.630464 0.795209 1.31942 2.2522 0.829973 0.835871 1.30909 0.952441 1.02961 1.2945 2.40634 0.962459 1.42806 1.21023 1.27418 1.9502 1.11041 0.715646 1.56481 1.2041 1.9047 1.00358 1.98573 1.44215 0.614331 1.01634 1.75861 2.34384 1.89286 1.16051 1.03899 0.808345 1.31061 1.6606 1.83539 1.5088 1.08383 2.6397 1.19382 1.60057 2.17012 1.35772 0.665645 0.993125 1.43606 1.59654 0.982368 1.96573 0.798505 1.01791 1.04388 1.82695 1.26446 1.55103 0.86306 0.901169 1.59289 1.34238 0.857902 0.695738 1.92861 0.71179 0.609228 0 1.47574 1.2431 1.28015 0.988658 1.68539 1.04417 1.1571 0.818233 0.991433 1.08344 1.02698 2.6733 1.71403 1.62529 0.894866 1.53741 1.34253 1.34953 1.15401 1.14152 0.933566 1.10012 0.819388 1.67878 2.26189 0.462627 1.91838 1.62725 2.30433 1.37479 1.43537 1.50161 0.62609 0.738359 2.8165 0.58322 1.65399 1.42542 2.03311 2.10848 1.65874 1.20861 1.24598 0.604436 1.10616 1.15242 0.8026 1.03564 1.82613 1.48481 1.27232 1.07408 1.16089 1.65048 2.13988 1.10346 0 1.09892 2.74221 0.761078 0.888351 1.70677 1.04854 0.879817 1.19816 0.472114 1.46431 1.07432 1.21103 1.2827 1.36544 1.39076 1.30142 1.37794 2.3625 1.51208 0.746895 0.973124 1.05109 1.87742 0.962294 0.943704 1.81102 1.62398 1.06859 1.47169 0.853165 1.29633 0.810555 1.34556 1.74767 4.45003 1.75586 0.793553 1.03757 1.00237 0.461639 1.11518 1.84318 2.09959 1.0597 0.649889 1.79705 1.27318 1.12531 1.43423 1.24022 1.19037 0.796894 1.05582 1.20096 1.35316 1.36475 0.921276 0.688991 0.889105 1.53729 1.87046 1.06214 1.64851 3.73909 1.18078 1.0461 0.671304 0.680582 1.47657 0.488876 1.55098 1.9319 1.10402 1.44402 2.81352 0.873691 0.716139 1.59557 0.7562 2.15861 0.912665 1.16343 1.10426 1.44835 0.85163 1.2153 1.47735 1.61054 1.43778 0.993407 1.33223 1.72268 1.58912 0.997077 3.31248 1.10553 1.35959 1.20882 1.53636 2.26579 1.35379 0.867132 1.04486 0.999374 1.47503 1.37317 1.21603 1.00331 0.850358 1.72482 1.5191 1.76154 0.76183 1.55766 1.65347 1.25357 1.69797 1.48995 1.06033 0.710964 1.45335 1.38864 1.47543 1.83295 0.701222 0.777674 2.76744 1.3994 1.74743 2.2102 0.894342 1.28351 1.97008 0.888388 1.83625 1.19769 0.898246 1.53957 1.28417 2.03709 2.11603 1.77828 1.48799 1.40203 0.683049 1.13434 1.0096 0.926839 1.65042 1.26557 2.31992 1.2417 1.09966 1.06856 0.737786 1.50634 1.06174 0.893712 2.58715 1.77698 1.06926 1.00334 1.75278 0.933171 0.69598 1.703 1.6942 0.911577 4.03825 2.29087 10.9181 1.71738 0.676877 0.395026 0.736428 1.44324 2.16163 2.27697 1.2004 0.800758 1.09257 0.847518 0.771482 1.64063 1.60943 3.4958 1.29109 1.48983 4.15136 1.77612 1.14881 1.4201 1.3312 0.708868 0.600874 1.84687 2.31262 1.45795 1.26435 4.47201 1.37884 1.22234 1.03224 2.23115 1.56287 1.05497 3.76646 1.66279 0.818052 1.86394 1.81872 0.707363 2.81233 1.04821 0.784103 1.78416 1.60491 1.24798 1.50196 1.35217 1.73653 0.99514 1.29536 1.22218 0.733842 1.39452 1.1258 2.47526 0.932427 1.17914 0.89178 0.755855 2.51731 1.15918 0.955349 0.967422 1.27081 0.977566 1.59217 1.09563 0.980449 1.46662 1.33777 0.74803 1.28991 1.80195 0.872051 1.11211 1.57825 1.80054 0.809129 0.836701 1.07952 1.62527 1.50004 1.11445 3.49056 0.888838 1.0788 1.26999 1.22041 1.57254 1.52471 0.735626 0.978482 2.1102 0.99037 0.825722 1.06664 1.12702 1.5576 1.99757 1.80117 0.950669 1.0327 1.67792 1.46828 2.04906 1.8984 1.09055 0.525887 0.746862 1.37699 0.937213 1.78921 1.00871 0.757498 1.26562 1.19459 0.534285 0.996799 1.19115 1.55154 1.55764 1.36736 1.53022 0.891296 1.6145 1.21012 1.62141 1.12624 1.42938 1.24478 0.56302 1.45936 1.47983 1.45796 2.04816 1.91718 1.18166 0.892045 0.889507 0.64088 0.672013 1.55668 1.59371 1.33032 2.61918 1.32062 1.13898 1.20722 1.70276 0.980788 1.65528 0.931536 1.90192 8.5724 1.09763 0.798216 0.834778 1.85726 0.70674 1.57283 1.37218 0.582803 1.05813 0.793205 1.1487 1.2511 1.03389 2.41884 1.72182 1.39747 0.987259 2.50895 0.915063 1.2659 2.19857 1.29118 0.901371 3.2155 0.762253 0.726608 0.674402 1.74505 1.12715 1.39313 1.11321 1.60474 1.61124 1.55252 1.17705 1.52409 2.20607 1.05356 0.75694 1.25742 1.06118 1.36272 0.839499 1.35983 1.65017 1.27366 0.718402 0.651214 0.863916 0.890146 0.811886 0.781552 0.953 0.982675 1.53385 3.84908 0.684017 0.893517 1.66677 0.810669 0.974999 1.32968 1.04631 1.32885 1.01543 0.69001 0.959401 1.13772 1.73017 0.893626 1.45483 1.34205 0.94584 1.55446 2.30428 1.77557 1.72134 0.549609 1.28052 1.25164 1.16506 1.93243 0.928748 1.77278 2.12756 1.33275 1.4984 1.06767 2.09665 1.51094 0 1.71488 0.892047 0.869061 0.913179 1.38731 0.950213 1.16462 0.753583 1.66744 2.82508 2.67127 0.824713 2.02961 1.00112 2.49739 1.12578 1.41456 2.6174 1.73855 1.02673 1.60477 2.35689 1.6051 1.10355 1.77868 1.10242 0.889331 2.05388 0.857349 1.64515 1.56465 1.45004 1.07655 1.08508 4.11911 1.69865 1.18256 0.774583 1.16641 1.0222 0.91254 1.56289 1.37017 2.02116 1.33081 0.93679 1.23198 0.640135 1.68543 1.44399 1.19049 1.24982 1.19687 1.39021 1.11117 1.13442 1.68063 1.36989 0.7303 0.822355 2.64863 1.91367 1.72635 1.20852 1.65836 1.62112 1.54772 1.30871 1.08675 1.40044 0.807114 1.6628 2.73348 3.68118 1.11095 0.992947 1.60852 1.35694 1.36826 2.08883 1.14418 3.05915 1.61354 1.32099 1.86458 1.15312 1.49761 1.01718 1.52985 1.45189 1.65996 0.72968 1.51811 0.666041 2.08359 2.69726 1.86056 3.6403 1.01521 0.865909 1.55404 1.42415 1.09543 1.05287 0.716129 1.17029 1.19009 1.45975 0.687377 0.825938 1.56488 1.5381 1.52627 1.65549 0.960654 1.73115 0.995125 0.668084 2.59041 1.6313 1.58692 0.664229 1.11082 0.761183 2.63441 1.41582 1.02166 1.35424 0.755222 0.912018 1.12178 2.81248 1.07904 2.15005 2.85621 0.562355 0.799802 2.32831 0.87552 1.62231 1.7213 0.77472 1.6811 0.977093 1.8562 2.08363 1.56905 1.9801 0.892508 0.4967 1.11359 0.849857 1.65222 0.845314 1.60145 0.848309 0.769702 1.07439 1.26308 1.35766 2.54917 0.881968 0.921315 0.774828 0.953423 2.56514 1.39227 1.11919 1.13764 0.905138 1.88418 1.93001 1.218 1.34829 1.36084 1.22868 0.599959 1.26257 1.20505 2.16055 1.55745 1.15104 1.69344 0.804321 1.58847 1.24663 1.27847 0.799011 1.14579 1.67178 1.40525 1.78355 1.71785 2.73877 1.15933 1.10073 1.95436 0.709973 1.04414 2.17503 2.27263 1.94284 0.888783 1.00993 1.1025 1.22788 1.19851 1.01805 1.69172 0.801336 1.69612 0.538111 1.05897 2.23245 3.35797 3.20185 1.52609 2.40782 1.44048 1.21337 0.987208 2.05378 1.16452 1.82255 1.02158 2.3202 1.4817 0.860139 1.57192 0.59924 1.10277 1.21229 1.85977 0.613846 0.938168 1.49311 1.23056 0.718733 1.29955 1.08506 1.14675 1.96229 1.59305 1.28696 1.7701 1.5313 0.894147 1.02313 1.40491 1.42723 1.28973 1.30046 1.26664 1.0132 1.46471 2.07729 0.843584 1.39883 1.44413 1.40515 1.73753 0.961558 1.61406 2.19865 1.70945 1.11312 1.10855 1.047 1.18832 1.46299 1.38874 1.21123 1.38526 0.834765 2.09038 0.70342 1.11505 0.691534 1.17107 1.07243 2.00727 1.99975 1.79454 1.89806 0.978583 1.09552 1.24532 1.57839 1.99934 0.943433 0.954487 0.647339 1.07335 1.10655 1.17797 1.56503 1.57651 2.18436 1.53493 1.40553 1.59172 0.957009 0.6682 1.25411 1.44108 1.09684 0.656196 1.3246 0.933656 1.2726 1.33736 0.827828 0.63653 2.22109 1.1912 1.82822 4.17957 0.886108 1.39547 1.23675 1.30102 1.37446 1.18792 0.980138 1.37915 1.19147 2.03199 1.73584 0.831808 1.30704 1.49189 0.655027 1.91846 1.22624 1.70801 0.707228 1.80731 1.21431 0.624761 1.11658 1.5663 0.868503 1.87424 1.06307 1.69363 0.721979 0.951633 1.13348 1.05012 0.873262 1.35268 2.01683 1.45486 1.66967 1.31114 1.39638 1.65689 0.901542 1.27583 1.01558 1.84602 1.20801 1.1917 1.08567 1.70674 1.3765 1.27565 2.21817 1.57979 1.94636 2.10577 1.42384 1.02211 0.863552 1.05425 1.7702 1.11242 1.67598 1.17462 1.20302 1.92893 1.57065 1.10915 1.09572 1.60283 1.48212 1.91812 2.5661 1.10783 2.30446 1.12858 0.830988 1.31114 1.20859 1.65385 1.19843 1.65121 0.560246 2.13224 0.967162 1.24656 0.981657 0.467725 2.10962 1.47902 0.73403 2.44896 1.46556 2.77881 2.02745 1.70489 1.76345 1.72402 1.30614 1.65217 1.51389 1.17747 1.49091 1.01509 1.2948 2.35317 2.15799 1.08178 1.38752 1.28498 4.587 0.857262 1.54932 1.54886 3.17844 2.00192 1.68135 0.794523 2.14142 0.964761 1.04206 1.82873 1.23651 1.74774 1.33617 1.48268 1.35844 1.56933 1.09945 0.721129 1.64088 1.23513 0.681772 1.15323 1.54137 2.25 1.08444 1.15324 1.18214 1.6726 1.21497 0.748044 2.83614 2.17524 1.72401 1.30497 0.560996 1.41137 0.959665 1.32003 1.29792 1.30494 8.83332 0.968218 1.37143 0.800377 0.983921 1.82603 1.44952 0.924243 0.909981 1.37118 1.31706 1.9083 0.497208 1.09313 1.32507 1.78507 1.53568 2.13467 1.16399 1.31147 1.33743 0.733133 1.08 2.00718 1.25245 1.65762 1.15996 0.890577 1.37551 2.15438 1.19139 1.33886 1.64115 0.682454 0.543797 1.23541 1.55649 1.59209 1.29551 1.04085 1.19971 0.944562 1.7538 2.20983 2.03643 1.03055 1.24764 1.15314 1.10599 1.73553 3.32499 0.910612 0.606715 1.54155 1.38573 0.900618 2.72544 0.732787 1.14016 2.809 1.07902 2.09956 0.648453 0.551395 1.56266 1.2882 1.29345 1.41058 1.78882 0.83916 1.02059 1.78171 1.86016 1.71755 1.55309 1.57044 1.91004 1.45958 1.62233 1.16472 1.56967 1.36639 0.780474 1.54174 0.968311 1.34379 1.51385 0.899523 0.821541 1.69779 1.40677 1.97076 2.63858 1.22229 1.36626 0.948734 1.20344 1.646 2.02622 1.97621 0.797866 1.2218 0.984364 1.88635 1.63447 1.20234 0.825254 1.73002 0.940425 2.26171 1.18177 1.00147 1.24186 1.37162 1.54263 2.25964 0.952171 1.62672 1.46824 0.836424 0.465501 0.957487 3.25013 1.09726 1.4202 0.531724 1.64601 1.57663 1.52283 0.973957 1.29431 2.76063 1.52307 1.08652 1.35429 1.21633 1.28395 1.25368 1.13185 1.81712 1.33307 1.97425 1.05222 1.18437 0.887156 2.2534 1.3386 1.06117 1.02944 1.06672 1.29304 1.40492 0.95761 1.188 1.54277 1.30713 1.27872 1.46239 1.75062 1.05946 1.07257 0.719325 1.08156 2.40539 0.976654 2.24996 1.80754 1.79435 0.418761 1.56968 1.15053 1.1388 2.04381 1.51046 1.19062 1.0304 0.910275 1.05336 1.66532 1.57817 1.29771 1.00548 1.23437 1.16409 0.899531 0.760118 2.2204 1.25245 0.60727 1.14988 2.94328 1.50586 1.14314 2.25647 4.22718 4.119 1.44988 2.24549 2.4085 ]
@@@ Frame-accuracy per-class: [ 82.1607 63.1083 79.4521 61.0837 66.6667 59.5745 44.0678 79.3409 71.0602 41.6107 87.6061 25.2632 83.2855 76.3251 25.1852 71.8147 68.4932 73.3624 69.4864 60.4027 69.5652 74.4731 68.3196 64.8501 54.8348 75.3623 50.7937 77.3931 46.0177 77.193 54.818 71.0706 69.6897 68.7898 86.5088 82.7292 91.5254 94.4551 77.43 60.2317 55.3846 86.9565 79.5062 57.4924 89.2624 78.3505 68.9076 63.5514 89.1604 72.6226 69.7691 83.0091 89.6708 26.3415 73.1006 69.3878 81.3839 62.4473 74.9014 0 66.0465 76.6114 22.2222 64.6154 56.6845 72.8324 75.154 60.8696 78.0985 78.329 65.0519 73.8869 81.0619 82.9268 87.936 37.1041 91.0353 69.5082 68.6869 37.037 68.8323 79.6117 80.4905 76.8539 75.3285 73.1707 69.3878 73.3119 68.5512 80.292 61.4379 84.5878 79.4521 56.4565 72.8905 60.9929 54.9849 73.3981 77.2603 74.5946 73.3668 59.5041 40.678 83.0534 70.4587 79.5322 70.1754 81.4249 38.7097 74.4395 70.6827 85.7685 47.7193 85.1249 32.6848 64.5161 53.012 71.066 45.7143 67.9376 63.2768 75.6757 71.7949 61.8557 80.7018 74.7346 65.3563 70.4225 42.4242 61.3027 50.2415 73.5751 63.4799 59.7156 59.867 63.1579 85.2559 59.5122 45.8498 58.2677 66.8113 46.7153 83.9841 39.1534 65.7277 68.4385 68.0851 58.8235 67.4699 75.6477 77.5087 75.6219 60.0619 75.1269 74.8752 75.4579 78.4314 47.191 79.4189 60.8696 80.1034 77.951 64.5087 68.9956 58.8235 49.2308 58.006 60.6061 59.5533 67.7686 82.23 76.6859 68.9076 69.5035 63.1111 0 56.3758 70.3533 81.6976 0 52.188 73.743 77.686 65.9794 63.5514 57.8512 82.0961 49.1803 65.7471 95.0749 70.5036 63.9053 75.3623 80.4665 60.4255 79.089 77.8281 55.1378 74.7475 77.951 58.9928 26.8657 84.7724 52.7221 64.1509 66.6667 58.2278 56.1404 70.8408 80.6723 68.6907 63.0137 72.8232 78.5047 49.7778 76.9716 39.8671 62.1762 63.6735 62.2754 57.3427 63.5875 61.5385 61.191 74.7604 80 54.3081 73.0038 79.4521 81.7346 71.7949 80 41.4201 76.8 86.3309 37.037 59.4752 71.6049 66.2614 70.7368 49.459 75.8294 79.1489 79.6928 82.3799 4.65116 17.3913 51.2968 31.339 44.3686 60.1093 51.7986 66.6667 60.6272 56.2874 58.8235 66.1088 75.195 71.1864 88.32 89.7507 54.1063 48.4211 83.9532 78.071 75.4579 84.2105 68.7697 57.1429 72.5051 68.3761 86.7925 63.8978 69.6486 33.7531 45.283 76.5957 39.0533 69.0909 68.0851 80.7418 51.4096 50.0942 80.6154 0 48.9209 76.489 43.1138 66.3677 77.8243 60.8 67.8186 75.7866 72.9064 45.8716 60.8187 61.6352 64.0523 70.6231 88.0734 65.8635 77.5337 63.8522 56.338 57.732 52.6749 35.8974 23.4818 68.0851 74.9091 83.1858 57.2438 64.9057 58.4885 44.0529 73.7327 65.0847 56.4706 62.7451 65.3103 80.4501 83.697 74.184 67.9045 73.183 73.1429 70.6587 76.6839 49.6124 56.9343 76.8362 81.519 49.5413 77.13 72.4409 78.3455 72.0327 53.9326 63.7993 46.6368 78.0781 64.3777 77.193 17.1429 75.0507 46.332 39.2453 73.2601 46.4135 62.069 79.0123 81.9788 69.1706 77.3218 70.6542 61.5385 87.5399 77.512 41.5584 68.7961 57.7778 69.9029 80.6172 65.3913 81.9672 68.3983 31.8339 42.5532 60.4527 78.3217 76.1958 71.6418 64.4809 65.3465 60.066 78.1731 49.4915 85.5524 32.7684 70.0252 58.9595 89.4118 73.1707 85.9903 52.9002 0 55.5133 74.6667 80.7512 44.1718 44.4444 40 67.7201 59.19 83.004 82.9157 77.4411 69.1358 38.4762 81.8653 75.2137 67.4157 72.2581 69.9371 62.0278 26.3473 67.1533 61.2766 65.5602 58.7678 30.6595 65.9026 80.3419 68.2927 61.7886 49.3438 74.8899 44.6847 63.8298 80.9422 72.9282 48.855 28.5714 37.4269 68.3292 68.1542 79.1809 55.643 54.0952 36.9231 55.4572 66.9039 29.2135 60.4423 47.4227 53.6585 61.0966 81.0573 71.5105 51.0638 48.2759 71.1111 44.8161 78.327 70.5882 72.5979 44.9568 58.0931 47.2574 68.7719 72.5756 63.4146 59.542 78.1893 81.7688 49.2754 80.7339 84.9339 0 54.9747 64.2534 67.7291 71.6511 55.1724 73.9018 65.8711 80.8511 68.6084 67.3993 72.0648 18.8235 39.4089 61.5385 78.174 51.7483 62.6415 57.6497 70.0422 74.2857 76.4045 73.0038 77.2277 47.3373 30.303 91.0384 41.7582 72 33.1707 60.8696 66.2379 52.8975 82.2823 79.7707 32 84.984 54.4578 55.1253 37.3626 34.1085 48.737 62.9816 60.3774 85.5346 76.8362 65.8385 76.4977 72.4077 38.5185 62.5551 57.4713 69.1244 68.1564 50.6024 42.8169 68.2422 0 64.4845 24.8963 82.2742 69.3878 54.3046 68.0851 84.8921 69.2449 88.454 63.2911 69.3878 70.1299 64.9275 63.4146 57.6577 60.2871 56.3758 31.9489 55.481 81.768 70.3448 67.7966 32.7273 73.3032 74.3202 46.1538 69.7674 69.0196 54.8673 72.3404 62.635 78.7637 63.586 49.6644 0 41.4545 80.9717 68.3625 74.4086 87.2314 68.7961 48.5333 38.5542 76.6355 81.6327 45.7143 67.4847 66.0661 60.7004 74.0741 53.7549 77.6119 72.9282 69.5481 62.8242 62.1723 79.1809 79.7637 77.8013 60.8126 50.2203 67.9045 52.7687 12.1212 66.6667 73.4694 80.8511 78.0328 62.2222 88.228 51.8519 60.6061 67.5422 61.0546 10.5263 78.4452 80.8625 55.9853 79.3443 48.5437 72.5664 69.7585 65.9913 56.5553 75.3927 64.6388 56.0748 57.4018 56.092 71.1864 61.9137 53.2374 69.3333 73.743 0 65.3595 65.7682 67.7596 54.4503 21.5054 60.0509 74.7141 67.9245 73.1707 57.868 65.6489 67.4033 73.817 80.2178 46.6258 55.6098 49.47 74.9206 58.2809 52.3691 67.7524 55.0725 45.9893 66.3755 79.2171 57.4713 59.3438 51.8828 52.5346 77.0186 80.3859 24 48.2192 55.7377 39.1608 79.4406 68.0203 42.3358 77.913 48.8889 66.4697 69.4864 45.1178 53.4351 37.8738 36.7816 51.2821 57.2029 61.3592 87.2727 63.1111 71.9212 71.5474 58.8957 71.5232 30.303 64 66.6667 74.0741 83.1169 60.1036 65.5949 74.9164 28.821 45.8716 72.7273 74.8387 38.5382 83.5821 76.2148 52.6316 53.0909 74.0576 0 39.3782 0 53.2974 79.3528 90.6815 77.628 54.844 39.0244 30.7692 64.5403 81.7814 67.807 70.8661 78.601 49.4624 65.1852 8.69565 68.8525 63.8037 0 50.5747 66.005 58.3162 62.5767 80.6366 81.3648 45.9016 38.5965 66.6667 78.0488 0 62.8272 68.7117 69.3069 41.4815 54.3689 72.7503 24.1611 52.1008 79.4007 44.1315 51.7413 83.2 8 72.5738 79.2541 42.7807 60.5042 65.928 59.8698 56.6929 50.6887 66.4789 54.3641 65.3244 83.871 65.3696 69.9229 30.4183 71.637 69.1943 73.8552 81.0997 31.5789 84.2105 76.9441 71.1864 66.6667 81.9277 51.0166 68.0412 69.9552 45.8204 59.5041 83.7905 57.9065 55.6391 74.1775 67.7104 54.1455 38.6059 76.0383 76.2667 70.4762 51.6704 49.3766 69.9029 26.087 75.0542 67.2304 68.4932 64.4211 61.2987 65.7439 80.8602 72.5389 27.5862 71.068 80.397 70.3934 74.0741 55.3506 42.2018 49.3827 74.3412 76.3359 52.2822 56.2963 47.1338 40 67.8869 87.9177 77.5444 59.0078 76.9231 52.973 72.214 80.9399 58.8235 75.4098 87.1537 70.7395 66.6667 54.0206 55.0725 67.9868 56.4263 73.6196 63.7681 68.476 46.5409 69.7674 66.1333 59.0274 84.2105 60.0733 58.0645 56.9191 38.806 49.7297 67.6017 76.1905 72.4706 82.6347 83.9952 58.0645 52.2167 63.3826 29.6296 56.9948 74.3662 68.14 43.6019 72.7592 74.2857 71.1779 43.2432 0 69.3767 80.2424 72.956 49.2891 78.5197 58.1315 66.2857 82.4919 69.7851 76.9231 67.6056 60.6742 69.9774 32 45.6432 54.9708 72.7273 11.4286 70.3583 65.1982 45.4054 75.2137 75.0524 24.7086 77.1267 80.6688 79.0419 37.8378 68.0514 60.3774 69.5652 57.4586 55.914 61.1465 66.055 55.8904 19.8758 70.6559 73.9496 62.4606 74.5981 62.4339 77.1574 61.2378 57.9104 65.1584 80.5846 82.0513 76.4444 76.0259 71.7087 73.5113 64.5503 64.4391 58.4867 0 84.1921 70.0337 49.4382 78.0316 79.803 66.1922 71.0218 64.7273 64.2534 83.6105 73.8648 70.2929 45.7143 75.2556 60.9137 60.4878 73.6842 57.3705 23.7624 54.6939 41.3793 83.5381 67.8112 60.1399 67.0866 36.5897 75.3129 41.7021 37.4728 63.1579 58.567 73.8255 34.4828 61.3139 0 54.039 73.4752 75.6989 75.9494 70.412 74.3034 62.8272 78.4969 56.4263 19.0476 16.2162 78.2334 51.505 66.6667 21.5054 69.1824 66.2021 14.8148 47.4419 70.2703 51.5759 33.5484 58.2677 71.1864 47.5836 66.6667 76.3636 46.3576 74.6507 50.1493 51.4943 53.8071 62.5592 66.9767 26.6667 53.5211 75.5556 77.6119 69.3498 69.9387 76.1099 51.9774 62.1762 42.953 61.6715 79.2584 70.948 83.6036 59.0786 57.6052 58.9928 61.0282 59.542 57.2347 68.4685 66.242 38.5965 55.0117 82.1114 71.8535 39.0805 43.2432 49.6 64.1975 56.5598 51.2 53.8922 59.1716 71.3781 56.8306 76.1421 47.5248 42.2939 11.0236 70.5882 72.444 51.0978 63.8411 58.5366 39.0244 71.9472 7.92079 55.615 63.1829 46.8293 70.5882 59.6026 74.0238 66.6667 61.008 44.7653 80.6378 58.8387 81.3559 35.8974 25.8824 42.2145 12.4611 71.5285 78.3193 50.6122 59.3607 66.6667 71.0963 83.816 52.2449 67.2087 61.9926 79.2079 77.5828 51.4464 50.6388 58.8921 56.0579 69.0979 52.1739 73.4793 81.8558 42.623 50.2547 55.181 81.717 65.3358 78.6418 29.6296 56.8266 72.2063 54.9954 75.2205 76.4179 70.1176 32.4324 62.1444 50.6596 11.7647 85.7143 80.8454 35.0133 75.1696 62.3853 48.589 81.448 48.1203 76.7213 45.5172 33.9726 45.7143 49.6454 83.871 86.1454 69.3333 75.775 56.1702 74.7305 55.2204 80.0441 81.5081 67.5052 63.7398 61.4379 37.5367 76.4045 78.7172 76.7701 74.4488 47.2727 50.8475 74.5387 70.8861 73.716 47.1204 48.1553 60.6403 58.0931 62.6866 68.7211 82.9111 65.3637 63.5607 47.7987 59.1885 68.5026 53.0612 76.7773 52.6316 62.3549 59.1304 78.6207 58.7413 52.6863 64.8649 53.2039 59.542 34.2508 74.5763 73.5786 47.6489 78.9579 72.5424 42.6966 42.9594 45.8427 78.2269 71.6578 72.3769 52.7607 63.8132 71.5328 51.1278 78.1038 47.5138 89.2308 66.8281 32.5581 19.4175 22.439 50.7937 30.2222 59.4595 66.2626 73.5751 32.5815 69.8413 54.4379 67.6692 46.778 54.5455 85.3147 59.0164 82.2171 66.4132 62.9325 43.5798 82.0168 70.4323 54.8148 65.3722 78.7487 58.3942 62.9333 66.1397 42.3645 55.5366 56.9863 47.3118 62.9213 73.2733 70.7692 59.0604 68.1223 62.5455 67.1587 63.6678 74.9522 49.5298 39.5664 74.5052 61.0687 59.4164 64.6465 44.358 79.4788 54.902 33.0097 56.7164 72.3327 73.2496 76.3052 72.0379 56.7901 57.4514 64.6465 62.2468 79.285 36.1011 80.6349 66.6667 87.5576 69.7674 68.4288 42.5036 32.5926 48.6957 45.509 74.3083 66.0085 66.56 55.1724 47.2622 54.2343 76.8473 83.2451 72.428 71.2074 72.2892 50.9804 59.9251 45.0331 54.902 62.9508 55.6522 71.6724 81.0997 66.6667 56.9343 63.4006 82.0453 63.7874 76.0108 75.2294 49.8952 71.5746 81.2854 42.807 64.7658 52.0167 18.6047 75.8621 61.3108 64.2452 61.3904 57.2238 64.6766 78.9238 53.3333 71.0744 43.4783 53.3333 78.4588 59.3472 64.5963 86.4368 43.038 59.2375 50.7772 82.2955 48.0151 65.4545 86.5417 74.3802 54.7486 76.0757 48.1283 70.6625 53.9326 78.2247 73.5084 65.0572 71.4134 71.6094 59.3968 38.6059 62.8571 57.6744 63.2258 62.8571 56.6416 71.9424 68.3292 72.428 47.5676 61.3909 70.0508 65.9341 47.1111 61.9647 66.3342 34.9515 63.5762 40.8163 37.8698 63.1579 72.1248 76.1809 76.8683 55.3911 70.5344 56.6845 70.9677 63.6015 50.9091 54.5906 64.3946 71.4715 60.9836 61.5385 45.8101 21.9718 65.1584 43.1925 70.0637 78.4141 60.619 59.9613 55.8952 67.3367 49.6552 85.1376 42.5249 75.242 68.5817 67.6819 88.4682 31.5789 56.4103 79.3434 34.9146 62.1723 30.1449 43.6364 60.8519 43.9276 48.0326 63.5294 53.8153 59.0164 69.0827 60.4651 71.5232 65.3595 39.0805 43.5556 69.4505 58.2857 64.2468 6.59341 71.8808 55.4839 57.5964 21.5768 37.4101 51.9793 80 41.8605 71.0744 67.9045 44.0191 73.2632 50.9583 60.3727 57.0543 55.4455 54.6479 69.3467 79.5356 47.7971 65.6716 80.1646 67.0713 54.6075 41.4977 68.323 70.0855 67.8851 57.3643 68.9076 76.3569 22.9075 31.5789 48.8746 69.7039 88.0734 61.7577 73.1392 63.1293 58.3569 65.4731 0 67.0232 56.3177 77.2036 74.0741 49.2013 64 73.1591 71.9368 65.8196 58.1315 39.801 83.5534 71.0875 67.9245 53.9419 60.2469 52.514 69.967 65.4244 57.0892 82.963 70.4684 47.619 65.8373 50.3632 64.5669 76.2145 58.3486 40.8964 65.7807 60.6811 63.0303 79.5127 85.4588 66.3594 50.2564 54.3779 65.8455 70.1252 69.1312 74.0973 50.3516 49.1979 32.6797 70.8752 60.8828 66.0287 72.1003 47.8632 0 73.0245 84.2884 63.0303 63.9498 76.4488 27.4882 78.6469 74.4589 32.0413 66.4207 40.5594 85.2989 85.1114 53.8012 66.8516 61.9392 56.2738 56.8421 83.682 73.5497 54.2222 52.7473 47.7212 59.0991 57.6271 43.5331 57.2207 44.665 74.9263 54.026 62.636 76.9448 55.0882 75.0716 64.0483 68.1004 81.9222 74.1313 48.5207 64.69 40.3756 37.6119 68.2274 64.7887 79.0123 71.6883 43.8095 46.1261 52.5745 78.5586 63.6735 74.1886 45.8781 51.9031 53.8244 80.1394 52.5822 73.2075 32 63.5838 72.5051 69.3878 58.5774 49.2239 36.8794 75.0594 49.6042 58.3554 73.6842 82.8829 74.4186 8.88889 66.5487 58.194 85.2044 57.0071 63.9676 53.2751 78.4566 62.8842 16.8421 61.6967 68.2635 55.8891 63.0508 66.6667 67.4058 75.8017 48.1675 63.4006 44.795 72.5462 60.6546 75.6514 36.2369 61.4887 70.9817 68.4807 70.317 69.4215 64.4068 76.9231 69.4158 56.4417 65.4867 62.9921 61.0169 56.7474 68.6695 72.0721 82.9982 72.7273 29.9841 72.5441 40.724 54.0881 54.7486 86.2893 54.0146 63.2892 69.7318 54.2056 59.0728 67.7755 73.0594 76.0291 71.2251 55.2017 54.0541 61.4565 68.5512 70.1031 70.8229 73.6156 79.5699 43.1373 66.2192 80.1131 62.952 18.9474 56.6929 66.055 30.2439 6.77966 5.33333 61.0526 29.2683 34.7107 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 1.09181 (Xent), [AvgXent: 1.09181, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 68.9341% <<

