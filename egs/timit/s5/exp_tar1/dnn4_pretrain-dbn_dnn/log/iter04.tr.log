nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.008 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter03_learnrate0.008_tr1.3399_cv2.2283 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter04 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975062
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.2475, max 7.77538, mean -0.00464958, stddev 0.983373, skewness 0.0162194, kurtosis 1.92828 ) 
[1] output of <AffineTransform> ( min -28.2023, max 21.7695, mean -3.28609, stddev 3.71516, skewness 0.156913, kurtosis 1.39952 ) 
[2] output of <Sigmoid> ( min 5.64812e-13, max 1, mean 0.193596, stddev 0.30046, skewness 1.60836, kurtosis 1.19873 ) 
[3] output of <AffineTransform> ( min -29.4657, max 16.2737, mean -4.01821, stddev 2.7741, skewness -0.0355755, kurtosis 2.4601 ) 
[4] output of <Sigmoid> ( min 1.59672e-13, max 1, mean 0.0988107, stddev 0.195953, skewness 2.90452, kurtosis 8.25238 ) 
[5] output of <AffineTransform> ( min -15.1931, max 11.6232, mean -3.21109, stddev 2.01661, skewness 0.632869, kurtosis 2.50027 ) 
[6] output of <Sigmoid> ( min 2.52183e-07, max 0.999991, mean 0.109219, stddev 0.190241, skewness 2.84203, kurtosis 8.1035 ) 
[7] output of <AffineTransform> ( min -23.7975, max 15.985, mean -2.97385, stddev 2.28183, skewness 0.61939, kurtosis 3.23422 ) 
[8] output of <Sigmoid> ( min 4.62232e-11, max 1, mean 0.139054, stddev 0.225584, skewness 2.29115, kurtosis 4.60343 ) 
[9] output of <AffineTransform> ( min -16.5928, max 16.8006, mean -2.93561, stddev 2.75771, skewness 1.39577, kurtosis 2.97885 ) 
[10] output of <Sigmoid> ( min 6.22075e-08, max 1, mean 0.164333, stddev 0.28052, skewness 1.92564, kurtosis 2.40323 ) 
[11] output of <AffineTransform> ( min -32.1376, max 19.0679, mean -3.68332, stddev 3.38845, skewness 1.00739, kurtosis 3.46523 ) 
[12] output of <Sigmoid> ( min 1.10357e-14, max 1, mean 0.140415, stddev 0.283323, skewness 2.16746, kurtosis 3.23377 ) 
[13] output of <AffineTransform> ( min -12.5821, max 20.1727, mean -0.00744548, stddev 3.15134, skewness 0.603926, kurtosis 1.1439 ) 
[14] output of <Softmax> ( min 7.27244e-14, max 0.997729, mean 0.000624902, stddev 0.016293, skewness 41.1699, kurtosis 1922.06 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.829166, max 1.1867, mean -0.000101746, stddev 0.0477076, skewness 0.174574, kurtosis 17.3423 ) 
[1] diff-output of <AffineTransform> ( min -0.304955, max 0.27424, mean 5.0096e-05, stddev 0.00907984, skewness 0.474107, kurtosis 58.3661 ) 
[2] diff-output of <Sigmoid> ( min -1.32318, max 1.30153, mean 8.9797e-05, stddev 0.0795198, skewness 0.165654, kurtosis 11.1355 ) 
[3] diff-output of <AffineTransform> ( min -0.248441, max 0.321451, mean 5.52419e-05, stddev 0.00986306, skewness 0.44697, kurtosis 66.1948 ) 
[4] diff-output of <Sigmoid> ( min -1.5056, max 1.33111, mean -0.000175743, stddev 0.102274, skewness -0.0125979, kurtosis 8.37409 ) 
[5] diff-output of <AffineTransform> ( min -0.244767, max 0.258984, mean 8.62501e-05, stddev 0.0102546, skewness 0.434426, kurtosis 50.0575 ) 
[6] diff-output of <Sigmoid> ( min -1.2947, max 1.52573, mean 0.000562883, stddev 0.0902392, skewness 0.0730319, kurtosis 9.74257 ) 
[7] diff-output of <AffineTransform> ( min -0.173273, max 0.288919, mean 6.34328e-05, stddev 0.00894383, skewness 0.455257, kurtosis 41.1651 ) 
[8] diff-output of <Sigmoid> ( min -0.795152, max 1.16631, mean 0.000244054, stddev 0.069442, skewness 0.0268628, kurtosis 9.32172 ) 
[9] diff-output of <AffineTransform> ( min -0.18844, max 0.18835, mean 4.85971e-05, stddev 0.0070798, skewness 0.0869514, kurtosis 43.5503 ) 
[10] diff-output of <Sigmoid> ( min -0.839505, max 0.93358, mean 0.000185326, stddev 0.0547379, skewness -0.0360384, kurtosis 12.2592 ) 
[11] diff-output of <AffineTransform> ( min -0.327696, max 0.212116, mean 7.44913e-05, stddev 0.00834032, skewness -0.144672, kurtosis 59.6604 ) 
[12] diff-output of <Sigmoid> ( min -1.79539, max 1.15654, mean 0.000877987, stddev 0.0911463, skewness -0.0686267, kurtosis 5.22124 ) 
[13] diff-output of <AffineTransform> ( min -0.99996, max 0.894756, mean -8.13685e-09, stddev 0.0190536, skewness -25.8817, kurtosis 1699.17 ) 
[14] diff-output of <Softmax> ( min -0.99996, max 0.894756, mean -8.13685e-09, stddev 0.0190536, skewness -25.8817, kurtosis 1699.17 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.22818, max 1.52512, mean -0.00130199, stddev 0.140249, skewness -0.0032997, kurtosis 2.3832 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.634737, max 0.554115, mean 0.0128245, stddev 0.15409, skewness -0.0219375, kurtosis 1.06491 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.839618, max 0.990373, mean 0.00253943, stddev 0.056581, skewness 0.130854, kurtosis 7.54608 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.799298, max 1.09353, mean 0.0141419, stddev 0.164077, skewness 0.164073, kurtosis 3.26809 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.590141, max 0.733056, mean 0.00217221, stddev 0.0360485, skewness 0.461146, kurtosis 12.2484 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.644441, max 0.987564, mean 0.02208, stddev 0.170413, skewness 0.367976, kurtosis 2.32418 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.56745, max 0.490037, mean 0.00178256, stddev 0.0321648, skewness 0.377881, kurtosis 10.5442 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.628775, max 0.855135, mean 0.0162388, stddev 0.153471, skewness 0.203522, kurtosis 2.28457 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.426691, max 0.395512, mean 0.0016974, stddev 0.0308344, skewness 0.286588, kurtosis 8.74676 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.425886, max 0.563617, mean 0.0124407, stddev 0.120127, skewness 0.318459, kurtosis 2.53983 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.493667, max 0.541298, mean 0.00333421, stddev 0.0426951, skewness 0.449603, kurtosis 8.21192 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.529591, max 0.480652, mean 0.0190697, stddev 0.12755, skewness 0.215136, kurtosis 2.04145 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -3.52163, max 2.29394, mean -8.33163e-08, stddev 0.10324, skewness -4.96023, kurtosis 89.2252 ) , lr-coef 1, max-norm 0
  bias_grad ( min -3.45862, max 1.82094, mean -7.89762e-09, stddev 0.33663, skewness -2.18837, kurtosis 16.7355 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 338432 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.50193, max 6.77601, mean -0.00405738, stddev 0.997423, skewness -0.00626004, kurtosis 2.0657 ) 
[1] output of <AffineTransform> ( min -31.6808, max 21.1359, mean -3.32657, stddev 4.04898, skewness 0.125735, kurtosis 1.32471 ) 
[2] output of <Sigmoid> ( min 1.74265e-14, max 1, mean 0.205794, stddev 0.314444, skewness 1.50144, kurtosis 0.787528 ) 
[3] output of <AffineTransform> ( min -34.7945, max 16.6638, mean -4.13907, stddev 2.90236, skewness -0.0782418, kurtosis 2.3067 ) 
[4] output of <Sigmoid> ( min 7.74348e-16, max 1, mean 0.0996081, stddev 0.200412, skewness 2.85992, kurtosis 7.87022 ) 
[5] output of <AffineTransform> ( min -14.7994, max 12.5315, mean -3.2047, stddev 2.04576, skewness 0.580099, kurtosis 2.29504 ) 
[6] output of <Sigmoid> ( min 3.7386e-07, max 0.999996, mean 0.111664, stddev 0.192948, skewness 2.77205, kurtosis 7.6236 ) 
[7] output of <AffineTransform> ( min -23.1213, max 16.0555, mean -2.90735, stddev 2.32049, skewness 0.596252, kurtosis 2.91123 ) 
[8] output of <Sigmoid> ( min 9.08932e-11, max 1, mean 0.147041, stddev 0.232609, skewness 2.16761, kurtosis 3.96194 ) 
[9] output of <AffineTransform> ( min -16.6406, max 16.2806, mean -2.90359, stddev 2.85946, skewness 1.36627, kurtosis 2.81924 ) 
[10] output of <Sigmoid> ( min 5.9304e-08, max 1, mean 0.171165, stddev 0.288396, skewness 1.84678, kurtosis 2.0543 ) 
[11] output of <AffineTransform> ( min -29.5691, max 19.6383, mean -3.75241, stddev 3.55076, skewness 0.975054, kurtosis 3.27549 ) 
[12] output of <Sigmoid> ( min 1.43986e-13, max 1, mean 0.143084, stddev 0.289424, skewness 2.12323, kurtosis 2.99455 ) 
[13] output of <AffineTransform> ( min -13.7789, max 20.7266, mean -0.0103807, stddev 3.42824, skewness 0.544629, kurtosis 0.989851 ) 
[14] output of <Softmax> ( min 5.48177e-15, max 0.991373, mean 0.000624924, stddev 0.0186049, skewness 40.9862, kurtosis 1811.17 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.753298, max 0.883919, mean -0.000432481, stddev 0.0394643, skewness -0.0672442, kurtosis 20.5601 ) 
[1] diff-output of <AffineTransform> ( min -0.245008, max 0.229763, mean -2.97464e-06, stddev 0.00707386, skewness 0.0266433, kurtosis 78.1061 ) 
[2] diff-output of <Sigmoid> ( min -1.38482, max 1.0303, mean -8.60583e-05, stddev 0.0636116, skewness -0.147563, kurtosis 17.2996 ) 
[3] diff-output of <AffineTransform> ( min -0.282707, max 0.385709, mean -4.71827e-05, stddev 0.0079439, skewness -0.0582097, kurtosis 113.644 ) 
[4] diff-output of <Sigmoid> ( min -1.62975, max 1.62186, mean 0.000228039, stddev 0.084482, skewness -0.0787912, kurtosis 15.8837 ) 
[5] diff-output of <AffineTransform> ( min -0.398784, max 0.230012, mean -7.26634e-05, stddev 0.00843386, skewness -1.14968, kurtosis 102.891 ) 
[6] diff-output of <Sigmoid> ( min -1.68433, max 1.20001, mean -0.000179131, stddev 0.0746997, skewness -0.147587, kurtosis 16.9956 ) 
[7] diff-output of <AffineTransform> ( min -0.257703, max 0.244315, mean -6.51396e-05, stddev 0.00731443, skewness -0.172859, kurtosis 63.6822 ) 
[8] diff-output of <Sigmoid> ( min -1.19248, max 0.978151, mean -0.000276518, stddev 0.0561353, skewness -0.0891945, kurtosis 15.2674 ) 
[9] diff-output of <AffineTransform> ( min -0.210642, max 0.140229, mean -4.06682e-05, stddev 0.00569861, skewness -0.569446, kurtosis 59.2944 ) 
[10] diff-output of <Sigmoid> ( min -0.866132, max 0.636385, mean -1.06042e-05, stddev 0.0445505, skewness -0.117242, kurtosis 16.7278 ) 
[11] diff-output of <AffineTransform> ( min -0.171509, max 0.208542, mean -2.23711e-05, stddev 0.00663678, skewness -0.309515, kurtosis 62.1258 ) 
[12] diff-output of <Sigmoid> ( min -0.908923, max 0.834169, mean 0.000149799, stddev 0.0727723, skewness -0.0463623, kurtosis 6.85441 ) 
[13] diff-output of <AffineTransform> ( min -0.999967, max 0.890153, mean -6.59609e-09, stddev 0.0147385, skewness -28.7524, kurtosis 2497.02 ) 
[14] diff-output of <Softmax> ( min -0.999967, max 0.890153, mean -6.59609e-09, stddev 0.0147385, skewness -28.7524, kurtosis 2497.02 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.19614, max 1.351, mean -0.000610398, stddev 0.114606, skewness 0.00455524, kurtosis 2.16667 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.40536, max 0.514006, mean -0.000761494, stddev 0.132649, skewness 0.176215, kurtosis 0.667941 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.655514, max 0.786923, mean -0.00270812, stddev 0.0514551, skewness -0.115455, kurtosis 7.84766 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.658208, max 0.724438, mean -0.0120788, stddev 0.14641, skewness -0.0798418, kurtosis 1.95032 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.816275, max 0.599744, mean -0.00198684, stddev 0.0338911, skewness -0.865063, kurtosis 19.4338 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.829456, max 0.632046, mean -0.0186018, stddev 0.167398, skewness -0.328214, kurtosis 2.46327 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.525775, max 0.598958, mean -0.00190034, stddev 0.0292285, skewness -0.401306, kurtosis 12.3318 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.708277, max 0.585787, mean -0.0166757, stddev 0.145379, skewness -0.331525, kurtosis 1.97384 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.399609, max 0.279589, mean -0.00155182, stddev 0.027624, skewness -0.397972, kurtosis 9.62726 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.588766, max 0.471376, mean -0.0104111, stddev 0.107966, skewness -0.396875, kurtosis 4.04664 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.436949, max 0.408145, mean -0.000736566, stddev 0.0374112, skewness -0.209362, kurtosis 8.25399 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.405215, max 0.493334, mean -0.00572697, stddev 0.113507, skewness -0.0994037, kurtosis 2.17806 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -1.86167, max 1.35607, mean -5.04349e-08, stddev 0.0788938, skewness -4.60283, kurtosis 83.3687 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.61502, max 1.35842, mean -6.85453e-09, stddev 0.23868, skewness -1.68781, kurtosis 10.6757 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0778657 min, processing 72439.2 frames per sec; i/o time 5.02475%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14106 318 182 101 16 23 147 394 174 74 294 47 870 141 67 129 255 114 165 74 149 213 181 183 408 103 94 245 56 199 233 219 209 78 485 234 501 261 303 129 32 34 202 163 535 145 178 160 16656 5473 1407 385 440 102 243 122 303 118 380 0 107 271 58 97 93 86 243 57 294 191 144 415 282 143 874 110 864 152 49 13 569 154 448 222 342 20 710 155 141 68 76 139 255 166 278 70 165 257 182 92 99 60 29 327 272 85 199 196 15 111 124 263 142 460 128 77 124 98 17 288 88 277 175 145 85 235 203 106 16 130 103 96 261 105 225 47 654 102 126 63 230 68 627 94 106 150 211 42 124 289 144 100 161 98 300 136 229 44 206 11 193 224 432 114 59 162 165 82 201 60 143 259 59 211 112 0 74 325 188 0 308 89 60 48 267 60 114 213 217 233 69 84 34 171 117 241 110 199 148 224 208 100 318 174 185 100 39 85 279 178 263 182 189 160 112 158 150 96 122 83 71 465 110 243 156 322 191 131 401 380 136 112 84 62 69 94 171 202 164 237 323 105 117 1041 218 21 103 173 175 146 274 69 106 143 83 59 358 320 29 312 180 310 237 470 549 136 85 158 80 245 175 26 156 156 198 132 23 84 27 70 350 301 265 162 4 208 159 83 111 119 62 231 365 304 54 85 79 76 168 163 124 705 189 106 48 121 19 123 117 137 169 141 132 456 113 108 147 127 25 491 355 389 168 188 199 87 83 96 64 68 88 197 54 111 190 205 366 44 139 111 166 116 142 17 246 129 132 136 118 101 283 141 319 231 267 110 156 104 38 203 22 154 518 287 30 115 144 23 375 214 888 167 91 50 151 941 147 529 88 198 86 42 20 103 215 7 131 37 106 81 22 12 221 160 126 219 148 121 262 96 292 133 232 397 251 83 68 117 120 105 280 174 760 20 61 190 113 277 70 233 90 65 10 85 200 246 146 190 262 32 169 140 133 203 48 20 191 113 261 70 14 67 149 131 195 140 173 225 118 142 479 20 65 121 644 103 272 567 0 296 110 125 160 72 193 209 23 154 136 123 42 101 71 350 71 132 225 118 52 133 131 151 84 16 351 136 37 102 80 155 336 499 610 12 156 207 219 45 193 336 298 26 79 88 241 108 284 67 113 217 108 268 207 177 338 0 305 120 149 24 75 211 69 271 255 39 24 38 172 143 166 104 74 156 223 90 72 29 82 110 165 110 21 127 56 70 231 501 270 74 7 137 123 314 232 395 203 187 41 160 122 17 81 166 128 40 126 167 271 254 173 133 146 338 236 381 113 188 153 16 31 122 164 152 22 403 94 16 266 540 9 424 185 271 152 51 169 517 345 194 95 131 53 165 217 206 266 69 37 89 10 229 185 91 95 46 196 393 238 61 98 65 90 158 275 81 102 141 157 238 200 153 34 93 114 536 130 350 119 108 80 155 62 182 91 71 357 98 68 287 22 338 165 148 65 150 43 19 475 257 27 112 101 300 81 75 49 62 166 121 115 96 155 149 114 163 60 77 150 33 195 123 137 225 13 96 1 371 772 359 185 304 20 19 266 123 818 63 1086 46 67 11 30 81 10 43 201 243 244 188 190 152 28 79 20 11 286 81 50 67 51 394 74 59 133 106 100 187 12 118 214 93 178 180 230 63 181 177 200 223 108 128 194 131 308 105 338 145 9 47 366 206 283 41 270 145 334 161 60 200 224 66 501 255 295 186 156 187 52 224 200 154 11 230 236 109 237 192 144 232 96 14 257 201 241 13 135 54 40 360 65 120 202 78 92 300 194 309 191 175 92 336 191 76 30 198 155 34 242 103 151 159 81 34 239 79 193 187 894 389 136 108 191 100 92 356 115 212 250 415 139 101 304 13 96 177 271 105 284 17 199 129 1 184 412 238 105 621 144 87 465 395 487 106 311 221 12 120 85 137 17 153 113 92 58 238 214 264 478 417 92 505 132 126 271 46 78 163 182 80 434 59 158 155 94 295 460 167 110 239 370 337 231 178 243 94 209 244 6 572 148 133 853 101 140 298 137 110 210 495 597 87 244 98 307 351 125 50 122 130 203 116 71 317 281 439 117 229 237 160 74 14 68 0 179 352 232 39 133 161 95 239 159 52 55 475 149 208 139 238 143 13 107 166 174 77 63 265 134 130 27 75 250 167 217 98 105 107 7 35 22 33 161 244 236 88 96 74 173 431 163 277 184 154 69 301 65 155 55 235 28 214 170 218 43 55 187 121 171 187 83 253 141 91 98 50 139 63 314 513 250 377 20 20 151 50 93 210 102 8 75 294 127 188 138 219 387 206 58 42 144 160 500 297 122 109 157 150 293 122 184 135 454 256 639 430 514 276 260 11 205 603 30 294 400 314 275 1369 13 135 174 545 623 167 212 18 228 189 8 269 378 188 368 54 407 110 66 152 72 182 17 70 15 364 187 435 117 417 215 453 278 238 307 229 170 222 514 1659 385 27 29 135 197 165 95 257 265 225 234 324 927 460 300 79 209 290 73 105 104 301 57 72 71 288 277 257 196 163 88 149 159 249 147 133 209 222 383 280 233 81 385 205 66 221 90 97 206 21 51 102 157 112 55 247 289 199 94 253 66 209 60 71 91 216 394 303 128 297 867 202 154 463 68 187 379 101 293 182 46 44 166 97 74 114 137 135 144 261 159 184 429 65 188 148 128 153 25 51 234 276 278 124 105 40 231 49 271 475 138 472 70 108 64 340 343 67 57 83 126 354 312 217 173 1139 101 283 121 161 41 25 133 75 25 152 172 146 145 67 68 173 860 150 185 54 238 244 264 142 245 359 64 188 236 440 467 176 100 111 397 181 34 127 285 168 80 217 39 170 96 409 264 27 293 60 89 290 93 158 44 360 209 393 470 276 215 186 17 107 387 87 199 486 200 364 92 208 98 45 112 198 200 51 75 73 84 123 256 497 140 236 327 93 108 130 82 201 557 166 152 149 89 177 110 106 78 340 468 258 114 99 72 272 150 361 278 295 290 28 136 365 263 133 172 27 246 193 368 212 124 30 441 21 75 76 130 112 227 87 275 45 268 77 220 120 69 290 57 21 181 188 104 237 443 402 322 50 177 99 344 374 167 607 329 146 320 241 58 191 64 178 543 113 28 155 219 163 210 154 367 176 195 1 841 138 164 67 156 162 210 126 393 144 100 416 188 132 120 202 89 151 241 532 67 245 136 522 206 63 792 272 178 150 161 82 451 1062 108 97 108 446 279 270 318 355 93 76 348 328 313 159 58 10 183 270 82 159 405 105 236 115 193 135 71 309 426 85 360 345 394 142 119 508 112 227 186 277 383 158 183 201 169 192 413 353 368 174 165 139 218 129 84 185 106 167 149 106 202 192 52 277 184 277 122 323 139 144 176 143 106 132 12 86 245 122 119 225 70 210 189 188 218 55 279 22 282 149 868 210 123 114 155 211 47 194 250 216 147 82 225 171 95 173 158 351 748 556 143 154 463 220 173 181 206 19 145 407 56 190 265 144 349 166 273 170 313 198 110 79 89 397 68 641 130 53 377 240 109 206 175 235 18 281 141 48 200 153 232 127 223 530 843 47 63 163 102 29 37 47 20 181 ]
@@@ Loss per-class: [ 0.509604 1.45198 0.764767 1.34119 1.32222 1.72927 1.90627 0.783241 1.04967 1.68297 0.506419 2.32719 0.64407 0.910174 2.35448 0.934419 1.08116 1.04872 1.25338 1.45622 0.979274 0.983462 1.13108 1.2393 1.54339 0.842593 1.75855 0.792522 1.55556 0.820865 1.57508 0.941797 1.23097 1.23072 0.563546 0.544762 0.369135 0.272747 0.79 1.51846 1.36818 0.619792 0.769336 1.21037 0.415836 0.88439 0.994645 1.17821 0.377433 0.855258 0.829545 0.657716 0.435242 2.11608 0.942111 1.27604 0.74576 1.03196 1.07306 0 1.25655 0.812303 2.85251 1.4162 1.69442 1.01567 0.872111 1.04178 1.0125 0.735372 1.29675 1.01324 0.796648 0.606995 0.439043 2.09246 0.289608 1.19662 1.05988 1.96138 0.995003 0.777291 0.662836 0.933832 0.97792 0.76644 1.04805 0.974547 1.05463 1.0299 1.24302 0.712783 0.658999 1.56965 0.868752 1.71184 1.69637 0.812519 0.869438 1.09557 0.813329 1.21377 1.47812 0.670575 1.07817 0.727311 1.15748 0.707289 1.79889 0.725424 0.978093 0.489668 1.72584 0.591894 2.33383 1.34006 1.70685 1.0102 1.17686 1.073 1.37213 0.940618 1.27283 1.23324 0.62477 0.890668 1.26191 0.962068 1.65238 1.39521 1.89336 1.07653 1.38861 1.60599 1.37579 1.03938 0.638399 1.55139 1.75064 1.36112 1.43223 1.45238 0.615345 2.07757 1.11711 1.18714 1.2516 1.04406 1.10182 0.943658 0.817656 1.06688 1.37538 0.933741 1.02164 0.792444 0.745442 1.56556 0.701907 1.43878 0.866189 0.740364 1.27969 1.37255 1.3987 1.61193 1.52379 1.42735 1.58832 0.976627 0.707731 0.958741 1.10548 1.33542 1.13566 0 1.6224 0.997475 0.689811 0 1.73507 0.947185 0.89989 1.19029 1.4271 1.20962 0.701892 1.51871 1.3021 0.245834 1.18998 1.36736 1.02668 0.708524 1.37301 0.854856 0.962881 1.48612 1.02511 0.890503 1.45562 2.1678 0.572462 1.73638 1.37625 0.909212 1.51498 1.37566 1.23771 0.750023 1.06746 1.21875 1.08229 0.719508 1.70316 0.757886 2.31446 1.45835 1.33708 1.2765 1.4667 1.29471 1.51208 1.51297 0.793254 0.821329 1.55655 0.928697 0.681494 0.608721 1.15326 0.759974 2.24854 0.816274 0.466808 2.14298 1.28998 0.971841 1.29349 1.1012 1.7248 0.942423 0.723875 0.724039 0.67928 6.17871 2.72128 1.55356 2.46622 2.22981 1.39587 1.31637 1.0887 1.50075 1.45268 1.40533 1.10338 1.01263 1.01854 0.531749 0.38554 1.50526 1.99888 0.65562 0.805881 0.895746 0.784431 1.2495 1.40763 0.976405 1.19743 0.506059 1.3357 0.97695 2.50593 1.86683 0.889444 1.66102 1.07969 1.19136 0.684408 1.7064 1.99445 0.724672 5.2961 1.71681 1.08587 1.92762 1.22349 0.963628 1.31126 1.18172 0.881692 1.11239 2.01941 1.27814 1.26778 1.11221 1.03639 0.4939 1.15664 0.827753 1.47789 1.40319 1.18674 1.6094 1.95886 3.04397 1.16773 0.901449 0.712583 1.61524 1.18624 1.40178 1.79116 0.878881 1.40769 1.47638 1.23683 1.29649 0.79125 0.588497 0.885626 1.26711 0.97227 1.00546 0.968646 0.869964 1.64366 1.38804 1.01331 0.702218 1.65091 0.87825 0.990448 0.924529 0.962259 1.72638 1.55637 1.69955 0.780548 1.30382 0.882003 2.08985 0.958403 1.95352 2.02306 1.005 2.16171 1.55801 0.83807 0.570606 1.11036 0.845306 1.07546 1.17101 0.536839 0.916195 1.63017 1.38667 1.66095 1.34014 0.725768 1.25268 1.14039 1.17015 2.49058 2.47053 1.37763 0.855602 0.963327 1.07157 1.17574 1.28943 1.55869 0.814293 1.49783 0.611348 2.79009 1.22504 1.96512 0.566637 1.16058 0.768497 1.84511 5.23432 1.50898 1.01497 0.774804 1.68727 2.03524 1.84319 1.09612 1.50458 0.748545 0.669056 0.868788 1.34163 2.3228 0.83265 0.903179 1.33179 1.01623 1.09935 1.38156 2.42661 1.01634 1.42512 1.26832 1.29198 2.03715 1.15521 0.779392 1.39065 1.15819 1.99305 1.02579 2.10967 1.46347 0.654069 1.06375 1.68425 1.99711 1.96498 1.21244 1.10979 0.86156 1.3994 1.67853 1.89878 1.60953 1.13323 2.60965 1.27761 1.6409 1.84115 1.38337 0.717956 1.02562 1.51771 1.27615 0.985905 2.05023 0.852818 1.08696 1.06527 1.93197 1.30918 1.66851 0.920633 0.949085 1.31395 1.42667 0.873147 0.736192 1.9499 0.751451 0.670188 0 1.57739 1.34633 1.2847 1.03449 1.69896 1.08716 1.23129 0.740121 1.08037 1.10256 1.0387 2.62919 1.757 1.58187 0.981524 1.6172 1.37497 1.44807 1.14638 1.18199 0.992246 1.09872 0.871187 1.78678 1.59669 0.502317 1.96552 1.48742 2.41968 1.47388 1.46263 1.59583 0.678159 0.806652 2.3056 0.648543 1.70744 1.52457 1.98331 2.17529 1.76822 1.29376 1.27647 0.651085 1.13377 1.1964 0.87644 1.12522 1.87774 1.55812 1.36905 1.07877 1.20757 1.71824 2.24912 1.18439 0 1.1947 2.77184 0.79429 0.777571 1.69933 1.13042 0.785372 1.26023 0.486011 1.51047 1.01502 1.11803 1.26941 1.44916 1.49192 1.33602 1.39879 2.44701 1.57859 0.75946 1.00426 1.02369 1.98061 0.997075 0.995143 1.89616 1.428 1.08145 1.56033 0.869242 1.34733 0.861709 1.41057 1.8208 3.43266 1.8225 0.828654 1.08428 1.01025 0.495366 1.1139 1.93077 2.04968 1.0624 0.669406 1.5058 1.36163 1.2004 1.48659 1.09009 1.30122 0.862912 1.08956 1.26361 1.40524 1.37604 0.866063 0.748254 0.904603 1.60729 1.92312 1.12754 1.69874 3.82903 1.19117 1.15835 0.693966 0.732935 1.06106 0.522476 1.54408 1.41634 1.157 1.49954 2.57092 0.944842 0.74881 1.6845 0.797167 2.1421 0.98541 1.24597 1.14375 1.53583 0.863278 1.29656 1.5632 1.65643 1.52148 1.04754 1.37142 1.75578 1.41968 1.02164 2.97422 1.1477 1.3803 1.25396 1.66625 2.41124 1.43101 0.953903 1.1234 0.933811 1.49662 1.42017 1.27875 1.02377 0.900437 1.70401 1.59842 1.88203 0.820359 1.64295 1.67429 1.29595 1.56755 1.5569 1.09862 0.76704 1.47228 1.45159 1.49492 1.88116 0.734522 0.785302 2.71635 1.47945 1.72751 2.3508 0.946161 1.35825 1.99439 0.982982 1.72207 1.26123 0.924318 1.63093 1.34045 2.12289 2.08637 1.39338 1.60141 1.45966 0.489363 1.22173 1.01695 0.977732 1.54793 1.25257 2.32232 1.22434 1.17587 1.02337 0.808803 1.55102 1.1044 0.864083 2.64242 1.79324 1.10694 0.972427 1.88564 0.862622 0.775938 1.73057 1.71486 0.972181 2.96149 2.43474 11.2047 1.7949 0.750503 0.405243 0.780181 1.55396 1.86655 1.9718 1.2511 0.772266 1.15348 0.918574 0.800356 1.76601 1.55226 2.899 1.18226 1.45226 3.44854 1.72526 1.25413 1.44747 1.36449 0.750608 0.65639 1.87384 1.87694 1.33099 1.12081 3.50575 1.43976 1.31458 1.07946 2.00139 1.46797 1.09765 3.60305 1.70188 0.821546 2.00101 1.87306 0.758646 2.00159 1.13278 0.844016 1.83161 1.63131 1.3633 1.55298 1.26545 1.68434 1.06628 1.38554 1.22332 0.789344 1.44431 1.15818 2.52009 1.01737 1.23805 0.894046 0.756326 2.34056 1.15596 1.00732 1.03946 1.35465 0.865384 1.70533 1.17335 1.01786 1.48898 1.39658 0.819448 1.31905 1.77577 0.920317 1.14422 1.65816 1.80176 0.845101 0.878051 1.07884 1.7188 1.56941 1.15058 3.32044 0.913773 1.08561 1.2662 1.24977 1.62387 1.57854 0.80159 1.02672 1.58848 1.06088 0.83474 1.09933 1.03663 1.65666 1.9046 1.71708 1.03789 0.991091 1.70954 1.50923 1.94895 1.95092 1.1467 0.547172 0.788986 1.48683 0.945354 1.85727 1.06321 0.838362 1.36054 0.902893 0.572581 1.08141 1.23193 1.62014 1.64617 1.39075 1.6441 0.951914 1.31455 1.18078 1.64173 1.17474 1.48842 1.29755 0.577633 1.51208 1.40337 1.49155 2.17715 1.89785 1.22649 0.955312 0.944414 0.68767 0.731544 1.62117 1.61109 1.38357 1.86071 1.25249 1.19493 1.25091 1.70996 1.0413 1.55404 0.981777 2.00988 8.80478 1.18291 0.833724 0.908107 1.97307 0.733467 1.63282 1.36662 0.625513 1.13213 0.846955 1.21994 1.33544 1.07727 2.01297 1.83688 1.48136 1.03355 2.38295 1.00094 1.35159 2.23872 1.26428 0.953418 3.18624 0.793197 0.802034 0.699962 1.89081 1.2097 1.3833 1.12184 1.63652 1.60841 1.5748 1.21874 1.59316 2.32079 1.15026 0.776728 1.34708 1.09151 1.37895 0.896167 1.41377 1.64018 1.2435 0.769554 0.694681 0.924183 0.924955 0.872922 0.822732 0.982088 1.05093 1.54924 3.25393 0.749663 0.922081 1.76246 0.871338 1.0301 1.34137 1.13094 1.36176 1.01892 0.751228 1.0138 1.20287 1.68414 0.905493 1.43373 1.35799 0.954064 1.62512 2.42336 1.82159 1.71963 0.587144 1.29154 1.29075 1.21247 2.0174 0.969816 1.88926 2.21421 1.32544 1.58688 1.07627 1.78018 1.36456 0 1.81682 0.943212 0.88598 0.878856 1.40693 0.923423 1.22643 0.792891 1.7419 2.68826 2.83376 0.887348 2.11365 1.06135 2.62787 1.1633 1.49909 2.07856 1.69791 1.07795 1.66877 2.41676 1.61493 1.17821 1.84475 1.15712 0.831851 2.07852 0.884268 1.75289 1.6379 1.49312 1.11817 0.996578 4.1251 1.45492 1.11524 0.691267 1.2032 1.05157 0.933384 1.65944 1.41981 1.98148 1.39814 0.991833 1.2788 0.682769 1.7676 1.39879 1.1962 1.32631 1.24192 1.48676 1.17722 1.18947 1.67585 1.4783 0.761858 0.881782 2.69821 1.81462 1.73852 1.29966 1.68548 1.6833 1.62257 1.36842 1.11255 1.30681 0.87386 1.76564 2.80441 3.66917 1.16178 1.061 1.64918 1.4373 1.11805 1.74156 1.18517 3.03177 1.71837 1.30482 1.95722 1.17183 1.50752 1.00175 1.46404 1.57941 1.69422 0.779696 1.58555 0.738491 2.06086 2.64323 1.97224 3.61111 1.10502 0.919997 1.64499 1.4329 1.12352 1.1071 0.726637 1.29757 1.2563 1.50221 0.734218 0.857756 1.63934 1.63976 1.61212 1.74088 1.06765 1.51602 1.05466 0.689112 2.56812 1.68521 1.63726 0.72472 1.17729 0.77586 2.22074 1.45745 1.11831 1.45371 0.836566 0.981544 1.14534 2.77631 1.11488 2.15323 2.585 0.585138 0.832882 2.32311 0.931028 1.49805 1.82758 0.870763 1.67114 1.01569 1.82692 2.12659 1.42312 1.98448 0.792422 0.53377 1.16539 0.905356 1.69389 0.889627 1.60898 0.893486 0.811564 1.12786 1.34994 1.41429 2.61562 0.960465 0.945121 0.824797 1.00021 1.99442 1.3349 1.00415 1.23065 0.874576 1.94532 1.97668 1.25649 1.41454 1.4722 1.27653 0.657115 1.28766 1.2763 2.13866 1.64268 1.17643 1.63976 0.771245 1.52961 1.27481 1.15799 0.803927 1.1558 1.72746 1.46467 1.8411 1.73343 2.73899 1.11745 1.12844 1.94706 0.766238 1.09983 2.23346 2.39655 2.05849 0.86149 1.1072 1.16729 1.23956 1.27908 0.998204 1.63331 0.801339 1.673 0.567171 1.1503 2.10239 3.27596 3.21122 1.62281 2.4162 1.34519 1.28568 1.0079 2.16381 1.18555 1.89405 1.06104 2.40017 1.54252 0.797703 1.60247 0.640523 1.16534 1.2541 1.89334 0.646748 0.994998 1.53769 1.27045 0.764508 1.32657 1.11153 1.18698 2.01416 1.65168 1.38928 1.66212 1.3085 0.969166 0.98676 1.40782 1.39562 1.29137 1.30198 1.30695 1.07559 1.50058 2.09563 0.901335 1.26314 1.44941 1.44166 1.81862 0.946666 1.46537 2.25595 1.68653 1.15877 1.16363 1.0375 1.16206 1.50507 1.42369 1.17307 1.41239 0.883322 2.1567 0.757397 1.12615 0.707551 1.0508 1.15037 2.11732 1.99227 1.87253 1.88558 0.984879 1.15589 1.29171 1.61859 2.03859 0.990108 1.03829 0.708747 1.08618 1.13642 1.1577 1.58185 1.61352 2.12193 1.5093 1.43609 1.48305 1.03792 0.7196 1.21637 1.50334 1.20994 0.713346 1.38424 0.928239 1.2425 1.45684 0.87895 0.674089 2.29746 1.2268 1.90802 4.19424 0.925571 1.48423 1.29829 1.38798 1.36822 1.22832 0.962887 1.47987 1.17598 1.96587 1.78581 0.83541 1.40212 1.45548 0.665376 1.84041 1.28941 1.71312 0.762268 1.84899 1.1223 0.640151 1.10405 1.62508 0.907276 1.96399 1.08359 1.54563 0.744875 1.04699 1.21724 1.09566 0.960578 1.4011 2.13473 1.01691 1.67644 1.35104 1.48922 1.69585 0.96602 1.35989 1.05583 1.8932 1.28071 1.20268 1.10073 1.77362 1.45059 1.36214 2.25102 1.5437 1.88277 2.16088 1.46695 1.08631 0.936767 1.06178 1.84748 1.15395 1.76484 1.16864 1.23442 2.0474 1.58287 1.20006 1.16108 1.65203 1.53031 1.93756 2.65889 1.13269 2.37471 1.19841 0.870224 1.38041 1.3265 1.67835 1.29573 1.66486 0.615704 2.19084 1.00666 1.29612 1.02852 0.504485 2.07276 1.55024 0.782076 2.52551 1.34886 2.81332 1.91158 1.76391 1.86953 1.81896 1.36352 1.6223 1.36797 1.20915 1.38871 0.972623 1.25953 2.37033 2.13811 1.14645 1.4069 1.30908 4.53383 0.905595 1.58599 1.59425 3.35281 2.11601 1.74633 0.776453 1.90424 1.03014 1.13639 1.88869 1.26185 1.81561 1.37423 1.49579 1.35461 1.55523 1.12493 0.760289 1.70649 1.29575 0.720333 1.212 1.57786 2.32258 1.16128 1.09617 1.16452 1.65475 1.31367 0.78929 2.90625 2.03887 1.78495 1.28184 0.607556 1.42012 0.972335 1.38375 1.36473 1.37272 8.88554 1.0293 1.44001 0.897059 1.03019 1.88054 1.519 0.956495 0.997152 1.37633 1.36897 1.97002 0.539681 1.14646 1.28259 1.73251 1.53984 2.06368 1.19434 1.34962 1.40063 0.685625 1.06973 2.03635 1.33762 1.7534 1.18168 0.958332 1.46616 2.21519 1.19804 1.43561 1.63774 0.733836 0.601231 1.18953 1.55435 1.59787 1.33132 1.10661 1.21972 0.947853 1.80307 2.17154 2.07225 1.09078 1.30829 1.17571 1.16512 1.78361 2.8049 0.971156 0.665043 1.56061 1.49711 0.911385 2.73946 0.787386 1.12424 2.86865 1.11872 2.21412 0.672183 0.569027 1.63348 1.35872 1.38313 1.53932 1.80176 0.870588 1.0519 1.82254 1.87279 1.80494 1.54993 1.59961 1.97374 1.49549 1.7029 1.10315 1.56493 1.39184 0.850993 1.62629 0.989831 1.32003 1.53868 0.937128 0.907721 1.86944 1.43095 2.04748 2.61724 1.27243 1.46516 0.96246 1.24474 1.58833 2.04842 2.04402 0.83968 1.26163 1.04569 1.9243 1.66765 1.22751 0.855154 1.74408 0.968888 1.91786 1.1961 1.0407 1.26091 1.39774 1.55565 2.24534 0.949154 1.72644 1.51244 0.882569 0.47463 0.981559 2.50213 1.10093 1.42755 0.56582 1.70194 1.60109 1.57877 0.982388 1.29034 2.81185 1.53605 1.10738 1.44207 1.24681 1.33291 1.28501 1.20013 1.86799 1.38896 1.95794 1.0867 1.24211 0.926462 2.31433 1.33601 1.10539 1.07406 1.08092 1.3322 1.40256 0.899661 1.13413 1.53858 1.34465 1.30341 1.4853 1.79994 1.10075 1.07623 0.746655 1.08741 2.53123 1.00739 2.42361 1.7535 1.81342 0.430144 1.66768 1.23074 1.14053 2.1361 1.56079 1.25509 0.985329 0.923599 1.11521 1.65561 1.2809 1.36169 1.06567 1.24372 1.21158 0.921605 0.779893 2.31991 1.32449 0.663667 1.20544 3.02947 1.53868 1.17042 2.33226 4.17322 4.18272 1.39824 2.28375 2.49751 ]
@@@ Frame-accuracy per-class: [ 80.7996 60.9105 77.2603 62.069 66.6667 63.8298 44.0678 77.3131 71.6332 46.9799 84.8896 33.6842 79.8392 77.0318 29.6296 70.2703 68.1018 73.3624 69.4864 55.0336 70.2341 71.6628 66.6667 57.7657 51.4076 75.3623 46.5608 74.5418 46.0177 73.183 51.8201 71.5262 66.8258 70.0637 82.3893 84.8614 90.5284 94.0727 77.43 61.0039 61.5385 86.9565 77.037 55.0459 87.7684 75.6014 68.9076 66.6667 87.6054 69.535 68.4192 82.4903 88.5358 28.2927 70.6366 66.1224 78.4185 67.5105 71.4849 0 62.3256 75.5064 22.2222 58.4615 47.0588 71.6763 75.154 55.6522 74.0238 76.7624 66.436 71.2395 76.4602 79.4425 86.6781 37.1041 90.2256 64.918 64.6465 59.2593 67.9543 75.0809 80.0446 77.3034 74.7445 82.9268 66.2913 72.0257 67.1378 75.9124 58.8235 78.853 77.1037 51.6517 71.0952 65.2482 51.3595 71.4563 73.9726 68.1081 73.3668 62.8099 54.2373 79.084 68.9908 79.5322 70.1754 81.4249 64.5161 77.13 72.2892 86.5275 47.7193 83.6048 29.572 59.3548 52.2088 63.9594 62.8571 65.8579 57.6271 72.4324 62.6781 61.1684 79.5322 75.1592 63.3907 73.2394 42.4242 56.705 47.343 64.2487 59.2734 54.0284 58.5366 67.3684 84.0336 56.5854 44.2688 58.2677 61.6052 54.0146 82.3904 42.328 61.0329 65.1163 67.6123 58.8235 62.6506 71.848 76.1246 72.6368 60.6811 73.0964 71.8802 72.5275 77.5599 42.6966 81.3559 60.8696 74.4186 77.5056 61.0405 66.3755 53.7815 48 50.1511 60.6061 57.072 62.8099 80.8362 72.8324 62.1849 68.5579 64 0 52.349 70.6605 77.9841 0 49.919 74.8603 79.3388 61.8557 60.1869 54.5455 80.3493 45.9016 62.9885 95.5032 67.6259 66.2722 75.3623 79.8834 56.1702 77.8468 76.0181 51.6291 71.3805 75.2784 53.717 23.8806 85.4003 51.0029 62.5337 70.6468 58.2278 56.1404 66.1896 77.8711 67.1727 63.0137 71.2401 77.8816 48.8889 76.9716 35.2159 59.0674 64.4898 68.2635 58.7413 59.2911 58.8235 56.6735 72.8435 78.7597 52.2193 70.7224 76.7123 80.9461 70.3297 79.1111 36.6864 73.6 86.3309 38.0952 57.7259 71.1111 60.7903 69.8947 44.5131 74.8815 76.5957 77.0043 81.4645 9.30233 16.4251 48.9914 32.4786 45.0512 56.8306 53.2374 69.4836 60.6272 56.2874 62.1849 65.272 69.8908 77.9661 85.12 89.1967 51.2077 46.7368 81.6153 76.0692 76.1905 83.0409 65.6151 54.6584 72.0978 64.3875 90.566 63.2588 65.1757 35.7683 43.0189 72.3404 41.4201 65.4545 62.4113 79.8859 49.0879 46.7043 77.5385 0 47.9616 71.4734 39.521 67.2646 72.8033 59.2 63.9309 74.6922 68.6371 40.367 65.4971 62.8931 65.3595 70.6231 85.6269 61.8474 74.8405 61.7414 52.5822 51.5464 47.7366 41.0256 23.4818 68.9362 74.1818 83.7758 55.1237 59.6226 57.3932 45.815 70.9677 64.4068 50.1961 70.5882 60.8342 76.512 84.9807 71.8101 65.7825 74.1855 69.7143 73.0539 73.5751 51.1628 64.2336 73.4463 79.4937 45.8716 77.13 71.3911 77.8589 70.6685 65.1685 60.2151 44.843 75.0751 63.5193 72.9825 45.7143 72.211 37.8378 33.9623 74.7253 42.1941 57.1429 78.6596 84.0989 68.5446 72.5702 65.4206 63.3484 85.623 74.6411 44.1558 66.3391 53.3333 67.9612 80.2314 65.7391 81.9672 58.8745 29.7578 38.2979 57.7896 80.1865 74.9578 68.6567 72.1311 65.3465 56.7657 76.6861 47.4576 84.9858 32.7684 70.0252 55.4913 84.7059 82.9268 87.9227 49.652 0 53.9924 74.6667 80.7512 47.8528 57.7778 56 68.1716 54.8287 83.004 81.549 72.7273 69.1358 35.4286 80.829 74.5299 66.6667 70.5376 67.673 59.2445 29.9401 67.1533 60.4255 65.5602 59.7156 29.2335 64.7564 78.6325 68.2927 61.7886 48.8189 72.2467 39.6396 55.3191 79.2291 71.8232 58.0153 38.0952 32.7485 65.3367 66.1258 74.4027 53.0184 52.9524 33.8462 53.0973 67.6157 29.9625 57.0025 41.2371 58.5366 60.5744 77.533 72.2753 53.9007 75.8621 69.6296 42.8094 76.0456 67.5192 71.1744 46.6859 58.5366 47.2574 68.0702 70.073 63.4146 56.4885 72.428 80.5275 43.4783 77.4312 82.1145 0 51.9393 55.2036 66.9323 71.028 53.7931 71.3178 63.9618 85.1064 66.6667 65.9341 67.2065 21.1765 37.4384 58.7413 75.0357 57.3427 60.3774 56.3193 68.3544 70.4762 74.1573 74.5247 75.2475 41.4201 54.5455 88.478 41.0256 69.3333 33.1707 58.3851 61.7363 50.8172 79.4795 78.2965 40 79.2332 53.012 51.9362 41.7582 32.5581 44.5765 57.9564 60.3774 79.2453 74.5763 62.94 76.4977 68.1898 42.963 59.9119 55.1724 67.2811 66.6667 49.6386 40 63.5155 0 60.8838 27.3859 80.9365 73.4694 51.6556 69.9764 83.4532 64.0884 85.7143 55.6962 73.4694 75.3247 68.4058 58.5366 50.4505 58.3732 57.7181 29.393 56.8233 78.453 70.3448 67.7966 29.0909 73.3032 69.4864 44.3439 65.1163 73.7255 49.5575 66.6667 62.203 76.9691 59.1497 46.9799 0 39.2727 79.3522 67.0906 74.4086 86.9785 68.3047 46.4 38.5542 74.1433 83.2653 57.1429 67.4847 64.2643 57.5875 76.5432 51.3834 76.4179 71.4549 69.5481 59.366 58.427 79.8635 78.2866 76.5328 59.502 52.8634 66.313 44.9511 12.1212 57.1429 69.3878 79.0274 75.4098 71.1111 86.2454 51.8519 72.7273 63.7899 59.9445 21.0526 76.7962 78.1671 52.6703 78.6885 52.4272 72.5664 65.1208 65.123 51.4139 76.4398 59.3156 46.729 55.5891 50.5747 69.7337 60.788 53.2374 69.3333 71.5084 19.0476 62.3094 65.2291 69.9454 52.356 23.6559 58.5242 71.9187 66.2474 73.1707 61.9289 65.6489 64.0884 68.7697 74.0472 42.9448 53.6585 49.47 73.6508 56.6038 52.3691 63.8436 49.2754 48.1283 63.7555 75.4893 59.0038 55.6348 53.5565 51.6129 75.7764 79.7428 22.4 46.0274 53.5519 34.965 76.6434 65.9898 43.7956 73.7391 57.7778 63.2201 70.6949 43.771 56.4885 36.5449 43.6782 56.4103 55.3102 59.4175 90.9091 59.5556 70.936 68.8852 65.0307 71.5232 30.303 65.6 63.6637 74.0741 77.9221 50.7772 63.0225 76.9231 30.5677 48.318 71.0744 74.8387 41.196 83.5821 74.1688 51.8219 51.6364 73.1707 22.2222 37.3057 0 50.3365 77.2816 90.1252 79.2453 51.2315 39.0244 35.8974 64.9156 77.7328 66.463 67.7165 77.6806 53.7634 63.7037 26.087 75.4098 66.2577 19.0476 52.8736 61.0422 57.4949 60.1227 77.9841 78.7402 43.2787 52.6316 69.1824 82.9268 26.087 60.3839 63.8037 69.3069 45.9259 56.3107 69.962 21.4765 57.1429 77.1536 38.4977 48.7562 80 40 63.2911 75.0583 51.3369 58.2633 64.8199 59.0022 64.5669 53.9945 64.2254 52.8678 64.877 82.9493 62.2568 65.8098 27.3764 70.0162 69.1943 73.2644 80.4124 31.5789 80 74.2156 66.8281 62.4339 81.9277 49.1682 64.6048 68.7593 48.2972 57.8512 78.3042 58.7973 54.1353 71.1864 70.0587 53.8071 43.4316 75.3994 74.6667 66.6667 48.5523 48.8778 71.1974 34.7826 73.3189 67.6533 65.7534 63.5789 56.6234 62.2837 78.7097 72.5389 55.1724 66.7961 79.4045 69.1511 66.6667 48.7085 47.7064 54.321 71.0125 71.7557 51.4523 56.7901 40.7643 42.1622 64.2263 86.8895 74.6365 54.3081 76.3533 51.8919 70.4309 78.8512 58.8235 78.6885 85.1385 65.5949 66.6667 53.1959 55.0725 64.0264 55.1724 68.7117 69.5652 70.5637 47.7987 67.7003 63.4667 56.4561 81.3864 59.3407 58.9862 57.9634 31.8408 52.973 66.7602 74.4589 72.9412 79.0419 81.5884 57.3477 51.2315 61.7406 59.2593 58.0311 68.169 64.825 48.3412 69.9473 68.5714 68.1704 40.1544 0 62.3306 79.0303 70.8595 44.5498 78.1979 53.9792 64 81.6327 68.268 76.1026 66.6667 58.748 69.526 40 41.4938 52.6316 68.3636 22.8571 68.4039 60.793 46.4865 75.2137 72.5367 25.641 74.8582 77.534 77.6048 28.1081 65.8754 60.3774 68.7747 57.8269 53.7634 58.5987 65.4434 54.2466 19.8758 66.2831 73.9496 63.0915 70.0965 60.3175 76.1421 61.2378 56.1194 66.0633 78.9144 79.0823 74.0741 73.0022 67.2269 72.2793 65.6085 62.0525 55.6237 0 82.7948 68.0135 44.1948 74.8682 75.8621 68.3274 68.3417 60.3636 66.0633 78.3848 72.4521 66.2762 50.2857 72.8016 58.8832 62.439 72.5462 54.1833 17.8218 54.6939 39.8467 81.5725 65.2361 54.5455 63.622 36.5897 72.81 42.5532 34.8584 63.1579 52.3364 72.4832 41.3793 61.3139 0 51.2535 71.773 73.9785 75.9494 71.161 74.9226 57.5916 76.4092 57.0533 22.8571 16.2162 76.3407 50.8361 64.7482 22.9391 67.086 64.1115 22.2222 53.9535 69.0691 49.8567 30.9677 58.2677 67.42 46.8401 64.3678 80 46.3576 72.2555 46.5672 47.3563 48.731 66.3507 68.8372 13.3333 70.4225 66.6667 80.597 67.4923 70.3476 73.5729 48.5876 61.1399 49.6644 58.7896 76.2457 67.8899 81.4414 52.5745 58.2524 60.4317 60.0332 59.542 53.3762 63.0631 64.9682 42.1053 55.9441 79.1789 70.9382 39.0805 48.6486 50.6667 59.2593 56.5598 51.7333 52.6946 58.3826 69.9647 62.2951 73.0964 39.604 40.1434 14.1732 68.6804 68.3544 48.7026 60.1325 73.1707 43.9024 68.6469 9.90099 49.1979 62.2328 42.9268 70.5882 56.9536 73.3447 65.8824 57.8249 44.0433 79.2711 56.5161 78.9346 44.4444 28.2353 39.4464 14.9533 67.7323 76.3025 50.6122 57.5342 66.0317 66.4452 80.7496 51.4286 66.6667 61.2546 79.2079 78.3626 48.319 46.6899 55.0049 56.0579 65.643 60.8696 71.0462 79.536 49.1803 51.2733 52.6841 77.9014 62.7949 77.6196 44.4444 56.0886 70.4871 51.6957 72.8148 74.0299 66.3529 32.4324 61.2691 50.1319 11.7647 83.1169 79.5244 38.1963 72.4559 64.2202 46.3804 77.8281 48.1203 76.7213 55.1724 36.1644 57.1429 55.3191 77.4194 83.6763 68.2667 70.9529 57.8723 74.012 53.8283 77.398 80.0718 65.8281 58.5366 59.695 36.9501 72.3596 75.9961 74.5405 73.6706 54.5455 57.6271 75.2768 66.8354 73.716 48.1675 47.767 61.3936 56.3193 60.1279 65.6394 79.8922 63.1922 62.5624 47.7987 53.4606 67.1256 55.7823 81.5166 58.3732 61.0282 69.5652 75.8621 60.1399 50.9532 61.2613 51.6505 56.9975 31.8043 76.8362 72.9097 47.0219 74.5491 69.8305 38.9513 42.0048 46.2921 79.0091 68.4492 66.8094 55.2147 60.7004 71.5328 49.6241 79.4582 48.6188 84.1026 63.4383 37.2093 23.301 21.4634 50.7937 32.8889 68.4685 61.8182 70.8117 33.0827 69.8413 50.4931 67.6692 44.8687 56.1983 85.3147 56.8306 80.3695 63.1179 62.603 43.5798 80 68.9337 53.3333 62.1359 77.2384 58.3942 62.9333 62.4506 43.3498 53.4923 56.4384 55.914 71.9101 72.6727 71.7949 59.0604 66.3755 64 67.8967 61.5917 70.7457 49.5298 42.8184 73.8068 71.7557 57.8249 62.6263 47.4708 74.9186 54.902 29.1262 57.5693 68.7161 70.377 73.8956 73.9336 54.321 53.5637 70.7071 61.1418 74.6583 31.769 78.0952 66.6667 83.871 71.3178 64.9046 43.6681 29.6296 46.9565 47.9042 73.5178 63.4697 64.64 54.2529 44.3804 53.7078 73.8916 80.4233 69.9588 70.5882 69.8795 54.902 56.9288 47.6821 50.9804 61.6393 57.3913 70.9898 78.3505 66.6667 49.635 62.2478 80.767 60.4651 76.5499 73.3945 48.218 67.4847 82.7977 37.8947 63.5438 49.7914 23.2558 73.7401 57.5053 63.1101 57.9679 58.9235 62.6866 78.0269 51.8239 68.8705 40.5797 56.4706 77.7583 56.3798 64.5963 82.2989 45.5696 62.7566 50.7772 81.5629 44.9905 69.0909 83.1346 72.7273 49.162 73.6661 44.9198 68.7697 51.6854 78.2247 71.599 61.7535 70.1382 69.4394 56.6125 35.9249 74.2857 56.7442 61.6774 61.7143 55.6391 67.4203 66.3342 71.3306 44.3243 58.5132 69.0355 65.9341 45.3333 55.4156 62.3441 34.9515 66.2252 44.898 37.8698 59.1093 71.345 72.7638 71.1744 49.8943 70.229 56.6845 68.2028 62.069 47.2727 56.0794 61.5247 65.4655 60.3279 59.5318 46.9274 20.2817 61.5385 40.3756 67.5159 77.2394 58.4845 55.706 51.5284 63.3166 46.8966 81.8349 42.5249 73.029 68.5817 68.0203 86.747 42.1053 51.2821 76.881 34.1556 65.9176 32.4638 58.1818 56.7951 44.4444 44.2334 63.0588 53.012 65.5738 67.7237 65.1163 71.5232 65.3595 39.8467 45.3333 67.6923 60.5714 66.4247 13.1868 72.2533 58.0645 52.6077 14.9378 35.9712 49.9139 80 51.1628 69.9725 66.313 44.0191 69.8947 49.1545 59.3789 57.6744 59.4059 55.2113 69.3467 76.9231 45.6609 62.0896 77.5309 65.8574 51.1945 40.2496 62.94 70.0855 66.3185 58.9147 64.986 76.7249 24.6696 38.5965 51.4469 68.3371 85.6269 63.658 73.1392 60.4082 52.6912 61.8926 0 63.8146 53.4296 74.772 72.5926 47.9233 61.5385 73.6342 68.7747 65.5654 57.4394 38.806 81.1525 69.496 65.6604 58.0913 55.8025 52.514 73.2673 62.5259 53.7089 84.4444 70.0611 47.619 62.5837 49.3947 62.9921 72.429 59.0826 34.1737 64.4518 55.7276 61.8182 77.2979 83.3882 70.9677 50.2564 58.9862 64.9496 68.6941 66.9131 75.6672 49.2264 53.4759 40.5229 70.0143 61.1872 65.7097 68.3386 47.8632 9.52381 72.4796 79.1128 58.1818 59.5611 74.7226 29.3839 78.6469 71.8615 32.0413 60.5166 34.965 83.0372 84.1735 53.8012 63.8003 58.466 54.2459 55.4386 81.1715 73.1563 53.3333 53.6264 43.4316 58.3784 57.1056 39.1167 56.1308 46.1538 75.5162 53.5065 59.0085 74.3989 52.6459 77.3639 64.0483 65.9498 79.1762 71.0425 40.2367 63.0728 40.3756 38.806 63.5452 61.0329 76.5432 68.5714 57.1429 47.9279 49.3225 78.9189 62.8571 71.4065 41.5771 51.2111 56.0907 76.6551 46.0094 72.4528 56 60.1156 69.6538 71.0204 57.7406 49.6674 43.9716 72.6841 43.7995 53.0504 70.4805 88.2883 71.5564 26.6667 67.6106 56.1873 83.7075 56.057 58.2996 52.4017 75.8842 64.7754 25.2632 63.2391 69.8603 54.9654 61.0169 60.6061 66.9623 71.7201 49.2147 60.5187 47.9495 69.9858 59.4522 74.3935 34.8432 60.8414 69.4714 67.1202 69.7406 65.5647 62.4697 76.9231 70.1031 57.6687 63.7168 64.5669 60.2637 56.0554 68.3834 73.8739 78.6106 73.3138 25.8373 72.0403 38.914 54.0881 56.9832 84.5283 51.0949 60.9509 68.9655 50.4673 58.0132 60.7069 75.7991 76.0291 68.9459 55.2017 54.0541 59.6803 69.9647 63.9175 67.3317 72.9642 78.7097 42.3529 65.3244 78.2281 61.5293 16.8421 56.6929 64.8318 29.2683 3.38983 13.3333 61.0526 34.1463 31.405 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 1.13757 (Xent), [AvgXent: 1.13757, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 67.2374% <<

