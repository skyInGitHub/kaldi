nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.008 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter01_learnrate0.008_tr2.7636_cv2.4547 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter02 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11887M, used:305M, total:12192M, free/total:0.974986
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.2475, max 7.77538, mean -0.00464958, stddev 0.983373, skewness 0.0162194, kurtosis 1.92828 ) 
[1] output of <AffineTransform> ( min -25.1975, max 15.7254, mean -3.21633, stddev 2.89352, skewness 0.158725, kurtosis 1.71671 ) 
[2] output of <Sigmoid> ( min 1.13993e-11, max 1, mean 0.157035, stddev 0.255478, skewness 2.00204, kurtosis 2.96354 ) 
[3] output of <AffineTransform> ( min -26.5633, max 16.6166, mean -3.7488, stddev 2.53077, skewness 0.0478769, kurtosis 3.18351 ) 
[4] output of <Sigmoid> ( min 2.90867e-12, max 1, mean 0.0990164, stddev 0.19076, skewness 2.98615, kurtosis 8.89759 ) 
[5] output of <AffineTransform> ( min -15.5379, max 12.42, mean -3.22833, stddev 2.02557, skewness 0.794931, kurtosis 3.03299 ) 
[6] output of <Sigmoid> ( min 1.78645e-07, max 0.999996, mean 0.107342, stddev 0.193061, skewness 2.92535, kurtosis 8.49631 ) 
[7] output of <AffineTransform> ( min -24.1467, max 15.8013, mean -3.22338, stddev 2.27426, skewness 0.639632, kurtosis 3.93853 ) 
[8] output of <Sigmoid> ( min 3.25996e-11, max 1, mean 0.119295, stddev 0.213397, skewness 2.63167, kurtosis 6.41466 ) 
[9] output of <AffineTransform> ( min -17.1651, max 15.2411, mean -3.12765, stddev 2.55544, skewness 1.50421, kurtosis 3.64025 ) 
[10] output of <Sigmoid> ( min 3.5098e-08, max 1, mean 0.140403, stddev 0.259023, skewness 2.23739, kurtosis 3.82903 ) 
[11] output of <AffineTransform> ( min -31.6816, max 18.1601, mean -3.40787, stddev 3.06959, skewness 1.13035, kurtosis 3.95319 ) 
[12] output of <Sigmoid> ( min 1.74125e-14, max 1, mean 0.141815, stddev 0.276121, skewness 2.18079, kurtosis 3.37558 ) 
[13] output of <AffineTransform> ( min -10.3387, max 16.1199, mean -0.00747548, stddev 2.4663, skewness 0.710131, kurtosis 1.41567 ) 
[14] output of <Softmax> ( min 2.04655e-11, max 0.986228, mean 0.000624875, stddev 0.0138038, skewness 42.82, kurtosis 2188.43 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.522277, max 1.11136, mean -0.000153896, stddev 0.0360507, skewness 0.450601, kurtosis 23.4553 ) 
[1] diff-output of <AffineTransform> ( min -0.284265, max 0.24122, mean 7.44676e-05, stddev 0.00798201, skewness 0.263359, kurtosis 62.3807 ) 
[2] diff-output of <Sigmoid> ( min -1.39269, max 0.968631, mean 0.000395348, stddev 0.0658746, skewness -0.0407849, kurtosis 11.9649 ) 
[3] diff-output of <AffineTransform> ( min -0.30821, max 0.209637, mean 5.93676e-05, stddev 0.00786011, skewness 0.0736908, kurtosis 67.2461 ) 
[4] diff-output of <Sigmoid> ( min -1.28079, max 1.12399, mean -0.000189078, stddev 0.0765506, skewness -0.0500552, kurtosis 7.35523 ) 
[5] diff-output of <AffineTransform> ( min -0.208544, max 0.159935, mean 8.55235e-05, stddev 0.00772674, skewness -0.00708594, kurtosis 45.6299 ) 
[6] diff-output of <Sigmoid> ( min -1.10348, max 0.875668, mean 0.000387879, stddev 0.0668056, skewness -0.0656683, kurtosis 7.58662 ) 
[7] diff-output of <AffineTransform> ( min -0.193032, max 0.150374, mean 7.55047e-05, stddev 0.00695691, skewness -0.103744, kurtosis 37.6739 ) 
[8] diff-output of <Sigmoid> ( min -0.897264, max 0.930971, mean 0.000258426, stddev 0.0581363, skewness -0.0809524, kurtosis 7.19479 ) 
[9] diff-output of <AffineTransform> ( min -0.13769, max 0.101571, mean 6.23324e-05, stddev 0.00608597, skewness -0.303377, kurtosis 33.5119 ) 
[10] diff-output of <Sigmoid> ( min -0.659046, max 0.930359, mean 0.00033785, stddev 0.049348, skewness -0.11654, kurtosis 8.53334 ) 
[11] diff-output of <AffineTransform> ( min -0.197269, max 0.145383, mean 0.000112611, stddev 0.00827746, skewness 0.0340263, kurtosis 27.2466 ) 
[12] diff-output of <Sigmoid> ( min -1.04205, max 0.776317, mean 0.00127121, stddev 0.0911301, skewness -0.0685557, kurtosis 1.94283 ) 
[13] diff-output of <AffineTransform> ( min -0.999823, max 0.899287, mean -3.73984e-09, stddev 0.0213679, skewness -29.418, kurtosis 1508.75 ) 
[14] diff-output of <Softmax> ( min -0.999823, max 0.899287, mean -3.73984e-09, stddev 0.0213679, skewness -29.418, kurtosis 1508.75 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.22316, max 1.25428, mean -0.00149341, stddev 0.125548, skewness 0.0285234, kurtosis 3.2746 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.341873, max 0.739358, mean 0.0190637, stddev 0.123548, skewness 0.43487, kurtosis 1.92296 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.914325, max 0.520251, mean 0.00237748, stddev 0.0373471, skewness 0.0331207, kurtosis 12.4904 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.683806, max 0.749022, mean 0.0151981, stddev 0.118067, skewness -0.0733547, kurtosis 4.50063 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.484089, max 0.434359, mean 0.00217775, stddev 0.0263742, skewness 0.505882, kurtosis 12.6692 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.421749, max 0.528651, mean 0.021894, stddev 0.11511, skewness 0.432323, kurtosis 1.74211 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.432975, max 0.353563, mean 0.00210398, stddev 0.0246927, skewness 0.307797, kurtosis 11.0996 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.631361, max 0.454067, mean 0.0193292, stddev 0.107174, skewness 0.128334, kurtosis 2.63354 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.328632, max 0.326636, mean 0.00187565, stddev 0.0239453, skewness 0.327394, kurtosis 9.46193 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.331635, max 0.482464, mean 0.0159571, stddev 0.0925541, skewness 0.34853, kurtosis 2.72725 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.53111, max 0.585396, mean 0.00422303, stddev 0.0403146, skewness 0.73722, kurtosis 9.45189 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.702719, max 0.747529, mean 0.0288284, stddev 0.133613, skewness 0.473501, kurtosis 2.99149 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -3.07427, max 1.74751, mean -1.82609e-08, stddev 0.116361, skewness -5.31376, kurtosis 82.3473 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.94556, max 1.75009, mean 3.72529e-09, stddev 0.383459, skewness -1.98949, kurtosis 11.3383 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 338432 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.50193, max 6.77601, mean -0.00405738, stddev 0.997423, skewness -0.00626004, kurtosis 2.0657 ) 
[1] output of <AffineTransform> ( min -29.1766, max 19.1132, mean -3.23511, stddev 3.37595, skewness 0.138474, kurtosis 1.54312 ) 
[2] output of <Sigmoid> ( min 2.13194e-13, max 1, mean 0.180071, stddev 0.283801, skewness 1.74419, kurtosis 1.76519 ) 
[3] output of <AffineTransform> ( min -33.1354, max 15.886, mean -3.92732, stddev 2.69126, skewness -0.0526037, kurtosis 2.82678 ) 
[4] output of <Sigmoid> ( min 4.06887e-15, max 1, mean 0.0985143, stddev 0.194204, skewness 2.94095, kurtosis 8.51187 ) 
[5] output of <AffineTransform> ( min -14.8611, max 12.4419, mean -3.21271, stddev 2.02628, skewness 0.679745, kurtosis 2.70205 ) 
[6] output of <Sigmoid> ( min 3.51498e-07, max 0.999996, mean 0.109201, stddev 0.192612, skewness 2.85773, kurtosis 8.10523 ) 
[7] output of <AffineTransform> ( min -25.1288, max 16.1827, mean -3.07129, stddev 2.29745, skewness 0.590968, kurtosis 3.38701 ) 
[8] output of <Sigmoid> ( min 1.22099e-11, max 1, mean 0.1325, stddev 0.222556, skewness 2.38936, kurtosis 5.08991 ) 
[9] output of <AffineTransform> ( min -15.1418, max 15.7493, mean -2.98193, stddev 2.70532, skewness 1.42061, kurtosis 3.11203 ) 
[10] output of <Sigmoid> ( min 2.65471e-07, max 1, mean 0.158166, stddev 0.275436, skewness 2.00078, kurtosis 2.72358 ) 
[11] output of <AffineTransform> ( min -31.8098, max 18.9497, mean -3.56642, stddev 3.27521, skewness 1.06593, kurtosis 3.619 ) 
[12] output of <Sigmoid> ( min 1.53173e-14, max 1, mean 0.142462, stddev 0.282804, skewness 2.14805, kurtosis 3.16418 ) 
[13] output of <AffineTransform> ( min -11.6134, max 18.4531, mean -0.0104068, stddev 2.91051, skewness 0.613282, kurtosis 1.15169 ) 
[14] output of <Softmax> ( min 1.26085e-12, max 0.974362, mean 0.00062488, stddev 0.0166993, skewness 41.3493, kurtosis 1895.03 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.984957, max 0.538196, mean -0.000384392, stddev 0.0348642, skewness -0.580217, kurtosis 22.6579 ) 
[1] diff-output of <AffineTransform> ( min -0.334371, max 0.152026, mean -1.5596e-05, stddev 0.00703751, skewness -0.71003, kurtosis 73.8501 ) 
[2] diff-output of <Sigmoid> ( min -1.48712, max 0.885976, mean -0.000340001, stddev 0.0606168, skewness -0.250748, kurtosis 15.2999 ) 
[3] diff-output of <AffineTransform> ( min -0.219167, max 0.243078, mean -3.85412e-05, stddev 0.0074454, skewness 0.0409529, kurtosis 78.2183 ) 
[4] diff-output of <Sigmoid> ( min -1.21543, max 1.04429, mean 0.000167514, stddev 0.0766026, skewness -0.00968465, kurtosis 9.93373 ) 
[5] diff-output of <AffineTransform> ( min -0.258519, max 0.179344, mean -6.48209e-05, stddev 0.00769837, skewness -0.304972, kurtosis 55.4221 ) 
[6] diff-output of <Sigmoid> ( min -1.19431, max 0.901179, mean -0.000206269, stddev 0.0684343, skewness -0.0617727, kurtosis 10.4036 ) 
[7] diff-output of <AffineTransform> ( min -0.152, max 0.220663, mean -5.47597e-05, stddev 0.0069231, skewness 0.195915, kurtosis 44.7194 ) 
[8] diff-output of <Sigmoid> ( min -0.85344, max 0.884071, mean -0.000287194, stddev 0.0557282, skewness -0.0309322, kurtosis 9.67153 ) 
[9] diff-output of <AffineTransform> ( min -0.130781, max 0.149439, mean -3.94212e-05, stddev 0.00573252, skewness -0.469226, kurtosis 42.1289 ) 
[10] diff-output of <Sigmoid> ( min -0.612504, max 0.630065, mean -2.65188e-05, stddev 0.0449872, skewness -0.0751116, kurtosis 11.505 ) 
[11] diff-output of <AffineTransform> ( min -0.177307, max 0.164103, mean -1.39263e-05, stddev 0.00714769, skewness -0.0990714, kurtosis 42.1873 ) 
[12] diff-output of <Sigmoid> ( min -0.936066, max 0.755534, mean 0.000389349, stddev 0.0786938, skewness -0.0111298, kurtosis 3.94678 ) 
[13] diff-output of <AffineTransform> ( min -0.999986, max 0.86956, mean -1.16823e-08, stddev 0.0174845, skewness -28.6099, kurtosis 1960.82 ) 
[14] diff-output of <Softmax> ( min -0.999986, max 0.86956, mean -1.16823e-08, stddev 0.0174845, skewness -28.6099, kurtosis 1960.82 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.35761, max 1.68324, mean -0.000537342, stddev 0.112494, skewness 0.0101554, kurtosis 2.75347 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.480628, max 0.512621, mean -0.00399254, stddev 0.120287, skewness 0.202022, kurtosis 0.900242 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.475666, max 0.764336, mean -0.0018526, stddev 0.0417744, skewness 0.0581778, kurtosis 7.50919 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.510981, max 0.514794, mean -0.00986654, stddev 0.131404, skewness 0.00235139, kurtosis 1.47199 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.566244, max 0.593198, mean -0.00172918, stddev 0.0289092, skewness -0.213329, kurtosis 13.6378 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.664369, max 0.668584, mean -0.0165942, stddev 0.144346, skewness 0.112031, kurtosis 2.61484 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.421254, max 0.55061, mean -0.00156829, stddev 0.026303, skewness -0.0155495, kurtosis 11.7496 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.495144, max 0.456916, mean -0.0140185, stddev 0.127225, skewness -0.0362379, kurtosis 1.82362 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.327299, max 0.330661, mean -0.00136345, stddev 0.0253419, skewness -0.20846, kurtosis 9.53909 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.475412, max 0.464724, mean -0.0100918, stddev 0.102798, skewness -0.0887797, kurtosis 3.43895 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.471331, max 0.441837, mean -0.000262027, stddev 0.0377477, skewness -0.0584453, kurtosis 8.81649 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.503782, max 0.526666, mean -0.00356512, stddev 0.120834, skewness 0.0675421, kurtosis 2.35941 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -3.64666, max 2.40358, mean -8.7431e-09, stddev 0.0927335, skewness -5.01439, kurtosis 90.7197 ) , lr-coef 1, max-norm 0
  bias_grad ( min -3.59736, max 1.64256, mean -1.49012e-09, stddev 0.295856, skewness -2.47785, kurtosis 20.6244 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0779741 min, processing 72338.6 frames per sec; i/o time 5.10059%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14106 318 182 101 16 23 147 394 174 74 294 47 870 141 67 129 255 114 165 74 149 213 181 183 408 103 94 245 56 199 233 219 209 78 485 234 501 261 303 129 32 34 202 163 535 145 178 160 16656 5473 1407 385 440 102 243 122 303 118 380 0 107 271 58 97 93 86 243 57 294 191 144 415 282 143 874 110 864 152 49 13 569 154 448 222 342 20 710 155 141 68 76 139 255 166 278 70 165 257 182 92 99 60 29 327 272 85 199 196 15 111 124 263 142 460 128 77 124 98 17 288 88 277 175 145 85 235 203 106 16 130 103 96 261 105 225 47 654 102 126 63 230 68 627 94 106 150 211 42 124 289 144 100 161 98 300 136 229 44 206 11 193 224 432 114 59 162 165 82 201 60 143 259 59 211 112 0 74 325 188 0 308 89 60 48 267 60 114 213 217 233 69 84 34 171 117 241 110 199 148 224 208 100 318 174 185 100 39 85 279 178 263 182 189 160 112 158 150 96 122 83 71 465 110 243 156 322 191 131 401 380 136 112 84 62 69 94 171 202 164 237 323 105 117 1041 218 21 103 173 175 146 274 69 106 143 83 59 358 320 29 312 180 310 237 470 549 136 85 158 80 245 175 26 156 156 198 132 23 84 27 70 350 301 265 162 4 208 159 83 111 119 62 231 365 304 54 85 79 76 168 163 124 705 189 106 48 121 19 123 117 137 169 141 132 456 113 108 147 127 25 491 355 389 168 188 199 87 83 96 64 68 88 197 54 111 190 205 366 44 139 111 166 116 142 17 246 129 132 136 118 101 283 141 319 231 267 110 156 104 38 203 22 154 518 287 30 115 144 23 375 214 888 167 91 50 151 941 147 529 88 198 86 42 20 103 215 7 131 37 106 81 22 12 221 160 126 219 148 121 262 96 292 133 232 397 251 83 68 117 120 105 280 174 760 20 61 190 113 277 70 233 90 65 10 85 200 246 146 190 262 32 169 140 133 203 48 20 191 113 261 70 14 67 149 131 195 140 173 225 118 142 479 20 65 121 644 103 272 567 0 296 110 125 160 72 193 209 23 154 136 123 42 101 71 350 71 132 225 118 52 133 131 151 84 16 351 136 37 102 80 155 336 499 610 12 156 207 219 45 193 336 298 26 79 88 241 108 284 67 113 217 108 268 207 177 338 0 305 120 149 24 75 211 69 271 255 39 24 38 172 143 166 104 74 156 223 90 72 29 82 110 165 110 21 127 56 70 231 501 270 74 7 137 123 314 232 395 203 187 41 160 122 17 81 166 128 40 126 167 271 254 173 133 146 338 236 381 113 188 153 16 31 122 164 152 22 403 94 16 266 540 9 424 185 271 152 51 169 517 345 194 95 131 53 165 217 206 266 69 37 89 10 229 185 91 95 46 196 393 238 61 98 65 90 158 275 81 102 141 157 238 200 153 34 93 114 536 130 350 119 108 80 155 62 182 91 71 357 98 68 287 22 338 165 148 65 150 43 19 475 257 27 112 101 300 81 75 49 62 166 121 115 96 155 149 114 163 60 77 150 33 195 123 137 225 13 96 1 371 772 359 185 304 20 19 266 123 818 63 1086 46 67 11 30 81 10 43 201 243 244 188 190 152 28 79 20 11 286 81 50 67 51 394 74 59 133 106 100 187 12 118 214 93 178 180 230 63 181 177 200 223 108 128 194 131 308 105 338 145 9 47 366 206 283 41 270 145 334 161 60 200 224 66 501 255 295 186 156 187 52 224 200 154 11 230 236 109 237 192 144 232 96 14 257 201 241 13 135 54 40 360 65 120 202 78 92 300 194 309 191 175 92 336 191 76 30 198 155 34 242 103 151 159 81 34 239 79 193 187 894 389 136 108 191 100 92 356 115 212 250 415 139 101 304 13 96 177 271 105 284 17 199 129 1 184 412 238 105 621 144 87 465 395 487 106 311 221 12 120 85 137 17 153 113 92 58 238 214 264 478 417 92 505 132 126 271 46 78 163 182 80 434 59 158 155 94 295 460 167 110 239 370 337 231 178 243 94 209 244 6 572 148 133 853 101 140 298 137 110 210 495 597 87 244 98 307 351 125 50 122 130 203 116 71 317 281 439 117 229 237 160 74 14 68 0 179 352 232 39 133 161 95 239 159 52 55 475 149 208 139 238 143 13 107 166 174 77 63 265 134 130 27 75 250 167 217 98 105 107 7 35 22 33 161 244 236 88 96 74 173 431 163 277 184 154 69 301 65 155 55 235 28 214 170 218 43 55 187 121 171 187 83 253 141 91 98 50 139 63 314 513 250 377 20 20 151 50 93 210 102 8 75 294 127 188 138 219 387 206 58 42 144 160 500 297 122 109 157 150 293 122 184 135 454 256 639 430 514 276 260 11 205 603 30 294 400 314 275 1369 13 135 174 545 623 167 212 18 228 189 8 269 378 188 368 54 407 110 66 152 72 182 17 70 15 364 187 435 117 417 215 453 278 238 307 229 170 222 514 1659 385 27 29 135 197 165 95 257 265 225 234 324 927 460 300 79 209 290 73 105 104 301 57 72 71 288 277 257 196 163 88 149 159 249 147 133 209 222 383 280 233 81 385 205 66 221 90 97 206 21 51 102 157 112 55 247 289 199 94 253 66 209 60 71 91 216 394 303 128 297 867 202 154 463 68 187 379 101 293 182 46 44 166 97 74 114 137 135 144 261 159 184 429 65 188 148 128 153 25 51 234 276 278 124 105 40 231 49 271 475 138 472 70 108 64 340 343 67 57 83 126 354 312 217 173 1139 101 283 121 161 41 25 133 75 25 152 172 146 145 67 68 173 860 150 185 54 238 244 264 142 245 359 64 188 236 440 467 176 100 111 397 181 34 127 285 168 80 217 39 170 96 409 264 27 293 60 89 290 93 158 44 360 209 393 470 276 215 186 17 107 387 87 199 486 200 364 92 208 98 45 112 198 200 51 75 73 84 123 256 497 140 236 327 93 108 130 82 201 557 166 152 149 89 177 110 106 78 340 468 258 114 99 72 272 150 361 278 295 290 28 136 365 263 133 172 27 246 193 368 212 124 30 441 21 75 76 130 112 227 87 275 45 268 77 220 120 69 290 57 21 181 188 104 237 443 402 322 50 177 99 344 374 167 607 329 146 320 241 58 191 64 178 543 113 28 155 219 163 210 154 367 176 195 1 841 138 164 67 156 162 210 126 393 144 100 416 188 132 120 202 89 151 241 532 67 245 136 522 206 63 792 272 178 150 161 82 451 1062 108 97 108 446 279 270 318 355 93 76 348 328 313 159 58 10 183 270 82 159 405 105 236 115 193 135 71 309 426 85 360 345 394 142 119 508 112 227 186 277 383 158 183 201 169 192 413 353 368 174 165 139 218 129 84 185 106 167 149 106 202 192 52 277 184 277 122 323 139 144 176 143 106 132 12 86 245 122 119 225 70 210 189 188 218 55 279 22 282 149 868 210 123 114 155 211 47 194 250 216 147 82 225 171 95 173 158 351 748 556 143 154 463 220 173 181 206 19 145 407 56 190 265 144 349 166 273 170 313 198 110 79 89 397 68 641 130 53 377 240 109 206 175 235 18 281 141 48 200 153 232 127 223 530 843 47 63 163 102 29 37 47 20 181 ]
@@@ Loss per-class: [ 0.654399 1.91176 1.25232 1.84872 4.09186 4.28552 2.39029 1.20978 1.44729 2.47271 0.777517 3.17357 0.926181 1.28302 3.18431 1.45091 1.40788 1.38293 1.78876 2.61277 1.42213 1.52176 1.7996 1.79234 1.95746 1.7657 2.36139 1.15492 2.16987 1.28036 2.05011 1.41981 1.88166 2.09996 0.880615 0.928642 0.550355 0.550789 1.22214 2.74107 2.97069 1.54816 1.18529 1.70329 0.660387 1.46108 1.37224 1.80518 0.457381 1.23238 0.996823 0.960756 0.718731 2.84713 1.32421 2.11668 1.0995 1.6242 1.4269 0 1.94851 1.16382 3.81485 2.26584 2.38654 1.87356 1.28767 1.67282 1.53751 1.20336 1.80686 1.39319 1.04883 0.925109 0.633544 2.54194 0.424519 1.87653 1.83222 4.70388 1.34146 1.07878 0.959848 1.32183 1.40467 2.96161 1.42534 1.44515 1.54427 1.94807 2.00943 1.12832 0.99105 2.29576 1.26763 2.7351 2.48018 1.13557 1.13004 1.60311 1.20162 2.16132 3.48721 1.00413 1.61386 1.12537 1.60539 1.07558 4.22551 1.3144 1.47301 0.714586 2.34833 0.826402 3.19415 2.32472 2.18356 1.59266 3.77893 1.48928 1.97585 1.32114 1.81707 1.83546 0.961533 1.41484 1.77311 1.45276 5.25481 1.86358 2.7754 1.68442 1.76588 2.21144 2.06088 2.32535 0.924328 2.14716 2.38752 2.18336 1.95394 2.46117 0.852791 2.89326 1.56524 1.79169 1.85609 2.45886 1.64836 1.30698 1.47829 1.66442 1.921 1.59659 1.48334 1.2736 1.0155 2.5438 0.995502 4.62304 1.28228 1.00069 1.68398 2.01378 2.28789 2.15091 1.97132 2.43086 2.12787 1.78132 1.31412 1.36062 1.60462 1.98448 1.6931 0 2.22714 1.46329 1.00399 0 2.11314 1.6259 1.40059 2.21518 1.82503 1.80261 1.10281 1.88841 1.76111 0.435738 1.68196 2.3463 2.1811 1.18719 1.90457 1.27726 1.40619 2.09948 1.69632 1.24337 2.1038 2.9598 0.898365 2.41363 2.26026 1.51733 3.03821 2.20955 1.68379 1.3484 1.58353 1.79402 1.4888 1.27011 2.3977 1.17396 3.1646 2.09506 1.90034 1.97782 2.23182 1.68931 2.33625 1.98122 1.1973 1.19166 1.97078 1.43627 1.007 0.922498 1.71237 1.42335 2.86052 1.46559 0.967298 3.2221 1.83241 1.5358 2.03998 1.86183 2.16203 1.50705 1.08314 0.923145 1.11736 9.37303 3.35128 2.09083 3.12964 3.23444 2.03006 2.26712 2.27563 2.0788 2.28516 2.69857 1.4994 1.36554 3.08584 0.867596 0.592975 1.95162 2.58541 0.922711 1.10449 1.55183 1.52797 1.86786 2.04074 1.47217 1.66717 1.71182 1.87289 1.36968 3.25179 2.591 2.47617 2.62203 3.20334 1.74456 1.07895 2.29062 2.75209 1.01482 8.9588 2.21324 1.59413 2.39202 2.0226 1.56471 2.14568 1.75465 1.25293 1.60232 3.4066 2.34995 1.78182 2.2161 1.53429 0.809498 1.6018 1.09736 2.30338 2.06266 2.04655 2.17409 4.4869 4.1499 1.83113 1.77141 1.22569 2.33275 1.80543 1.83528 2.41191 1.47718 1.9333 2.13154 2.45533 1.75582 1.25627 0.880746 1.43456 1.88119 1.47645 1.65904 1.67528 1.36442 2.34721 2.72208 1.75403 1.12244 2.23248 1.48373 1.61011 1.49829 1.28182 3.43881 2.38324 2.5782 1.18309 1.90215 1.29611 7.30458 1.42176 2.46925 2.6467 1.45177 2.78695 2.22981 1.44224 0.957641 1.54828 1.21832 1.5184 1.65338 1.12108 1.4356 2.60929 1.94281 3.79529 1.86664 1.08545 1.8835 2.22104 1.81287 3.06905 4.79357 1.8918 1.35518 1.28203 1.60793 2.13506 2.39571 2.12827 1.08787 1.94045 0.852286 3.82375 1.80369 2.84392 1.20048 2.38162 1.53684 2.7795 9.14799 2.37913 2.30463 1.32659 2.93737 4.19303 5.58056 1.63058 2.03369 1.11694 1.05247 1.32744 1.92634 2.87168 1.22828 1.29443 2.1074 1.35163 1.51267 1.90692 3.2485 1.47065 2.19817 1.94442 1.88938 2.70674 1.61121 1.07703 3.69734 2.18014 2.58205 1.50366 2.72887 2.35103 1.18868 1.53399 2.91031 5.38757 2.94308 1.74521 1.57886 1.44046 1.78119 2.36978 3.18576 2.16389 1.72067 3.43974 1.74507 2.90211 4.09829 2.24753 1.10081 1.54924 2.55438 3.67669 1.49425 2.77079 1.35698 1.66603 1.85942 2.66819 1.68619 2.31225 1.35024 1.24328 3.23007 2.28113 1.46357 1.07479 2.77812 1.06411 0.883762 0 2.03082 2.02378 2.01455 1.32785 2.90515 1.46419 1.72191 2.01626 1.75954 1.76301 1.73504 4.01529 2.56171 2.73958 1.49435 2.52509 2.02741 1.89323 2.01202 2.12191 1.54724 1.87724 1.30493 2.7009 4.50808 0.948211 2.71673 3.20668 3.38043 2.58251 2.06281 2.07298 0.930238 1.15666 5.80476 1.11134 2.41372 2.07744 3.27197 2.83959 2.15635 1.67675 2.92786 1.35063 1.56211 1.70703 1.31202 1.59943 2.81117 2.22937 1.81847 1.78954 1.83349 2.39072 2.96422 1.5981 0 1.61536 3.70996 1.44033 2.12064 2.81097 1.67382 2.05078 1.79944 0.785221 2.65384 2.4151 2.42896 2.13516 2.06878 1.95004 2.04877 2.30428 3.19249 2.13244 1.38219 1.92579 2.40193 2.89642 1.41127 1.53241 2.785 3.21566 1.46628 2.35619 1.36918 1.90638 1.16308 2.05943 2.47961 8.43138 2.50806 1.53207 1.58548 1.39096 0.739251 1.80517 2.64955 3.56169 1.53769 1.08702 3.89099 2.12387 1.76008 2.02017 2.52351 2.13998 1.29433 1.67874 1.99797 2.04858 2.06623 1.63467 1.0402 1.48514 2.11005 2.51374 1.63823 2.39778 5.85204 2.50142 1.81484 1.01857 1.19385 3.26351 0.884373 2.52986 4.75692 1.71475 2.01098 6.5824 1.32534 1.13585 2.18035 1.14716 3.12 1.47115 1.74742 1.51414 1.98995 1.47403 2.03547 2.13005 2.2534 1.94054 1.44601 1.89078 3.0029 2.93941 1.56884 6.74218 1.5128 1.95261 1.94193 2.54905 3.52757 1.97441 1.34194 1.58077 1.7612 2.33166 2.04447 1.98975 1.80882 1.17775 2.47654 2.2471 2.39319 1.32917 2.18634 2.30249 1.90211 2.90517 2.16648 1.63441 1.09433 2.29942 1.87404 2.38232 2.84333 1.11312 1.47265 3.70935 2.37326 2.75793 3.5514 1.47023 2.06583 2.93203 1.41096 3.70245 1.65766 1.39268 2.23495 1.94941 3.03486 3.85248 3.6321 2.0418 2.02481 1.70516 2.18859 1.70678 1.39467 2.3384 2.35544 3.4812 2.1728 1.52288 1.56727 1.25676 2.57206 1.6568 1.39928 3.62204 2.60551 2.13114 1.64554 2.67933 1.71957 1.167 2.61258 2.56849 1.51292 8.55036 3.24849 10.7928 2.6016 1.1093 0.705267 1.24273 1.96949 4.58269 4.51037 1.63808 1.19986 1.46963 1.74004 1.07907 2.56793 2.29454 5.94016 2.06787 2.46373 8.00064 2.96123 1.85367 2.09463 2.0136 1.28315 1.04415 2.65571 4.40714 2.39458 3.18052 8.21457 1.96962 1.92675 2.01266 3.70723 2.62039 1.53518 4.81285 3.16494 1.49396 2.74102 2.43131 1.31825 5.82397 1.66152 1.27872 2.66407 2.34463 1.85892 2.23938 2.65447 2.56346 1.46622 1.79569 1.84553 1.35688 2.26989 1.71242 3.3383 1.34414 1.97089 1.39529 1.37176 6.88736 1.57304 1.41575 1.45802 1.7905 1.60564 2.13559 1.92786 1.56525 2.18449 1.96929 1.24058 1.78259 2.58011 1.33957 1.68136 2.20348 2.6131 1.33785 1.35625 2.18459 2.15346 2.22134 1.85166 6.52512 1.36635 1.84576 2.00726 1.73751 2.13166 2.28749 1.312 1.5252 5.01201 1.58281 1.30411 1.73611 3.69638 2.66357 3.20897 3.30676 1.41314 2.0304 2.5395 2.10556 2.72834 2.97719 1.59929 0.982987 1.1835 1.92719 1.63111 2.49561 1.56695 1.2312 2.0062 2.08553 0.946388 1.57407 2.14161 2.12956 2.35783 1.89955 2.46378 1.72962 3.01757 1.87385 2.57857 1.69155 2.0395 1.62507 0.91996 2.20039 2.31623 2.02449 3.05384 2.93463 1.76471 1.43542 1.33573 1.00186 1.02639 2.39694 2.22221 1.94719 6.93973 2.22374 1.72735 1.84174 2.6743 1.49912 3.3059 1.51763 2.78131 8.74821 1.70123 1.40271 1.37273 2.70538 1.05968 2.35695 2.2296 0.901279 1.57327 1.22307 1.65039 1.8276 1.60639 5.4509 2.55395 2.10509 1.57623 4.88227 1.51933 1.83591 3.14472 2.27508 1.27371 4.26866 1.14351 1.15085 1.0016 2.7218 1.62783 2.25064 1.74946 2.29739 2.98175 2.69409 1.92599 2.30157 3.08602 1.51721 1.64972 1.9469 1.77486 2.32241 1.33926 1.9906 2.35538 2.17428 1.30484 1.10405 1.39048 1.43153 1.35256 1.22938 1.44694 1.57069 2.15184 8.17401 1.06189 1.40844 2.56397 1.24569 1.80583 2.28859 1.51996 2.08986 1.74407 1.24386 1.33426 1.65369 2.7569 1.34825 2.27076 1.96307 1.37083 2.34308 3.71517 2.49379 2.66855 1.01598 2.0709 2.0762 1.62912 2.58868 1.49047 2.64686 2.77631 1.92338 2.17715 1.8473 3.78514 2.55032 0 2.51239 1.35581 1.35568 2.35706 2.30619 1.45876 2.05016 1.18779 2.63517 3.5471 3.48298 1.23396 2.87815 1.6202 3.31128 1.7034 1.98306 6.97092 2.59319 1.49535 2.23818 3.51422 2.49285 1.71562 2.65629 1.52514 1.93586 3.01836 1.31167 2.40742 2.17422 2.06698 1.88562 1.80771 7.83028 3.09888 2.47576 1.59255 1.97888 1.46526 1.40859 2.18301 2.28851 3.04559 2.02877 1.38988 2.0128 0.974655 2.35967 2.094 1.96783 1.80028 2.26797 2.02441 2.07061 1.74782 3.44085 1.96736 1.17358 1.24873 3.86408 3.48395 2.61092 2.0181 2.34215 2.18865 2.23579 1.9809 1.82355 2.36943 1.4942 2.90076 3.77775 4.95698 1.65742 1.43906 2.40718 2.08528 3.61578 3.94346 1.89093 4.0035 2.29032 2.01295 2.8436 5.37614 2.25725 1.5143 2.37709 2.33299 2.22474 1.22905 2.09939 1.11383 3.31071 3.66724 2.5349 4.66064 1.44886 1.30373 2.30665 2.13383 1.70006 1.70662 1.23362 1.74851 1.79963 2.20963 1.00139 1.3183 2.09838 2.14387 2.08454 2.31813 1.56333 4.83593 1.45925 1.01337 4.26471 2.57878 2.15755 1.19038 1.71381 0.982279 5.02759 2.24122 1.51349 1.87939 1.13417 1.35071 1.62897 4.81946 1.65445 3.03202 6.97089 0.940853 1.19496 3.03048 1.32009 2.95912 2.3021 1.24816 2.56385 1.7281 3.12995 2.78731 3.74171 2.90833 2.22917 0.843302 1.68179 1.19757 2.36577 1.26311 2.25635 1.32188 1.24941 1.53514 1.78823 1.98757 3.3878 1.40749 1.39767 1.03498 1.38143 4.24522 2.97772 1.76596 1.68609 1.56006 2.80778 2.74108 1.67637 1.79925 1.96213 1.89537 0.86531 1.78093 1.74448 3.47566 2.26061 1.60128 3.01144 1.45355 2.64538 1.90699 2.53241 1.24762 2.23963 2.2336 1.95373 2.57197 2.56055 3.85231 1.91344 1.95292 2.8232 1.06593 1.57181 2.97676 3.10385 2.71649 1.38095 1.65626 1.77226 2.28663 1.76527 1.4886 2.71766 1.17708 2.61271 0.905182 1.6577 3.46578 4.57506 4.39012 2.22228 3.41174 2.63982 1.93205 1.35917 2.76592 1.71233 2.75234 1.62107 3.18156 2.35355 2.01248 2.40635 1.04667 1.63258 1.8517 2.65027 1.1237 1.28004 2.15842 2.19422 1.15394 1.95149 1.63716 1.59697 2.86124 2.39504 2.04884 2.93135 2.76672 1.53535 1.93254 2.43988 2.47091 2.20445 1.93709 2.08197 1.68308 2.16384 2.88968 1.2032 2.43704 2.06018 2.04696 2.46283 1.66338 3.69845 3.30456 2.4289 1.67284 1.7275 2.1261 1.97773 2.55597 1.83857 2.25232 1.87072 1.25363 2.8235 1.04609 1.88092 1.4588 1.89864 1.49663 2.68853 3.0274 2.83782 2.63255 1.50403 1.58482 1.79401 2.03473 2.8434 1.19824 1.69989 0.994543 1.83684 1.7966 2.461 2.86789 2.39548 3.29808 3.34517 1.92136 2.30536 1.63786 1.14677 2.24753 2.30953 1.74778 0.969679 2.13734 1.67188 2.12313 1.77487 1.21425 1.03281 3.21364 1.72092 2.68498 5.26148 1.44685 1.89962 1.90754 1.89649 2.14334 2.09694 1.69585 1.94074 1.71216 3.17674 2.4667 1.25491 1.92602 2.38025 1.10059 3.46042 1.8916 2.95025 1.09525 2.43428 3.14726 0.957808 2.04152 2.39067 1.40031 2.85512 1.63782 3.05417 1.07769 1.56528 1.64193 1.49742 1.44271 2.03928 2.77353 4.12358 2.54166 1.81012 2.12051 2.46248 1.31226 1.88447 1.55195 2.65063 1.7769 1.6712 2.13618 2.45877 1.84992 1.82851 3.49667 2.86636 3.3386 3.03327 2.35329 1.499 1.22506 1.6521 2.46208 1.67736 2.82816 2.07144 1.85689 2.79445 1.9494 1.52125 1.66632 2.41743 2.1544 2.96252 3.26121 2.0005 3.12419 1.65292 1.48931 1.82102 1.98742 2.58719 1.97794 2.54972 1.01703 2.95609 1.38741 1.84943 1.40281 0.760792 4.12555 2.26268 1.0636 3.29018 2.66428 3.67496 4.16337 2.41183 2.60861 2.34426 1.988 2.66367 2.9895 1.62634 3.36307 1.84621 2.23937 3.28652 3.20975 1.63002 2.55004 1.80238 6.00767 1.23544 2.92605 2.20942 4.18641 2.89471 2.30878 1.8217 3.97042 1.4654 1.70307 2.47668 1.85174 2.28115 1.78354 2.01923 2.80873 2.29855 1.6487 1.10356 2.22342 1.88957 0.93601 1.88617 2.32711 2.95363 1.79903 1.95621 1.73217 2.62368 1.90221 1.09149 3.97803 4.57186 2.43606 1.91062 0.983237 2.00182 1.54642 1.91565 1.88097 1.99125 9.12722 1.33819 2.09342 1.31077 1.60879 2.62239 2.26225 1.49172 1.45235 2.00524 2.04102 2.8801 0.873083 1.66632 2.10796 2.51325 2.26578 3.07267 1.80927 2.05855 1.97018 1.67537 1.59606 2.75552 1.71868 2.34849 2.05136 1.38828 2.04238 2.93562 2.04431 1.8715 2.63713 1.10541 0.863793 2.08271 2.64297 2.63357 1.91126 1.73136 1.91192 1.39058 2.31772 3.43397 2.90662 1.43894 1.84887 1.62047 1.73253 2.58663 7.32038 1.43215 1.0165 2.57708 2.065 1.50055 3.54071 1.11715 1.75657 3.72104 1.91381 3.18617 1.13987 0.847747 2.48175 1.9918 1.82598 2.04362 2.77719 1.27095 1.50898 2.62976 2.65686 2.36616 2.11666 2.2004 2.91905 2.1609 2.35428 1.78605 2.27222 1.93586 1.2463 2.14936 1.51366 1.97032 2.01056 1.67003 1.29151 2.65451 2.0875 2.75098 3.48773 1.80213 2.11745 1.43535 1.93108 2.81654 2.88585 2.68347 1.19006 1.84512 1.48235 2.71343 2.42859 1.71098 1.36956 2.65598 1.81207 4.85262 2.04194 1.56174 2.02991 2.25803 2.26708 3.74022 1.43471 2.33988 2.07646 1.22513 1.15756 1.57778 5.37458 1.79446 2.22975 0.863457 2.34125 2.49185 2.44464 1.7325 2.20464 4.21306 2.17905 1.77218 2.01836 1.93562 2.1753 1.98177 1.63582 2.68504 2.11518 3.04031 1.56892 1.62279 1.39784 3.23509 2.11463 1.54753 1.4943 1.9271 1.91679 2.21074 2.45054 2.12196 2.25563 2.46007 1.96529 2.1429 2.45001 1.54846 1.73496 1.26323 1.91497 3.24999 1.53322 3.37149 3.1644 2.78691 0.694714 2.54587 1.63449 2.00732 3.17041 2.17099 1.641 1.56784 1.42872 1.60954 2.42241 3.27888 1.9684 1.52197 2.63496 1.89873 1.50978 1.26623 3.0478 1.83613 0.933439 1.561 3.95491 2.94742 1.76669 3.28957 6.00623 5.38204 2.63163 4.0015 3.19559 ]
@@@ Frame-accuracy per-class: [ 76.3265 50.8634 66.8493 52.2167 24.2424 21.2766 34.5763 67.1736 65.3295 26.8456 78.0985 16.8421 71.1086 66.4311 10.3704 59.4595 59.0998 68.9956 54.9849 32.2148 58.194 54.3326 58.9532 45.7766 43.3293 54.1063 28.5714 64.3585 37.1681 59.1479 42.3983 58.3144 52.506 48.4076 76.2101 72.9211 85.9422 88.3365 66.5568 32.4324 36.9231 66.6667 66.1728 37.3089 80.6723 65.2921 59.3838 50.4673 86.3987 54.6451 60.675 76.524 80.8173 14.6341 60.3696 54.6939 70.1812 47.2574 61.7608 0 49.3023 67.035 13.6752 46.1538 31.016 55.4913 66.1191 45.2174 63.837 62.141 45.6747 61.3718 72.2124 71.777 80.2744 21.7195 86.6397 50.4918 46.4646 7.40741 60.0527 66.6667 72.6867 70.1124 65.9854 43.9024 57.2836 59.8071 55.1237 54.0146 36.6013 69.5341 68.1018 34.8348 62.1185 35.461 30.8157 60.5825 66.3014 60.5405 67.3367 42.9752 20.339 71.145 53.211 66.6667 54.6366 71.7557 19.3548 60.0897 58.6345 80.0759 33.6842 77.3073 14.786 38.7097 41.7671 50.7614 17.1429 57.8856 41.8079 63.0631 48.433 48.11 70.1754 61.1465 53.0713 57.277 6.06061 46.7433 28.9855 48.7047 50.8604 40.7583 38.1375 25.2632 76.547 38.0488 26.8775 28.3465 51.1931 27.7372 79.3625 23.2804 49.7653 50.4983 48.227 30.5882 48.1928 63.9033 59.5156 52.7363 45.8204 55.8376 60.8985 63.7363 73.6383 26.9663 68.2809 8.69565 67.7003 71.2695 51.5607 44.5415 28.5714 35.6923 42.2961 43.6364 41.6873 36.3636 62.7178 62.8131 50.4202 56.7376 47.1111 0 37.5839 62.3656 67.9045 0 41.8152 54.7486 52.8926 28.866 52.7103 34.7107 67.2489 39.3443 51.4943 89.0792 48.9209 36.6864 46.3768 68.8047 49.3617 65.0104 63.3484 39.599 54.5455 66.3697 39.8082 14.9254 75.9812 35.5301 39.3531 52.7363 30.3797 33.9181 57.6029 61.6246 52.3719 49.3151 59.6306 64.1745 37.3333 68.1388 20.598 42.487 49.7959 47.9042 34.965 52.4168 42.5339 48.46 63.2588 68.5271 39.6867 61.597 67.995 70.9593 53.4799 56.8889 24.8521 67.2 77.6978 22.2222 44.3149 53.8272 44.9848 53.0526 34.6213 67.2986 66.383 72.2036 70.0229 0 10.628 32.2767 21.6524 26.6212 41.8944 17.2662 36.6197 47.3868 35.9281 26.8908 57.4616 64.8986 27.1186 78.4 86.4266 38.9694 34.9474 75.4516 68.2439 60.8059 59.6491 54.2587 45.9627 58.2485 56.4103 56.6038 54.3131 59.4249 20.6549 28.6792 51.0638 26.0355 18.1818 48.227 69.3295 35.8209 30.8851 75.0769 0 37.4101 60.815 28.7425 52.0179 54.3933 46.4 45.3564 65.3899 58.1281 22.0183 42.1053 50.3145 33.9869 55.7864 77.6758 52.2088 68.1786 46.9657 41.3146 26.8041 32.0988 5.12821 12.9555 50.2128 53.0909 69.6165 33.2155 42.2642 45.345 26.4317 55.2995 50.1695 36.8627 50.9804 47.8128 64.135 77.0218 55.1929 50.9284 57.1429 56 58.6826 61.1399 34.1085 26.2774 57.6271 68.8608 36.6972 60.9865 49.8688 65.2068 60.3001 24.7191 45.8781 27.8027 64.2643 49.7854 66.6667 0 56.7951 27.7992 16.6038 60.0733 26.1603 45.3202 67.0194 74.2049 56.651 59.6112 51.9626 54.2986 69.0096 61.244 18.1818 56.0197 17.7778 53.0744 71.9383 42.7826 62.2951 45.8874 20.7612 4.25532 47.4035 66.2005 67.7546 54.3284 42.623 31.6832 43.5644 69.8885 33.8983 80.6421 15.8192 59.4458 38.1503 75.2941 53.6585 71.4976 29.2343 0 32.6996 45.3333 65.7277 20.8589 22.2222 0 47.8555 44.8598 70.3557 73.8041 62.6263 51.0288 25.1429 67.3575 61.8803 41.1985 60.6452 55.8491 47.3161 20.3593 51.0949 44.2553 52.2822 36.9668 14.6168 49.8567 71.2689 43.9024 37.3984 33.5958 61.674 27.027 34.0426 67.2377 62.9834 33.5878 9.52381 10.5263 55.8603 53.9554 60.7509 42.5197 37.7143 21.5385 39.528 54.8043 17.9775 42.2604 22.6804 24.3902 35.5091 68.7225 58.1262 19.8582 27.5862 51.8519 30.1003 61.597 51.6624 54.0925 34.5821 48.337 35.443 56.1404 63.3994 39.0244 29.0076 60.9053 72.149 24.1546 72.2936 78.0617 0 40.1349 35.2941 47.012 64.1745 22.069 63.0491 48.6874 63.8298 47.8964 52.0147 50.2024 4.70588 22.6601 32.1678 62.1969 30.7692 45.283 42.1286 48.1013 47.619 61.4232 51.711 63.3663 17.7515 18.1818 75.6757 27.8388 32 16.5854 38.5093 45.0161 41.0104 72.4725 72.0721 0 65.8147 37.5904 40.0911 10.989 18.6047 37.7415 48.9112 37.7358 60.3774 59.887 50.1035 59.9078 54.1301 19.2593 38.7665 43.6782 44.2396 53.6313 27.4699 31.5493 55.5391 0 47.7905 15.7676 60.2007 53.0612 27.8146 53.4279 53.2374 55.2486 75.9295 22.7848 20.4082 38.961 44.058 46.6899 37.8378 35.4067 42.953 15.3355 49.217 65.1934 38.6207 40.678 15.7576 59.7285 57.4018 20.8145 51.1628 62.7451 28.3186 52.4823 47.9482 70.5882 42.5139 30.8725 0 22.5455 59.919 51.8283 65.8065 80.4046 48.6486 28.2667 14.4578 64.1745 69.3878 28.5714 46.6258 54.0541 43.5798 46.9136 26.8775 62.6866 55.9853 49.9018 47.8386 44.1948 66.2116 70.6056 55.814 47.9685 40.5286 54.1114 31.2704 0 34.9206 50.6122 71.1246 63.6066 40 77.3234 26.455 0 47.2795 50.5088 0 65.96 69.0027 41.6206 65.5738 33.0097 57.2271 53.5266 57.8871 47.8149 63.8743 38.7833 28.0374 37.4622 43.2184 60.5327 50.2814 28.777 45.3333 52.514 0 57.5163 46.9003 52.459 32.4607 2.15054 45.2926 61.7535 51.9916 53.6585 39.5939 44.2748 50.8287 46.6877 68.6025 36.8098 35.122 33.9223 55.873 44.4444 35.9102 52.1173 28.9855 33.1551 44.5415 69.5247 39.0805 43.6519 31.7992 26.7281 62.1118 55.9486 8 23.0137 20.765 15.3846 63.7762 51.7766 27.7372 61.913 8.88889 52.5849 53.1722 30.9764 47.3282 23.2558 4.5977 20.5128 45.0053 43.4951 72.7273 34.6667 54.1872 57.9035 45.3988 41.0596 10.101 38.4 58.2583 59.2593 70.9957 27.9793 45.6592 63.5452 19.214 34.8624 34.7107 61.9355 21.9269 59.7015 61.8926 31.5789 32 58.5366 0 26.943 0 36.8775 68.8673 80.3894 64.69 40.7225 0 10.2564 56.6604 67.2065 59.6213 33.0709 71.33 30.1075 47.4074 0 65.5738 38.0368 0 16.092 47.6427 43.5318 44.5808 66.8435 67.7165 22.2951 10.5263 41.5094 39.0244 0 47.8185 49.0798 33.6634 19.2593 34.9515 59.3156 10.7383 21.8487 62.9213 26.2911 35.8209 64.5333 0 55.6962 68.5315 24.5989 42.0168 50.4155 43.3839 22.0472 34.1598 58.0282 44.8878 44.2953 63.5945 36.5759 48.329 18.251 61.5883 54.9763 61.4476 64.6048 0 71.5789 66.8486 57.1429 51.1464 67.4699 40.2957 43.9863 54.4096 30.3406 39.6694 66.3342 46.7706 25.5639 62.014 53.229 41.6244 27.3458 65.1757 61.8667 45.7143 43.6526 30.4239 47.8964 0 64.2082 51.5856 48.4018 46.7368 43.1169 49.1349 67.5269 54.9223 6.89655 56.3107 69.9752 57.1429 22.2222 28.7823 5.50459 24.6914 59.0846 45.8015 27.3859 38.0247 21.6561 20.5405 56.5724 75.5784 60.7431 43.8642 50.7123 38.9189 54.9777 72.5849 40.5229 52.459 79.597 51.4469 43.4783 40.4124 37.6812 52.1452 36.3636 49.0798 40.5797 55.9499 28.9308 57.3643 50.1333 51.09 71.887 43.2234 44.2396 49.0862 18.9055 33.5135 54.979 58.0087 64 73.8523 72.2022 45.8781 40.3941 46.6338 0 29.0155 55.7746 53.0387 21.8009 58.348 34.2857 57.1429 20.8494 0 49.3225 63.2727 60.7966 26.5403 69.3484 43.5986 34.2857 73.899 60.4298 67.6923 58.216 48.1541 58.2393 0 25.7261 36.2573 56.7273 0 54.7231 42.2907 21.6216 41.0256 66.6667 9.79021 70.6994 67.2936 72.8144 10.8108 53.6103 42.2642 59.2885 43.0939 38.7097 29.2994 44.0367 41.0959 8.69565 60.9896 50.4202 50.4732 48.2315 43.3862 64.2978 44.2997 38.806 46.1538 63.048 68.556 61.037 60.9071 50.4202 61.6016 50.7937 48.21 40.0818 0 74.9345 57.2391 31.4607 66.198 59.1133 40.5694 59.2965 37.0909 40.724 66.5083 64.1776 56.7364 29.7143 65.0307 38.5787 47.1545 63.1579 35.8566 9.90099 42.449 23.7548 68.3047 45.4936 37.7622 53.5433 28.0639 61.2059 25.5319 24.4009 47.5789 42.9907 52.349 13.7931 36.4964 0 35.0975 62.4113 65.8065 32.9114 43.4457 66.2539 34.555 68.476 29.4671 17.1429 10.8108 70.0315 36.1204 49.4005 14.3369 53.2495 52.9617 0 21.3953 54.0541 36.6762 10.3226 42.5197 58.0038 30.4833 57.4713 58.1818 17.2185 60.6786 35.2239 36.7816 32.4873 42.654 49.3023 0 28.169 44.4444 65.6716 47.678 60.1227 63.0021 35.0282 38.342 22.8188 39.1931 69.2932 52.5994 74.2342 43.9024 47.8964 41.7266 46.1028 21.374 42.4437 34.2342 49.2569 7.01754 40.5594 66.8622 58.5812 20.6897 9.00901 26.6667 40.3292 45.481 39.4667 41.9162 41.0256 53.0035 31.694 54.8223 23.7624 23.6559 0 56.5978 57.8384 29.5409 46.6225 29.2683 14.6341 54.1254 0 33.1551 40.8551 22.439 0 31.7881 62.1392 38.4314 38.7268 32.491 69.7039 46.4516 66.8281 15.3846 18.8235 29.0657 3.11526 58.1419 66.8908 35.102 40.1826 49.5238 53.1561 69.8467 41.6327 51.4905 47.9705 70.8471 68.616 33.1509 35.7724 44.1205 40.1447 58.3493 0 61.8005 72.0795 16.3934 30.8998 45.6929 64.2289 51.5426 73.0924 7.40741 34.6863 61.3181 40.5133 64.4747 61.4925 55.5294 5.40541 44.2013 31.6623 0 76.0668 69.2206 22.2812 63.772 40.367 33.865 65.1584 30.0752 60.3279 17.931 19.726 28.5714 32.6241 51.6129 77.6406 54.4 65.9013 37.4468 66.5868 39.9072 65.2701 68.2226 53.6688 45.5285 46.6231 23.4604 62.4719 65.8892 70.8647 65.1102 25.4545 20.339 58.3026 53.1646 58.006 36.6492 34.5631 52.354 47.4501 49.0405 52.0801 74.1779 50.8143 50.5824 18.8679 42.4821 59.5525 25.8503 66.3507 27.7512 46.4345 45.2174 66.2069 39.1608 40.9012 48.6486 37.2816 41.7303 15.2905 57.6271 62.8763 24.4514 66.1323 63.0508 24.7191 30.5489 35.5056 68.8396 55.9715 55.6745 26.9939 50.3243 54.5012 39.0977 73.1377 32.0442 68.7179 47.9419 27.907 7.76699 6.82927 33.6508 15.1111 37.8378 46.0606 61.8307 19.5489 53.9683 35.8974 46.6165 33.8902 28.0992 51.7483 38.2514 72.5173 51.4575 47.4465 25.6809 67.2269 62.2478 43.4568 41.4239 67.5297 43.7956 49.6 53.4914 26.601 36.7973 42.1918 38.7097 40.4494 60.0601 49.2308 26.8456 29.6943 37.0909 53.1365 48.4429 55.4493 33.8558 24.9322 63.7951 33.5878 41.3793 47.8114 35.0195 61.8893 3.92157 13.5922 43.4968 54.6112 56.0144 44.1767 48.3412 27.1605 45.3564 50.5051 47.5138 68.3491 21.6606 70.8995 46.8085 57.1429 62.0155 55.5066 27.9476 19.2593 20.8696 29.9401 59.2885 52.7504 52.16 42.2989 29.9712 43.0891 58.1281 70.5467 55.9671 48.9164 26.506 39.2157 39.7004 22.5166 11.7647 49.1803 35.3623 58.7031 66.6667 38.5185 27.7372 45.5331 72.9808 40.5316 55.5256 51.3761 42.7673 57.2597 74.8582 20.3509 53.7678 34.7705 9.30233 64.191 50.74 45.403 46.8449 36.2606 40.796 59.1928 42.5157 59.5041 20.2899 43.1373 67.951 43.9169 49.6894 76.3218 15.1899 46.9208 23.8342 71.0623 32.1361 18.1818 77.3424 46.281 22.3464 63.6833 29.9465 53.6278 24.7191 69.0707 55.8473 50.5718 59.2986 58.5895 38.9791 25.2011 22.8571 39.0698 53.4194 44.5714 33.0827 53.2374 50.3741 62.0027 23.7838 44.6043 65.9898 35.1648 32 49.8741 52.3691 11.6505 27.8146 19.0476 20.1183 36.4372 58.8694 67.5377 59.7865 40.592 56.4885 22.4599 44.2396 49.8084 27.8788 46.6501 52.3767 51.6517 38.6885 48.8294 26.8156 11.2676 38.009 25.3521 56.051 61.3803 49.9466 41.0058 30.5677 49.2462 24.8276 70.0917 29.2359 65.0069 52.7828 59.8985 82.2719 0 37.3626 72.5034 22.7704 28.4644 12.7536 14.5455 41.3793 29.4574 34.1927 42.8235 32.1285 22.9508 57.0781 27.907 54.3046 37.9085 23.7548 29.3333 51.8681 33.1429 52.9946 0 62.9423 30.9677 39.9093 5.80913 23.0216 41.9966 46.9565 18.6047 55.0964 54.6419 22.0096 57.6842 38.5569 52.1739 44.3411 31.6832 34.9296 56.2814 69.0856 30.9746 52.5373 73.251 51.2898 33.4471 26.8331 44.7205 41.0256 50.1305 37.2093 53.2213 68.2613 6.1674 3.50877 34.0836 58.3144 73.3945 52.2565 51.7799 48.9796 41.9263 41.9437 0 55.7338 31.769 61.3982 57.7778 34.5048 46.1538 58.4323 58.498 52.3507 42.2145 21.8905 68.9076 61.008 47.5472 39.834 33.5802 29.0503 56.7657 43.0642 38.6854 60.7407 59.4705 30.7692 53.3971 36.3196 36.2205 60.1893 40 26.3305 34.5515 40.8669 35.1515 69.103 77.6471 56.2212 25.641 36.8664 47.4804 53.6673 50.2773 64.9922 33.7553 28.877 23.5294 60.5452 47.4886 48.8038 57.0533 27.3504 0 59.9455 72.0887 33.9394 45.1411 61.8989 20.8531 69.3446 58.0087 19.1214 42.8044 16.7832 70.1131 77.374 36.2573 48.2663 46.0203 42.0786 40 72.8033 63.5202 31.1111 32.5275 36.4611 45.045 39.6349 18.2965 41.4169 27.2953 61.9469 36.3636 48.6094 67.6096 37.9919 58.4527 46.5257 58.7814 59.0389 61.7761 31.9527 47.9784 27.23 26.2687 58.194 46.9484 64.1975 51.4286 20.9524 24.5045 37.3984 69.5495 51.4286 66.4606 27.957 33.91 40.2266 58.5366 28.169 46.0377 0 48.5549 59.8778 40.8163 37.6569 32.3725 11.3475 63.658 31.6623 42.9708 60.4119 63.0631 58.6762 4.44444 48.4956 42.1405 75.4174 43.7055 46.9636 26.2009 58.5209 43.9716 8.42105 43.7018 47.9042 41.5704 44.0678 41.2121 43.9024 65.3061 32.4607 47.8386 22.7129 59.175 49.4322 64.8697 15.331 42.0712 56.7422 55.7823 48.9914 55.6474 44.0678 51.2821 48.11 44.908 33.6283 53.0184 47.8343 33.91 59.2275 56.4565 68.3729 49.8534 14.992 56.927 17.1946 13.8365 30.1676 77.2327 30.6569 48.0125 43.6782 31.7757 46.3576 53.2225 54.7945 67.7966 55.8405 44.1614 32.4324 41.2078 55.8304 32.9897 53.3666 62.5407 67.957 24.3137 53.2438 70.311 47.7771 6.31579 17.3228 53.211 14.6341 0 2.66667 40 4.87805 15.978 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 1.63861 (Xent), [AvgXent: 1.63861, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 55.3426% <<

