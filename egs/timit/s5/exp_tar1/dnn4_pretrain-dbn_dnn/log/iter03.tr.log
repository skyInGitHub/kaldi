nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.008 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter02_learnrate0.008_tr1.6386_cv2.2716 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter03 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11887M, used:305M, total:12192M, free/total:0.974986
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
ali-to-post ark:- ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.2475, max 7.77538, mean -0.00464958, stddev 0.983373, skewness 0.0162194, kurtosis 1.92828 ) 
[1] output of <AffineTransform> ( min -27.3208, max 18.8432, mean -3.24619, stddev 3.34846, skewness 0.160764, kurtosis 1.51511 ) 
[2] output of <Sigmoid> ( min 1.36366e-12, max 1, mean 0.178377, stddev 0.282295, skewness 1.75843, kurtosis 1.82227 ) 
[3] output of <AffineTransform> ( min -28.7228, max 16.1347, mean -3.91121, stddev 2.66266, skewness -0.00895767, kurtosis 2.76855 ) 
[4] output of <Sigmoid> ( min 3.3562e-13, max 1, mean 0.0979649, stddev 0.192459, skewness 2.95861, kurtosis 8.67428 ) 
[5] output of <AffineTransform> ( min -15.2633, max 11.3923, mean -3.20949, stddev 2.0053, skewness 0.695903, kurtosis 2.74418 ) 
[6] output of <Sigmoid> ( min 2.35083e-07, max 0.999989, mean 0.108167, stddev 0.190283, skewness 2.88736, kurtosis 8.36222 ) 
[7] output of <AffineTransform> ( min -23.8363, max 15.4994, mean -3.06716, stddev 2.27198, skewness 0.619521, kurtosis 3.51891 ) 
[8] output of <Sigmoid> ( min 4.44658e-11, max 1, mean 0.130995, stddev 0.220031, skewness 2.42191, kurtosis 5.28951 ) 
[9] output of <AffineTransform> ( min -16.5397, max 16.3425, mean -2.98753, stddev 2.67404, skewness 1.4313, kurtosis 3.18878 ) 
[10] output of <Sigmoid> ( min 6.56005e-08, max 1, mean 0.156401, stddev 0.272711, skewness 2.02314, kurtosis 2.83823 ) 
[11] output of <AffineTransform> ( min -32.3505, max 18.9014, mean -3.57376, stddev 3.24467, skewness 1.05837, kurtosis 3.6695 ) 
[12] output of <Sigmoid> ( min 8.91998e-15, max 1, mean 0.140461, stddev 0.279812, skewness 2.17768, kurtosis 3.31589 ) 
[13] output of <AffineTransform> ( min -11.9025, max 18.6098, mean -0.00775133, stddev 2.87083, skewness 0.644761, kurtosis 1.24722 ) 
[14] output of <Softmax> ( min 7.44595e-13, max 0.995201, mean 0.000624881, stddev 0.0154583, skewness 41.5052, kurtosis 1990.04 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.581883, max 0.892409, mean -0.000151825, stddev 0.0420737, skewness 0.12571, kurtosis 13.2662 ) 
[1] diff-output of <AffineTransform> ( min -0.245768, max 0.201922, mean 5.59154e-05, stddev 0.00859119, skewness 0.104807, kurtosis 50.0438 ) 
[2] diff-output of <Sigmoid> ( min -1.08809, max 1.03418, mean 0.00031087, stddev 0.0735971, skewness 0.0567204, kurtosis 9.42307 ) 
[3] diff-output of <AffineTransform> ( min -0.236747, max 0.246997, mean 4.94622e-05, stddev 0.00903289, skewness 0.283913, kurtosis 57.9517 ) 
[4] diff-output of <Sigmoid> ( min -1.06117, max 1.29532, mean -0.000102009, stddev 0.0922238, skewness -0.0211195, kurtosis 7.45397 ) 
[5] diff-output of <AffineTransform> ( min -0.248519, max 0.217942, mean 8.51938e-05, stddev 0.0092671, skewness 0.130944, kurtosis 46.1707 ) 
[6] diff-output of <Sigmoid> ( min -1.03419, max 1.15907, mean 0.000625866, stddev 0.0812778, skewness -0.00352946, kurtosis 8.12574 ) 
[7] diff-output of <AffineTransform> ( min -0.158193, max 0.176254, mean 6.92028e-05, stddev 0.00821396, skewness 0.119026, kurtosis 35.0365 ) 
[8] diff-output of <Sigmoid> ( min -0.902, max 1.16369, mean 0.000313134, stddev 0.0658299, skewness -0.0419181, kurtosis 8.39805 ) 
[9] diff-output of <AffineTransform> ( min -0.195569, max 0.126089, mean 5.46003e-05, stddev 0.00675291, skewness -0.283256, kurtosis 37.4636 ) 
[10] diff-output of <Sigmoid> ( min -0.859361, max 1.22514, mean 0.000252217, stddev 0.0528659, skewness -0.0955375, kurtosis 11.4456 ) 
[11] diff-output of <AffineTransform> ( min -0.290963, max 0.161226, mean 9.11303e-05, stddev 0.00831978, skewness -0.00338863, kurtosis 42.9296 ) 
[12] diff-output of <Sigmoid> ( min -1.41544, max 1.1087, mean 0.00103984, stddev 0.0912876, skewness -0.057867, kurtosis 3.488 ) 
[13] diff-output of <AffineTransform> ( min -0.999959, max 0.916032, mean -8.59844e-09, stddev 0.0201878, skewness -26.3153, kurtosis 1576.3 ) 
[14] diff-output of <Softmax> ( min -0.999959, max 0.916032, mean -8.59844e-09, stddev 0.0201878, skewness -26.3153, kurtosis 1576.3 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.21144, max 1.10157, mean -0.00132279, stddev 0.135417, skewness -0.0116237, kurtosis 2.65162 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.619126, max 0.500944, mean 0.0143143, stddev 0.14368, skewness 0.0231161, kurtosis 0.962698 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.78665, max 0.781277, mean 0.00217995, stddev 0.0483005, skewness 0.0858536, kurtosis 8.46192 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.792053, max 0.777926, mean 0.0126623, stddev 0.143886, skewness 0.0275135, kurtosis 3.23632 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.480768, max 0.564725, mean 0.0021424, stddev 0.031911, skewness 0.406814, kurtosis 12.376 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.573556, max 0.68772, mean 0.0218096, stddev 0.144525, skewness 0.267083, kurtosis 1.65868 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.617682, max 0.558965, mean 0.00196555, stddev 0.0292426, skewness 0.309552, kurtosis 11.437 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.766903, max 0.806261, mean 0.017716, stddev 0.135042, skewness 0.12072, kurtosis 3.28943 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.391254, max 0.39377, mean 0.00179748, stddev 0.028115, skewness 0.251975, kurtosis 8.92778 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.373998, max 0.453593, mean 0.0139776, stddev 0.109604, skewness 0.250933, kurtosis 2.13732 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.479514, max 0.512857, mean 0.00384211, stddev 0.0420864, skewness 0.551598, kurtosis 8.633 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.630016, max 0.629607, mean 0.0233294, stddev 0.130425, skewness 0.344448, kurtosis 2.53134 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.89308, max 2.40889, mean 1.08863e-08, stddev 0.109153, skewness -4.78865, kurtosis 82.4487 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.83294, max 2.10448, mean -2.98023e-09, stddev 0.357771, skewness -1.80425, kurtosis 12.2472 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 338432 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.50193, max 6.77601, mean -0.00405738, stddev 0.997423, skewness -0.00626004, kurtosis 2.0657 ) 
[1] output of <AffineTransform> ( min -31.039, max 19.9931, mean -3.2768, stddev 3.74374, skewness 0.131481, kurtosis 1.40447 ) 
[2] output of <Sigmoid> ( min 3.31088e-14, max 1, mean 0.195147, stddev 0.301821, skewness 1.59628, kurtosis 1.15254 ) 
[3] output of <AffineTransform> ( min -34.5271, max 16.409, mean -4.0342, stddev 2.8021, skewness -0.0706894, kurtosis 2.53603 ) 
[4] output of <Sigmoid> ( min 1.01176e-15, max 1, mean 0.0992712, stddev 0.197573, skewness 2.89309, kurtosis 8.13885 ) 
[5] output of <AffineTransform> ( min -14.902, max 12.449, mean -3.21394, stddev 2.03516, skewness 0.622934, kurtosis 2.47363 ) 
[6] output of <Sigmoid> ( min 3.37391e-07, max 0.999996, mean 0.110129, stddev 0.192366, skewness 2.81795, kurtosis 7.88925 ) 
[7] output of <AffineTransform> ( min -23.914, max 16.1835, mean -2.97695, stddev 2.30446, skewness 0.597269, kurtosis 3.11303 ) 
[8] output of <Sigmoid> ( min 4.1141e-11, max 1, mean 0.140431, stddev 0.227845, skewness 2.26419, kurtosis 4.44472 ) 
[9] output of <AffineTransform> ( min -16.0452, max 15.929, mean -2.93098, stddev 2.78609, skewness 1.39109, kurtosis 2.94281 ) 
[10] output of <Sigmoid> ( min 1.07563e-07, max 1, mean 0.165716, stddev 0.282649, skewness 1.90978, kurtosis 2.32607 ) 
[11] output of <AffineTransform> ( min -30.5544, max 19.3178, mean -3.67342, stddev 3.41527, skewness 1.02048, kurtosis 3.42923 ) 
[12] output of <Sigmoid> ( min 5.37497e-14, max 1, mean 0.142253, stddev 0.285973, skewness 2.14068, kurtosis 3.09875 ) 
[13] output of <AffineTransform> ( min -12.6041, max 19.7918, mean -0.010079, stddev 3.1955, skewness 0.57629, kurtosis 1.05414 ) 
[14] output of <Softmax> ( min 9.16666e-14, max 0.985581, mean 0.000624905, stddev 0.0178026, skewness 41.1778, kurtosis 1850.93 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.29566, max 0.984678, mean -0.00034144, stddev 0.038342, skewness -0.258887, kurtosis 35.5371 ) 
[1] diff-output of <AffineTransform> ( min -0.402735, max 0.222626, mean -4.70246e-06, stddev 0.007161, skewness -0.449183, kurtosis 106.984 ) 
[2] diff-output of <Sigmoid> ( min -1.61094, max 0.9149, mean -0.000207886, stddev 0.0628561, skewness -0.205309, kurtosis 17.8531 ) 
[3] diff-output of <AffineTransform> ( min -0.259418, max 0.310857, mean -4.81759e-05, stddev 0.00778524, skewness 0.117333, kurtosis 99.1097 ) 
[4] diff-output of <Sigmoid> ( min -1.35867, max 1.27261, mean 0.000227646, stddev 0.0813181, skewness -0.0152845, kurtosis 12.7999 ) 
[5] diff-output of <AffineTransform> ( min -0.366004, max 0.212061, mean -7.5765e-05, stddev 0.00815918, skewness -0.601982, kurtosis 77.5971 ) 
[6] diff-output of <Sigmoid> ( min -1.5014, max 1.00339, mean -0.000226355, stddev 0.0725322, skewness -0.0613151, kurtosis 13.1777 ) 
[7] diff-output of <AffineTransform> ( min -0.179484, max 0.211027, mean -6.33003e-05, stddev 0.00721068, skewness 0.198247, kurtosis 51.4125 ) 
[8] diff-output of <Sigmoid> ( min -0.93865, max 0.851303, mean -0.000295273, stddev 0.0565467, skewness -0.0247775, kurtosis 12.2657 ) 
[9] diff-output of <AffineTransform> ( min -0.162094, max 0.147912, mean -4.24272e-05, stddev 0.00577626, skewness -0.434658, kurtosis 49.4535 ) 
[10] diff-output of <Sigmoid> ( min -0.662118, max 0.632543, mean -3.32114e-05, stddev 0.045073, skewness -0.0704247, kurtosis 14.0791 ) 
[11] diff-output of <AffineTransform> ( min -0.179445, max 0.192744, mean -1.82224e-05, stddev 0.00689569, skewness -0.229266, kurtosis 52.0544 ) 
[12] diff-output of <Sigmoid> ( min -0.977516, max 0.862907, mean 0.0002657, stddev 0.0757986, skewness -0.0226419, kurtosis 5.49552 ) 
[13] diff-output of <AffineTransform> ( min -0.99998, max 0.867508, mean -9.33942e-09, stddev 0.0160381, skewness -28.5318, kurtosis 2213.02 ) 
[14] diff-output of <Softmax> ( min -0.99998, max 0.867508, mean -9.33942e-09, stddev 0.0160381, skewness -28.5318, kurtosis 2213.02 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.58526, max 1.99596, mean -0.000576959, stddev 0.115467, skewness 0.0243266, kurtosis 3.59527 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.438361, max 0.500331, mean -0.00120382, stddev 0.131034, skewness 0.286585, kurtosis 0.919517 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.55037, max 0.845396, mean -0.00262363, stddev 0.0475083, skewness 0.0122144, kurtosis 8.10157 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.526817, max 0.691278, mean -0.012333, stddev 0.140391, skewness 0.0288616, kurtosis 2.05163 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.619278, max 0.587955, mean -0.00206366, stddev 0.0317799, skewness -0.473056, kurtosis 15.0857 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.764582, max 0.635697, mean -0.0193958, stddev 0.157479, skewness -0.0398617, kurtosis 2.43668 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.459005, max 0.594334, mean -0.00183556, stddev 0.028196, skewness -0.129927, kurtosis 11.54 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.558304, max 0.54956, mean -0.0162049, stddev 0.139005, skewness -0.123999, kurtosis 1.85659 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.360196, max 0.299858, mean -0.00155798, stddev 0.0270031, skewness -0.223727, kurtosis 9.54048 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.561715, max 0.460741, mean -0.0108613, stddev 0.107844, skewness -0.133889, kurtosis 3.92007 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.468407, max 0.425301, mean -0.000500486, stddev 0.0380376, skewness -0.110196, kurtosis 8.70183 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.50116, max 0.464066, mean -0.00466492, stddev 0.11855, skewness 0.0238352, kurtosis 2.33713 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.78077, max 1.69184, mean -1.04213e-08, stddev 0.0854193, skewness -4.82666, kurtosis 86.0851 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.73841, max 1.50189, mean -4.02331e-09, stddev 0.26534, skewness -2.0922, kurtosis 15.2171 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0780139 min, processing 72301.7 frames per sec; i/o time 5.05665%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14106 318 182 101 16 23 147 394 174 74 294 47 870 141 67 129 255 114 165 74 149 213 181 183 408 103 94 245 56 199 233 219 209 78 485 234 501 261 303 129 32 34 202 163 535 145 178 160 16656 5473 1407 385 440 102 243 122 303 118 380 0 107 271 58 97 93 86 243 57 294 191 144 415 282 143 874 110 864 152 49 13 569 154 448 222 342 20 710 155 141 68 76 139 255 166 278 70 165 257 182 92 99 60 29 327 272 85 199 196 15 111 124 263 142 460 128 77 124 98 17 288 88 277 175 145 85 235 203 106 16 130 103 96 261 105 225 47 654 102 126 63 230 68 627 94 106 150 211 42 124 289 144 100 161 98 300 136 229 44 206 11 193 224 432 114 59 162 165 82 201 60 143 259 59 211 112 0 74 325 188 0 308 89 60 48 267 60 114 213 217 233 69 84 34 171 117 241 110 199 148 224 208 100 318 174 185 100 39 85 279 178 263 182 189 160 112 158 150 96 122 83 71 465 110 243 156 322 191 131 401 380 136 112 84 62 69 94 171 202 164 237 323 105 117 1041 218 21 103 173 175 146 274 69 106 143 83 59 358 320 29 312 180 310 237 470 549 136 85 158 80 245 175 26 156 156 198 132 23 84 27 70 350 301 265 162 4 208 159 83 111 119 62 231 365 304 54 85 79 76 168 163 124 705 189 106 48 121 19 123 117 137 169 141 132 456 113 108 147 127 25 491 355 389 168 188 199 87 83 96 64 68 88 197 54 111 190 205 366 44 139 111 166 116 142 17 246 129 132 136 118 101 283 141 319 231 267 110 156 104 38 203 22 154 518 287 30 115 144 23 375 214 888 167 91 50 151 941 147 529 88 198 86 42 20 103 215 7 131 37 106 81 22 12 221 160 126 219 148 121 262 96 292 133 232 397 251 83 68 117 120 105 280 174 760 20 61 190 113 277 70 233 90 65 10 85 200 246 146 190 262 32 169 140 133 203 48 20 191 113 261 70 14 67 149 131 195 140 173 225 118 142 479 20 65 121 644 103 272 567 0 296 110 125 160 72 193 209 23 154 136 123 42 101 71 350 71 132 225 118 52 133 131 151 84 16 351 136 37 102 80 155 336 499 610 12 156 207 219 45 193 336 298 26 79 88 241 108 284 67 113 217 108 268 207 177 338 0 305 120 149 24 75 211 69 271 255 39 24 38 172 143 166 104 74 156 223 90 72 29 82 110 165 110 21 127 56 70 231 501 270 74 7 137 123 314 232 395 203 187 41 160 122 17 81 166 128 40 126 167 271 254 173 133 146 338 236 381 113 188 153 16 31 122 164 152 22 403 94 16 266 540 9 424 185 271 152 51 169 517 345 194 95 131 53 165 217 206 266 69 37 89 10 229 185 91 95 46 196 393 238 61 98 65 90 158 275 81 102 141 157 238 200 153 34 93 114 536 130 350 119 108 80 155 62 182 91 71 357 98 68 287 22 338 165 148 65 150 43 19 475 257 27 112 101 300 81 75 49 62 166 121 115 96 155 149 114 163 60 77 150 33 195 123 137 225 13 96 1 371 772 359 185 304 20 19 266 123 818 63 1086 46 67 11 30 81 10 43 201 243 244 188 190 152 28 79 20 11 286 81 50 67 51 394 74 59 133 106 100 187 12 118 214 93 178 180 230 63 181 177 200 223 108 128 194 131 308 105 338 145 9 47 366 206 283 41 270 145 334 161 60 200 224 66 501 255 295 186 156 187 52 224 200 154 11 230 236 109 237 192 144 232 96 14 257 201 241 13 135 54 40 360 65 120 202 78 92 300 194 309 191 175 92 336 191 76 30 198 155 34 242 103 151 159 81 34 239 79 193 187 894 389 136 108 191 100 92 356 115 212 250 415 139 101 304 13 96 177 271 105 284 17 199 129 1 184 412 238 105 621 144 87 465 395 487 106 311 221 12 120 85 137 17 153 113 92 58 238 214 264 478 417 92 505 132 126 271 46 78 163 182 80 434 59 158 155 94 295 460 167 110 239 370 337 231 178 243 94 209 244 6 572 148 133 853 101 140 298 137 110 210 495 597 87 244 98 307 351 125 50 122 130 203 116 71 317 281 439 117 229 237 160 74 14 68 0 179 352 232 39 133 161 95 239 159 52 55 475 149 208 139 238 143 13 107 166 174 77 63 265 134 130 27 75 250 167 217 98 105 107 7 35 22 33 161 244 236 88 96 74 173 431 163 277 184 154 69 301 65 155 55 235 28 214 170 218 43 55 187 121 171 187 83 253 141 91 98 50 139 63 314 513 250 377 20 20 151 50 93 210 102 8 75 294 127 188 138 219 387 206 58 42 144 160 500 297 122 109 157 150 293 122 184 135 454 256 639 430 514 276 260 11 205 603 30 294 400 314 275 1369 13 135 174 545 623 167 212 18 228 189 8 269 378 188 368 54 407 110 66 152 72 182 17 70 15 364 187 435 117 417 215 453 278 238 307 229 170 222 514 1659 385 27 29 135 197 165 95 257 265 225 234 324 927 460 300 79 209 290 73 105 104 301 57 72 71 288 277 257 196 163 88 149 159 249 147 133 209 222 383 280 233 81 385 205 66 221 90 97 206 21 51 102 157 112 55 247 289 199 94 253 66 209 60 71 91 216 394 303 128 297 867 202 154 463 68 187 379 101 293 182 46 44 166 97 74 114 137 135 144 261 159 184 429 65 188 148 128 153 25 51 234 276 278 124 105 40 231 49 271 475 138 472 70 108 64 340 343 67 57 83 126 354 312 217 173 1139 101 283 121 161 41 25 133 75 25 152 172 146 145 67 68 173 860 150 185 54 238 244 264 142 245 359 64 188 236 440 467 176 100 111 397 181 34 127 285 168 80 217 39 170 96 409 264 27 293 60 89 290 93 158 44 360 209 393 470 276 215 186 17 107 387 87 199 486 200 364 92 208 98 45 112 198 200 51 75 73 84 123 256 497 140 236 327 93 108 130 82 201 557 166 152 149 89 177 110 106 78 340 468 258 114 99 72 272 150 361 278 295 290 28 136 365 263 133 172 27 246 193 368 212 124 30 441 21 75 76 130 112 227 87 275 45 268 77 220 120 69 290 57 21 181 188 104 237 443 402 322 50 177 99 344 374 167 607 329 146 320 241 58 191 64 178 543 113 28 155 219 163 210 154 367 176 195 1 841 138 164 67 156 162 210 126 393 144 100 416 188 132 120 202 89 151 241 532 67 245 136 522 206 63 792 272 178 150 161 82 451 1062 108 97 108 446 279 270 318 355 93 76 348 328 313 159 58 10 183 270 82 159 405 105 236 115 193 135 71 309 426 85 360 345 394 142 119 508 112 227 186 277 383 158 183 201 169 192 413 353 368 174 165 139 218 129 84 185 106 167 149 106 202 192 52 277 184 277 122 323 139 144 176 143 106 132 12 86 245 122 119 225 70 210 189 188 218 55 279 22 282 149 868 210 123 114 155 211 47 194 250 216 147 82 225 171 95 173 158 351 748 556 143 154 463 220 173 181 206 19 145 407 56 190 265 144 349 166 273 170 313 198 110 79 89 397 68 641 130 53 377 240 109 206 175 235 18 281 141 48 200 153 232 127 223 530 843 47 63 163 102 29 37 47 20 181 ]
@@@ Loss per-class: [ 0.573838 1.67126 0.958969 1.53138 2.11217 2.37711 2.12009 0.965764 1.21022 1.9875 0.615131 2.63199 0.764316 1.06365 2.71738 1.11665 1.22538 1.18855 1.49632 1.88977 1.14597 1.19264 1.39888 1.45191 1.72377 1.17701 2.02306 0.938057 1.82502 0.995852 1.78731 1.14226 1.4796 1.55033 0.68446 0.688439 0.44064 0.357826 0.965447 1.95682 1.91655 0.871873 0.940151 1.41121 0.509181 1.10889 1.16132 1.43914 0.412596 1.00651 0.910438 0.782088 0.543816 2.37913 1.09667 1.58693 0.880579 1.26789 1.21836 0 1.53943 0.948382 3.24041 1.71486 1.95885 1.32682 1.04672 1.26028 1.21382 0.920236 1.50013 1.16811 0.903936 0.74804 0.519132 2.2948 0.341271 1.49172 1.33026 2.83822 1.14197 0.888392 0.78241 1.09031 1.15114 1.3213 1.20869 1.16626 1.23692 1.33545 1.51914 0.85899 0.788922 1.8936 1.03806 2.12274 2.00721 0.955544 0.978328 1.27999 0.971274 1.56542 2.20484 0.799196 1.2891 0.85941 1.33232 0.850315 2.50912 0.921953 1.17987 0.570758 1.99136 0.681264 2.72274 1.72135 1.9195 1.25205 1.9558 1.24486 1.61241 1.10968 1.50295 1.48584 0.733481 1.09738 1.47651 1.17311 2.73817 1.59864 2.23229 1.33539 1.55598 1.84974 1.65384 1.49012 0.760911 1.76908 2.02075 1.64562 1.6628 1.79679 0.724596 2.38983 1.30024 1.42499 1.49708 1.42253 1.30234 1.09896 1.04695 1.2998 1.61516 1.19262 1.20565 0.975029 0.860838 1.93047 0.811639 2.30929 1.03812 0.858298 1.46221 1.64022 1.73715 1.83681 1.719 1.8243 1.81243 1.24846 0.902956 1.11284 1.26012 1.59614 1.36004 0 1.88259 1.17649 0.807495 0 1.90668 1.16091 1.09519 1.52877 1.59711 1.46809 0.859237 1.67823 1.49645 0.319015 1.34705 1.72344 1.429 0.897659 1.60484 1.01265 1.12229 1.7357 1.27992 1.0334 1.71592 2.4763 0.689911 2.00916 1.72998 1.12495 2.01904 1.71026 1.43578 0.966508 1.28507 1.4604 1.25791 0.914363 1.99815 0.924701 2.66096 1.71254 1.57184 1.55504 1.78248 1.46935 1.82732 1.72352 0.953125 0.969956 1.7283 1.13062 0.806134 0.730245 1.36467 0.969312 2.49602 1.03683 0.624129 2.52767 1.5216 1.19612 1.58657 1.399 1.92637 1.15107 0.860052 0.815004 0.853276 7.30939 3.01232 1.78106 2.75352 2.62658 1.64418 1.63607 1.48251 1.74545 1.77654 1.87803 1.26831 1.15806 1.43813 0.665754 0.465739 1.69104 2.24884 0.757922 0.929522 1.13559 1.02693 1.49525 1.65952 1.17755 1.40354 0.848584 1.54848 1.13174 2.85179 2.15465 1.39496 2.00786 1.70655 1.39731 0.829938 1.94738 2.31643 0.844351 7.26882 1.93099 1.29092 2.14333 1.54566 1.20191 1.62832 1.40377 1.0436 1.30872 2.51887 1.6266 1.44873 1.4928 1.23677 0.607536 1.32882 0.944976 1.79581 1.66965 1.50781 1.84113 2.75434 3.52188 1.40971 1.20254 0.896732 1.89904 1.44507 1.58171 2.0518 1.0987 1.61208 1.75623 1.65279 1.49572 0.974351 0.714153 1.05533 1.51996 1.14923 1.23478 1.23337 1.0353 1.92263 1.84404 1.28915 0.847906 1.84736 1.0979 1.23618 1.14572 1.08801 2.31744 1.86638 2.04369 0.945011 1.54376 1.03897 3.48453 1.12209 2.15526 2.30554 1.17269 2.424 1.84363 1.06421 0.710128 1.28641 1.00212 1.25095 1.34759 0.735226 1.09183 1.97598 1.62041 2.47332 1.57514 0.856597 1.50417 1.45277 1.42857 2.76166 3.36033 1.59674 1.04647 1.10424 1.29167 1.5317 1.70242 1.8287 0.931795 1.69059 0.706171 3.19063 1.46787 2.30887 0.737369 1.51869 1.04084 2.22333 6.92025 1.85209 1.41275 0.963911 2.16679 2.72689 2.94621 1.30414 1.72796 0.906966 0.823475 1.0524 1.54784 2.55529 1.00844 1.06878 1.64184 1.15138 1.28993 1.60297 2.73583 1.19401 1.74635 1.53508 1.51685 2.33331 1.32675 0.89778 2.13672 1.48074 2.25213 1.19998 2.4016 1.81702 0.843695 1.22655 2.16644 3.02669 2.32513 1.41387 1.3126 1.09445 1.55082 1.96611 2.3566 1.83532 1.37261 2.97763 1.47246 2.11891 2.46665 1.74325 0.878086 1.24807 1.89793 1.99741 1.17314 2.36582 1.03786 1.31362 1.36449 2.22499 1.48408 1.90434 1.09258 1.07668 1.96877 1.74006 1.11257 0.867138 2.30993 0.886272 0.761131 0 1.78266 1.5971 1.54018 1.14437 2.19052 1.25271 1.43304 1.10188 1.34571 1.36694 1.30972 3.14095 2.08525 2.06108 1.19178 1.9833 1.63221 1.62594 1.4739 1.51693 1.213 1.40145 1.03312 2.15504 2.34577 0.666276 2.29433 2.03587 2.84157 1.85622 1.71248 1.80629 0.7833 0.953462 3.48543 0.817098 2.00621 1.7512 2.47204 2.46083 1.9356 1.45124 1.78452 0.869836 1.28822 1.4106 1.04758 1.31591 2.22938 1.82547 1.56008 1.37416 1.45183 2.00462 2.5704 1.3673 0 1.35926 3.21178 1.01465 1.18621 2.14723 1.35855 1.18794 1.49037 0.596717 1.91525 1.44882 1.49161 1.59226 1.68394 1.66439 1.60651 1.71349 2.78888 1.82723 1.00891 1.33529 1.47866 2.34474 1.14765 1.20108 2.23655 1.94389 1.24296 1.81737 1.04833 1.60323 0.98466 1.66874 2.07994 5.65937 2.11934 1.08267 1.27838 1.14617 0.595038 1.39982 2.20256 2.67183 1.24039 0.823462 2.35265 1.62854 1.4152 1.71228 1.53852 1.60703 1.03946 1.30692 1.54117 1.692 1.67383 1.18019 0.874461 1.12279 1.82536 2.19045 1.3281 1.97934 4.57268 1.63175 1.39435 0.826968 0.928473 1.676 0.670505 1.90735 2.47265 1.36936 1.72688 4.12175 1.09765 0.913901 1.9038 0.953581 2.54599 1.18377 1.46487 1.30498 1.73048 1.06954 1.58667 1.78714 1.90982 1.69157 1.21385 1.59006 2.2286 1.87367 1.22469 4.25807 1.28703 1.61272 1.52329 1.99328 2.80066 1.64351 1.10995 1.31801 1.19554 1.80385 1.66111 1.54539 1.32314 1.02752 2.04103 1.85776 2.10796 1.0081 1.86655 1.94805 1.56337 2.04885 1.79518 1.29723 0.899924 1.83513 1.6299 1.84783 2.25858 0.881828 1.01692 3.11456 1.8495 2.12362 2.87181 1.17545 1.62331 2.3923 1.14834 2.43502 1.43177 1.11115 1.87763 1.57378 2.50522 2.75841 2.09716 1.78981 1.69891 0.772417 1.57269 1.2752 1.14877 1.85221 1.60792 2.79643 1.59061 1.32752 1.2358 0.98188 1.95613 1.30752 1.0718 3.09703 2.12898 1.40257 1.23972 2.20841 1.15434 0.92705 2.10449 2.06299 1.16548 4.91947 2.76703 11.0202 2.14517 0.903518 0.51819 0.965094 1.73872 2.68634 2.79 1.41209 0.931256 1.30413 1.17705 0.921391 2.05287 1.79517 3.89157 1.44705 1.7998 5.18349 2.16159 1.49404 1.71813 1.64639 0.95073 0.824022 2.19064 2.66573 1.74893 1.56065 5.32538 1.66636 1.55073 1.40353 2.62192 1.8829 1.29963 4.13249 2.22662 1.07621 2.31964 2.11496 0.962854 3.02125 1.31579 1.02911 2.18728 1.92181 1.54102 1.84005 1.7765 2.07907 1.23131 1.56248 1.46222 0.969314 1.76565 1.38212 2.86405 1.15979 1.52472 1.10352 0.990363 3.91989 1.2953 1.17414 1.21612 1.56123 1.11565 1.89388 1.4486 1.25277 1.78076 1.61105 0.972391 1.52258 2.0911 1.09079 1.35969 1.88304 2.15306 1.06056 1.07068 1.43711 1.91002 1.82291 1.42446 4.38487 1.10813 1.40558 1.56173 1.46118 1.83931 1.88096 0.994635 1.21417 2.3689 1.26613 1.00503 1.36787 1.81112 2.04455 2.35087 2.35361 1.19027 1.36028 2.03963 1.76789 2.26864 2.3126 1.33828 0.709914 0.944793 1.67259 1.20517 2.12004 1.26396 0.993447 1.59374 1.26592 0.703558 1.28926 1.49444 1.84508 1.92343 1.5906 1.98148 1.24317 1.85346 1.46008 1.99681 1.38382 1.70713 1.44821 0.713328 1.81575 1.77271 1.70946 2.52699 2.30878 1.45192 1.14036 1.12056 0.801475 0.850152 1.9423 1.84137 1.62619 3.08927 1.63428 1.3947 1.49432 2.10667 1.22991 2.05078 1.19229 2.29764 8.89948 1.39519 1.05926 1.11367 2.26668 0.867318 1.93405 1.68052 0.740312 1.31044 1.00533 1.39449 1.56458 1.30054 3.15508 2.14317 1.73159 1.23131 3.10946 1.20664 1.54614 2.62191 1.60983 1.08488 3.68058 0.92756 0.94065 0.83106 2.23845 1.39024 1.71888 1.34716 1.91345 2.09321 1.9509 1.47772 1.90493 2.66082 1.32099 1.05673 1.58673 1.36349 1.70203 1.0861 1.66368 1.90565 1.60064 0.963943 0.852138 1.10968 1.11915 1.05742 1.01162 1.16418 1.2635 1.80153 5.30608 0.86894 1.09141 2.07073 1.02088 1.2874 1.70475 1.29685 1.65019 1.27609 0.926347 1.15346 1.39051 2.1006 1.08848 1.76591 1.60176 1.11878 1.89072 2.93591 2.09753 2.095 0.751991 1.62224 1.5774 1.38063 2.27872 1.18012 2.2185 2.45366 1.56704 1.85202 1.32913 2.47722 1.75462 0 2.10564 1.11243 1.06895 1.31274 1.74094 1.13623 1.5509 0.946857 2.08957 3.0284 3.09344 1.04306 2.43776 1.28651 2.96005 1.38246 1.69387 3.63395 2.06464 1.24785 1.92007 2.86068 1.92613 1.4002 2.20083 1.30825 1.12207 2.4459 1.05125 2.01256 1.87919 1.72514 1.42664 1.28982 5.64123 2.03261 1.54253 0.912835 1.50927 1.2208 1.12358 1.85846 1.7615 2.35272 1.63944 1.14975 1.54755 0.801651 2.0242 1.69814 1.46839 1.53145 1.58725 1.71434 1.49667 1.42265 2.38385 1.69337 0.924869 1.02884 3.16478 2.42922 2.09903 1.58037 1.96523 1.90076 1.89128 1.61405 1.35755 1.73206 1.08033 2.18211 3.2175 4.20454 1.38247 1.21013 1.98433 1.69118 1.7662 2.50307 1.47538 3.44922 1.95531 1.60975 2.28522 2.36902 1.76817 1.21214 1.80822 1.87261 1.95181 0.947316 1.80156 0.886186 2.56356 3.03488 2.20188 4.08838 1.24529 1.07834 1.91 1.70817 1.3434 1.35048 0.921689 1.4953 1.48721 1.80842 0.843345 1.0484 1.8489 1.86776 1.82515 1.98893 1.27388 2.49943 1.22781 0.817191 3.17294 2.05456 1.86773 0.91071 1.39628 0.870813 3.03772 1.75772 1.27655 1.63104 0.951132 1.13847 1.34206 3.45585 1.33289 2.52177 4.30342 0.726248 0.998038 2.65609 1.08717 2.02361 2.02733 0.998268 1.99049 1.29309 2.36522 2.43105 2.19374 2.29685 1.15106 0.663193 1.37469 1.03034 1.97279 1.0553 1.87271 1.06299 0.968085 1.3132 1.52837 1.64383 2.96369 1.14008 1.11649 0.913771 1.1594 2.7271 1.94019 1.29153 1.41598 1.13536 2.34452 2.30336 1.42963 1.56066 1.67828 1.54496 0.750424 1.49436 1.46131 2.68036 1.91857 1.34326 2.11895 0.997368 1.94612 1.54532 1.63552 0.938203 1.54633 1.94898 1.66563 2.136 2.07668 3.2176 1.42377 1.43804 2.3107 0.886015 1.29879 2.5359 2.71035 2.35486 1.08099 1.31567 1.41094 1.65045 1.48666 1.18342 2.10762 0.963268 2.04633 0.678338 1.36251 2.5996 3.81926 3.71152 1.87714 2.82854 1.80053 1.54411 1.17051 2.41106 1.38453 2.22735 1.26932 2.73049 1.86179 1.19029 1.94503 0.800869 1.3689 1.51405 2.18924 0.836358 1.12857 1.79446 1.63184 0.913385 1.57434 1.34149 1.36476 2.36561 1.95381 1.65879 2.13469 1.8386 1.18619 1.32903 1.77888 1.82865 1.66843 1.53297 1.58965 1.31563 1.76917 2.43972 1.02408 1.69436 1.69314 1.69297 2.12368 1.21811 2.141 2.5995 2.0068 1.3772 1.38071 1.45028 1.45079 1.91687 1.61261 1.51721 1.61323 1.03801 2.43331 0.880694 1.39713 0.958236 1.37414 1.3004 2.37726 2.42202 2.25429 2.17284 1.16166 1.34534 1.51265 1.81058 2.37639 1.0876 1.2825 0.820882 1.35714 1.37745 1.60476 1.99284 1.88138 2.58947 2.10207 1.63542 1.79577 1.26911 0.870536 1.58276 1.80339 1.44775 0.81326 1.6743 1.21237 1.51872 1.58188 1.0162 0.812142 2.67269 1.44103 2.22757 4.6283 1.12244 1.66316 1.55866 1.60457 1.65246 1.54415 1.24202 1.68806 1.39145 2.35528 2.03897 1.0113 1.6252 1.81091 0.82494 2.43001 1.51964 2.19341 0.893617 2.10619 1.60993 0.76628 1.43867 1.92912 1.11921 2.32197 1.29005 2.03567 0.874457 1.24073 1.39792 1.26919 1.14969 1.66786 2.39897 1.87112 2.03086 1.56404 1.74957 2.0294 1.11526 1.55988 1.27023 2.18589 1.47967 1.40435 1.51144 2.04677 1.59943 1.5699 2.7444 2.02266 2.43663 2.50135 1.81498 1.26425 1.05748 1.28432 2.11638 1.37435 2.18224 1.50358 1.47236 2.32835 1.75408 1.3501 1.36025 1.97777 1.77857 2.38718 2.9249 1.44625 2.70966 1.35633 1.11704 1.56839 1.58921 2.02978 1.56894 2.03152 0.762339 2.5182 1.16775 1.53044 1.18052 0.607901 2.90408 1.84101 0.894721 2.85507 1.90969 3.17793 2.59459 2.02534 2.20003 2.06132 1.61577 2.07012 1.88894 1.38749 1.93602 1.31117 1.6258 2.76373 2.60496 1.33319 1.8421 1.52283 5.14027 1.03992 2.07452 1.84698 3.70808 2.42397 2.00181 1.12051 2.4877 1.21976 1.37059 2.10431 1.50519 2.02886 1.55203 1.69962 1.87343 1.86076 1.32928 0.906043 1.93569 1.55754 0.817695 1.48896 1.88988 2.58674 1.40251 1.43424 1.41348 2.02615 1.56688 0.919616 3.36247 2.98666 2.05457 1.54328 0.739804 1.65736 1.18942 1.60141 1.58503 1.62436 9.17267 1.15795 1.70466 1.04182 1.25818 2.18301 1.81823 1.15276 1.18782 1.6579 1.63603 2.33895 0.666699 1.36397 1.55598 2.10533 1.84827 2.50019 1.44344 1.65305 1.64064 0.999114 1.27197 2.3279 1.50446 1.99325 1.50895 1.13666 1.71014 2.52959 1.55285 1.63016 2.0038 0.886618 0.70528 1.53271 1.97379 2.03365 1.5663 1.35607 1.49756 1.1227 2.02851 2.67161 2.44542 1.2564 1.53993 1.35612 1.39195 2.07926 4.45009 1.15917 0.807833 1.95828 1.72879 1.13558 3.0776 0.92184 1.3701 3.23143 1.43357 2.60777 0.847175 0.681904 1.96785 1.61867 1.57769 1.75302 2.25261 1.02425 1.25423 2.16916 2.20644 2.05846 1.7864 1.87124 2.34594 1.77773 1.9795 1.37277 1.87436 1.62591 1.02631 1.84356 1.20409 1.60034 1.73326 1.21865 1.05192 2.1923 1.67853 2.32755 3.02569 1.5122 1.72197 1.14697 1.50494 2.06 2.38528 2.30943 0.986971 1.49485 1.23218 2.27112 1.98423 1.43521 1.06074 2.1043 1.26995 2.92976 1.51267 1.24731 1.54123 1.74127 1.83271 2.84798 1.12057 1.97797 1.73867 1.02266 0.660388 1.22248 3.53139 1.38229 1.74934 0.679879 1.96409 1.95333 1.9101 1.25003 1.6371 3.37728 1.79965 1.38835 1.67052 1.53675 1.67968 1.56552 1.39332 2.20004 1.6581 2.40112 1.2875 1.40881 1.12119 2.68898 1.64212 1.28718 1.2367 1.41139 1.58197 1.70937 1.43456 1.47047 1.85824 1.72102 1.59013 1.76865 2.06024 1.29529 1.315 0.948103 1.38972 2.86383 1.19636 2.81528 2.26789 2.16231 0.527744 2.01485 1.41207 1.44076 2.51143 1.81361 1.41094 1.21587 1.12134 1.32378 1.97267 1.77103 1.60944 1.23115 1.72364 1.46422 1.13714 0.957139 2.62378 1.51605 0.774459 1.37085 3.4072 2.05605 1.41335 2.70995 4.95614 4.64621 1.80012 2.82192 2.79952 ]
@@@ Frame-accuracy per-class: [ 78.7793 55.887 70.137 56.1576 48.4848 55.3191 38.6441 72.7503 69.341 38.9262 81.4941 18.9474 76.0482 73.4982 19.2593 67.1815 63.7965 68.1223 64.0483 49.6644 66.8896 66.0422 64.4628 53.406 47.246 67.6329 40.2116 69.6538 42.4779 64.6617 47.5375 63.3257 61.5752 57.3248 79.7116 79.7441 88.5344 92.9254 72.4876 48.6486 52.3077 78.2609 71.6049 48.9297 84.5938 72.8522 63.3053 54.8287 87.0411 63.9993 64.4405 80.6744 85.5846 17.561 64.8871 59.5918 74.7941 59.0717 67.5427 0 57.6744 72.9282 20.5128 54.359 39.5722 65.896 70.6366 52.1739 69.6095 70.4961 58.1315 67.148 73.9823 75.2613 83.8193 28.9593 88.3748 59.0164 62.6263 29.6296 64.4425 71.8447 77.592 71.9101 69.781 73.1707 62.7727 66.2379 60.0707 68.6131 50.9804 76.7025 75.1468 43.2432 67.1454 55.3191 47.1299 66.7961 71.2329 64.8649 71.3568 54.5455 33.8983 74.8092 62.7523 69.0058 66.6667 77.3537 45.1613 68.1614 66.6667 83.4915 42.807 81.6504 24.9027 50.3226 42.5703 56.8528 45.7143 63.7782 54.2373 67.027 56.9801 54.9828 77.193 67.9406 56.0197 62.9108 42.4242 49.8084 38.6473 58.0311 53.1549 51.1848 52.3282 54.7368 80.6723 48.7805 34.7826 55.1181 57.2668 39.4161 80.3187 34.9206 55.3991 55.814 56.2648 49.4118 53.8153 66.3212 71.2803 64.6766 54.4892 64.9746 64.5591 71.0623 75.817 38.2022 75.5448 60.8696 68.7339 73.9421 53.4104 59.3886 48.7395 43.0769 48.3384 54.5455 50.1241 51.2397 74.5645 67.8227 58.8235 66.1939 51.5556 0 38.9262 67.5883 76.9231 0 45.3809 69.2737 67.7686 53.6082 56.4486 47.9339 72.4891 42.623 57.4713 92.5054 58.9928 52.071 72.4638 76.3848 54.4681 73.2919 70.5882 46.6165 63.2997 71.7149 48.4412 22.8856 81.3187 46.9914 53.9084 65.6716 45.5696 46.7836 62.6118 71.7087 60.7211 55.3425 64.3799 72.8972 43.5556 71.9243 30.5648 54.9223 57.1429 55.0898 48.951 56.7132 52.4887 52.1561 70.9265 74.1085 45.4308 66.9202 71.731 78.5808 65.2015 73.7778 30.7692 72 83.4532 33.8624 51.312 65.679 54.7112 60.6316 38.3308 71.09 71.4894 73.9318 75.9725 4.65116 16.4251 44.9568 25.641 36.8601 49.9089 40.2878 61.9718 53.6585 43.1138 45.3782 62.4826 66.7707 67.7966 81.28 88.6427 47.9871 43.7895 79.2774 72.0655 71.0623 73.6842 58.0442 53.4161 65.9878 59.8291 75.4717 58.7859 63.8978 27.7078 34.717 72.3404 35.503 61.8182 56.7376 74.7504 44.7761 39.548 74.4615 0 44.1247 64.5768 31.1377 60.9865 64.4351 49.6 57.4514 69.7674 64.0394 34.8624 54.9708 56.6038 57.5163 65.8754 84.4037 54.6185 71.7222 54.8813 46.0094 49.4845 41.9753 35.8974 17.004 66.383 69.0909 78.4661 48.7633 52.0755 52.3549 37.0044 64.5161 60.339 47.0588 58.8235 53.5097 70.8861 81.3864 67.6558 62.069 70.6767 64 69.4611 70.4663 46.5116 48.1752 67.7966 74.9367 44.0367 67.2646 60.8924 71.5328 67.6671 44.9438 58.0645 38.565 70.8709 57.5107 71.5789 34.2857 67.3428 37.8378 27.9245 68.1319 31.2236 55.1724 76.1905 81.2721 61.9718 69.5464 62.4299 59.7285 81.7891 68.8995 33.7662 59.9509 40 62.1359 78.4957 58.087 68.8525 55.4113 26.9896 29.7872 53.7949 71.7949 72.2566 62.0896 59.0164 51.4851 53.4653 73.3935 43.3898 82.9084 25.9887 64.4836 47.3988 87.0588 73.1707 81.1594 43.6195 0 41.0646 69.3333 75.1174 36.8098 44.4444 32 59.5937 46.1059 78.2609 76.9932 68.6869 60.9053 32.7619 71.5026 66.3248 54.6816 67.0968 59.8742 54.8708 27.5449 58.3942 53.617 59.751 52.1327 20.6774 58.4527 74.8192 58.5366 50.4065 43.0446 65.1982 34.2342 48.227 73.6617 67.4033 44.2748 19.0476 22.2222 62.3441 62.4746 68.942 45.1444 44.9524 27.6923 47.7876 59.0747 23.97 51.5971 30.9278 43.9024 45.4308 73.1278 63.8623 42.5532 55.1724 66.6667 34.7826 70.7224 61.3811 66.9039 41.4986 53.2151 43.8819 63.1579 64.2336 58.5366 45.8015 66.6667 77.4244 32.8502 76.6972 80.5286 0 45.8685 53.3937 58.9641 69.7819 37.2414 67.1835 55.8473 72.3404 59.5469 59.3407 59.919 9.41176 31.5271 46.1538 68.7589 40.5594 54.3396 52.3282 59.9156 62.8571 68.9139 64.6388 71.2871 28.4024 36.3636 82.2191 33.6996 56 27.3171 50.9317 54.0193 46.3596 76.8769 75.8395 24 74.1214 43.8554 46.9248 28.5714 26.8734 42.4963 55.2764 56.6038 75.4717 71.1864 57.971 64.5161 62.5659 28.1481 47.5771 52.4138 56.2212 63.3147 39.0361 37.1831 60.2659 0 58.2651 19.0871 73.5786 69.3878 39.7351 61.9385 74.8201 59.3002 82.9746 40.5063 65.3061 64.9351 57.3913 56.446 45.6456 48.8038 52.349 23.6422 53.2438 72.9282 57.931 57.6271 26.6667 70.5882 64.6526 32.5792 60.4651 69.8039 44.2478 62.4113 56.5875 74.3769 52.1257 42.953 0 29.0909 71.2551 60.7313 72.6882 83.1858 59.4595 38.4 21.6867 70.405 78.3673 34.2857 58.8957 61.2613 52.9183 64.1975 43.4783 68.6567 65.5617 59.725 54.1787 48.6891 72.3549 75.3323 70.1903 54.7837 48.4581 62.069 38.4365 6.06061 47.619 56.3265 72.9483 72.7869 53.3333 83.0235 44.4444 54.5455 57.7861 55.3191 10.5263 71.6137 74.9326 49.3554 72.7869 46.6019 66.0767 61.0628 61.6498 49.8715 71.2042 48.6692 37.3832 47.7341 46.8966 65.8596 56.2852 43.1655 61.3333 68.1564 0 59.2593 58.7601 61.2022 49.2147 17.2043 52.9262 66.8361 59.9581 66.6667 51.7766 54.9618 57.4586 57.4132 70.7804 38.0368 47.8049 41.6961 66.0317 52.8302 45.3865 58.6319 43.4783 38.5027 55.0218 73.439 49.0421 50.4993 47.6987 38.7097 72.0497 70.0965 14.4 36.1644 45.9016 26.5734 70.7692 54.8223 33.5766 67.8261 35.5556 60.2659 62.2356 33.67 50.3817 31.2292 25.2874 51.2821 51.3144 53.2039 80 50.6667 64.0394 64.5591 56.4417 62.2517 16.1616 56 60.6607 66.6667 74.4589 49.7409 56.5916 68.8963 24.4541 42.2018 56.1983 69.6774 34.5515 71.6418 67.5192 45.3441 41.4545 66.5188 0 32.1244 0 41.7227 72.4919 86.2309 70.6199 45.977 29.2683 20.5128 60.4128 73.6842 63.653 56.6929 74.9195 49.4624 57.7778 17.3913 68.8525 53.9877 0 43.6782 55.5831 49.2813 54.3967 73.2095 75.0656 32.1311 45.614 59.1195 73.1707 0 56.1955 62.5767 61.3861 35.5556 48.5437 66.4132 17.4497 45.3782 68.9139 34.7418 40.796 72 16 61.6034 73.6597 34.2246 52.1008 59.8338 51.6269 36.2205 44.0771 60.8451 47.8803 56.8233 74.6544 47.4708 60.1542 22.8137 65.8023 62.5592 68.2422 73.5395 0 75.7895 70.9413 62.4697 56.4374 79.5181 46.2107 56.3574 62.4813 41.4861 52.8926 75.8105 53.0067 40.6015 66.999 62.6223 50.423 39.1421 70.2875 68.2667 57.1429 44.5434 41.3965 61.4887 8.69565 72.885 58.351 58.4475 57.2632 50.3896 56.0554 72.2581 68.3938 34.4828 63.301 75.9305 63.354 44.4444 42.0664 36.6972 41.9753 66.8516 65.6489 37.3444 48.3951 33.121 36.7568 59.9002 82.7763 67.8514 49.6084 62.6781 48.6486 64.4874 78.329 50.9804 72.1311 82.6196 60.4502 55.0725 44.5361 46.3768 56.1056 47.6489 60.1227 60.8696 65.9708 40.2516 65.1163 58.1333 54.332 78.0488 46.8864 52.5346 54.3081 28.8557 42.1622 59.467 69.2641 66.8235 76.6467 77.0156 51.6129 48.2759 55.1724 37.037 45.5959 63.662 59.6685 38.8626 64.3234 51.4286 63.1579 31.6602 0 56.3686 73.2121 65.8281 38.8626 75.1408 47.7509 54.8571 77.7658 65.9924 71.3846 61.9718 53.6116 64.1084 32 35.6846 45.614 65.4545 5.71429 61.2378 56.3877 35.6757 66.6667 71.2788 16.317 74.8582 73.1452 74.491 25.9459 59.9407 53.5849 64.0316 50.0921 47.3118 47.1338 55.0459 48.2192 17.3913 62.1404 68.9076 55.5205 62.3794 55.0265 71.066 52.3344 49.5522 62.4434 70.9812 73.4143 67.8519 70.4104 62.1849 68.5832 60.3175 55.8473 47.4438 0 79.6507 64.6465 35.206 71.0018 69.9507 56.2278 64.9916 50.9091 56.1086 75.0594 70.4339 63.5983 37.7143 69.1207 52.7919 55.935 70.8393 50.1992 13.8614 50.6122 28.3525 76.1671 58.3691 46.1538 57.0079 33.0373 68.2594 34.0426 30.9368 58.1053 45.4829 69.7987 41.3793 56.9343 0 40.1114 69.2199 70.5376 60.7595 58.427 72.4458 48.1675 72.2338 42.0063 19.0476 12.6126 73.6067 45.4849 59.952 16.4875 62.0545 56.446 7.40741 36.2791 61.2613 44.1261 23.2258 50.3937 62.1469 39.4052 60.5364 76.3636 33.1126 71.0579 41.194 42.7586 42.6396 54.9763 59.5349 0 47.8873 57.7778 74.6269 56.3467 66.2577 69.7674 42.9379 44.5596 38.9262 51.2968 73.2329 60.5505 78.9189 47.6965 51.7799 54.6763 51.7413 51.9084 47.5884 48.6486 58.5987 24.5614 46.1538 75.6598 64.5309 36.7816 34.2342 39.4667 49.3827 51.895 42.1333 47.9042 52.86 63.6042 46.9945 67.0051 29.703 32.2581 4.72441 64.5469 65.0438 38.3234 54.0397 58.5366 29.2683 61.3861 3.9604 42.7807 48.4561 40 35.2941 43.7086 69.2699 59.6078 53.0504 38.9892 76.5376 52.9032 73.1235 32.4786 25.8824 35.9862 9.34579 63.7363 71.5966 43.2653 51.1416 57.1429 63.7874 75.6388 44.0816 59.0786 55.3506 75.6876 72.9045 43.4715 41.115 50.3401 48.8246 60.6526 34.7826 69.5864 76.3877 32.7869 42.7844 48.9388 73.4499 56.9873 74.8448 22.2222 45.7565 67.0487 46.3795 68.9655 68.6567 62.1176 27.027 52.954 40.1055 0 79.4063 75.5614 30.7692 68.6567 53.211 42.454 72.3982 40.6015 68.8525 33.1034 29.0411 40 43.9716 77.4194 78.738 62.9333 69.3456 51.9149 70.6587 48.7239 72.5469 74.6858 60.7966 53.0081 54.0305 30.4985 66.9663 71.137 72.9135 70.8171 50.9091 44.0678 70.1107 59.2405 66.4653 39.7906 41.5534 58.7571 50.9978 55.4371 58.5516 76.8733 57.5461 56.5724 35.2201 47.7327 64.3718 50.3401 72.9858 43.0622 52.073 53.913 71.7241 51.7483 45.7539 57.2973 46.6019 49.3639 28.1346 68.9266 67.5585 37.6176 71.7435 67.1186 35.206 35.3222 40.4494 73.5332 64.5276 61.6702 46.6258 55.5123 64.7202 45.1128 76.298 47.5138 78.9744 52.7845 32.5581 15.534 12.6829 42.5397 25.7778 63.0631 54.9495 64.5941 26.5664 68.7831 44.5759 63.1579 39.6181 46.281 75.5245 45.9016 76.6744 56.7807 54.6952 38.9105 75.9664 66.7435 49.8765 56.3107 71.6289 54.0146 57.0667 59.025 34.4828 45.9966 48.7671 47.3118 58.427 68.4685 64.6154 51.0067 52.4017 51.6364 61.9926 55.3633 65.0096 40.7524 35.2304 68.6845 51.9084 50.3979 57.2391 36.5759 69.0554 39.2157 27.1845 51.1727 62.5678 66.0682 65.8635 64.455 34.5679 48.8121 62.6263 53.407 71.9243 27.4368 74.709 58.156 78.341 71.3178 61.674 36.9723 29.6296 31.3043 41.9162 68.7747 58.11 58.56 49.6552 38.0403 47.477 66.0099 75.1323 60.9053 59.4427 48.1928 43.1373 53.1835 34.4371 31.3725 56.3934 48.1159 64.8464 72.8522 51.8519 42.3358 55.9078 76.8158 51.8272 67.9245 62.3853 46.1216 64.6217 79.3951 28.0702 58.6558 43.1154 17.0543 71.0875 54.5455 53.8025 53.6898 50.9915 56.7164 69.0583 47.7987 63.9118 31.8841 48.6275 74.2557 51.0386 59.6273 81.3793 30.3797 55.7185 39.3782 76.9231 38.5633 50.9091 80.0681 62.8099 37.9888 70.9122 38.5027 64.9842 47.191 75.7282 68.2578 58.4498 63.1243 63.6528 48.7239 28.9544 62.8571 47.4419 57.8065 57.1429 43.1078 61.0483 59.8504 68.3128 33.5135 51.3189 69.0355 52.7473 34.6667 53.9043 58.3541 23.301 51.6556 31.2925 33.1361 46.9636 67.0565 70.5528 68.3274 45.666 64.1221 42.7807 58.0645 57.4713 37.5758 51.1166 57.7578 61.2613 50.4918 55.5184 33.5196 19.1549 53.3937 30.9859 61.1465 69.0162 54.429 51.4507 42.7948 55.2764 31.7241 77.4312 33.887 68.8797 62.4776 63.9594 85.3701 17.5439 44.6886 74.9658 28.8425 45.6929 24.9275 40 50.7099 38.2429 39.3487 57.8824 42.5703 59.0164 61.6082 60.4651 58.2781 58.8235 32.1839 41.7778 61.978 49.1429 58.8022 4.3956 67.4115 45.1613 48.5261 13.278 30.2158 46.4716 67.8261 37.2093 66.1157 62.069 35.4067 61.8947 42.841 56.646 50.5426 51.4851 47.3239 65.3266 75.1814 37.6502 56.7164 75.2263 60.698 45.0512 35.2574 55.0725 61.5385 59.0078 51.1628 59.944 72.6771 12.3348 21.0526 44.373 65.1481 84.4037 58.4323 65.3722 54.6939 49.8584 52.1739 0 60.9626 44.7653 69.9088 65.1852 42.8115 54.7692 66.5083 64.8221 59.2122 49.827 29.8507 75.3902 66.313 60.3774 49.7925 44.9383 46.9274 64.0264 52.588 47.5117 81.4815 65.1731 40.293 58.5646 44.5521 51.9685 65.9937 50.2752 29.6919 50.4983 48.2972 54.5455 74.4186 81.1294 66.3594 40 47.0046 54.8712 61.1807 58.0407 70.9576 43.038 40.6417 30.0654 64.8494 54.7945 59.3301 63.9498 37.6068 9.52381 65.9401 76.525 47.2727 53.2915 70.2836 25.5924 75.6871 65.8009 26.8734 53.1365 26.5734 77.5444 81.3599 45.614 58.2524 50.6512 46.6413 43.5088 76.9874 67.4533 48 44.3956 39.6783 53.3333 47.9791 29.0221 52.861 38.2134 71.3864 46.7532 55.3809 69.5898 45.5902 68.7679 53.7764 63.0824 72.3112 70.2703 34.3195 58.7601 33.8028 33.4328 62.2074 54.4601 70.6173 60.2597 41.9048 36.3964 43.3604 74.5946 58.7755 69.2427 34.4086 40.8304 47.0255 70.3833 40.3756 64.1509 24 54.3353 64.7658 60.4082 49.3724 41.2417 28.3688 68.4086 37.9947 49.3369 67.7346 77.4775 65.8318 17.7778 58.7611 49.4983 80.7139 47.0309 55.8704 40.1747 66.881 57.6832 12.6316 54.4987 61.0778 50.8083 52.2034 54.5455 56.3193 68.2216 41.8848 55.9078 35.9621 65.4339 54.7762 70.2606 23.6934 55.0162 62.9989 61.678 61.0951 61.157 54.7215 76.9231 63.9175 50.0613 49.5575 57.2178 54.2373 47.7509 64.3777 69.0691 73.8574 63.3431 21.0526 69.0176 31.6742 41.5094 48.0447 81.761 40.8759 53.0008 62.8352 42.9907 55.0993 57.7963 65.7534 73.6077 60.3989 49.2569 37.8378 51.5098 64.311 53.6082 63.3416 71.0098 73.5484 32.9412 59.5078 75.4006 53.9419 12.6316 39.3701 58.7156 19.5122 0 5.33333 50.5263 24.3902 23.6915 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 1.33993 (Xent), [AvgXent: 1.33993, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 62.1023% <<

