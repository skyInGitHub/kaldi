nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.00025 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter08_learnrate0.0005_tr0.7203_cv1.7298 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter09 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975016
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.81539, max 8.96107, mean 0.00568746, stddev 0.99447, skewness 0.129835, kurtosis 2.1535 ) 
[1] output of <AffineTransform> ( min -29.3355, max 24.9404, mean -3.40323, stddev 4.09542, skewness 0.122781, kurtosis 1.24431 ) 
[2] output of <Sigmoid> ( min 1.8187e-13, max 1, mean 0.204884, stddev 0.314516, skewness 1.50273, kurtosis 0.788488 ) 
[3] output of <AffineTransform> ( min -29.5824, max 15.2212, mean -4.07815, stddev 2.75254, skewness -0.0577094, kurtosis 2.18288 ) 
[4] output of <Sigmoid> ( min 1.42084e-13, max 1, mean 0.0956762, stddev 0.190393, skewness 2.94407, kurtosis 8.61641 ) 
[5] output of <AffineTransform> ( min -14.1391, max 10.7725, mean -3.09308, stddev 1.94156, skewness 0.533496, kurtosis 2.13302 ) 
[6] output of <Sigmoid> ( min 7.23579e-07, max 0.999979, mean 0.113302, stddev 0.185823, skewness 2.75378, kurtosis 7.77385 ) 
[7] output of <AffineTransform> ( min -20.3822, max 17.1813, mean -2.75598, stddev 2.26143, skewness 0.520374, kurtosis 2.42173 ) 
[8] output of <Sigmoid> ( min 1.40642e-09, max 1, mean 0.15675, stddev 0.233263, skewness 2.03969, kurtosis 3.44887 ) 
[9] output of <AffineTransform> ( min -16.9088, max 17.2957, mean -2.82205, stddev 2.86179, skewness 1.30265, kurtosis 2.43999 ) 
[10] output of <Sigmoid> ( min 4.53518e-08, max 1, mean 0.179628, stddev 0.292771, skewness 1.75483, kurtosis 1.71213 ) 
[11] output of <AffineTransform> ( min -31.0016, max 25.2414, mean -3.66662, stddev 3.65426, skewness 0.963068, kurtosis 3.03116 ) 
[12] output of <Sigmoid> ( min 3.437e-14, max 1, mean 0.151908, stddev 0.297637, skewness 2.01519, kurtosis 2.52168 ) 
[13] output of <AffineTransform> ( min -15.0167, max 24.8565, mean -0.0187651, stddev 3.675, skewness 0.52395, kurtosis 0.929247 ) 
[14] output of <Softmax> ( min 4.59993e-16, max 0.999965, mean 0.000657831, stddev 0.0194341, skewness 40.2061, kurtosis 1741.93 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.2704, max 1.18879, mean -0.000148181, stddev 0.0541269, skewness -0.248576, kurtosis 29.9481 ) 
[1] diff-output of <AffineTransform> ( min -0.442552, max 0.327808, mean 5.58898e-06, stddev 0.0101931, skewness -0.0805703, kurtosis 86.813 ) 
[2] diff-output of <Sigmoid> ( min -1.84038, max 1.86141, mean 0.000450905, stddev 0.0923726, skewness 0.120519, kurtosis 17.5861 ) 
[3] diff-output of <AffineTransform> ( min -0.42924, max 0.510037, mean -1.01624e-05, stddev 0.0115779, skewness 0.0812262, kurtosis 115.495 ) 
[4] diff-output of <Sigmoid> ( min -2.32912, max 2.07367, mean 0.000357769, stddev 0.12724, skewness -0.00240091, kurtosis 16.6234 ) 
[5] diff-output of <AffineTransform> ( min -0.545404, max 0.353599, mean 9.75045e-06, stddev 0.0121141, skewness -0.175972, kurtosis 85.1741 ) 
[6] diff-output of <Sigmoid> ( min -2.23856, max 1.72607, mean 0.0003766, stddev 0.103607, skewness -0.0225301, kurtosis 16.9993 ) 
[7] diff-output of <AffineTransform> ( min -0.288378, max 0.232099, mean 1.895e-05, stddev 0.00976544, skewness -0.209983, kurtosis 50.4506 ) 
[8] diff-output of <Sigmoid> ( min -1.40667, max 1.16638, mean 0.000226654, stddev 0.0716778, skewness -0.0304256, kurtosis 16.1117 ) 
[9] diff-output of <AffineTransform> ( min -0.259496, max 0.158273, mean 1.58519e-05, stddev 0.00714988, skewness -0.375907, kurtosis 59.1889 ) 
[10] diff-output of <Sigmoid> ( min -1.14616, max 0.842553, mean 0.000200017, stddev 0.0545598, skewness -0.0982318, kurtosis 18.9957 ) 
[11] diff-output of <AffineTransform> ( min -0.23526, max 0.209254, mean 5.60141e-06, stddev 0.00788886, skewness -0.344157, kurtosis 66.621 ) 
[12] diff-output of <Sigmoid> ( min -2.16357, max 1.33008, mean -0.000458968, stddev 0.083152, skewness -0.191768, kurtosis 11.1538 ) 
[13] diff-output of <AffineTransform> ( min -0.995615, max 0.942723, mean -4.27428e-09, stddev 0.0157171, skewness -26.6376, kurtosis 2275.53 ) 
[14] diff-output of <Softmax> ( min -0.995615, max 0.942723, mean -4.27428e-09, stddev 0.0157171, skewness -26.6376, kurtosis 2275.53 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.83061, max 1.65397, mean -0.000278073, stddev 0.161663, skewness -0.00977147, kurtosis 2.04976 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.484862, max 0.470455, mean 0.00143079, stddev 0.150541, skewness -0.0852965, kurtosis 0.366919 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -1.01503, max 0.872847, mean -0.000467182, stddev 0.0693607, skewness -0.0298354, kurtosis 6.35573 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.89183, max 0.895479, mean -0.00260158, stddev 0.176165, skewness 0.0126825, kurtosis 2.09385 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.805278, max 0.666874, mean 0.000278474, stddev 0.0403393, skewness -0.111501, kurtosis 12.3923 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.0541, max 0.625929, mean 0.00249609, stddev 0.175048, skewness -0.0880579, kurtosis 2.26107 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.436699, max 0.458251, mean 0.000603533, stddev 0.0331068, skewness -0.0310711, kurtosis 8.90173 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.628081, max 0.477031, mean 0.0048512, stddev 0.142836, skewness -0.108662, kurtosis 1.86489 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.437311, max 0.332645, mean 0.000568853, stddev 0.0312313, skewness -0.0416449, kurtosis 6.83787 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.493858, max 0.353717, mean 0.0040581, stddev 0.105516, skewness -0.00952077, kurtosis 1.9013 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.606141, max 0.370641, mean 0.000363437, stddev 0.0427578, skewness -0.0960145, kurtosis 7.34565 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.665226, max 0.453902, mean 0.00143398, stddev 0.122439, skewness -0.146889, kurtosis 2.45175 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.29888, max 2.12991, mean -2.54856e-08, stddev 0.0851793, skewness -4.43635, kurtosis 75.8904 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.61141, max 1.54814, mean -8.78384e-09, stddev 0.250843, skewness -1.61673, kurtosis 10.5704 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 342784 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -6.78548, max 7.66488, mean 0.00618661, stddev 0.998336, skewness 0.126755, kurtosis 2.01683 ) 
[1] output of <AffineTransform> ( min -29.2417, max 24.7934, mean -3.37497, stddev 4.12936, skewness 0.142709, kurtosis 1.21704 ) 
[2] output of <Sigmoid> ( min 1.99742e-13, max 1, mean 0.208054, stddev 0.317543, skewness 1.47886, kurtosis 0.702792 ) 
[3] output of <AffineTransform> ( min -31.4095, max 18.1272, mean -4.08391, stddev 2.79225, skewness -0.0568098, kurtosis 2.19383 ) 
[4] output of <Sigmoid> ( min 2.28578e-14, max 1, mean 0.0974807, stddev 0.193468, skewness 2.90103, kurtosis 8.28889 ) 
[5] output of <AffineTransform> ( min -13.7873, max 11.2876, mean -3.09323, stddev 1.9668, skewness 0.531986, kurtosis 2.19762 ) 
[6] output of <Sigmoid> ( min 1.02858e-06, max 0.999987, mean 0.114541, stddev 0.18781, skewness 2.72656, kurtosis 7.5712 ) 
[7] output of <AffineTransform> ( min -21.1693, max 16.9241, mean -2.74911, stddev 2.28519, skewness 0.522956, kurtosis 2.43942 ) 
[8] output of <Sigmoid> ( min 6.40145e-10, max 1, mean 0.158417, stddev 0.235365, skewness 2.02116, kurtosis 3.34943 ) 
[9] output of <AffineTransform> ( min -16.578, max 17.3797, mean -2.8105, stddev 2.88452, skewness 1.31027, kurtosis 2.4711 ) 
[10] output of <Sigmoid> ( min 6.31341e-08, max 1, mean 0.181417, stddev 0.294797, skewness 1.73442, kurtosis 1.62575 ) 
[11] output of <AffineTransform> ( min -27.8765, max 22.2963, mean -3.66754, stddev 3.66748, skewness 0.972294, kurtosis 2.96891 ) 
[12] output of <Sigmoid> ( min 7.82292e-13, max 1, mean 0.152943, stddev 0.299043, skewness 2.00038, kurtosis 2.45518 ) 
[13] output of <AffineTransform> ( min -15.8644, max 23.5702, mean -0.0185395, stddev 3.68169, skewness 0.546846, kurtosis 0.987597 ) 
[14] output of <Softmax> ( min 1.8548e-15, max 0.997858, mean 0.000657834, stddev 0.0193977, skewness 39.576, kurtosis 1691.19 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.2319, max 1.38734, mean -0.000262193, stddev 0.0451902, skewness 0.159237, kurtosis 35.3952 ) 
[1] diff-output of <AffineTransform> ( min -0.234866, max 0.343463, mean 2.53597e-05, stddev 0.00852785, skewness 0.498076, kurtosis 76.2536 ) 
[2] diff-output of <Sigmoid> ( min -1.35025, max 1.59603, mean -0.000146719, stddev 0.0774401, skewness 0.0192335, kurtosis 16.7621 ) 
[3] diff-output of <AffineTransform> ( min -0.258129, max 0.357552, mean 2.35938e-05, stddev 0.00959465, skewness 0.410944, kurtosis 92.8225 ) 
[4] diff-output of <Sigmoid> ( min -1.42346, max 1.47372, mean -2.66245e-05, stddev 0.103847, skewness -0.0035221, kurtosis 12.4127 ) 
[5] diff-output of <AffineTransform> ( min -0.286404, max 0.26035, mean 2.35194e-05, stddev 0.00997374, skewness 0.0467655, kurtosis 58.5129 ) 
[6] diff-output of <Sigmoid> ( min -1.20569, max 1.40894, mean 4.52136e-05, stddev 0.0865382, skewness 0.0288615, kurtosis 13.542 ) 
[7] diff-output of <AffineTransform> ( min -0.234256, max 0.218919, mean 1.99889e-05, stddev 0.00819668, skewness 0.214685, kurtosis 49.2995 ) 
[8] diff-output of <Sigmoid> ( min -0.957186, max 0.971642, mean 0.000220183, stddev 0.0606736, skewness 0.00945425, kurtosis 14.9941 ) 
[9] diff-output of <AffineTransform> ( min -0.158659, max 0.131834, mean 1.15817e-05, stddev 0.00608807, skewness -0.333391, kurtosis 54.3669 ) 
[10] diff-output of <Sigmoid> ( min -0.902326, max 0.792656, mean 7.69033e-05, stddev 0.0468067, skewness -0.120368, kurtosis 19.8631 ) 
[11] diff-output of <AffineTransform> ( min -0.242264, max 0.215494, mean -3.56488e-07, stddev 0.00690117, skewness -0.403687, kurtosis 85.1791 ) 
[12] diff-output of <Sigmoid> ( min -2.63998, max 2.24765, mean 0.000233431, stddev 0.0741757, skewness -0.235218, kurtosis 24.8246 ) 
[13] diff-output of <AffineTransform> ( min -0.999947, max 0.96095, mean -6.05972e-09, stddev 0.0137111, skewness -25.0153, kurtosis 2413.92 ) 
[14] diff-output of <Softmax> ( min -0.999947, max 0.96095, mean -6.05972e-09, stddev 0.0137111, skewness -25.0153, kurtosis 2413.92 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.53975, max 1.75576, mean -0.00097426, stddev 0.131272, skewness -0.00329451, kurtosis 2.28111 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.633238, max 0.644282, mean 0.00649211, stddev 0.151192, skewness -0.00192596, kurtosis 1.10037 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.547756, max 0.743867, mean 0.00141013, stddev 0.0595415, skewness 0.0908887, kurtosis 5.90096 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.785133, max 0.861732, mean 0.00603997, stddev 0.169205, skewness 0.159777, kurtosis 2.62651 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.708166, max 0.644987, mean 0.000616138, stddev 0.0361573, skewness 0.0331646, kurtosis 12.6657 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.05761, max 0.77714, mean 0.00602096, stddev 0.184945, skewness -0.0455436, kurtosis 3.11994 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.444925, max 0.407881, mean 0.000611702, stddev 0.0302908, skewness -0.0469437, kurtosis 9.30454 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.69143, max 0.626181, mean 0.00511716, stddev 0.147891, skewness -0.0450152, kurtosis 1.93405 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.431591, max 0.361301, mean 0.000430886, stddev 0.0289084, skewness -0.189185, kurtosis 8.63709 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.6097, max 0.561657, mean 0.0029649, stddev 0.107532, skewness -0.199423, kurtosis 3.92341 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.493841, max 0.487473, mean 4.49098e-05, stddev 0.0398936, skewness -0.124385, kurtosis 9.59379 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.58521, max 0.56066, mean -9.12513e-05, stddev 0.121678, skewness -0.137982, kurtosis 3.45855 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.40954, max 2.99396, mean -3.13512e-08, stddev 0.0774778, skewness -2.83942, kurtosis 125.603 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.03648, max 2.01456, mean -9.09755e-09, stddev 0.232113, skewness -1.1005, kurtosis 20.9438 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0782446 min, processing 73015.4 frames per sec; i/o time 5.17105%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14111 120 114 116 102 29 147 431 139 624 262 548 95 133 232 62 162 188 145 264 293 157 210 252 206 227 177 121 194 213 59 160 138 41 524 149 489 359 331 244 27 18 144 252 121 124 944 114 5399 17569 1561 284 471 20 632 126 26 94 273 190 263 30 128 442 158 105 525 11 77 78 552 418 679 528 1016 172 727 226 492 148 41 38 347 273 210 329 186 75 361 141 50 229 14 179 16 260 399 380 208 348 168 179 81 181 88 1263 98 58 160 98 115 54 66 62 11 119 350 151 110 448 126 190 86 63 70 151 159 154 147 99 51 457 174 395 129 114 299 480 34 300 110 192 230 423 223 68 294 243 288 142 120 14 444 408 166 105 144 162 529 125 74 223 6 210 64 142 100 249 210 274 130 35 152 111 628 206 146 284 105 10 20 172 279 270 107 661 122 308 130 173 423 220 622 85 221 292 20 66 211 128 191 614 140 15 160 183 392 155 147 70 20 125 365 508 342 43 242 266 181 354 229 517 160 211 158 92 236 201 194 33 15 451 392 162 89 139 99 401 98 88 71 358 242 87 117 16 197 149 150 216 426 191 185 158 110 313 96 94 154 130 118 114 166 121 21 289 100 381 83 90 18 148 268 118 186 92 525 93 176 196 123 174 146 156 68 60 152 179 13 146 212 95 173 135 298 16 240 157 78 116 133 150 196 69 70 269 161 182 203 142 109 580 111 212 100 113 81 22 106 188 435 309 183 96 159 180 813 140 117 84 160 60 136 105 93 279 49 323 115 81 187 130 220 198 248 229 121 138 321 339 134 107 289 145 381 16 122 414 251 218 14 704 214 173 295 205 31 188 148 232 127 78 197 214 102 228 131 158 286 12 325 95 342 165 147 125 128 38 240 479 145 74 148 97 75 288 83 71 221 75 341 213 744 497 119 182 123 166 206 71 174 21 369 305 186 525 28 62 137 211 161 86 153 69 98 289 226 97 32 248 67 432 171 470 200 262 113 68 112 237 175 493 28 74 192 110 147 76 178 359 200 35 65 15 148 172 163 12 106 46 106 215 128 158 115 37 61 128 34 180 113 80 227 21 80 215 103 113 91 332 175 93 103 339 102 197 194 276 33 250 439 144 479 88 246 22 155 155 186 44 355 235 212 135 123 240 272 212 71 252 101 106 188 76 61 17 82 47 139 27 164 88 260 223 132 257 98 177 282 25 59 247 184 238 139 298 77 80 278 302 61 410 162 317 174 79 22 160 279 126 205 160 228 522 176 162 39 25 152 251 223 86 286 122 166 15 119 81 176 132 85 109 289 78 185 137 361 29 347 417 364 180 85 89 269 23 149 133 121 83 160 410 95 466 17 101 145 14 66 44 19 216 251 140 66 52 161 311 239 133 142 268 107 151 0 355 94 68 210 42 10 178 124 47 82 201 71 323 122 177 221 226 105 181 815 94 322 180 82 190 119 1408 32 372 114 94 24 267 55 79 63 291 21 150 99 752 230 170 140 110 8 98 137 290 267 238 179 97 239 110 166 159 62 123 14 30 87 117 100 356 341 52 95 143 51 151 264 109 363 8 275 14 204 202 154 229 140 80 115 52 45 276 235 129 256 254 94 238 182 131 86 130 130 96 196 120 148 225 34 202 54 553 173 208 160 275 133 618 6 45 306 59 45 178 28 112 171 289 96 111 63 455 146 103 77 247 134 346 420 197 51 400 17 181 362 122 83 799 204 92 131 1688 75 185 61 630 124 236 80 58 118 320 115 14 516 106 54 103 280 177 169 213 101 56 536 291 116 201 195 336 18 111 70 109 79 37 111 187 128 201 1008 95 457 71 152 219 305 96 191 130 235 14 71 155 225 240 189 307 189 632 15 275 157 359 52 39 8 261 510 564 249 222 352 43 224 221 130 126 45 161 151 30 170 155 229 37 61 191 190 136 49 411 41 153 223 35 366 639 104 127 85 142 456 275 230 113 288 21 120 29 17 214 79 214 255 110 257 77 118 218 13 68 101 63 251 59 183 125 145 170 202 215 109 241 161 267 174 256 90 200 49 76 92 161 276 222 56 463 654 317 130 77 151 144 186 175 292 131 213 86 220 270 108 57 131 395 106 113 85 403 81 189 54 110 144 363 179 368 232 184 400 191 489 231 230 350 465 586 149 317 131 273 50 275 11 97 38 135 368 286 204 137 215 257 418 210 224 110 55 60 75 172 202 525 277 145 337 68 189 117 50 276 313 136 179 423 28 167 194 461 203 601 9 190 227 238 177 113 47 189 451 171 151 181 96 142 129 322 103 83 200 170 55 11 92 243 494 291 121 170 693 104 145 434 141 13 101 57 58 167 42 351 179 195 376 0 245 378 244 79 288 97 116 1082 263 205 374 312 163 126 277 43 154 146 187 138 227 205 91 202 84 124 191 184 214 123 421 234 163 207 69 392 407 805 555 331 459 257 193 152 270 256 205 168 82 44 30 84 134 350 392 468 81 109 138 51 163 98 350 55 219 95 217 185 182 155 54 676 231 99 147 82 316 70 292 251 114 185 205 101 293 88 170 372 143 247 89 183 269 159 159 470 190 148 36 484 150 85 151 135 220 209 180 557 157 313 294 94 360 143 119 227 207 88 71 75 349 843 251 120 51 173 149 253 192 299 302 211 74 152 113 43 85 136 421 115 104 242 228 232 13 59 331 189 125 243 355 398 250 272 145 118 163 1961 152 115 363 91 134 74 378 346 72 160 400 86 256 55 11 200 228 129 162 250 490 56 205 245 156 452 435 409 169 263 194 225 99 561 179 234 364 164 141 80 185 173 8 19 29 132 207 139 64 156 211 16 76 131 93 282 224 71 388 32 160 40 547 120 241 139 286 192 752 249 120 243 218 46 211 120 291 79 257 198 13 1281 166 13 738 488 437 90 370 118 174 163 276 49 154 104 131 124 316 100 468 303 218 68 14 30 260 250 215 829 131 141 45 131 217 166 115 118 64 313 270 608 334 412 132 73 312 298 428 246 226 69 124 375 68 167 62 230 198 165 219 127 190 133 948 357 222 171 259 511 147 80 207 240 212 225 164 53 112 147 121 25 150 149 324 411 249 100 41 133 521 301 150 62 303 411 60 18 110 174 40 394 52 240 331 284 215 421 114 247 430 133 48 109 90 50 18 1198 95 97 208 60 279 137 170 245 280 190 293 117 334 217 91 223 276 271 218 124 173 308 265 129 146 20 159 258 333 162 477 154 438 52 1106 298 479 38 841 127 66 85 66 26 192 67 285 218 115 177 412 385 148 434 168 156 454 403 22 125 84 360 157 205 290 170 429 71 149 131 109 88 156 90 129 330 14 559 412 392 145 155 181 425 252 187 74 157 216 56 231 191 281 147 170 165 579 328 249 278 354 74 559 114 283 243 343 212 193 227 115 79 194 48 410 65 80 109 135 90 215 117 185 53 480 464 62 80 ]
@@@ Loss per-class: [ 0.312088 0.713532 0.741633 0.844681 0.558442 0.832196 1.57343 0.498338 0.450558 0.441262 0.221346 0.471027 0.492372 0.463986 0.832503 0.695055 0.652413 0.792552 0.587779 0.441116 0.365986 0.622501 0.31911 0.736713 0.89097 0.343527 0.744755 0.47026 0.64497 0.357155 0.816327 0.80713 0.849958 0.710208 0.190657 0.395331 0.173929 0.251003 0.467975 1.22381 1.18338 1.025 0.35312 0.95857 0.82135 0.351132 0.766842 0.681909 0.419484 0.216826 0.44258 1.24906 0.335494 0.746543 0.437415 0.568521 1.26297 0.711241 0.269052 1.12542 0.682227 0.490922 0.580845 0.252924 1.08392 0.745671 1.00964 0.843685 0.453479 0.62422 0.510545 0.338358 0.595488 0.504709 0.192547 0.589045 0.545171 0.821343 0.282456 0.89982 0.821039 0.985952 0.318627 0.426343 0.345638 0.804955 0.399986 0.361153 0.725169 0.962577 0.559927 0.530097 1.14362 0.536116 1.29533 0.641837 0.663005 0.424016 0.995112 0.370954 0.409439 1.28494 1.15829 0.538206 0.60923 0.420772 0.562103 0.797216 0.514866 0.885149 0.780982 1.20697 0.571691 0.728715 1.71656 0.686708 0.425571 0.37126 1.21014 0.872325 0.557278 0.60807 0.571435 1.37297 0.673324 0.624834 0.595349 1.13935 0.690689 1.13838 0.853993 1.01881 0.88169 0.502401 0.771983 0.51111 0.699822 0.825375 0.763913 0.333143 1.04308 0.499571 0.385295 0.552165 1.16121 0.768221 1.224 0.573907 0.361341 1.26922 0.481493 1.21683 0.240064 0.446988 0.690222 0.491229 1.22098 0.852349 0.446303 0.885061 0.630527 0.832912 1.93955 0.647122 0.598475 0.577557 0.789366 0.315774 0.891459 0.60782 0.674462 0.873134 0.658368 0.410739 0.323949 0.340478 0.613411 0.590076 1.13916 1.71921 0.540249 0.506663 0.7615 0.911873 0.863799 0.702168 0.704767 0.394751 0.453654 0.875762 0.485851 1.21549 0.366483 0.720435 0.457361 0.204616 1.1724 1.079 0.363012 0.7546 0.481784 0.328346 0.7111 0.648943 1.46701 1.28897 0.873449 0.989975 0.744463 0.883416 0.338068 1.11598 0.663751 1.19715 0.531013 0.443583 0.329657 0.674655 0.814054 0.437544 0.603198 0.471834 1.45732 0.909412 0.760878 0.531227 0.489674 0.518262 1.01661 0.995839 0.89363 0.794545 0.946744 0.636842 0.859129 0.495754 1.12825 0.503451 0.553835 0.762581 0.318934 0.414764 0.552319 0.386652 0.685449 1.046 0.30908 0.554437 0.655695 0.494288 0.498147 0.644496 1.30327 0.703939 0.509287 0.549249 0.842491 0.897928 1.02119 0.730004 0.838026 0.325789 1.22011 0.38291 1.0986 0.556855 0.759948 0.553228 0.661398 0.695026 0.472119 0.780882 0.461226 0.51913 0.626167 0.53141 0.387809 0.803879 0.498747 0.298407 0.48886 0.472283 0.417942 1.02111 0.752555 1.81753 0.461713 0.535197 1.11436 0.794744 0.274673 0.895668 0.438448 0.657005 0.359507 2.12583 0.692721 1.54134 0.903967 0.440286 0.893213 0.853363 1.36174 1.29162 1.1077 1.06364 0.938857 0.438228 0.464179 0.611897 0.665338 0.435383 0.530257 0.978268 1.10921 0.886371 0.644746 0.858687 1.20442 0.830636 0.353791 0.424242 0.615933 0.493178 1.42615 0.728715 0.410396 0.848677 0.437982 0.98486 0.542737 0.433386 0.748552 1.51641 0.631513 0.675398 0.981185 1.06467 0.702902 1.11165 0.844157 0.4329 0.374848 0.548747 0.447551 0.792876 0.98249 0.37704 1.08066 0.884523 0.86474 0.701703 1.23662 0.508465 1.08436 1.38297 0.827211 0.408801 0.840018 0.600838 1.71933 0.348394 1.1389 1.04073 0.745806 0.656097 1.43465 0.870434 0.694428 0.509444 0.838735 0.425421 1.16581 0.773469 1.33854 0.472722 0.799443 0.708591 0.536171 1.57253 0.535115 1.39851 0.4447 0.60771 0.676421 1.02778 0.653324 0.554617 0.379363 0.417606 1.14072 0.614535 0.791224 0.712559 0.757365 0.612842 0.469112 0.764292 0.69394 1.06681 0.444926 0.688389 0.428998 0.277355 1.49837 0.495523 0.516586 0.632092 0.78803 0.800207 1.38781 1.35703 0.492048 0.414539 0.815073 0.596886 1.43122 1.04671 0.371675 0.811519 0.776358 0.836357 1.086 0.674986 3.12479 0.39777 0.351406 1.9448 0.665429 0.531105 1.76205 0.843059 0.706476 0.362909 1.03535 0.687335 1.21653 0.374586 1.13491 0.777567 0.95202 0.575483 1.04838 1.26173 0.31462 0.836771 0.570439 0.505301 0.744478 0.621284 1.20746 0.730372 0.558692 0.54274 0.401087 1.16869 0.487264 0.600253 0.500466 1.36917 0.569805 0.993146 0.467188 1.23211 0.620324 0.725066 0.738564 0.862788 0.847326 0.90222 0.5453 0.549525 0.404076 0.747079 0.511921 0.979621 0.786145 0.84148 0.414702 0.526989 0.408402 1.28328 0.812349 0.711462 0.514426 0.891327 0.641685 0.4578 1.11357 0.685535 0.53516 1.18914 0.740752 0.500568 0.588608 0.771137 0.87761 1.03841 0.898019 1.18114 0.729118 0.614799 0.740049 1.04533 1.03603 0.961896 0.705411 0.61094 0.57066 0.595124 0.692721 1.44028 0.851403 0.577466 1.13102 1.5192 0.804003 0.774366 1.14072 0.87873 0.333437 0.496646 1.17755 0.759666 0.410536 0.983906 1.19869 0.966146 0.717151 1.98611 0.696764 0.752581 0.615327 0.667989 0.541795 0.428031 1.2412 1.78975 0.588109 0.653826 1.70578 0.518496 1.46686 0.812927 0.529745 0.751853 1.07523 0.852016 0.953972 0.797243 1.27235 0.71116 0.532167 0.609408 0.775329 0.981152 1.84461 1.06245 0.642818 1.07766 0.824093 0.668343 0.262515 1.04898 0.870592 0.959864 1.16298 0.672833 0.626519 0.936759 1.42547 1.02771 0.777538 1.09648 0.583154 0.405111 0.645044 1.73967 0.596203 0.807904 0.927769 0.615984 0.842594 0.796292 1.06586 1.22766 0.603441 0.333456 0.411185 0.854176 0.724769 0.450179 1.05009 0.554122 0.261702 0.627037 0.568901 1.54411 0.842052 2.14761 1.22332 0.333622 0.655215 2.10834 0.914322 0.69783 0.585898 1.15271 0.587843 0.352204 1.07215 0.358512 1.38153 0.562501 0 0.76575 0.923921 0.611089 1.25071 0.985717 0.844732 0.472034 0.765569 0.526495 1.36301 0.952416 0.559576 0.681038 0.73062 0.775235 0.890993 0.909301 0.814981 0.673952 0.883501 1.00763 0.48595 0.885409 0.589894 0.789597 0.773414 0.389272 0.940909 0.532027 0.751661 1.14509 0.777089 0.934777 1.02132 0.790699 0.394513 0.771724 0.905343 0.851457 1.23286 0.331005 0.697376 1.37818 0.947138 0.901868 2.91898 0.787689 1.29157 0.499244 1.00328 0.676375 0.870621 0.759226 0.34668 0.705373 0.436843 1.5321 0.56021 0.656875 0.974875 1.74538 1.1843 0.696631 0.895626 0.442145 0.504017 0.723287 0.706609 0.824709 0.840339 1.21182 0.600292 0.542166 0.607403 1.51425 1.03423 0.951491 0.539602 0.629148 1.1944 0.482574 0.67425 1.73237 0.748521 1.10404 0.885551 1.09588 0.964505 2.10731 1.31483 0.617991 0.821843 0.905659 1.41605 1.00792 1.76967 0.469752 1.03557 0.839 1.1694 0.443521 0.461656 0.643724 0.715052 0.660923 0.525152 0.368724 0.831747 0.621094 0.884946 0.980658 1.14208 0.553705 1.10363 1.15692 0.884635 0.68181 1.64193 0.823778 0.682509 1.46395 0.881523 0.844192 0.535056 1.0993 0.882504 0.743616 1.15298 0.600039 1.01135 0.764032 1.20261 0.670956 0.825351 1.15159 1.23314 1.00454 1.58245 0.721421 0.638078 0.543598 1.20309 0.476398 0.752303 0.567726 0.885752 0.481566 0.742547 0.566456 0.466176 0.406343 0.571338 0.761344 1.0068 0.65528 0.533774 0.70824 0.944369 0.912158 0.452314 0.656013 1.10301 0.540625 0.939697 1.1425 0.651878 1.27837 0.542527 0.861677 0.476019 0.769035 0.875777 0.711759 1.22907 0.661659 0.784402 0.801498 0.818781 0.518123 0.94982 0.923642 0.738657 1.16576 1.23293 0.627414 0.50551 0.606866 0.81167 0.651168 0.626203 0.436098 0.587384 0.978195 0.942996 1.06833 0.551935 0.471652 1.55394 0.575924 0.72088 0.399896 0.533413 1.07063 1.37741 0.816273 1.47751 0.951555 0.528475 0.802971 1.91568 0.371954 1.9592 0.750887 0.524739 0.929603 0.712083 0.715305 0.356947 1.18407 0.488037 0.874019 1.07233 1.61649 0.647959 1.18561 0.93065 0.961318 0.670598 0.803526 1.00436 0.813878 2.51794 0.63215 0.847533 0.647887 1.10853 0.931821 1.15614 0.499356 0.760511 0.387214 0.431822 0.378506 1.30553 0.684217 0.60907 0.932926 0.839799 0.463529 0.913185 1.61738 0.700458 1.52531 0.905416 0.934361 0.92027 0.933093 0.863427 1.28509 1.03209 1.8524 0.969715 0.871775 0.783489 1.4272 0.689723 2.0012 1.00136 1.04628 0.881902 1.21233 0.627467 1.22509 1.74518 0.857678 1.20081 1.45616 1.64959 1.0959 0.948358 0.60305 0.3879 0.448264 0.962795 1.08024 0.885336 1.24156 0.711183 0.957163 0.806228 0.539738 0.44137 0.855448 0.318994 1.31344 1.70613 0.438854 0.713442 0.903202 0.93105 0.382092 1.10696 0.447124 0.673213 0.968896 0.427681 0.753692 0.54526 1.15168 0.533218 0.783919 0.927711 1.17526 1.16849 0.558296 0.652954 0.450796 0.239067 1.05654 0.831082 0.327889 0.96269 0.845868 0.874446 1.17356 0.642726 0.912991 0.53146 1.19687 0.7159 0.936604 0.929189 0.794696 1.36319 1.29677 0.5674 0.669349 0.883477 0.823194 0.880761 0.835064 1.0382 0.708694 0.576078 0.547641 1.26518 1.04355 0.906084 1.01962 0.748293 0.529019 0.72764 0.753876 1.39151 0.826542 1.62764 0.679759 0.569693 1.15046 0.716786 0.780321 0.283387 0.594848 0.768876 0.925394 0.842341 0.847123 0.571557 1.76106 1.55677 0.786762 1.045 1.24007 0.789771 0.573263 0.637631 1.15223 3.44332 0.866789 0.786051 1.12703 1.04268 1.07013 1.24508 1.2026 0.81896 1.65075 0.651186 0.80298 0.671656 1.07627 0.9688 0.580274 0.921493 1.43807 0.641904 0.650165 1.19319 1.02105 0.596299 1.10405 0.330025 0.869075 1.46106 1.35649 0.935715 0.753744 0.597687 0.750208 0.832098 1.51621 1.48044 0.670714 1.20109 0.657657 1.258 0.511705 1.33411 0.654704 0.646677 0 1.11685 0.605727 0.619648 1.35846 0.696216 0.951888 0.945044 0.813987 1.00046 0.827065 0.474406 0.706605 0.948854 0.96536 0.761771 0.805485 0.620277 0.909101 0.779538 0.686901 0.628363 0.680576 0.714616 0.721682 1.14798 1.05523 0.636206 1.02695 1.00457 0.756816 0.617634 0.83229 0.856077 0.626523 0.87421 0.976121 0.9928 0.198583 0.287847 0.366059 0.749131 0.966844 1.1788 0.617617 0.624757 1.21485 0.401838 0.528499 0.609487 0.470956 0.887085 1.89815 1.14979 0.616303 0.624757 0.470927 1.13387 1.25589 0.960021 0.927706 1.25771 0.857424 0.543552 0.63116 1.00642 1.0034 0.918068 0.913427 1.02829 1.01641 1.96826 0.742176 0.920637 0.971548 1.15976 0.640019 0.474338 0.63523 0.820552 0.702962 1.02379 0.78506 0.926711 0.790222 0.802257 1.38281 1.47932 0.682883 0.615511 0.710201 0.482274 0.755076 1.36028 0.620056 1.25925 0.626145 1.05535 1.03823 1.37947 0.843411 0.612596 1.37333 1.25308 1.09113 0.741703 1.33061 0.718554 0.68014 0.964864 0.633751 0.802112 1.76192 0.533553 0.989513 0.970393 1.30299 0.704317 1.32926 0.766259 0.743561 0.659664 0.483565 0.897506 1.01539 1.13822 1.51126 1.49814 0.860312 1.10792 0.949455 0.58211 0.526444 1.01484 0.761173 1.01022 0.603766 0.833239 1.0795 0.880302 0.52278 0.798569 0.911338 0.725536 0.926174 1.04063 1.88753 0.6457 0.989078 0.550249 0.507558 0.753042 0.919493 1.01595 1.03281 0.805257 1.66573 0.886501 0.462694 0.66341 0.689346 0.427681 0.957149 1.01066 0.870424 0.72987 0.814249 1.12107 1.25441 0.760309 1.08592 1.25624 1.26996 1.94258 1.01577 1.31336 1.18511 0.737406 0.824787 0.85127 0.66609 0.664373 0.773743 0.708064 0.555154 0.564445 0.597604 0.754884 0.583544 1.05313 0.790032 1.30569 0.599382 0.941733 0.276805 0.608955 2.5108 0.563212 1.26909 0.977099 0.539966 3.09471 0.672176 1.31932 1.01891 1.28305 1.83199 0.856813 0.759779 0.598394 0.719857 1.71774 1.25582 0.742067 0.511261 0.994225 2.02845 0.622998 1.04052 1.403 2.21443 1.07369 0.321228 0.569347 1.34945 0.994706 0.730648 0.842561 1.0198 0.67626 1.62742 1.7933 1.16821 1.51112 1.13613 0.79334 0.994833 0.31774 0.955087 0.803673 0.61342 1.27038 0.760874 0.680702 0.722909 0.529828 1.41729 0.808541 0.686432 0.981879 0.622583 0.810931 1.12164 0.821727 0.543465 2.28643 0.921927 1.05308 0.62607 0.847463 0.305068 0.734842 0.975335 1.29976 0.841639 1.02684 0.807221 0.885131 1.05507 1.2474 0.696057 0.736223 1.57718 0.607544 0.814297 0.610021 0.695502 0.757037 1.159 0.437134 0.446971 0.789392 0.803147 1.19322 0.729833 0.641568 0.737734 0.778039 1.18219 1.16039 1.46769 2.37243 0.681603 1.07676 0.700254 0.937145 0.631166 1.33518 0.458306 1.51786 0.771474 1.46349 0.52241 0.768785 0.753805 0.531649 1.02306 0.679393 0.438173 1.50358 1.16818 1.07701 1.08257 1.58125 0.801186 1.02619 1.30314 1.45609 0.74369 1.0557 1.26041 0.799176 0.791816 0.734863 0.797282 0.760658 0.72287 0.984435 1.0785 1.0369 1.01884 0.80194 2.01678 0.981103 0.700913 0.595062 0.450759 1.27679 1.09447 0.795011 0.346472 0.846577 0.651285 0.586997 0.54228 0.965494 0.707515 0.935748 0.446299 0.886909 1.31022 1.66598 1.58242 1.00583 1.05784 1.05514 0.506415 0.644042 0.636717 1.40523 1.41055 1.29409 1.44878 0.840519 0.734858 0.515879 1.38803 0.766939 0.845733 0.931371 0.771644 1.91093 0.825059 0.797952 0.838011 2.14802 1.2387 1.08705 0.770044 1.09748 0.999704 0.751267 1.78824 1.178 0.981377 0.670522 1.16113 0.783191 0.821098 0.81309 1.22877 0.467405 0.76751 0.778877 1.09973 0.798079 1.28905 1.44179 1.47768 1.35772 1.43769 0.653651 0.439896 0.731133 1.07823 1.38861 0.457924 1.25246 0.735723 1.00075 0.768019 0.778524 1.51375 0.626736 0.648407 1.39885 0.845508 1.40076 0.571349 0.804669 0.948524 0.923433 1.31053 1.36604 2.16275 1.08904 1.46725 1.55109 0.288094 1.08321 1.02327 1.04595 0.950372 0.60684 0.755939 0.687002 1.06141 1.27007 0.874621 0.768711 0.680349 0.913282 1.0916 0.537799 2.02087 1.63245 0.789972 1.07982 1.18381 0.533551 0.810369 0.980761 0.846763 0.520607 0.569299 0.32936 0.574503 0.631666 1.16436 0.940369 0.748521 0.708692 0.765376 0.999849 0.665398 1.27616 0.934528 1.23603 1.23467 0.469254 0.664558 0.728851 0.827952 0.682347 0.924854 2.03552 1.53449 1.42729 0.673822 0.796416 1.22833 0.619892 0.32161 2.50149 1.51794 ]
@@@ Frame-accuracy per-class: [ 87.7936 79.668 82.0961 69.5279 87.8049 71.1864 56.2712 86.9061 91.0394 87.2698 96.381 85.1413 91.0995 91.3858 76.9892 80 80.6154 78.5146 82.4742 87.3346 90.971 79.3651 88.361 80 72.6392 90.1099 79.4366 87.2428 81.2339 90.8665 70.5882 76.6355 78.7004 89.1566 96.0915 91.6388 95.8121 94.2976 86.5762 64.6217 61.8182 86.4865 86.5052 67.7228 81.4815 89.1566 62.361 82.9694 87.2118 93.1956 85.943 55.536 92.6829 82.9268 88.6957 83.004 45.283 80.4233 92.5046 62.9921 77.7989 95.082 84.0467 94.9153 70.6625 81.5166 68.1256 78.2609 90.3226 87.8981 88.5068 91.0394 81.3834 86.6604 95.4255 78.2609 85.4983 75.4967 91.1675 74.7475 74.6988 72.7273 91.5108 90.3108 94.5368 77.6935 87.9357 90.0662 78.2849 74.9117 85.1485 82.7887 68.9655 80.7799 48.4848 83.3013 85.8573 90.6702 70.024 90.3874 89.6142 61.2813 60.1227 87.6033 87.0056 88.0886 85.2792 78.6325 86.6044 76.1421 71.8615 55.0459 82.7068 78.4 34.7826 85.3556 89.301 92.4092 67.8733 78.2609 83.004 83.4646 90.1734 56.6929 85.1064 86.4686 84.0125 56.9579 82.7119 75.3769 77.6699 68.6339 72.7794 87.2314 74.9035 82.0961 80.1336 76.5869 84.058 93.178 74.2081 87.2727 91.974 85.0059 64.877 72.9927 65.5348 86.2423 91.8544 63.1579 86.3071 55.1724 92.9134 91.0649 76.2763 89.0995 67.8201 75.6923 90.2738 78.0876 87.2483 80.9843 15.3846 85.0356 82.1705 81.4035 80.597 93.3868 77.9097 78.6885 78.1609 76.0563 79.3443 90.583 92.7605 91.0412 83.959 84.71 65.4028 28.5714 92.6829 89.2754 81.5742 73.1978 74.4186 79.8186 84.898 91.0859 87.3563 77.8098 86.1865 63.0385 87.0683 74.8538 85.3273 97.094 78.0488 54.1353 90.3073 77.0428 87.7285 92.5956 82.5623 90.3226 62.3053 63.2153 74.9045 71.3826 80 73.7589 92.6829 74.1036 83.4473 69.0265 82.6277 87.3563 89.8969 83.3021 80.4408 87.4471 82.3529 86.1836 58.567 79.4326 80.1262 83.2432 90.4863 87.8412 64.7815 62.6866 83.871 79.5127 73.121 81.2308 88.2682 85.3047 70.3518 88.6675 87.3096 77.9661 93.7063 87.3082 86.1856 91.4286 83.4043 66.6667 92.6582 86.9565 81.0631 88.6836 85.3458 74.1514 55.5256 78.8644 89.5928 84.5295 74.6114 75.1323 69.9029 77.3946 70.0422 90.8297 51.0511 89.7119 69.7674 87.0466 79.602 84.1415 87.4251 81.768 91.8919 76.7677 88.2682 84.3882 85.2547 84.3243 91.7222 73.7968 85.5524 93.1298 89.8785 91.1175 90.785 76.6773 80.292 67.7686 86.5574 82.4513 59.2593 79.1809 92.7059 74.3455 89.9135 78.9668 89.7822 30.303 80.2495 52.0635 72.6115 92.7039 75.6554 77.7409 53.4351 56.1151 73.7589 65.3061 71.8266 90.9589 87.9607 81.4035 82.1918 89.578 88.7892 72 64.6766 74.0088 82.2086 66.6667 61.0329 77.4536 91.3892 86.9144 81.1989 89.1192 54.5455 81.4404 89.6128 75.4448 84.2553 79.2899 84.1121 89.2562 73.2601 54.0284 83.4225 82.6476 68.6869 68.6244 78.7879 61.3497 76.2667 89.6552 88.8889 85.1385 89.7384 75.817 72.428 90.2527 68.1182 73.6377 74.3494 83.7209 66.6667 87.9725 69.2005 60.6061 77.551 86.6104 73.5586 81.4645 55.1724 90.1348 70.3963 66.8588 82.2335 79.3187 57.1429 76.9231 78.7879 87.3118 80.7843 91.7197 69.3671 75.0583 58.5366 89.7155 76.8061 81.388 85.5148 56 85.4071 54.4503 90.5109 83.3837 81.3559 78.8845 81.7121 90.9091 90.6445 89.2596 65.2921 83.2215 75.4209 82.0513 82.1192 82.4957 89.8204 79.7203 81.2641 74.1722 87.5549 84.7775 89.9933 92.0603 59.4142 84.9315 82.5911 86.4865 76.5133 78.3217 57.3066 60.4651 86.0622 89.0344 79.8928 82.3977 59.6491 75.2 88.7273 75.6501 74.9226 75.1445 67.7524 87.7698 8.12183 88.0829 91.3907 51.2821 89.2308 84.1046 48.8889 77.6879 81.0496 89.9044 65.8354 82.2857 65.1982 91.9708 61.3333 79.5789 68.9459 86.1196 80.7018 56.3758 94.026 75.1131 86.1017 84.9673 77.8711 82.0584 61.8454 78.8732 79.3893 96.7742 91.5825 62.6087 85.0153 88 91.0798 60.2151 83.5681 67.7494 84.8249 59.9369 85.7143 77.3333 73.1707 73.93 72.4638 72.0222 85.4626 88.1988 92.3077 83.7209 89.441 64.5012 83.0918 77.533 86.3388 87.218 90.5983 54.5455 80.1932 80.7069 85.8537 75.9494 81.7481 88.6076 59.7015 83.4331 86.2344 60.8997 79.2492 84.7458 83.1643 80 77.1704 73.3119 77.2118 62.9213 79.6062 78.9809 78.5882 75.2768 75.3036 74.4283 80.7339 82.3529 83.9161 83.1683 82.7586 63.8498 72.679 83.6601 69.9187 62.8571 71.5152 80 65.9498 72.7273 89.9696 85.8757 65.2591 80.9843 89.0566 72.233 61.9289 74.9296 81.0619 47.0588 75.6303 79.1919 83.4688 81.761 88.172 86.7672 61.9355 50.9317 85.4578 82.6446 47.1545 85.9927 57.8462 77.7953 87.6791 76.7296 57.7778 77.2586 74.7764 77.4704 65.2068 80.9969 86.2144 83.0622 79.8867 68.3077 58.2278 78.4314 79.3443 66.004 80.0895 77.4566 94.5899 65.3061 73.8739 70.9677 71.9665 80.9816 81.5864 71.6981 63.1579 70.3196 80.4836 63.6943 83.558 89.4545 78.2849 44.0678 84.8921 70.8982 72.9767 82.5485 76.0234 80.4469 67.5325 63.8298 82.2742 92.8839 88.8889 74.2515 85.9813 86.2363 63.8743 84.4587 97.1429 82.7586 87.2852 48.2759 73.6842 40.4494 66.6667 87.7598 80.3181 34.8754 73.6842 81.9048 81.1146 65.1685 84.7599 88.3895 70.1754 91.6201 54.8837 86.4686 0 72.5738 74.0741 83.2117 67.4584 65.8824 76.1905 87.9552 83.5341 88.4211 59.3939 73.9454 79.7203 79.7527 75.102 72.6761 74.0406 78.1457 75.8294 82.6446 69.8958 62.4339 85.2713 71.4681 87.2727 77.6903 78.6611 88.6049 64.6154 85.906 82.0961 69.8413 77.551 71.028 68.4685 80.5031 91.3386 81.3036 83.7209 76.412 63.3166 90.7641 75.9219 63.9296 71.1744 72.3982 0 80.203 66.9091 89.1566 72.8972 80.5031 76.3231 81.0256 88.9353 76.0181 87.6877 62.069 91.2 78.5425 55.1724 68.8525 64 78.2979 76.6169 90.3226 85.5051 80 82.7225 73.1707 79.6117 60.7261 82.0416 85.8447 84.7318 58.8235 65.6987 75.8621 85.5746 81.4815 64.0777 86.7102 81.8505 44.7205 77.0563 57.1429 70.3297 68.7161 72.1868 50.1931 66.2768 82.9077 80.4233 74.2138 60.274 68.4411 47.3988 85.8238 74.3295 78.7565 67.6845 88.7967 88.8889 82.4834 86.9565 80.9877 88.0734 89.2502 73.7752 83.4532 74.7664 72.9583 61.4232 85.6912 92.3077 70.3297 75.367 77.3109 54.9451 79.5518 91.2281 61.3333 74.6356 73.2297 87.0466 60.0897 81.8898 81.888 68.942 85.9903 72.2581 81.6162 60.9665 79.9423 75.3864 66.3291 66.0194 71.9101 57.1429 83.7466 82.7586 88.1633 56.2874 87.1795 79.7066 82.1622 76.0456 85.9935 83.4437 83.0189 91.0569 88.8184 87.5502 79.0698 64.5963 87.1795 85.2321 78.3151 70.1299 68.9655 88.8674 80.7512 67.8899 85.9903 76.2923 70.9859 83.1858 64.1686 90.6404 76.1062 86.3001 78.9022 78.1116 81.3896 62.4041 83.5067 86.4865 81.6143 78.0142 85.8447 75.4717 74.6667 78.0269 54.9333 56.8093 85.8561 85.5726 81.6754 81.0929 86.7133 80 88.3827 87.3977 68.3938 74.1514 62.8352 84.5011 89.6552 53.1469 84.8875 79.3792 89.8129 85.4881 66.6667 60.1583 77.7866 51.6129 76.588 86.9841 83.7274 34.2857 91.1392 35.2941 76.8642 87.1694 75.1107 82.9659 84.0449 90.2128 73.5632 85.9688 74.4921 68.9655 57.7075 90.1099 68.1115 75.9076 81.9672 79.7654 77.8135 76.2527 80 39.0244 82.5065 74.5407 81.3187 62.6263 71.932 60.241 86.645 79.6421 92.9577 86.7667 88.1939 61.244 82.3529 83.0409 68.7719 79.5181 88.5662 73.7527 60.793 81.1092 55.814 76.3485 74.5763 91.4286 71.7949 75.4717 58.2751 69.6673 45.2489 71.068 73.5484 76.7932 52.6316 81.4815 37.9562 68.9655 74.0157 73.161 77.3109 81.7439 64.5418 56.3574 75.6598 63.7037 59.3968 57.5342 68.7371 74.3034 85.2336 87.106 90.8382 77.3481 65.3367 82.8283 54.902 77.8378 73.6842 72.3327 84.9438 88.4956 76.5912 90.4507 70.2362 42.1456 89.0323 81.8482 74.0484 70.2413 87.1795 64.9573 87.4525 80.5621 63.5838 87.9819 80.5915 83.871 73.0435 87.4525 79.8989 73.2394 67.8414 58.4795 86.4932 79.7546 86.0158 91.7431 70.5882 82.3529 91.8845 70.7521 75.1696 77.8495 62.8726 79.9001 73.6292 87.2319 57.4514 77.2234 73.3238 73.4694 77.9199 64.214 67.0866 82.1293 77.8793 77.2277 75.8621 78.2609 81.0256 70.1299 76.7528 86.0244 85.5148 55.7457 64 77.0302 71.4563 81.4815 89.3112 83.7416 80.543 68.4685 79.3388 55.6291 83.4783 86.4198 62.4167 81.0811 78.3505 91.2593 83.2117 80.2111 69.7872 65.3465 74.141 87.0813 52.0147 56.8245 79.8111 70.1754 62.0896 77.635 86.0238 80.5897 68.3292 0 73.4908 78.6813 67.9245 73.2394 73.1278 84.2105 65.9631 79.2913 47.2303 81.1881 75.4821 90.1554 65.2632 66.4093 82.7907 71.4976 55.0898 75.3117 80.9384 66.6667 69.5652 86.4865 66.1191 90.5966 76.1578 58.4362 63.9296 70.9445 81.3397 88.6598 77.7906 77.7385 59.2593 52.2167 81.7391 63.2479 81.791 72.9412 85.064 56.2674 84.399 80.7437 0 69.6538 84.0159 83.4356 55.3459 80.0693 74.8718 69.5279 71.4088 67.1727 75.4258 84.6462 77.44 77.0642 73.5178 78.9189 85.0575 84.1424 76.4505 82.1333 81.5884 84.3956 84.6715 80.8743 78.0247 68.6391 71.4859 84.5953 71.5447 73.6597 74.4939 80.1898 71.2154 75.841 87.2289 69.0647 71.3376 74.6012 94.5996 92.1692 92.6094 80.7399 73.0097 63.5659 81.9672 83.9187 61.2086 90.5109 85.4599 80 94.382 72.1311 42.6036 69.8885 86.1626 84.0764 86.4461 72.3926 53.8813 72.9242 73.7864 63.6086 75.1269 83.0243 84.6847 70.615 77.4869 69.8851 64.69 75.0685 70.7395 44.0367 79.9704 69.9784 73.3668 68.4746 84.8485 86.2559 85.1064 80.3419 75.9443 75.9825 80.8625 69.5864 74.8768 75.9796 67.7966 56.305 77.3154 85.0174 84.4444 90.5028 80.109 60.1113 84.6395 57.0533 83.3156 78.2152 70.0337 76.7123 76.9866 83.7209 60.8187 65.3465 69.3727 79.8186 63.9618 75.9003 77.13 73.0159 84.8485 79.4567 48.6772 90.7074 66.899 76.1506 69.4505 78.0723 56.4972 76.9231 78.1457 80.9728 85.2401 73.5586 70.5394 64.0777 62.8242 54.1806 77.712 69.0909 73.7896 82.6446 85.5792 76.5101 78.6885 70.4846 80.4598 70.1754 67.3993 74.4958 89.1775 82.2967 75.8763 77.8993 70.5376 74.0741 47.0588 79.9397 71.7678 84.4622 85.4209 79.3249 74.2785 74.6507 74.8624 78.3505 44.7257 79.5107 87.3821 85.2459 83.9827 90.784 74.3169 71.3755 81.8792 76.8824 77.0563 67.5862 62.3053 79.1511 67.052 65.1072 73.8739 52.1739 74.813 63.0197 64.8649 81.2308 73.8523 72.7829 86.7257 87.5912 81.8737 80.5112 83.9779 80.597 85.9585 84.3658 84.63 68.3805 79.8226 56.2814 81.0329 75.766 90.8316 82.5789 29.7872 85.5124 72.0497 66.3073 85.879 0 82.0513 57.6271 69.434 66.506 50.8961 72.8682 77.9553 86.9976 78.7879 45.7516 65.3992 81.2834 84.9558 72.6058 44.7552 83.9125 67.6923 66.0436 34.5679 62.2831 92.9461 84.058 63.0824 71.9023 76.8831 71.7608 74.1483 82.1577 50.5133 46.6819 58.0645 54.3735 65.5602 77.187 69.1824 92.8155 75.5668 88.8889 82.4034 54.0541 88.8889 80.8395 77.175 86.6286 53.0387 75.8435 84.3882 73.3524 87.4618 71.9711 66.6667 78.3172 87.0813 44.8669 73.0924 67.9305 82.5871 77.6948 93.575 76.8879 68.6131 62.069 85.2459 67.9463 79.0419 75.174 64.135 57.7947 76.3251 70.3297 55.5133 82.7586 78.6787 81.3853 82.7004 79.0698 67.3046 87.6155 86.1134 69.9552 78.303 67.9245 84.3537 82.88 78.057 75.1459 62.069 72.4062 58.9928 30.5221 82.5566 61.3139 83.5821 81.6 86.7679 62.4685 87.6133 56.0364 78.4314 61.9423 86.1423 80.0211 78.3217 87.191 67.6385 76.6859 87.9765 52.8814 74.5342 77.1084 65.6965 45.1765 79.3792 72.9483 57.9439 65.7778 74.5763 74.8971 74.5098 79.7342 74.2475 80.1233 78.4933 75.7515 82.5871 77.1084 65.1685 73.8255 74.2952 79.7342 46.4 76.112 78.2503 85.9504 97.2973 66.9683 69.914 71.6049 93.2826 78.0952 80.6653 85.6712 89.6309 70.5336 81.376 75.9825 88.0808 71.5447 63.6704 65.9794 49.3151 71.8232 69.3069 59.4595 85.1898 80.6283 76.9231 67.6259 59.5041 63.3274 63.2727 80.3519 82.2811 84.492 58.7927 79.3867 81.7021 73.8416 76.7816 39.3443 75.6152 76.6727 80.2947 40.7323 64.257 75.5043 80.389 67.42 72.5869 81.2287 34.1463 72.7273 73.501 82.1589 66.4615 82.3037 71.8447 79.5895 53.3333 86.8504 81.072 81.3347 72.7273 79.3821 69.0196 60.1504 59.6491 60.1504 56.6038 85.1948 93.3333 79.8599 70.0229 70.1299 86.7606 66.9091 81.4527 68.0135 80.7825 78.9318 54.3131 86.0286 82.7757 62.2222 84.4622 66.2722 83.2178 76.8254 72.5061 70.568 60.4106 60.5355 36.3636 66.2207 57.7947 44.7489 93.7853 67.7316 71.8232 71.0425 73.8275 82.7586 79.8928 82.1818 69.5541 65.2921 72.0257 78.7879 80.8461 74.0594 74.1333 83.2215 48.254 51.2702 81.4159 76.0259 67.3629 86.3233 80 69.7947 77.3414 85.7636 85.5403 90.5812 85.0987 83.2158 55.0336 72.9223 75.9825 82.5397 81.7248 72.198 80 64.5995 74.2857 62.3377 56.6038 88.4319 84.5361 79.1717 77.8626 83.2298 73.0594 36.9004 50.8287 61.2529 82.5532 76.5499 48.5981 85.3278 92.3574 32 54.6584 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 0.708859 (Xent), [AvgXent: 0.708859, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 80.0907% <<

