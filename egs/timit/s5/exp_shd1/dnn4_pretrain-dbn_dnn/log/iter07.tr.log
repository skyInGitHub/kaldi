nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.001 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter06_learnrate0.002_tr0.7863_cv1.8036 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter07 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975016
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.81539, max 8.96107, mean 0.00568746, stddev 0.99447, skewness 0.129835, kurtosis 2.1535 ) 
[1] output of <AffineTransform> ( min -29.119, max 25.0362, mean -3.39846, stddev 4.08194, skewness 0.123703, kurtosis 1.2642 ) 
[2] output of <Sigmoid> ( min 2.25827e-13, max 1, mean 0.204359, stddev 0.313974, skewness 1.50772, kurtosis 0.807091 ) 
[3] output of <AffineTransform> ( min -29.9092, max 15.5679, mean -4.09245, stddev 2.77527, skewness -0.0466109, kurtosis 2.19956 ) 
[4] output of <Sigmoid> ( min 1.02467e-13, max 1, mean 0.0961451, stddev 0.192154, skewness 2.93418, kurtosis 8.50743 ) 
[5] output of <AffineTransform> ( min -14.3421, max 11.0518, mean -3.11434, stddev 1.95757, skewness 0.548746, kurtosis 2.17221 ) 
[6] output of <Sigmoid> ( min 5.90623e-07, max 0.999984, mean 0.112729, stddev 0.186778, skewness 2.76478, kurtosis 7.80277 ) 
[7] output of <AffineTransform> ( min -20.2903, max 17.2216, mean -2.7799, stddev 2.2667, skewness 0.531267, kurtosis 2.4557 ) 
[8] output of <Sigmoid> ( min 1.54186e-09, max 1, mean 0.154991, stddev 0.232935, skewness 2.0627, kurtosis 3.54196 ) 
[9] output of <AffineTransform> ( min -17.1887, max 17.629, mean -2.83437, stddev 2.85903, skewness 1.30749, kurtosis 2.47192 ) 
[10] output of <Sigmoid> ( min 3.42791e-08, max 1, mean 0.178407, stddev 0.292177, skewness 1.76717, kurtosis 1.75636 ) 
[11] output of <AffineTransform> ( min -30.4129, max 25.3834, mean -3.67855, stddev 3.6399, skewness 0.963202, kurtosis 3.04249 ) 
[12] output of <Sigmoid> ( min 6.19232e-14, max 1, mean 0.150888, stddev 0.296605, skewness 2.02671, kurtosis 2.57361 ) 
[13] output of <AffineTransform> ( min -14.8202, max 24.9401, mean -0.0179375, stddev 3.63222, skewness 0.531023, kurtosis 0.935954 ) 
[14] output of <Softmax> ( min 1.30085e-15, max 0.999974, mean 0.000657829, stddev 0.0190584, skewness 40.2715, kurtosis 1759.75 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.08238, max 1.45177, mean -0.00018468, stddev 0.0579707, skewness -0.171293, kurtosis 29.7727 ) 
[1] diff-output of <AffineTransform> ( min -0.437503, max 0.279694, mean 1.16822e-05, stddev 0.0106769, skewness -0.434459, kurtosis 85.469 ) 
[2] diff-output of <Sigmoid> ( min -2.01818, max 1.83385, mean 0.000600958, stddev 0.0964135, skewness 0.15621, kurtosis 18.8383 ) 
[3] diff-output of <AffineTransform> ( min -0.428141, max 0.494082, mean -1.22525e-05, stddev 0.0120755, skewness 0.134343, kurtosis 109.977 ) 
[4] diff-output of <Sigmoid> ( min -2.42041, max 2.51865, mean 0.000474846, stddev 0.13121, skewness 0.0725386, kurtosis 15.9742 ) 
[5] diff-output of <AffineTransform> ( min -0.573748, max 0.44894, mean 1.83406e-05, stddev 0.012628, skewness 0.0257702, kurtosis 96.6216 ) 
[6] diff-output of <Sigmoid> ( min -2.36483, max 2.41459, mean 0.000504826, stddev 0.10773, skewness 0.0702006, kurtosis 17.388 ) 
[7] diff-output of <AffineTransform> ( min -0.291827, max 0.279747, mean 2.71145e-05, stddev 0.0102285, skewness 0.0878231, kurtosis 55.3789 ) 
[8] diff-output of <Sigmoid> ( min -1.45433, max 1.37025, mean 0.000256055, stddev 0.0750963, skewness 0.0392514, kurtosis 15.9823 ) 
[9] diff-output of <AffineTransform> ( min -0.25231, max 0.240751, mean 2.42139e-05, stddev 0.0075166, skewness -0.164746, kurtosis 61.6235 ) 
[10] diff-output of <Sigmoid> ( min -1.17447, max 1.06494, mean 0.000201875, stddev 0.0572538, skewness -0.0133429, kurtosis 18.0924 ) 
[11] diff-output of <AffineTransform> ( min -0.397632, max 0.196212, mean 2.36148e-05, stddev 0.00830412, skewness -0.721401, kurtosis 84.6328 ) 
[12] diff-output of <Sigmoid> ( min -2.2588, max 1.21875, mean -0.000359267, stddev 0.0873775, skewness -0.265451, kurtosis 10.7062 ) 
[13] diff-output of <AffineTransform> ( min -0.999333, max 0.89342, mean -4.15296e-09, stddev 0.0166043, skewness -24.9812, kurtosis 2077.93 ) 
[14] diff-output of <Softmax> ( min -0.999333, max 0.89342, mean -4.15296e-09, stddev 0.0166043, skewness -24.9812, kurtosis 2077.93 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.73153, max 1.75959, mean 0.000317982, stddev 0.167626, skewness -0.0186577, kurtosis 2.13902 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.711001, max 0.574088, mean 0.00299067, stddev 0.16406, skewness -0.122241, kurtosis 0.695445 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -1.03728, max 0.915131, mean -0.000721605, stddev 0.0728598, skewness -0.0225748, kurtosis 6.46202 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.948945, max 0.957153, mean -0.00313666, stddev 0.192568, skewness -0.0687212, kurtosis 2.36994 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.985181, max 0.918055, mean 0.000444381, stddev 0.043067, skewness 0.101148, kurtosis 14.3886 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.10354, max 0.79389, mean 0.00469521, stddev 0.197885, skewness -0.0050019, kurtosis 2.37545 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.451323, max 0.673889, mean 0.00079908, stddev 0.0356562, skewness 0.190716, kurtosis 10.0369 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.672656, max 0.640838, mean 0.00694136, stddev 0.163322, skewness 0.133659, kurtosis 1.69158 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.426057, max 0.500713, mean 0.000854719, stddev 0.0336251, skewness 0.22659, kurtosis 7.47068 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.586708, max 0.558939, mean 0.00619879, stddev 0.12073, skewness 0.241344, kurtosis 2.3024 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.920402, max 0.476699, mean 0.00117502, stddev 0.0458632, skewness -0.0639832, kurtosis 10.1805 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.948061, max 0.559055, mean 0.00604535, stddev 0.137752, skewness -0.137422, kurtosis 4.02561 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -3.2009, max 2.43164, mean -2.43327e-08, stddev 0.0909434, skewness -4.17435, kurtosis 80.3849 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.81234, max 1.9352, mean -3.13709e-09, stddev 0.27635, skewness -1.7398, kurtosis 15.6759 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 342784 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -6.78548, max 7.66488, mean 0.00618661, stddev 0.998336, skewness 0.126755, kurtosis 2.01683 ) 
[1] output of <AffineTransform> ( min -29.1076, max 24.7074, mean -3.37336, stddev 4.12271, skewness 0.143805, kurtosis 1.23036 ) 
[2] output of <Sigmoid> ( min 2.28424e-13, max 1, mean 0.207695, stddev 0.317223, skewness 1.48238, kurtosis 0.714382 ) 
[3] output of <AffineTransform> ( min -31.3984, max 18.2219, mean -4.08935, stddev 2.80346, skewness -0.0491951, kurtosis 2.20153 ) 
[4] output of <Sigmoid> ( min 2.31125e-14, max 1, mean 0.0977835, stddev 0.194421, skewness 2.89495, kurtosis 8.22828 ) 
[5] output of <AffineTransform> ( min -13.9132, max 11.1593, mean -3.10517, stddev 1.97699, skewness 0.539694, kurtosis 2.20922 ) 
[6] output of <Sigmoid> ( min 9.06929e-07, max 0.999986, mean 0.1143, stddev 0.188452, skewness 2.73031, kurtosis 7.57138 ) 
[7] output of <AffineTransform> ( min -21.1488, max 17.1079, mean -2.75994, stddev 2.28957, skewness 0.52812, kurtosis 2.44389 ) 
[8] output of <Sigmoid> ( min 6.53413e-10, max 1, mean 0.157747, stddev 0.235447, skewness 2.0295, kurtosis 3.37854 ) 
[9] output of <AffineTransform> ( min -16.6325, max 17.6284, mean -2.81693, stddev 2.88642, skewness 1.31188, kurtosis 2.48196 ) 
[10] output of <Sigmoid> ( min 5.97845e-08, max 1, mean 0.180966, stddev 0.294733, skewness 1.73838, kurtosis 1.63826 ) 
[11] output of <AffineTransform> ( min -27.4824, max 22.2446, mean -3.67004, stddev 3.66236, skewness 0.973999, kurtosis 2.96373 ) 
[12] output of <Sigmoid> ( min 1.16027e-12, max 1, mean 0.152763, stddev 0.298902, skewness 2.00229, kurtosis 2.46286 ) 
[13] output of <AffineTransform> ( min -15.7045, max 24.2022, mean -0.0178839, stddev 3.66312, skewness 0.547773, kurtosis 0.991102 ) 
[14] output of <Softmax> ( min 2.12971e-15, max 0.999309, mean 0.000657834, stddev 0.0194369, skewness 39.7517, kurtosis 1707.46 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.81782, max 1.76245, mean -0.000167185, stddev 0.0449946, skewness 0.122357, kurtosis 73.2579 ) 
[1] diff-output of <AffineTransform> ( min -0.218118, max 0.436845, mean 1.78444e-05, stddev 0.0083501, skewness 1.18787, kurtosis 105.705 ) 
[2] diff-output of <Sigmoid> ( min -1.78077, max 1.91344, mean -0.00019662, stddev 0.075924, skewness 0.214565, kurtosis 22.213 ) 
[3] diff-output of <AffineTransform> ( min -0.293795, max 0.418499, mean 2.26729e-05, stddev 0.00940409, skewness 0.757464, kurtosis 106.825 ) 
[4] diff-output of <Sigmoid> ( min -1.48095, max 2.23538, mean -2.98836e-05, stddev 0.100779, skewness 0.0367174, kurtosis 13.4036 ) 
[5] diff-output of <AffineTransform> ( min -0.288268, max 0.355726, mean 2.65478e-05, stddev 0.00971469, skewness 0.203582, kurtosis 63.9783 ) 
[6] diff-output of <Sigmoid> ( min -1.21354, max 1.94112, mean -1.03658e-05, stddev 0.0843141, skewness 0.0799098, kurtosis 14.4738 ) 
[7] diff-output of <AffineTransform> ( min -0.216189, max 0.313109, mean 2.31697e-05, stddev 0.00801281, skewness 0.313452, kurtosis 53.6269 ) 
[8] diff-output of <Sigmoid> ( min -0.93388, max 1.292, mean 0.000197901, stddev 0.059629, skewness 0.0456394, kurtosis 15.6627 ) 
[9] diff-output of <AffineTransform> ( min -0.148378, max 0.184587, mean 1.37701e-05, stddev 0.0059913, skewness -0.155689, kurtosis 56.9213 ) 
[10] diff-output of <Sigmoid> ( min -0.93705, max 0.939115, mean 4.66714e-05, stddev 0.0460364, skewness -0.107004, kurtosis 19.6814 ) 
[11] diff-output of <AffineTransform> ( min -0.238002, max 0.186784, mean 5.22949e-06, stddev 0.00679479, skewness -0.418072, kurtosis 81.3698 ) 
[12] diff-output of <Sigmoid> ( min -2.61095, max 2.12193, mean 0.000203273, stddev 0.0729508, skewness -0.296593, kurtosis 22.9018 ) 
[13] diff-output of <AffineTransform> ( min -0.999953, max 0.968019, mean -6.34035e-09, stddev 0.0136174, skewness -25.8696, kurtosis 2420.78 ) 
[14] diff-output of <Softmax> ( min -0.999953, max 0.968019, mean -6.34035e-09, stddev 0.0136174, skewness -25.8696, kurtosis 2420.78 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.87205, max 2.12313, mean -0.000797089, stddev 0.13075, skewness 0.031269, kurtosis 3.20112 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.568576, max 0.678371, mean 0.00456813, stddev 0.143929, skewness 0.0906595, kurtosis 1.03601 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.568105, max 0.693469, mean 0.00140708, stddev 0.0583079, skewness 0.163191, kurtosis 6.19034 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.797478, max 0.884169, mean 0.00580426, stddev 0.162313, skewness 0.203584, kurtosis 2.83174 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.609211, max 0.605812, mean 0.000722621, stddev 0.0354179, skewness 0.147328, kurtosis 11.9844 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.949637, max 0.792911, mean 0.00679628, stddev 0.17615, skewness 0.0665375, kurtosis 2.89949 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.442444, max 0.39709, mean 0.000737721, stddev 0.0295168, skewness 0.052443, kurtosis 8.87109 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.624689, max 0.591271, mean 0.00593147, stddev 0.140082, skewness 0.0500114, kurtosis 1.73755 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.39943, max 0.365321, mean 0.000544543, stddev 0.0281426, skewness 0.0243, kurtosis 7.9275 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.463846, max 0.510911, mean 0.00352523, stddev 0.102496, skewness 0.0741374, kurtosis 3.13659 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.461926, max 0.508355, mean 0.00032805, stddev 0.0387354, skewness -0.0736385, kurtosis 9.39048 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.569138, max 0.560438, mean 0.00133874, stddev 0.116107, skewness -0.0875236, kurtosis 3.74555 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.25035, max 2.79723, mean -4.76132e-08, stddev 0.0759526, skewness -2.71793, kurtosis 114.8 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.13609, max 2.01821, mean -5.96046e-09, stddev 0.224952, skewness -1.02384, kurtosis 19.9398 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0782442 min, processing 73015.8 frames per sec; i/o time 5.23295%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14111 120 114 116 102 29 147 431 139 624 262 548 95 133 232 62 162 188 145 264 293 157 210 252 206 227 177 121 194 213 59 160 138 41 524 149 489 359 331 244 27 18 144 252 121 124 944 114 5399 17569 1561 284 471 20 632 126 26 94 273 190 263 30 128 442 158 105 525 11 77 78 552 418 679 528 1016 172 727 226 492 148 41 38 347 273 210 329 186 75 361 141 50 229 14 179 16 260 399 380 208 348 168 179 81 181 88 1263 98 58 160 98 115 54 66 62 11 119 350 151 110 448 126 190 86 63 70 151 159 154 147 99 51 457 174 395 129 114 299 480 34 300 110 192 230 423 223 68 294 243 288 142 120 14 444 408 166 105 144 162 529 125 74 223 6 210 64 142 100 249 210 274 130 35 152 111 628 206 146 284 105 10 20 172 279 270 107 661 122 308 130 173 423 220 622 85 221 292 20 66 211 128 191 614 140 15 160 183 392 155 147 70 20 125 365 508 342 43 242 266 181 354 229 517 160 211 158 92 236 201 194 33 15 451 392 162 89 139 99 401 98 88 71 358 242 87 117 16 197 149 150 216 426 191 185 158 110 313 96 94 154 130 118 114 166 121 21 289 100 381 83 90 18 148 268 118 186 92 525 93 176 196 123 174 146 156 68 60 152 179 13 146 212 95 173 135 298 16 240 157 78 116 133 150 196 69 70 269 161 182 203 142 109 580 111 212 100 113 81 22 106 188 435 309 183 96 159 180 813 140 117 84 160 60 136 105 93 279 49 323 115 81 187 130 220 198 248 229 121 138 321 339 134 107 289 145 381 16 122 414 251 218 14 704 214 173 295 205 31 188 148 232 127 78 197 214 102 228 131 158 286 12 325 95 342 165 147 125 128 38 240 479 145 74 148 97 75 288 83 71 221 75 341 213 744 497 119 182 123 166 206 71 174 21 369 305 186 525 28 62 137 211 161 86 153 69 98 289 226 97 32 248 67 432 171 470 200 262 113 68 112 237 175 493 28 74 192 110 147 76 178 359 200 35 65 15 148 172 163 12 106 46 106 215 128 158 115 37 61 128 34 180 113 80 227 21 80 215 103 113 91 332 175 93 103 339 102 197 194 276 33 250 439 144 479 88 246 22 155 155 186 44 355 235 212 135 123 240 272 212 71 252 101 106 188 76 61 17 82 47 139 27 164 88 260 223 132 257 98 177 282 25 59 247 184 238 139 298 77 80 278 302 61 410 162 317 174 79 22 160 279 126 205 160 228 522 176 162 39 25 152 251 223 86 286 122 166 15 119 81 176 132 85 109 289 78 185 137 361 29 347 417 364 180 85 89 269 23 149 133 121 83 160 410 95 466 17 101 145 14 66 44 19 216 251 140 66 52 161 311 239 133 142 268 107 151 0 355 94 68 210 42 10 178 124 47 82 201 71 323 122 177 221 226 105 181 815 94 322 180 82 190 119 1408 32 372 114 94 24 267 55 79 63 291 21 150 99 752 230 170 140 110 8 98 137 290 267 238 179 97 239 110 166 159 62 123 14 30 87 117 100 356 341 52 95 143 51 151 264 109 363 8 275 14 204 202 154 229 140 80 115 52 45 276 235 129 256 254 94 238 182 131 86 130 130 96 196 120 148 225 34 202 54 553 173 208 160 275 133 618 6 45 306 59 45 178 28 112 171 289 96 111 63 455 146 103 77 247 134 346 420 197 51 400 17 181 362 122 83 799 204 92 131 1688 75 185 61 630 124 236 80 58 118 320 115 14 516 106 54 103 280 177 169 213 101 56 536 291 116 201 195 336 18 111 70 109 79 37 111 187 128 201 1008 95 457 71 152 219 305 96 191 130 235 14 71 155 225 240 189 307 189 632 15 275 157 359 52 39 8 261 510 564 249 222 352 43 224 221 130 126 45 161 151 30 170 155 229 37 61 191 190 136 49 411 41 153 223 35 366 639 104 127 85 142 456 275 230 113 288 21 120 29 17 214 79 214 255 110 257 77 118 218 13 68 101 63 251 59 183 125 145 170 202 215 109 241 161 267 174 256 90 200 49 76 92 161 276 222 56 463 654 317 130 77 151 144 186 175 292 131 213 86 220 270 108 57 131 395 106 113 85 403 81 189 54 110 144 363 179 368 232 184 400 191 489 231 230 350 465 586 149 317 131 273 50 275 11 97 38 135 368 286 204 137 215 257 418 210 224 110 55 60 75 172 202 525 277 145 337 68 189 117 50 276 313 136 179 423 28 167 194 461 203 601 9 190 227 238 177 113 47 189 451 171 151 181 96 142 129 322 103 83 200 170 55 11 92 243 494 291 121 170 693 104 145 434 141 13 101 57 58 167 42 351 179 195 376 0 245 378 244 79 288 97 116 1082 263 205 374 312 163 126 277 43 154 146 187 138 227 205 91 202 84 124 191 184 214 123 421 234 163 207 69 392 407 805 555 331 459 257 193 152 270 256 205 168 82 44 30 84 134 350 392 468 81 109 138 51 163 98 350 55 219 95 217 185 182 155 54 676 231 99 147 82 316 70 292 251 114 185 205 101 293 88 170 372 143 247 89 183 269 159 159 470 190 148 36 484 150 85 151 135 220 209 180 557 157 313 294 94 360 143 119 227 207 88 71 75 349 843 251 120 51 173 149 253 192 299 302 211 74 152 113 43 85 136 421 115 104 242 228 232 13 59 331 189 125 243 355 398 250 272 145 118 163 1961 152 115 363 91 134 74 378 346 72 160 400 86 256 55 11 200 228 129 162 250 490 56 205 245 156 452 435 409 169 263 194 225 99 561 179 234 364 164 141 80 185 173 8 19 29 132 207 139 64 156 211 16 76 131 93 282 224 71 388 32 160 40 547 120 241 139 286 192 752 249 120 243 218 46 211 120 291 79 257 198 13 1281 166 13 738 488 437 90 370 118 174 163 276 49 154 104 131 124 316 100 468 303 218 68 14 30 260 250 215 829 131 141 45 131 217 166 115 118 64 313 270 608 334 412 132 73 312 298 428 246 226 69 124 375 68 167 62 230 198 165 219 127 190 133 948 357 222 171 259 511 147 80 207 240 212 225 164 53 112 147 121 25 150 149 324 411 249 100 41 133 521 301 150 62 303 411 60 18 110 174 40 394 52 240 331 284 215 421 114 247 430 133 48 109 90 50 18 1198 95 97 208 60 279 137 170 245 280 190 293 117 334 217 91 223 276 271 218 124 173 308 265 129 146 20 159 258 333 162 477 154 438 52 1106 298 479 38 841 127 66 85 66 26 192 67 285 218 115 177 412 385 148 434 168 156 454 403 22 125 84 360 157 205 290 170 429 71 149 131 109 88 156 90 129 330 14 559 412 392 145 155 181 425 252 187 74 157 216 56 231 191 281 147 170 165 579 328 249 278 354 74 559 114 283 243 343 212 193 227 115 79 194 48 410 65 80 109 135 90 215 117 185 53 480 464 62 80 ]
@@@ Loss per-class: [ 0.32798 0.741762 0.805811 0.841405 0.575834 0.964843 1.64977 0.536158 0.484766 0.474336 0.248693 0.506611 0.524721 0.494583 0.855257 0.752738 0.693847 0.850214 0.621202 0.449872 0.390984 0.661286 0.322197 0.762338 0.941818 0.355309 0.775272 0.519895 0.676635 0.387469 0.878105 0.742233 0.880698 0.782398 0.205557 0.412183 0.187041 0.268564 0.51005 1.25617 1.21391 1.01181 0.37079 1.01287 0.866009 0.358376 0.807486 0.686943 0.456021 0.229874 0.449641 1.2731 0.347117 0.79974 0.43848 0.601598 1.24783 0.696672 0.283912 1.15289 0.685617 0.57147 0.638438 0.265056 1.09893 0.805188 1.0487 1.11908 0.491911 0.666706 0.545173 0.369232 0.555489 0.532207 0.199065 0.573429 0.578648 0.849506 0.315482 0.935415 0.866623 1.05703 0.342228 0.44443 0.350984 0.835786 0.406453 0.372674 0.754934 1.02511 0.599831 0.579869 1.14514 0.553957 1.27329 0.680001 0.691694 0.443933 1.07334 0.378279 0.447437 1.36889 1.25048 0.570195 0.663479 0.441325 0.574361 0.877782 0.57953 0.958302 0.778079 1.30958 0.598699 0.793985 1.89826 0.738282 0.448333 0.386008 1.26819 0.917912 0.601531 0.691056 0.607936 1.47112 0.6844 0.64344 0.60189 1.16221 0.728418 1.20878 0.896851 1.06772 0.949249 0.54306 0.807681 0.45747 0.727126 0.860924 0.850577 0.365419 1.02597 0.543526 0.402327 0.592067 1.24819 0.86471 1.21308 0.593377 0.36898 1.26396 0.518623 1.14389 0.239167 0.47272 0.747817 0.52644 1.25807 0.850633 0.477491 0.905065 0.656756 0.855967 2.02952 0.714916 0.656847 0.5673 0.816609 0.352789 0.89959 0.599394 0.643144 0.950095 0.709483 0.449259 0.350242 0.371051 0.647907 0.637734 1.10875 1.83205 0.550382 0.52474 0.805308 0.965907 0.898154 0.738423 0.736118 0.403573 0.479767 0.945108 0.503274 1.28289 0.387186 0.783989 0.459317 0.207689 1.24031 1.14858 0.380301 0.824305 0.521058 0.359186 0.760685 0.622102 1.52949 1.33016 0.920337 0.988096 0.788942 0.91578 0.372943 1.13961 0.713602 1.24435 0.557868 0.455497 0.342807 0.695896 0.882953 0.465877 0.665643 0.491547 1.53098 0.976188 0.767631 0.548626 0.512757 0.521025 1.05729 0.998764 0.890921 0.841125 1.01134 0.688221 0.858057 0.542678 1.17345 0.524556 0.56098 0.823923 0.336155 0.449765 0.592159 0.410915 0.727845 1.11566 0.300612 0.583077 0.679274 0.518445 0.52938 0.708343 1.37578 0.784301 0.507666 0.563592 0.887267 0.946157 1.06165 0.773914 0.8607 0.346299 1.23314 0.416745 1.16867 0.591998 0.748584 0.561735 0.697005 0.73195 0.475117 0.825587 0.494543 0.547526 0.663368 0.526536 0.409963 0.830134 0.538799 0.308105 0.520385 0.48217 0.440135 1.0231 0.760491 1.86311 0.455534 0.589102 1.1686 0.834056 0.292741 0.903685 0.441585 0.675305 0.395291 2.29411 0.728203 1.6011 0.918411 0.461967 0.941323 0.894828 1.38258 1.35024 1.15442 1.13029 1.01324 0.442745 0.46568 0.683356 0.710567 0.460469 0.587191 0.98155 1.15527 0.933022 0.707015 0.917917 1.25872 0.884382 0.378825 0.455612 0.666049 0.542275 1.48953 0.748604 0.440209 0.887933 0.476659 1.06973 0.584668 0.436549 0.783972 1.58177 0.689855 0.730549 1.05656 1.11196 0.726534 1.14149 0.893232 0.420736 0.393112 0.604053 0.465647 0.838385 1.06871 0.401241 1.12317 0.941729 0.870549 0.750996 1.2945 0.529445 1.1107 1.47205 0.889328 0.439439 0.867716 0.621801 1.86099 0.373832 1.21536 1.08459 0.777241 0.70992 1.44229 0.91118 0.708196 0.551023 0.89465 0.475469 1.23457 0.806297 1.34402 0.525393 0.823488 0.760836 0.569745 1.74301 0.545609 1.38857 0.472543 0.639713 0.705757 1.11486 0.711359 0.592649 0.405293 0.439944 1.22337 0.622271 0.836632 0.760711 0.765249 0.642482 0.534175 0.821421 0.734148 1.1247 0.459049 0.755951 0.460521 0.296113 1.55752 0.492281 0.549069 0.60611 0.830856 0.825965 1.45528 1.36849 0.522156 0.443688 0.822718 0.650425 1.46584 1.13769 0.393991 0.835024 0.8114 0.903243 1.16785 0.708677 3.2386 0.423984 0.37057 2.04611 0.758025 0.579698 1.84887 0.904864 0.75093 0.365828 1.07296 0.695253 1.25734 0.395803 1.1786 0.827395 0.951344 0.605342 1.1039 1.34572 0.359198 0.916689 0.592428 0.51528 0.802293 0.679029 1.25382 0.779022 0.582542 0.635225 0.422949 1.20291 0.515573 0.649497 0.537149 1.37191 0.523734 1.04275 0.516687 1.26211 0.631896 0.733145 0.757008 0.880278 0.828414 0.925026 0.552509 0.552481 0.418793 0.824348 0.550084 0.955764 0.862525 0.90511 0.468862 0.580269 0.458452 1.33257 0.848762 0.757625 0.574418 0.954253 0.665353 0.479161 1.19379 0.691611 0.55159 1.26494 0.741831 0.532257 0.649824 0.850165 0.901338 1.08623 0.959671 1.25125 0.782681 0.660333 0.781598 1.10505 1.09484 1.04329 0.725732 0.637696 0.609897 0.637403 0.730697 1.49276 0.868882 0.611083 1.096 1.49601 0.801882 0.822727 1.17946 0.940317 0.362811 0.486735 1.25253 0.795428 0.440447 1.03244 1.23399 1.02027 0.759729 2.06789 0.750782 0.80452 0.642117 0.718895 0.577349 0.437772 1.29987 1.84689 0.621209 0.717399 1.86156 0.552726 1.54782 0.870662 0.524857 0.748998 0.998037 0.91662 1.01335 0.868444 1.32843 0.791663 0.559614 0.636549 0.844816 0.967064 1.9147 1.09807 0.679759 1.12593 0.897453 0.661563 0.269574 1.09408 0.924453 0.972073 1.24164 0.681001 0.670205 1.00913 1.33664 1.08882 0.803543 1.19672 0.569116 0.438859 0.696537 1.73553 0.644056 0.857706 0.961672 0.642304 0.880617 0.838056 1.11673 1.36889 0.657545 0.321265 0.456502 0.788652 0.789803 0.482504 1.16903 0.563684 0.285926 0.66662 0.59091 1.53941 0.856597 2.04503 1.26049 0.370244 0.676033 2.18624 0.982018 0.75258 0.640608 1.20664 0.610721 0.389839 1.0915 0.355136 1.46853 0.568493 0 0.805815 0.944105 0.675204 1.26053 1.02314 0.884134 0.510469 0.828263 0.533192 1.45868 1.00035 0.575425 0.693765 0.749323 0.821807 0.905542 0.937977 0.822361 0.710152 0.928393 0.996119 0.508506 0.916409 0.649362 0.816256 0.812485 0.404951 1.0579 0.555697 0.793717 1.10947 0.795273 0.984816 1.03189 0.805409 0.420366 0.812683 0.999911 0.907911 1.27209 0.328042 0.745178 1.45707 0.991573 0.941488 3.18579 0.848155 1.35553 0.521621 1.0609 0.693155 0.880438 0.849414 0.374409 0.747373 0.454371 1.60211 0.592474 0.70904 0.977514 1.80992 1.29398 0.703705 0.951248 0.458615 0.534475 0.717015 0.700005 0.891726 0.857956 1.1742 0.634527 0.596006 0.632909 1.836 1.06279 1.00142 0.586462 0.649632 1.19813 0.524685 0.731504 1.80953 0.755312 1.13346 0.913703 1.12002 0.993283 2.21626 1.38114 0.664482 0.814266 0.980368 1.46409 1.0929 1.81692 0.514279 1.07116 0.890478 1.22522 0.469635 0.486827 0.670305 0.752961 0.685537 0.575318 0.387508 0.882419 0.676423 0.914994 1.05239 1.1647 0.589761 1.07681 1.25968 0.924437 0.753761 1.67139 0.909701 0.692923 1.50904 0.944157 0.871511 0.593918 1.09917 0.886105 0.778745 1.15969 0.647612 1.11204 0.757083 1.19845 0.709886 0.862981 1.20767 1.33955 1.04455 1.81236 0.762953 0.685796 0.58712 1.27174 0.502874 0.756959 0.656616 0.90678 0.511892 0.766699 0.583387 0.49811 0.428034 0.612819 0.812778 1.10589 0.702019 0.552269 0.746729 1.00787 0.880658 0.475633 0.67999 1.15952 0.549045 0.987171 1.18672 0.704868 1.31081 0.569738 0.880396 0.51737 0.83906 0.919701 0.750435 1.27272 0.70703 0.773413 0.848903 0.871048 0.552191 1.02596 0.968005 0.73742 1.24235 1.30316 0.638375 0.534182 0.629272 0.827511 0.720804 0.661061 0.450387 0.591915 1.04978 1.00086 1.11047 0.577484 0.565646 1.6291 0.615556 0.730322 0.406001 0.566952 1.12763 1.46418 0.876692 1.63959 0.998239 0.541694 0.82259 2.02591 0.395853 2.2364 0.805992 0.562457 0.967299 0.739218 0.705647 0.372452 1.21948 0.537744 0.860667 1.13091 1.64873 0.67009 1.24479 0.960389 1.03188 0.727544 0.820532 1.04095 0.818106 2.65897 0.670249 0.907604 0.713162 1.1594 0.996657 1.21433 0.527122 0.830522 0.405019 0.474046 0.409375 1.42285 0.754102 0.627499 0.956289 0.882599 0.469338 0.99121 1.6726 0.73471 1.66735 0.949355 0.94163 0.988244 0.990244 0.962773 1.35463 1.07059 1.93643 0.972615 0.938924 0.781715 1.51728 0.738818 2.0841 0.968851 1.13177 0.930455 1.24515 0.67368 1.28576 1.78648 0.896613 1.26022 1.5134 1.75244 1.14657 0.963099 0.647131 0.399662 0.447848 1.04996 1.14806 0.954277 1.28174 0.738198 0.994909 0.846786 0.577372 0.449566 0.925908 0.349175 1.39121 1.84716 0.446928 0.720086 0.949262 0.953178 0.417706 1.16137 0.485597 0.704355 0.984274 0.447579 0.792425 0.565924 1.25762 0.542749 0.806617 0.890814 1.21535 1.24386 0.587315 0.72623 0.474345 0.248426 1.10812 0.89113 0.343943 1.007 0.896324 0.904675 1.25056 0.666124 0.974062 0.560736 1.25284 0.73779 0.987632 1.00207 0.852481 1.40972 1.28933 0.57527 0.698079 0.89208 0.875208 1.01452 0.886824 1.08834 0.753222 0.596982 0.555755 1.33948 1.10289 0.955009 1.0717 0.782473 0.542107 0.778012 0.750663 1.24227 0.892326 1.71312 0.733701 0.601154 1.21113 0.751519 0.844354 0.304305 0.64877 0.827573 0.980329 0.883025 0.890268 0.615162 1.81775 1.60757 0.798831 1.09878 1.2931 0.827924 0.599847 0.670121 1.18661 2.96918 0.909701 0.818289 1.22902 1.0976 1.09717 1.34725 1.25581 0.840211 1.72812 0.695943 0.8583 0.692081 1.0988 1.05343 0.597915 0.973232 1.51034 0.692424 0.667527 1.20917 1.05904 0.646704 1.16755 0.354001 0.906668 1.5026 1.40096 0.978131 0.790136 0.640776 0.783584 0.894061 1.5711 1.52876 0.698097 1.12703 0.632895 1.22436 0.554078 1.44526 0.711819 0.666629 0 1.15868 0.660186 0.663711 1.5221 0.723986 1.02202 0.978112 0.850588 1.07165 0.855764 0.484168 0.728581 0.990141 0.986155 0.740312 0.872255 0.640375 0.788535 0.786956 0.723871 0.662321 0.705177 0.778504 0.761956 1.23287 1.13379 0.63718 1.06473 1.0482 0.757036 0.630551 0.888598 0.819747 0.671484 0.937736 0.996319 1.04672 0.203411 0.306964 0.380594 0.775374 0.994162 1.22813 0.658468 0.683071 1.25088 0.422472 0.58386 0.639213 0.476455 1.00708 2.04011 1.05608 0.638513 0.665734 0.487726 1.19305 1.28902 0.988213 0.914478 1.34032 0.90589 0.56346 0.724251 0.988265 1.05962 0.956828 0.864618 1.07897 1.07791 1.99675 0.772844 0.965502 1.03086 1.19055 0.681743 0.500524 0.631751 0.834004 0.755203 1.03029 0.756521 0.942001 0.811598 0.84922 1.40268 1.50967 0.565743 0.651206 0.755264 0.482589 0.799701 1.39459 0.660181 1.31166 0.672753 1.09076 1.05824 1.43891 0.887026 0.626768 1.42111 1.31595 1.11674 0.784827 1.35364 0.758467 0.715181 1.01906 0.68251 0.834888 1.81123 0.525515 1.0505 1.00569 1.33804 0.73126 1.43223 0.82691 0.776872 0.711368 0.514036 0.919416 1.08922 1.17006 1.58908 1.54626 0.887787 1.13164 1.00906 0.625294 0.545344 1.10092 0.777829 1.09724 0.643563 0.898441 1.11223 0.905167 0.561187 0.8492 0.995287 0.75756 1.00582 1.09484 1.96296 0.682335 0.97951 0.588493 0.519036 0.773428 0.969966 1.0412 1.11678 0.864676 1.73705 0.920443 0.489122 0.720885 0.74689 0.429739 1.00906 1.06189 0.917646 0.772956 0.861654 1.22256 1.29923 0.816532 1.14469 1.33191 1.33695 2.10896 1.08544 1.38455 1.15997 0.757679 0.841004 0.861442 0.685802 0.6791 0.779963 0.71837 0.608217 0.595886 0.639615 0.80816 0.593013 1.09362 0.832095 1.33803 0.612447 0.945239 0.302064 0.625248 2.61712 0.597199 1.28418 0.981555 0.596084 3.12292 0.710525 1.35455 1.10479 1.32087 1.91708 0.936023 0.838037 0.629091 0.735815 1.84527 1.26724 0.724358 0.543175 1.04755 2.08686 0.670835 1.12178 1.43687 2.15892 1.05856 0.343428 0.630093 1.36173 1.05526 0.76807 0.897199 1.06712 0.727433 1.64865 1.89656 1.18576 1.55718 1.16432 0.838816 0.922758 0.337719 1.02671 0.86781 0.61434 1.32307 0.839184 0.728905 0.764843 0.562088 1.57759 0.846573 0.717435 1.0203 0.676526 0.834311 1.189 0.883885 0.568189 2.35602 0.981923 1.11747 0.665397 0.898442 0.342044 0.750515 1.01133 1.49031 0.986325 1.07451 0.793497 0.938814 1.09392 1.1971 0.724199 0.757216 1.63912 0.609891 0.880888 0.65371 0.759376 0.779552 1.1985 0.490543 0.415554 0.842485 0.857945 1.22695 0.734835 0.677532 0.814771 0.831935 1.24061 1.21031 1.56175 2.43735 0.728349 1.14042 0.760082 0.943295 0.663278 1.39975 0.481927 1.59692 0.774291 1.54047 0.553475 0.801887 0.777778 0.57125 1.07863 0.720689 0.470864 1.58476 1.17565 1.13329 1.04863 1.68126 0.840722 1.06476 1.26504 1.51291 0.807464 1.05775 1.25839 0.833289 0.794565 0.770327 0.834587 0.789537 0.780827 1.02103 1.13148 1.07488 1.08689 0.857949 2.0851 1.00795 0.736371 0.593427 0.462773 1.33119 1.10477 0.847712 0.348399 0.89485 0.673661 0.62336 0.548466 1.00522 0.728941 1.03314 0.469659 0.914957 1.38365 1.7428 1.59863 1.052 1.10522 1.11821 0.512082 0.706241 0.691269 1.46775 1.5166 1.34963 1.49745 0.842167 0.770531 0.536202 1.46879 0.778722 0.929498 0.965456 0.814471 2.002 0.88954 0.840406 0.844496 2.25239 1.28609 1.188 0.818122 1.13595 1.05298 0.780402 1.81863 1.20922 0.978395 0.699509 1.2103 0.798974 0.826214 0.849415 1.34423 0.503515 0.789558 0.795751 1.14535 0.833026 1.37007 1.47113 1.60133 1.42119 1.43603 0.67452 0.482974 0.76557 1.1345 1.42245 0.453075 1.31569 0.748429 1.01583 0.785182 0.834752 1.5833 0.642879 0.66775 1.45114 0.880225 1.44894 0.614365 0.864883 0.996824 0.970801 1.35376 1.4273 2.3079 1.14512 1.52515 1.61095 0.304945 1.04773 1.09315 1.04103 0.998573 0.663715 0.774977 0.709516 1.1091 1.31951 0.929285 0.77064 0.705459 0.924553 1.12685 0.574668 2.06163 1.68978 0.802435 1.12303 1.23281 0.537398 0.811909 1.00426 0.877226 0.560823 0.585455 0.320306 0.621284 0.638247 1.20494 0.98126 0.743732 0.754087 0.820595 1.0414 0.704988 1.31807 0.998216 1.3173 1.26423 0.511454 0.724513 0.751661 0.860376 0.751661 0.946308 2.08638 1.59283 1.45464 0.707254 0.850757 1.23229 0.640087 0.324847 2.64203 1.58865 ]
@@@ Frame-accuracy per-class: [ 87.0212 82.1577 75.1092 72.9614 85.8537 64.4068 55.5932 87.1379 90.3226 86.7894 94.8571 84.959 90.0524 87.6404 76.5591 76.8 76.9231 75.8621 81.7869 90.3592 89.9489 81.2698 90.7363 78.0198 73.6077 90.989 75.493 83.9506 82.2622 88.993 68.9076 82.866 78.7004 84.3373 95.9009 90.301 95.8121 93.185 85.9729 62.9857 65.4545 86.4865 85.8131 63.3663 80.6584 90.7631 61.0905 81.2227 85.5264 92.8598 85.1105 56.239 92.2587 82.9268 88.3794 83.004 49.0566 80.4233 92.8702 66.1417 78.1784 88.5246 79.3774 94.2373 70.0315 76.7773 67.9353 60.8696 91.6129 86.6242 87.6018 90.0836 81.6777 85.9035 94.8352 80 85.6357 76.8212 90.5584 74.0741 77.1084 67.5325 90.0719 90.3108 95.4869 75.8725 90.0804 88.7417 76.3485 72.0848 83.1683 82.3529 75.8621 81.337 54.5455 80.6142 84.3554 89.8817 66.6667 89.8135 89.6142 60.7242 57.6687 85.3994 83.6158 87.1389 87.3096 82.0513 85.3583 76.1421 73.5931 56.8807 84.2105 75.2 26.087 81.1715 88.1598 91.7492 66.9683 76.7001 83.004 80.315 86.7052 50.3937 83.6879 86.4686 87.1473 56.9579 82.0339 73.3668 79.6117 67.1038 70.4871 87.4842 73.3591 83.8428 81.803 76.5869 78.2609 92.5125 74.2081 86.7532 90.2386 83.8253 61.745 70.073 67.2326 84.1889 91.5078 61.0526 87.9668 62.069 94.4882 89.5961 78.0781 90.0474 65.0519 78.1538 88.1964 74.1036 85.906 79.1946 15.3846 83.1354 79.0698 82.1053 82.5871 92.1844 77.4347 78.6885 81.9923 81.6901 78.0328 91.4798 91.8059 90.0726 83.2765 81.5466 69.1943 38.0952 92.6829 89.2754 76.9231 71.719 74.4186 79.2139 80 91.0859 85.0575 75.5043 85.9504 61.678 86.9076 72.5146 87.5847 97.094 68.2927 52.6316 89.8345 73.1518 86.6841 91.9447 83.274 96.7742 57.9439 61.5804 73.3758 73.3119 78.6441 73.7589 92.6829 75.6972 82.0793 67.2566 82.6277 87.3563 90.3093 81.0507 76.584 86.0367 80.1743 85.4106 56.0748 77.5414 83.2808 80 88.3721 89.8263 64.7815 71.6418 83.871 77.0764 69.2994 78.1538 86.0335 83.871 69.3467 87.4222 88.3249 77.9661 93.7063 86.4714 84.9485 89.1429 82.5532 60.6061 93.1646 82.9431 80.3987 88.6836 84.408 73.6292 52.2911 76.3407 88.6878 85.8054 73.5751 76.1905 71.1974 76.6284 71.73 91.7031 54.0541 88.0658 69.7674 82.5561 81.592 83.3552 86.2275 83.9779 91.8919 78.1145 86.7784 85.2321 82.5737 85.4054 90.5804 69.5187 83.2861 92.112 89.8785 89.9713 89.4198 77.3163 80.292 62.8099 87.2131 81.337 51.8519 77.8157 92.7059 73.2984 90.4899 84.1328 89.7822 30.303 77.3389 51.4286 72.6115 91.8455 77.1536 76.412 51.9084 54.6763 70.922 62.7087 69.969 90.9589 86.9779 75.7895 80.3653 87.8553 86.9955 72.4706 65.6716 71.3656 82.2086 71.1111 57.277 79.0451 90.2411 84.6527 79.564 88.0829 53.2915 83.1025 89.1211 74.0214 83.4043 78.1065 84.1121 92.562 72.5275 51.1848 82.3529 80.5009 66.6667 66.7697 76.1905 63.8037 74.6667 90.4215 89.7959 82.6196 88.5312 76.2527 70.7819 88.8087 65.3188 70.9867 74.3494 82.7907 68.0484 86.5979 70.5111 54.5455 77.551 85.8866 75.1491 79.1762 55.1724 89.709 67.1329 66.2824 80.203 79.8054 57.1429 76.3926 78.1145 86.0215 77.6471 91.7197 66.8354 75.0583 59.5122 88.4026 69.962 76.9716 83.4206 56 86.6359 60.733 88.4672 80.9668 80.678 76.494 80.9339 88.3117 89.8129 88.0083 63.2302 80.5369 73.4007 80 80.7947 82.8423 82.6347 76.9231 80.8126 67.5497 86.9693 81.4988 89.456 91.4573 60.251 87.1233 80.1619 85.2853 76.0291 75.5245 58.4527 55.814 87.4154 88.707 78.8204 81.6365 63.1579 68.8 88 77.0686 71.8266 68.2081 64.4951 84.8921 9.13706 87.3921 92.7152 46.1538 89.2308 82.495 44.4444 76.763 81.0496 88.6291 67.3317 83.4286 68.7225 91.9708 60.4444 76.6316 68.9459 85.5117 80.7018 56.3758 91.9481 73.3032 83.3898 84.9673 74.5098 80.1113 62.8429 78.8732 82.4427 96.7742 90.9091 60.2899 85.0153 88 87.3239 55.914 83.5681 64.5012 85.6031 61.8297 86.5801 77.3333 73.1707 70.8171 75.3623 73.6842 84.5815 86.9565 90.989 83.7209 85.7143 69.1415 81.1594 73.1278 85.2459 85.1128 88.8889 56.6845 83.0918 77.1723 85.8537 72.4051 80.2057 88.6076 59.7015 83.8323 86.0068 57.4394 77.3723 84.7458 82.3529 80 75.8842 71.3826 75.6032 58.427 78.7623 76.4331 73.8824 75.2768 73.6842 73.5967 81.8349 81.8824 83.9161 81.9802 78.8177 61.9718 71.618 82.3529 63.4146 62.8571 75.1515 77.8947 65.9498 72.7273 89.3617 89.2655 66.4107 78.7472 89.0566 73.0097 58.8832 74.9296 80 47.0588 77.3109 77.9798 83.4688 80.9224 86.7384 87.1022 54.1935 48.4472 83.6625 80 45.5285 85.0183 57.8462 75.2756 87.6791 77.9874 62.2222 74.7664 73.3453 73.5178 64.2336 77.8816 83.151 82.8708 75.9207 70.1538 50.6329 82.3529 78.6885 65.6064 76.9575 80.9249 93.5428 66.1224 71.4715 64.5161 72.8033 78.5276 81.0198 68.6792 66.6667 61.1872 80.4836 61.1465 86.7925 88 76.3485 40.678 83.4532 67.0659 71.8793 83.1025 74.8538 78.2123 69.0167 63.8298 81.6054 92.8839 88.8889 77.8443 84.1121 85.9927 61.7801 85.5305 97.1429 80.7882 84.5361 48.2759 73.6842 49.4382 61.5385 89.1455 81.5109 36.2989 75.188 80 78.0186 62.6003 83.9248 86.1423 65.2632 90.1304 55.814 85.1485 0 72.0113 73.0159 81.7518 66.9834 68.2353 66.6667 87.395 81.9277 88.4211 59.3939 72.4566 79.7203 79.4436 79.1837 73.2394 74.9436 76.3797 72.0379 82.6446 66.4623 61.3757 84.9612 72.0222 83.6364 77.6903 79.4979 88.2499 58.4615 85.3691 79.476 68.7831 81.6327 65.7944 66.6667 80.5031 88.189 79.9314 83.7209 73.0897 66.3317 91.0299 74.1866 62.7566 69.0391 70.5882 0 77.1574 64 89.5009 70.2804 80.5031 75.2089 75.8974 88.9353 75.1131 87.0871 57.6803 89.6 79.3522 62.069 52.459 62.8571 77.4468 75.6219 89.7616 84.041 80 83.7696 71.777 73.7864 63.3663 80.1512 81.2785 85.0069 23.5294 65.3358 75.8621 82.1516 83.4568 62.1359 86.7102 80.427 43.4783 75.3247 51.4286 70.3297 69.0778 71.3376 48.6486 64.7173 82.1218 77.2487 72.5367 59.726 66.9202 50.8671 83.5249 75.8621 77.7202 68.1934 87.1369 87.5421 82.9268 86.9565 80.4938 86.2385 89.7922 73.1988 82.494 71.6511 71.5064 61.4232 83.5893 92.3077 74.7253 75.0408 72.2689 50.5495 75.07 91.2281 54.2222 74.6356 71.848 82.9016 60.9865 81.8898 79.6926 68.942 85.0242 61.9355 81.2121 61.71 77.3449 73.9596 64.8101 67.9612 67.4157 45.7143 82.6446 79.1724 89.7959 55.0898 86.3039 80.1956 78.9189 78.327 85.5197 79.4702 83.0189 87.8049 88.977 85.9438 75.2643 58.3851 87.1795 85.2321 75.819 66.6667 68.9655 87.5121 79.8122 66.055 85.0242 75.9358 67.6056 80.236 62.7635 89.6552 74.3363 85.1817 77.8731 78.97 80.8933 61.8926 84.101 86.4865 78.0269 69.5035 84.0183 72.956 72 78.0269 52.8 61.4786 85.3598 84.7794 79.5812 79.1257 82.5175 81.3115 87.0159 86.743 67.3575 76.7624 61.3027 85.7749 89.6552 48.951 84.8875 79.3792 89.8129 80.2111 65.3659 56.9921 75.8893 45.1613 73.6842 85.7143 80.1113 30.4762 93.6709 11.7647 76.0994 85.9941 72.9849 81.3627 84.4944 90.7801 75.8621 84.6325 77.2009 68.1992 56.917 90.1099 66.8731 73.2673 68.8525 78.0059 79.0997 75.3813 77.3333 40.6504 81.4621 70.8661 79.8535 62.6263 70.2309 53.012 84.0391 73.8255 87.3239 86.221 86.4738 63.1579 80 79.5322 68.7719 79.5181 87.1143 74.1866 59.9119 77.9896 55.814 75.5187 81.3559 85.7143 68.9977 70.4403 60.6061 68.4932 43.4389 72.233 72.2581 78.481 50.3432 81.4815 32.1168 75.8621 69.2913 73.161 75.6303 83.3787 62.9482 58.4192 73.3138 64.1975 57.5406 52.0548 66.6667 77.3994 82.6168 86.533 91.2281 71.8232 65.8354 74.7475 56.2092 72.4324 72.4458 72.3327 84.9438 92.0354 74.6494 89.0756 68.3465 38.3142 86.4516 81.1881 73.3564 71.3137 87.7493 65.641 85.9316 80.0937 67.052 88.4354 80.2218 82.9493 64.3478 86.692 79.646 73.2394 66.0793 52.6316 86.4932 74.8466 81.7942 93.578 66.9683 76.8166 88.8583 67.4095 71.3704 76.129 64.4986 80.1498 73.107 84.9847 56.5875 78.0911 71.0414 71.3212 76.3853 60.8696 70.2362 81.3688 76.0512 75.2475 74.0472 78.2609 76.9231 70.1299 74.5387 84.9389 87.26 53.3007 64 74.2459 69.9029 79.8088 85.9857 81.5145 78.733 64.8649 74.3802 52.9801 81.7391 86.4198 61.0847 80.7207 76.2887 90.0741 86.1314 76.5172 70.6383 67.3267 72.6944 85.1675 54.2125 56.2674 79.3388 73.6842 62.6866 77.1208 83.2069 80.0983 68.9942 0 73.4908 76.9231 65.8281 73.2394 66.9604 77.8947 63.8522 79.5127 48.3965 78.5479 72.1763 90.1554 68.0702 64.0927 82.7907 71.4976 52.6946 71.8204 80.9384 59.4595 69.5652 82.1622 64.4764 88.1699 76.1578 55.144 63.9296 69.6467 82.2967 85.2234 76.6398 77.7385 51.8519 54.1872 76.5217 61.5385 85.9701 70.5882 83.926 54.5961 81.8414 82.0717 0 69.6538 79.5244 82.2086 52.8302 78.3362 69.7436 70.3863 70.1155 63.7571 74.4526 85.7143 77.44 71.5596 73.5178 78.5586 78.1609 85.4369 81.9113 82.6667 81.5884 83.0769 85.1582 80.8743 74.0741 62.7219 67.4699 85.1175 71.5447 71.7949 72.8745 80.9015 69.0832 76.4526 86.2651 63.3094 70.828 73.1288 94.4755 90.5491 92.3077 81.8281 71.8447 58.9147 79.3443 82.0702 62.3782 89.5377 83.6795 78.7879 94.382 68.8525 47.3373 72.8625 85.8773 82.0382 84.7385 72.3926 51.1416 72.2022 77.6699 60.5505 73.0964 82.1683 86.4865 71.9818 75.3927 68.9655 70.0809 71.7808 70.0965 44.0367 79.0835 68.2505 72.3618 66.4407 81.2121 83.7283 86.5248 81.3675 75.5467 77.7293 77.0889 67.6399 76.8473 71.2095 59.887 56.305 83.7584 85.7143 83.2323 88.2682 78.4741 60.4824 84.0125 58.3072 80.7651 75.0656 71.3805 73.9726 75.129 83.0565 56.1404 63.3663 65.6827 78.458 62.0525 73.1302 76.2332 71.1111 82.6156 77.4194 51.8519 89.043 66.2021 72.8033 66.8132 78.5542 48.5876 75.5245 78.1457 78.1116 84.8844 72.3658 69.7095 66.0194 64.5533 53.5117 74.9507 69.6104 71.4524 82.6446 83.2151 71.1409 80 65.1982 80.4598 65.4971 65.9341 73.0724 86.5801 81.3397 75.0515 77.8993 68.8172 66.6667 47.0588 77.8281 71.2401 83.6653 85.8316 77.0745 74.5295 75.8483 67.5229 77.6632 44.7257 77.6758 86.0056 80.6557 80.5195 89.9587 72.1311 69.8885 79.1946 75.8256 77.0563 68.9655 65.4206 77.4032 67.052 62.3782 72.0721 34.7826 74.3142 61.2691 66.4093 79.3846 73.4531 74.6177 83.1858 87.5912 80.2444 83.0671 82.4309 79.9082 84.4933 80.826 85.0095 67.3522 78.9357 54.2714 81.5672 72.4234 91.6844 82.0302 28.5714 85.5124 65.8385 67.3854 83.5735 0 82.0513 57.6271 64.1509 61.2048 48.7455 71.3178 80.5112 86.052 84.8485 43.1373 63.1179 79.1444 84.2478 71.2695 40.5594 82.1107 70.7692 59.8131 34.5679 64.2922 88.7967 82.4017 61.6487 69.459 76.8831 70.5648 70.9419 77.1784 50.1027 44.3936 55.914 50.1182 64.7303 72.3842 69.1824 90.8738 74.0554 66.6667 81.7011 51.0511 96.2963 77.8605 75.3327 86.1714 48.6188 75.0337 83.5443 72.2063 84.4037 72.6944 62.6263 75.0809 85.1675 41.0646 70.6827 66.0348 81.592 76.4141 92.5865 79.1762 67.1533 62.069 65.5738 69.0979 78.2435 76.5661 62.3267 63.1179 77.0318 76.9231 50.1901 83.2184 75.6757 80.5195 81.8565 77.5194 68.8995 84.2884 87.9211 68.4604 75.8788 66.4151 84.3537 82.56 76.0469 74.9125 62.069 71.5232 61.8705 32.1285 80.4261 62.7737 81.194 81.6 85.9002 59.9496 86.4048 52.8474 79.2157 60.8924 83.8951 78.0179 78.042 83.5955 64.1399 76.3006 87.39 48.8136 69.5652 74.6988 65.2807 44.7059 76.7184 71.7325 61.6822 63.1111 72.5424 73.251 66.6667 77.0764 74.2475 80.7396 77.5213 74.1483 80.597 74.6988 62.9213 73.442 72.3051 81.0631 41.6 74.4646 76.7922 87.6033 97.2973 63.3484 72.7794 71.6049 93.0292 76.1905 79.8337 83.8612 88.9279 70.5336 80.1898 74.2358 87.6768 72.0093 62.1723 63.9175 51.1416 72.9282 73.2673 48.6486 85.3567 77.4869 73.8462 65.2278 59.5041 60.8229 63.2727 82.6979 79.8371 85.5615 57.7428 80.4089 74.8936 76.5321 75.8621 36.0656 72.4832 74.5027 80.2947 34.3249 64.257 69.7406 79.4165 67.7966 70.2703 80.5461 43.9024 67.7116 73.8878 81.5592 62.1538 83.3508 72.4919 76.6249 49.5238 85.0429 80.067 79.8749 67.5325 77.0053 64.3137 57.1429 53.8012 61.6541 56.6038 84.1558 90.3704 78.1086 66.3616 69.2641 87.3239 65.697 80.6744 69.3603 80.3222 75.9644 52.3962 86.4686 82.0322 48.8889 78.0876 65.0888 83.7725 75.5556 70.5596 69.5353 58.651 60.3027 34.965 66.8896 56.2738 45.6621 93.7853 69.0096 70.7182 71.0425 73.525 82.7586 78.8204 81.9394 66.7516 63.2302 71.3826 81.5427 80.8461 72.8713 73.0667 83.2215 41.2698 49.4226 84.9558 76.0259 62.6632 85.6128 77.9661 69.7947 77.9456 84.3831 86.1492 91.7836 83.6625 82.3695 63.0872 70.5987 77.7293 80.776 79.2608 71.9068 80 63.0491 69.8901 59.7403 56.6038 85.347 82.4742 79.659 74.8092 79.5031 73.0594 35.4244 50.8287 59.3968 80.8511 74.9326 52.3364 84.9116 91.7115 32 50.9317 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 0.74175 (Xent), [AvgXent: 0.74175, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 79.0997% <<

