nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.0005 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter07_learnrate0.001_tr0.7417_cv1.7581 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter08 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975016
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
ali-to-post ark:- ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.81539, max 8.96107, mean 0.00568746, stddev 0.99447, skewness 0.129835, kurtosis 2.1535 ) 
[1] output of <AffineTransform> ( min -29.2588, max 24.9705, mean -3.40178, stddev 4.091, skewness 0.123091, kurtosis 1.25136 ) 
[2] output of <Sigmoid> ( min 1.96367e-13, max 1, mean 0.204694, stddev 0.314329, skewness 1.5045, kurtosis 0.795117 ) 
[3] output of <AffineTransform> ( min -29.7151, max 15.3739, mean -4.08185, stddev 2.76065, skewness -0.0530052, kurtosis 2.19369 ) 
[4] output of <Sigmoid> ( min 1.24426e-13, max 1, mean 0.0958982, stddev 0.191059, skewness 2.93954, kurtosis 8.57143 ) 
[5] output of <AffineTransform> ( min -14.1485, max 10.8908, mean -3.1006, stddev 1.94827, skewness 0.53882, kurtosis 2.14756 ) 
[6] output of <Sigmoid> ( min 7.16751e-07, max 0.999981, mean 0.113156, stddev 0.186257, skewness 2.75621, kurtosis 7.77298 ) 
[7] output of <AffineTransform> ( min -20.3167, max 17.1898, mean -2.76324, stddev 2.26439, skewness 0.522931, kurtosis 2.42963 ) 
[8] output of <Sigmoid> ( min 1.50165e-09, max 1, mean 0.156298, stddev 0.233298, skewness 2.0455, kurtosis 3.47034 ) 
[9] output of <AffineTransform> ( min -17.0542, max 17.4509, mean -2.8258, stddev 2.86269, skewness 1.30351, kurtosis 2.44807 ) 
[10] output of <Sigmoid> ( min 3.92154e-08, max 1, mean 0.17934, stddev 0.292717, skewness 1.75772, kurtosis 1.72124 ) 
[11] output of <AffineTransform> ( min -30.8097, max 25.2202, mean -3.66862, stddev 3.65092, skewness 0.963093, kurtosis 3.03067 ) 
[12] output of <Sigmoid> ( min 4.16387e-14, max 1, mean 0.151735, stddev 0.297455, skewness 2.01718, kurtosis 2.53081 ) 
[13] output of <AffineTransform> ( min -14.9765, max 24.9465, mean -0.0182896, stddev 3.66194, skewness 0.525678, kurtosis 0.930622 ) 
[14] output of <Softmax> ( min 6.73728e-16, max 0.999969, mean 0.000657831, stddev 0.0193223, skewness 40.2435, kurtosis 1749.13 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.02939, max 1.44084, mean -0.000142106, stddev 0.0558862, skewness -0.236094, kurtosis 31.6916 ) 
[1] diff-output of <AffineTransform> ( min -0.460522, max 0.316791, mean 4.40231e-06, stddev 0.010401, skewness -0.348825, kurtosis 87.9889 ) 
[2] diff-output of <Sigmoid> ( min -1.93845, max 1.90547, mean 0.000466236, stddev 0.0941324, skewness 0.116499, kurtosis 18.2035 ) 
[3] diff-output of <AffineTransform> ( min -0.427745, max 0.518213, mean -1.1822e-05, stddev 0.0117943, skewness 0.158943, kurtosis 116.008 ) 
[4] diff-output of <Sigmoid> ( min -2.39594, max 2.43199, mean 0.000402588, stddev 0.129079, skewness 0.0256452, kurtosis 16.5657 ) 
[5] diff-output of <AffineTransform> ( min -0.561765, max 0.365257, mean 1.11773e-05, stddev 0.0123267, skewness -0.234375, kurtosis 87.4088 ) 
[6] diff-output of <Sigmoid> ( min -2.32461, max 1.85901, mean 0.000394215, stddev 0.105257, skewness -0.0130962, kurtosis 17.1732 ) 
[7] diff-output of <AffineTransform> ( min -0.29622, max 0.279735, mean 2.29777e-05, stddev 0.00994056, skewness -0.130994, kurtosis 52.6613 ) 
[8] diff-output of <Sigmoid> ( min -1.44426, max 1.17393, mean 0.000239008, stddev 0.0729405, skewness -0.0098857, kurtosis 16.2105 ) 
[9] diff-output of <AffineTransform> ( min -0.262007, max 0.160624, mean 1.83129e-05, stddev 0.00728401, skewness -0.367467, kurtosis 60.2782 ) 
[10] diff-output of <Sigmoid> ( min -1.16432, max 0.873879, mean 0.000187002, stddev 0.05547, skewness -0.0837231, kurtosis 18.6598 ) 
[11] diff-output of <AffineTransform> ( min -0.272628, max 0.201391, mean 1.37821e-05, stddev 0.0080216, skewness -0.39627, kurtosis 68.2481 ) 
[12] diff-output of <Sigmoid> ( min -2.19712, max 1.20998, mean -0.00043543, stddev 0.084552, skewness -0.217352, kurtosis 10.9935 ) 
[13] diff-output of <AffineTransform> ( min -0.997449, max 0.93145, mean -4.16644e-09, stddev 0.0160098, skewness -26.0123, kurtosis 2212.24 ) 
[14] diff-output of <Softmax> ( min -0.997449, max 0.93145, mean -4.16644e-09, stddev 0.0160098, skewness -26.0123, kurtosis 2212.24 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.86561, max 1.68646, mean -0.00010353, stddev 0.163887, skewness -0.0240225, kurtosis 2.08139 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.567693, max 0.518537, mean 0.001127, stddev 0.153461, skewness -0.126851, kurtosis 0.422034 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -1.06938, max 0.883484, mean -0.000618778, stddev 0.0704735, skewness -0.0459928, kurtosis 6.62864 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.957787, max 0.908662, mean -0.00302642, stddev 0.180169, skewness -0.0487803, kurtosis 2.31433 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.852538, max 0.675234, mean 0.000300324, stddev 0.0411949, skewness -0.0733433, kurtosis 13.0674 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.14857, max 0.640297, mean 0.00286135, stddev 0.181405, skewness -0.122531, kurtosis 2.52188 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.443494, max 0.593964, mean 0.000702704, stddev 0.0338356, skewness 0.0397439, kurtosis 9.19565 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.641298, max 0.559635, mean 0.0058823, stddev 0.14811, skewness -0.032923, kurtosis 1.83903 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.425696, max 0.350637, mean 0.000650856, stddev 0.0319214, skewness 0.0421856, kurtosis 6.99418 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.550579, max 0.408263, mean 0.00468809, stddev 0.109631, skewness 0.0713925, kurtosis 2.03048 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.678996, max 0.384945, mean 0.000727782, stddev 0.0436177, skewness -0.0398338, kurtosis 7.73606 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.664993, max 0.489802, mean 0.0035282, stddev 0.126374, skewness -0.0884981, kurtosis 2.70063 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.53391, max 2.2742, mean -3.09863e-08, stddev 0.0869899, skewness -4.34987, kurtosis 76.3302 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.80582, max 1.73121, mean -8.47013e-09, stddev 0.258373, skewness -1.60199, kurtosis 11.4299 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 342784 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -6.78548, max 7.66488, mean 0.00618661, stddev 0.998336, skewness 0.126755, kurtosis 2.01683 ) 
[1] output of <AffineTransform> ( min -29.1967, max 24.7583, mean -3.37449, stddev 4.12702, skewness 0.143038, kurtosis 1.22172 ) 
[2] output of <Sigmoid> ( min 2.08936e-13, max 1, mean 0.207924, stddev 0.317426, skewness 1.48011, kurtosis 0.706996 ) 
[3] output of <AffineTransform> ( min -31.4266, max 18.1344, mean -4.08598, stddev 2.79575, skewness -0.0550574, kurtosis 2.19608 ) 
[4] output of <Sigmoid> ( min 2.24709e-14, max 1, mean 0.0975559, stddev 0.193746, skewness 2.89949, kurtosis 8.27245 ) 
[5] output of <AffineTransform> ( min -13.8186, max 11.2472, mean -3.09763, stddev 1.97008, skewness 0.534378, kurtosis 2.1989 ) 
[6] output of <Sigmoid> ( min 9.96913e-07, max 0.999987, mean 0.114435, stddev 0.188005, skewness 2.7281, kurtosis 7.57306 ) 
[7] output of <AffineTransform> ( min -21.1641, max 16.9588, mean -2.7528, stddev 2.28628, skewness 0.523975, kurtosis 2.43657 ) 
[8] output of <Sigmoid> ( min 6.43476e-10, max 1, mean 0.158182, stddev 0.235373, skewness 2.0239, kurtosis 3.35885 ) 
[9] output of <AffineTransform> ( min -16.5826, max 17.4677, mean -2.81356, stddev 2.885, skewness 1.31103, kurtosis 2.47608 ) 
[10] output of <Sigmoid> ( min 6.28466e-08, max 1, mean 0.181198, stddev 0.294744, skewness 1.73629, kurtosis 1.63177 ) 
[11] output of <AffineTransform> ( min -27.7414, max 22.2143, mean -3.66832, stddev 3.66502, skewness 0.973416, kurtosis 2.96603 ) 
[12] output of <Sigmoid> ( min 8.95529e-13, max 1, mean 0.152867, stddev 0.298994, skewness 2.00118, kurtosis 2.45828 ) 
[13] output of <AffineTransform> ( min -15.8383, max 23.9474, mean -0.0182952, stddev 3.67533, skewness 0.547417, kurtosis 0.989776 ) 
[14] output of <Softmax> ( min 2.10395e-15, max 0.998597, mean 0.000657834, stddev 0.019406, skewness 39.6371, kurtosis 1697.81 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.49987, max 1.52336, mean -0.000240529, stddev 0.0447328, skewness 0.102185, kurtosis 46.4898 ) 
[1] diff-output of <AffineTransform> ( min -0.218674, max 0.376975, mean 2.02381e-05, stddev 0.00840206, skewness 0.742264, kurtosis 83.1829 ) 
[2] diff-output of <Sigmoid> ( min -1.43129, max 1.70601, mean -0.00018805, stddev 0.0763477, skewness 0.0698499, kurtosis 17.6559 ) 
[3] diff-output of <AffineTransform> ( min -0.248237, max 0.381155, mean 2.08482e-05, stddev 0.00946171, skewness 0.501305, kurtosis 94.7563 ) 
[4] diff-output of <Sigmoid> ( min -1.39729, max 1.81366, mean -4.28982e-05, stddev 0.102142, skewness 0.00518338, kurtosis 12.3116 ) 
[5] diff-output of <AffineTransform> ( min -0.288756, max 0.303441, mean 2.29427e-05, stddev 0.00982082, skewness 0.103237, kurtosis 58.4877 ) 
[6] diff-output of <Sigmoid> ( min -1.20955, max 1.65407, mean 8.53834e-08, stddev 0.0853128, skewness 0.0441278, kurtosis 13.5572 ) 
[7] diff-output of <AffineTransform> ( min -0.232402, max 0.263677, mean 2.11039e-05, stddev 0.00809167, skewness 0.255393, kurtosis 49.7645 ) 
[8] diff-output of <Sigmoid> ( min -0.97634, max 1.05852, mean 0.000208319, stddev 0.0600561, skewness 0.0196335, kurtosis 14.9856 ) 
[9] diff-output of <AffineTransform> ( min -0.154263, max 0.14078, mean 1.23635e-05, stddev 0.00603045, skewness -0.279997, kurtosis 54.6012 ) 
[10] diff-output of <Sigmoid> ( min -0.916553, max 0.853692, mean 5.81127e-05, stddev 0.0463854, skewness -0.112929, kurtosis 19.693 ) 
[11] diff-output of <AffineTransform> ( min -0.239285, max 0.207902, mean 1.7479e-06, stddev 0.00684537, skewness -0.38796, kurtosis 83.5548 ) 
[12] diff-output of <Sigmoid> ( min -2.63025, max 2.2502, mean 0.000219526, stddev 0.0736261, skewness -0.24904, kurtosis 24.5437 ) 
[13] diff-output of <AffineTransform> ( min -0.999947, max 0.963829, mean -6.34157e-09, stddev 0.0136578, skewness -25.2798, kurtosis 2409.91 ) 
[14] diff-output of <Softmax> ( min -0.999947, max 0.963829, mean -6.34157e-09, stddev 0.0136578, skewness -25.2798, kurtosis 2409.91 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.63964, max 1.88977, mean -0.000871948, stddev 0.130112, skewness 0.00644606, kurtosis 2.50504 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.605079, max 0.644111, mean 0.00518095, stddev 0.148434, skewness 0.0246193, kurtosis 1.02875 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.563418, max 0.728457, mean 0.0012803, stddev 0.0587489, skewness 0.103306, kurtosis 5.81878 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.796524, max 0.845653, mean 0.00533716, stddev 0.165914, skewness 0.14462, kurtosis 2.57979 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.643914, max 0.631894, mean 0.000612471, stddev 0.0357437, skewness 0.0834719, kurtosis 12.3234 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.03054, max 0.793201, mean 0.00587332, stddev 0.181831, skewness 0.0200743, kurtosis 3.15146 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.437784, max 0.400923, mean 0.000658248, stddev 0.029928, skewness 0.00900848, kurtosis 9.04922 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.654076, max 0.621385, mean 0.00540259, stddev 0.144853, skewness 0.0175247, kurtosis 1.90391 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.425838, max 0.372563, mean 0.00047071, stddev 0.0285641, skewness -0.0812718, kurtosis 8.35802 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.551356, max 0.550003, mean 0.00316506, stddev 0.105484, skewness -0.0488882, kurtosis 3.67497 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.480738, max 0.488988, mean 0.000147669, stddev 0.0393784, skewness -0.0942206, kurtosis 9.5291 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.567853, max 0.563329, mean 0.000447449, stddev 0.119142, skewness -0.107098, kurtosis 3.54883 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.36131, max 2.93474, mean -4.74142e-08, stddev 0.0768127, skewness -2.71347, kurtosis 120.487 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.07102, max 1.97987, mean -7.84272e-09, stddev 0.228895, skewness -1.03612, kurtosis 20.1651 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0783457 min, processing 72921.2 frames per sec; i/o time 5.21945%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14111 120 114 116 102 29 147 431 139 624 262 548 95 133 232 62 162 188 145 264 293 157 210 252 206 227 177 121 194 213 59 160 138 41 524 149 489 359 331 244 27 18 144 252 121 124 944 114 5399 17569 1561 284 471 20 632 126 26 94 273 190 263 30 128 442 158 105 525 11 77 78 552 418 679 528 1016 172 727 226 492 148 41 38 347 273 210 329 186 75 361 141 50 229 14 179 16 260 399 380 208 348 168 179 81 181 88 1263 98 58 160 98 115 54 66 62 11 119 350 151 110 448 126 190 86 63 70 151 159 154 147 99 51 457 174 395 129 114 299 480 34 300 110 192 230 423 223 68 294 243 288 142 120 14 444 408 166 105 144 162 529 125 74 223 6 210 64 142 100 249 210 274 130 35 152 111 628 206 146 284 105 10 20 172 279 270 107 661 122 308 130 173 423 220 622 85 221 292 20 66 211 128 191 614 140 15 160 183 392 155 147 70 20 125 365 508 342 43 242 266 181 354 229 517 160 211 158 92 236 201 194 33 15 451 392 162 89 139 99 401 98 88 71 358 242 87 117 16 197 149 150 216 426 191 185 158 110 313 96 94 154 130 118 114 166 121 21 289 100 381 83 90 18 148 268 118 186 92 525 93 176 196 123 174 146 156 68 60 152 179 13 146 212 95 173 135 298 16 240 157 78 116 133 150 196 69 70 269 161 182 203 142 109 580 111 212 100 113 81 22 106 188 435 309 183 96 159 180 813 140 117 84 160 60 136 105 93 279 49 323 115 81 187 130 220 198 248 229 121 138 321 339 134 107 289 145 381 16 122 414 251 218 14 704 214 173 295 205 31 188 148 232 127 78 197 214 102 228 131 158 286 12 325 95 342 165 147 125 128 38 240 479 145 74 148 97 75 288 83 71 221 75 341 213 744 497 119 182 123 166 206 71 174 21 369 305 186 525 28 62 137 211 161 86 153 69 98 289 226 97 32 248 67 432 171 470 200 262 113 68 112 237 175 493 28 74 192 110 147 76 178 359 200 35 65 15 148 172 163 12 106 46 106 215 128 158 115 37 61 128 34 180 113 80 227 21 80 215 103 113 91 332 175 93 103 339 102 197 194 276 33 250 439 144 479 88 246 22 155 155 186 44 355 235 212 135 123 240 272 212 71 252 101 106 188 76 61 17 82 47 139 27 164 88 260 223 132 257 98 177 282 25 59 247 184 238 139 298 77 80 278 302 61 410 162 317 174 79 22 160 279 126 205 160 228 522 176 162 39 25 152 251 223 86 286 122 166 15 119 81 176 132 85 109 289 78 185 137 361 29 347 417 364 180 85 89 269 23 149 133 121 83 160 410 95 466 17 101 145 14 66 44 19 216 251 140 66 52 161 311 239 133 142 268 107 151 0 355 94 68 210 42 10 178 124 47 82 201 71 323 122 177 221 226 105 181 815 94 322 180 82 190 119 1408 32 372 114 94 24 267 55 79 63 291 21 150 99 752 230 170 140 110 8 98 137 290 267 238 179 97 239 110 166 159 62 123 14 30 87 117 100 356 341 52 95 143 51 151 264 109 363 8 275 14 204 202 154 229 140 80 115 52 45 276 235 129 256 254 94 238 182 131 86 130 130 96 196 120 148 225 34 202 54 553 173 208 160 275 133 618 6 45 306 59 45 178 28 112 171 289 96 111 63 455 146 103 77 247 134 346 420 197 51 400 17 181 362 122 83 799 204 92 131 1688 75 185 61 630 124 236 80 58 118 320 115 14 516 106 54 103 280 177 169 213 101 56 536 291 116 201 195 336 18 111 70 109 79 37 111 187 128 201 1008 95 457 71 152 219 305 96 191 130 235 14 71 155 225 240 189 307 189 632 15 275 157 359 52 39 8 261 510 564 249 222 352 43 224 221 130 126 45 161 151 30 170 155 229 37 61 191 190 136 49 411 41 153 223 35 366 639 104 127 85 142 456 275 230 113 288 21 120 29 17 214 79 214 255 110 257 77 118 218 13 68 101 63 251 59 183 125 145 170 202 215 109 241 161 267 174 256 90 200 49 76 92 161 276 222 56 463 654 317 130 77 151 144 186 175 292 131 213 86 220 270 108 57 131 395 106 113 85 403 81 189 54 110 144 363 179 368 232 184 400 191 489 231 230 350 465 586 149 317 131 273 50 275 11 97 38 135 368 286 204 137 215 257 418 210 224 110 55 60 75 172 202 525 277 145 337 68 189 117 50 276 313 136 179 423 28 167 194 461 203 601 9 190 227 238 177 113 47 189 451 171 151 181 96 142 129 322 103 83 200 170 55 11 92 243 494 291 121 170 693 104 145 434 141 13 101 57 58 167 42 351 179 195 376 0 245 378 244 79 288 97 116 1082 263 205 374 312 163 126 277 43 154 146 187 138 227 205 91 202 84 124 191 184 214 123 421 234 163 207 69 392 407 805 555 331 459 257 193 152 270 256 205 168 82 44 30 84 134 350 392 468 81 109 138 51 163 98 350 55 219 95 217 185 182 155 54 676 231 99 147 82 316 70 292 251 114 185 205 101 293 88 170 372 143 247 89 183 269 159 159 470 190 148 36 484 150 85 151 135 220 209 180 557 157 313 294 94 360 143 119 227 207 88 71 75 349 843 251 120 51 173 149 253 192 299 302 211 74 152 113 43 85 136 421 115 104 242 228 232 13 59 331 189 125 243 355 398 250 272 145 118 163 1961 152 115 363 91 134 74 378 346 72 160 400 86 256 55 11 200 228 129 162 250 490 56 205 245 156 452 435 409 169 263 194 225 99 561 179 234 364 164 141 80 185 173 8 19 29 132 207 139 64 156 211 16 76 131 93 282 224 71 388 32 160 40 547 120 241 139 286 192 752 249 120 243 218 46 211 120 291 79 257 198 13 1281 166 13 738 488 437 90 370 118 174 163 276 49 154 104 131 124 316 100 468 303 218 68 14 30 260 250 215 829 131 141 45 131 217 166 115 118 64 313 270 608 334 412 132 73 312 298 428 246 226 69 124 375 68 167 62 230 198 165 219 127 190 133 948 357 222 171 259 511 147 80 207 240 212 225 164 53 112 147 121 25 150 149 324 411 249 100 41 133 521 301 150 62 303 411 60 18 110 174 40 394 52 240 331 284 215 421 114 247 430 133 48 109 90 50 18 1198 95 97 208 60 279 137 170 245 280 190 293 117 334 217 91 223 276 271 218 124 173 308 265 129 146 20 159 258 333 162 477 154 438 52 1106 298 479 38 841 127 66 85 66 26 192 67 285 218 115 177 412 385 148 434 168 156 454 403 22 125 84 360 157 205 290 170 429 71 149 131 109 88 156 90 129 330 14 559 412 392 145 155 181 425 252 187 74 157 216 56 231 191 281 147 170 165 579 328 249 278 354 74 559 114 283 243 343 212 193 227 115 79 194 48 410 65 80 109 135 90 215 117 185 53 480 464 62 80 ]
@@@ Loss per-class: [ 0.317428 0.727594 0.761736 0.871998 0.570989 0.884075 1.60484 0.515169 0.457743 0.45491 0.233458 0.485141 0.506077 0.476476 0.841412 0.71474 0.664717 0.813283 0.605483 0.44874 0.376753 0.641892 0.319328 0.744134 0.910392 0.3408 0.752124 0.489789 0.65674 0.372715 0.842122 0.780079 0.859676 0.740252 0.197171 0.400124 0.176682 0.257488 0.485354 1.22968 1.19196 1.01864 0.359613 0.97784 0.840034 0.358031 0.784379 0.688628 0.431974 0.221517 0.442948 1.26385 0.339213 0.74379 0.434704 0.578398 1.23595 0.712169 0.273139 1.13396 0.677363 0.519896 0.606778 0.255756 1.09766 0.770128 1.02427 0.950964 0.46553 0.634396 0.522622 0.350497 0.572807 0.512787 0.194347 0.581062 0.556907 0.829665 0.295102 0.905605 0.841456 1.00823 0.326418 0.434205 0.346362 0.81268 0.403128 0.361729 0.736934 0.987232 0.571175 0.547167 1.14667 0.541758 1.26492 0.650096 0.673413 0.432628 1.03224 0.368443 0.423631 1.32588 1.19311 0.547559 0.627628 0.426155 0.56119 0.860492 0.548942 0.911163 0.785223 1.24382 0.598955 0.736647 1.76885 0.703847 0.428224 0.377722 1.22016 0.88827 0.577559 0.639436 0.582582 1.41343 0.679911 0.629446 0.589728 1.15481 0.707514 1.16104 0.872068 1.03474 0.90763 0.512416 0.782934 0.478894 0.703459 0.837264 0.785615 0.345469 1.04929 0.518763 0.391473 0.569122 1.19327 0.801239 1.21955 0.578517 0.366446 1.25991 0.493954 1.16917 0.239055 0.454479 0.707353 0.498301 1.22796 0.855168 0.457971 0.889001 0.632946 0.836239 1.92444 0.672125 0.618102 0.580365 0.805137 0.331042 0.89506 0.603069 0.67534 0.902797 0.681254 0.426341 0.33422 0.34798 0.624207 0.608777 1.10923 1.76875 0.548992 0.517892 0.77738 0.93388 0.877527 0.720358 0.713697 0.395424 0.464211 0.899999 0.488509 1.22906 0.373638 0.750294 0.455821 0.204665 1.18798 1.10075 0.372588 0.786235 0.496324 0.338501 0.728958 0.638957 1.48465 1.29767 0.889918 0.988997 0.758753 0.893354 0.355594 1.12848 0.683997 1.21058 0.544978 0.443958 0.333373 0.681121 0.835003 0.447752 0.628121 0.477672 1.49772 0.933484 0.752008 0.532951 0.493259 0.522792 1.02881 0.988176 0.889152 0.812599 0.969554 0.659124 0.862893 0.512787 1.14059 0.51321 0.547915 0.781413 0.324331 0.426499 0.566303 0.393665 0.702392 1.08748 0.305578 0.563931 0.663593 0.499279 0.506861 0.674251 1.32819 0.735396 0.510508 0.549423 0.853494 0.910769 1.02862 0.751537 0.840018 0.329862 1.22821 0.3952 1.11308 0.571519 0.749306 0.550507 0.67418 0.705633 0.469827 0.797209 0.472985 0.526463 0.634652 0.540912 0.395188 0.805323 0.512081 0.300583 0.50351 0.480265 0.428213 1.02118 0.759447 1.84024 0.453828 0.556478 1.14905 0.80632 0.280889 0.913268 0.435644 0.666983 0.377442 2.21427 0.708097 1.56181 0.902575 0.446703 0.913779 0.864847 1.36063 1.3105 1.12283 1.0836 0.96041 0.432782 0.458706 0.642668 0.676208 0.445887 0.550625 0.98332 1.13418 0.909919 0.663159 0.878504 1.2252 0.851603 0.363266 0.436305 0.640697 0.511699 1.45421 0.740044 0.421224 0.863733 0.451331 1.02424 0.55767 0.431778 0.756564 1.53829 0.651672 0.6998 1.00661 1.07774 0.713754 1.12193 0.865928 0.424935 0.37955 0.562875 0.456055 0.809285 1.02355 0.384372 1.097 0.905367 0.861619 0.722531 1.25376 0.51679 1.09217 1.40719 0.855077 0.419161 0.835419 0.61051 1.75144 0.357876 1.17028 1.05263 0.758451 0.679977 1.43169 0.880481 0.692939 0.526234 0.86152 0.440384 1.19452 0.789352 1.34087 0.489876 0.810285 0.730701 0.551357 1.65768 0.536469 1.37692 0.456523 0.619511 0.680057 1.06041 0.678647 0.564439 0.387788 0.427017 1.17314 0.617421 0.805341 0.731617 0.758327 0.617258 0.493523 0.783475 0.708519 1.09385 0.451205 0.711392 0.440293 0.286499 1.51498 0.497301 0.527479 0.612166 0.803282 0.813428 1.40709 1.3659 0.500598 0.424139 0.832319 0.61844 1.42635 1.07957 0.382559 0.815743 0.785664 0.863648 1.11868 0.687864 3.16649 0.403942 0.361066 1.99856 0.697486 0.556667 1.79628 0.866402 0.716277 0.362368 1.04453 0.691605 1.23151 0.382448 1.15212 0.798954 0.942515 0.58736 1.06679 1.29841 0.331358 0.864056 0.580899 0.506105 0.760314 0.646039 1.22966 0.746738 0.564614 0.59497 0.403529 1.17706 0.501279 0.620488 0.510926 1.40338 0.537751 1.0108 0.486026 1.24586 0.625055 0.727037 0.762141 0.864262 0.822456 0.909948 0.54874 0.554348 0.413503 0.781007 0.526228 0.971422 0.809696 0.869613 0.43861 0.544187 0.426305 1.30238 0.827342 0.731711 0.549884 0.915861 0.649486 0.462135 1.15979 0.685621 0.536624 1.21995 0.734139 0.513407 0.617737 0.78785 0.884427 1.0457 0.915086 1.21472 0.744981 0.631421 0.756138 1.06469 1.05725 0.997895 0.70973 0.621598 0.58673 0.610615 0.70385 1.45812 0.855634 0.591031 1.12905 1.4867 0.811302 0.785698 1.14522 0.90715 0.347909 0.487862 1.21337 0.771592 0.419147 1.00148 1.20702 0.982428 0.738252 2.01335 0.717273 0.771992 0.618791 0.685547 0.553527 0.422161 1.2752 1.81377 0.597892 0.678668 1.78059 0.531521 1.50279 0.831824 0.523938 0.751137 1.04205 0.882779 0.98301 0.824689 1.29025 0.743849 0.542866 0.615979 0.802771 0.969017 1.86171 1.06175 0.650428 1.09677 0.854293 0.668188 0.266326 1.05722 0.885452 0.940925 1.19443 0.67666 0.642947 0.958667 1.39146 1.04805 0.787228 1.13493 0.571346 0.416238 0.66442 1.72511 0.615163 0.828017 0.936272 0.622547 0.866416 0.810523 1.08143 1.27062 0.62491 0.324217 0.429058 0.817741 0.740321 0.467338 1.10131 0.55231 0.267535 0.639609 0.576728 1.52326 0.85454 2.12161 1.2382 0.349805 0.664571 2.13927 0.940656 0.716296 0.605297 1.17195 0.602506 0.366026 1.07763 0.357707 1.41594 0.552107 0 0.777728 0.925895 0.631561 1.25533 0.993214 0.858933 0.487773 0.793468 0.527478 1.40684 0.967829 0.563542 0.683677 0.747949 0.788795 0.893809 0.926301 0.808875 0.684066 0.900991 1.02434 0.498222 0.895675 0.609709 0.796468 0.797129 0.394294 0.995256 0.541947 0.776279 1.15272 0.785135 0.95576 1.01918 0.796801 0.406651 0.781661 0.93775 0.870241 1.2417 0.328004 0.715673 1.40654 0.951888 0.907685 3.03172 0.815183 1.30362 0.50696 1.02668 0.68287 0.876855 0.79646 0.353688 0.7252 0.447173 1.55882 0.570256 0.674469 0.982829 1.78524 1.22732 0.705385 0.915309 0.448366 0.516943 0.724483 0.6973 0.847801 0.842518 1.20216 0.611955 0.565802 0.614087 1.64236 1.04967 0.966182 0.555983 0.636073 1.19606 0.501408 0.692957 1.75752 0.747079 1.11917 0.899336 1.10594 0.975624 2.1477 1.33715 0.636789 0.821358 0.934561 1.43889 1.04318 1.77961 0.495484 1.03837 0.84774 1.18314 0.454951 0.474042 0.65532 0.713857 0.663087 0.545904 0.370634 0.848997 0.643376 0.891493 1.01196 1.14859 0.566606 1.08811 1.2007 0.903046 0.712365 1.64306 0.858333 0.683567 1.47077 0.907323 0.848203 0.554237 1.09354 0.89029 0.757121 1.15437 0.621725 1.03967 0.750324 1.21326 0.68257 0.835793 1.17074 1.28128 1.01768 1.66434 0.741308 0.654196 0.559935 1.22015 0.484717 0.758405 0.600385 0.900162 0.493859 0.752092 0.569683 0.484799 0.40937 0.588626 0.783169 1.04562 0.667286 0.537932 0.724904 0.977143 0.890657 0.459215 0.663115 1.13288 0.538563 0.952163 1.1537 0.679709 1.2796 0.547913 0.869184 0.491128 0.795058 0.893236 0.725189 1.25005 0.675709 0.755745 0.812038 0.857803 0.534117 0.983771 0.941826 0.730751 1.19799 1.26605 0.623878 0.516672 0.612858 0.813248 0.675215 0.636695 0.440907 0.587199 1.00845 0.969488 1.07653 0.56188 0.513313 1.57172 0.583015 0.715182 0.397751 0.544438 1.08769 1.4076 0.840918 1.55231 0.966882 0.541547 0.809804 1.96323 0.377902 2.09318 0.77336 0.536857 0.937794 0.726733 0.705715 0.361814 1.20009 0.509496 0.863092 1.09663 1.62002 0.645417 1.20262 0.942336 0.991607 0.694234 0.805074 1.01989 0.812393 2.57074 0.636982 0.873401 0.674214 1.13012 0.949928 1.18532 0.506873 0.785342 0.389435 0.448464 0.390116 1.36343 0.711917 0.616274 0.938108 0.852827 0.462248 0.952034 1.62651 0.717971 1.56496 0.916569 0.941094 0.945951 0.952843 0.90578 1.30573 1.03729 1.89141 0.968836 0.889746 0.784228 1.45717 0.716223 2.03236 1.00578 1.07148 0.900285 1.2437 0.645086 1.24045 1.76147 0.87845 1.22255 1.48367 1.68408 1.10834 0.950511 0.620283 0.388105 0.440521 1.00038 1.09847 0.932308 1.24717 0.707399 0.969505 0.814354 0.55545 0.440554 0.886146 0.328695 1.34054 1.76182 0.44555 0.708532 0.934051 0.934616 0.398207 1.12596 0.458867 0.680195 0.980062 0.438127 0.770465 0.5496 1.18762 0.536649 0.793062 0.909643 1.18295 1.20664 0.567691 0.679461 0.460176 0.238466 1.07231 0.852978 0.335661 0.972563 0.86327 0.886846 1.20511 0.648572 0.92974 0.540405 1.22024 0.726479 0.954222 0.960443 0.815795 1.3711 1.29767 0.566548 0.684979 0.883554 0.845675 0.939625 0.855717 1.05704 0.728939 0.582604 0.551223 1.29308 1.06186 0.920009 1.03798 0.763397 0.533145 0.740828 0.752509 1.32428 0.851278 1.65034 0.701799 0.577707 1.17453 0.728538 0.805669 0.293005 0.621239 0.785733 0.94667 0.876292 0.861628 0.590655 1.78485 1.57219 0.788905 1.05137 1.25921 0.80258 0.585094 0.646695 1.16166 3.19401 0.890831 0.799386 1.16376 1.06506 1.08918 1.27789 1.21203 0.823661 1.69582 0.66111 0.814751 0.678194 1.08027 0.999731 0.581392 0.940202 1.48491 0.660324 0.653976 1.19979 1.02447 0.617346 1.1315 0.339786 0.878392 1.4592 1.36753 0.948648 0.769602 0.61005 0.76207 0.866138 1.50888 1.50475 0.681994 1.14403 0.644461 1.24172 0.529132 1.37729 0.671323 0.653912 0 1.13472 0.62511 0.637181 1.42969 0.702291 0.972111 0.964378 0.826141 1.02884 0.839121 0.475964 0.713008 0.961 0.97308 0.742046 0.832534 0.627763 0.833858 0.785771 0.694259 0.63593 0.681899 0.73731 0.742053 1.16974 1.08684 0.629013 1.04125 1.01815 0.757942 0.617615 0.856601 0.844216 0.647042 0.885762 0.984085 1.00859 0.198587 0.295712 0.372877 0.760374 0.967729 1.18771 0.634234 0.646961 1.23173 0.40719 0.547316 0.621196 0.472888 0.930662 1.98604 1.104 0.621089 0.642959 0.474701 1.15525 1.25721 0.9742 0.92094 1.28613 0.869661 0.548511 0.661611 0.994606 1.0194 0.926692 0.89223 1.04288 1.04323 1.98401 0.753444 0.930098 1.00021 1.17626 0.65092 0.484349 0.628665 0.822576 0.724437 1.02896 0.767812 0.928136 0.807528 0.820354 1.40267 1.4837 0.613172 0.633762 0.732823 0.475427 0.773442 1.36606 0.636274 1.27505 0.642456 1.06486 1.03098 1.3899 0.856595 0.622797 1.39837 1.27844 1.09997 0.758234 1.33445 0.735898 0.691146 0.977424 0.648511 0.818289 1.78159 0.519533 1.0167 0.976954 1.31409 0.718674 1.36516 0.791096 0.742931 0.680666 0.495608 0.90579 1.04853 1.14259 1.55484 1.51621 0.85846 1.12056 0.964173 0.597195 0.535809 1.04394 0.767808 1.04694 0.617203 0.861719 1.09941 0.884035 0.538349 0.817782 0.944571 0.737834 0.952582 1.04721 1.92268 0.659076 0.982583 0.562849 0.497036 0.759221 0.936351 1.02445 1.06565 0.825092 1.70372 0.900447 0.472825 0.689027 0.711057 0.42785 0.977832 1.02048 0.881041 0.746847 0.832523 1.15677 1.26634 0.781039 1.1087 1.28523 1.28906 2.00178 1.03557 1.34093 1.16913 0.740913 0.826302 0.855435 0.674851 0.669262 0.756905 0.716786 0.576598 0.577022 0.61353 0.773802 0.585106 1.06909 0.805045 1.32082 0.601718 0.942135 0.285663 0.614844 2.55443 0.573143 1.29137 0.964771 0.556777 3.08448 0.685674 1.32789 1.06189 1.29183 1.87167 0.889218 0.788825 0.608818 0.73363 1.75689 1.267 0.726207 0.51998 1.01546 2.03486 0.64379 1.07877 1.41922 2.18283 1.06749 0.330002 0.594683 1.34943 1.02173 0.735978 0.857878 1.0386 0.696175 1.61856 1.82499 1.19321 1.53367 1.13311 0.806102 0.958341 0.324493 0.983818 0.850277 0.607955 1.28706 0.772825 0.700826 0.737554 0.542021 1.48143 0.825454 0.696586 0.990519 0.64682 0.815218 1.15266 0.835608 0.552593 2.30757 0.933647 1.07032 0.643035 0.865584 0.323252 0.741685 0.990546 1.37528 0.904099 1.05016 0.799259 0.910893 1.06703 1.21555 0.705409 0.736063 1.58932 0.609785 0.837713 0.624544 0.722846 0.769329 1.16513 0.461712 0.427797 0.805223 0.823366 1.20459 0.735014 0.655508 0.76661 0.796926 1.20237 1.1688 1.49555 2.41222 0.69979 1.09224 0.714956 0.932777 0.647494 1.35894 0.467229 1.54042 0.770865 1.49747 0.529697 0.779644 0.762088 0.550918 1.04874 0.692588 0.4507 1.53067 1.18524 1.10005 1.05988 1.62289 0.813294 1.03391 1.30403 1.47562 0.768501 1.06117 1.25772 0.813888 0.788499 0.750765 0.811902 0.770376 0.747048 0.996659 1.1002 1.04706 1.04249 0.815212 2.04941 0.992943 0.715129 0.592906 0.44547 1.2975 1.09746 0.810024 0.339854 0.856779 0.662411 0.601061 0.546973 0.973832 0.708881 0.97597 0.452133 0.889886 1.32785 1.68957 1.59687 1.02471 1.07196 1.06925 0.504045 0.673372 0.662017 1.43457 1.45011 1.31502 1.47523 0.840731 0.746924 0.52581 1.42012 0.765387 0.870519 0.946089 0.787131 1.92578 0.848352 0.811867 0.833944 2.18852 1.26709 1.1274 0.786086 1.11409 1.02059 0.761801 1.7885 1.18034 0.967882 0.675044 1.17607 0.790461 0.824108 0.822716 1.28392 0.480667 0.781228 0.779798 1.12114 0.809477 1.31051 1.45774 1.53287 1.3867 1.44197 0.66467 0.460244 0.745582 1.10714 1.40776 0.45102 1.27541 0.738252 1.00167 0.768774 0.79717 1.55388 0.633735 0.655445 1.41683 0.855437 1.42843 0.585507 0.824723 0.964152 0.944534 1.31847 1.38464 2.21863 1.11651 1.47934 1.5786 0.295617 1.05345 1.0479 1.05457 0.969046 0.627072 0.760953 0.690623 1.08029 1.28625 0.895316 0.76374 0.689378 0.91594 1.10721 0.551526 2.03073 1.65075 0.787847 1.09995 1.19145 0.529792 0.809302 0.978065 0.860965 0.536682 0.5747 0.326381 0.592187 0.625253 1.18112 0.953163 0.748198 0.727544 0.785272 1.01745 0.683898 1.29173 0.962976 1.26327 1.25026 0.485993 0.689904 0.735863 0.840116 0.70719 0.930148 2.04595 1.55548 1.4259 0.683664 0.818365 1.2459 0.626833 0.31851 2.56018 1.55226 ]
@@@ Frame-accuracy per-class: [ 87.5811 82.1577 79.476 68.6695 85.8537 67.7966 54.9153 86.9061 91.0394 86.7894 96 84.412 91.0995 90.6367 76.129 76.8 78.1538 77.9841 80.4124 88.8469 91.3118 80 90.2613 80.7921 71.6707 90.989 76.6197 86.4198 81.2339 90.8665 68.9076 79.1277 79.4224 86.747 96.0915 92.3077 96.0163 94.5758 85.6712 62.5767 65.4545 86.4865 85.8131 67.7228 80.6584 89.1566 62.0434 82.9694 86.6932 93.0875 86.4553 56.239 92.4708 82.9268 88.8538 84.585 45.283 81.4815 92.8702 64.042 77.4194 91.8033 84.0467 94.0113 68.7697 78.673 67.1741 78.2609 89.0323 87.8981 88.3258 91.0394 81.2362 86.8496 95.032 79.4203 85.0859 76.3797 91.1675 74.0741 74.6988 72.7273 91.223 91.042 95.0119 77.39 89.008 88.7417 77.7317 72.0848 83.1683 82.7887 68.9655 80.2228 54.5455 83.3013 85.607 90.1445 69.0647 90.6743 90.2077 60.1671 61.3497 86.5014 88.1356 88.0886 84.264 75.2137 84.1121 76.1421 73.5931 55.0459 84.2105 76.8 34.7826 82.8452 89.301 91.7492 66.9683 78.2609 82.2134 82.9396 90.1734 51.9685 82.2695 85.1485 85.8934 56.9579 82.0339 72.3618 79.6117 68.6339 71.6332 87.2314 74.9035 85.5895 81.4691 77.0031 81.1594 93.178 73.3032 86.7532 91.5401 85.0059 63.9821 72.9927 66.893 84.5996 91.5078 60.3509 87.1369 62.069 93.1384 90.8201 76.8769 89.0995 65.7439 75.6923 89.3296 77.2908 87.2483 80.5369 15.3846 84.0855 80.6202 81.4035 82.5871 92.986 77.9097 79.0528 81.2261 78.8732 79.3443 90.583 92.4423 91.0412 83.959 83.304 67.2986 28.5714 92.6829 88.6957 79.7853 72.4584 73.4884 79.6674 83.2653 90.1135 87.3563 76.0807 86.1865 63.4921 86.747 76.0234 85.7788 97.4359 73.1707 54.1353 90.3073 73.93 87.7285 92.1074 82.5623 96.7742 60.4361 62.6703 74.3949 72.6688 78.6441 75.1773 92.6829 75.6972 83.4473 68.2399 83.2117 87.3563 90.3093 83.6773 80.4408 86.8829 80.1743 85.7971 57.9439 78.9598 81.388 81.0811 90.9091 88.3375 64.7815 65.6716 77.4194 79.0698 72.8662 80 88.2682 84.5878 67.3367 88.4184 88.3249 77.9661 93.7063 86.7503 86.1856 91.4286 82.5532 66.6667 91.6456 84.2809 79.0698 89.1455 85.1114 74.1514 54.4474 78.2334 89.5928 85.8054 74.6114 74.0741 70.5502 76.6284 71.73 91.7031 51.0511 88.8889 69.7674 84.6287 82.5871 83.8794 86.2275 83.9779 91.8919 76.7677 87.8957 83.5443 84.1823 84.3243 90.961 73.7968 82.7195 93.1298 89.8785 89.9713 90.785 77.3163 81.7518 66.1157 85.9016 80.7799 59.2593 77.8157 93.1765 73.2984 89.9135 81.1808 90.4523 30.303 79.0021 51.4286 72.6115 92.7039 76.4045 77.7409 53.944 56.1151 73.7589 63.4508 72.4458 90.9589 89.4349 80 81.2785 88.5444 86.9955 72.9412 65.6716 74.8899 82.2086 66.6667 61.0329 78.5146 91.3892 85.622 81.7439 89.1192 55.1724 82.5485 89.244 76.1566 84.2553 79.2899 84.1121 92.562 73.2601 50.237 83.4225 82.6476 64.6465 68.0062 77.9221 63.8037 75.7333 90.4215 88.4354 84.131 89.336 76.2527 71.6049 89.5307 67.1851 72.1649 74.3494 83.7209 65.9758 86.5979 68.9384 60.6061 76.7347 86.6104 76.3419 81.0069 55.1724 90.4187 69.4639 66.2824 82.2335 79.8054 53.9683 75.8621 79.4613 87.3118 79.2157 92.9936 66.3291 76.4569 61.4634 88.4026 74.5247 79.4953 84.8168 56 85.4071 54.4503 90.5109 82.1752 81.3559 78.8845 80.9339 88.3117 90.6445 89.0511 65.2921 83.2215 73.4007 81.0256 82.1192 83.1889 86.2275 76.9231 80.8126 70.1987 87.8477 83.3724 89.3217 91.6583 58.5774 86.0274 81.7814 86.4865 75.5448 76.9231 57.3066 65.1163 86.3329 89.0344 79.3566 82.0171 66.6667 73.6 89.4545 77.5414 73.065 73.9884 68.4039 84.8921 8.12183 87.7375 91.3907 48.2051 89.2308 82.8974 47.4074 77.2254 81.0496 89.6918 66.3342 83.0476 66.0793 91.9708 57.7778 77.4737 69.5157 85.309 80.7018 56.3758 92.987 75.1131 84.7458 84.9673 77.8711 82.0584 62.3441 78.8732 80.916 96.7742 92.2559 62.6087 83.792 88 90.1408 55.914 84.507 66.8213 86.3813 62.4606 85.7143 80 73.1707 73.93 75.3623 72.5762 85.4626 88.1988 91.8681 83.7209 88.1988 67.2854 83.0918 75.7709 85.2459 86.6165 88.8889 56.6845 81.1594 78.6451 83.9024 75.9494 81.2339 87.8843 56.7164 83.0339 86.4619 60.2076 78.6236 82.4859 82.3529 80 74.5981 73.955 77.2118 60.6742 79.8875 78.1316 76.2353 76.0148 74.4939 74.0125 80.367 81.8824 83.9161 81.5842 82.7586 62.9108 73.2095 84.9673 68.2927 62.8571 70.303 77.8947 68.1004 76.3636 89.9696 87.0056 65.643 80.9843 88.3019 72.233 59.8985 74.9296 81.0619 43.1373 77.3109 78.7879 82.3848 81.3417 88.172 87.1022 58.0645 52.1739 84.7397 81.3223 43.9024 85.9927 60.3077 76.5354 87.6791 76.7296 57.7778 77.2586 72.9875 76.6798 65.2068 79.1277 84.4639 82.8708 79.3201 68.3077 53.1646 82.3529 78.6885 65.6064 76.9575 76.3006 94.5899 65.3061 73.2733 70.9677 72.8033 80.9816 81.5864 69.434 60.8187 67.5799 81.1744 59.8726 84.6361 88.7273 77.7317 44.0678 84.8921 69.7006 72.1536 83.1025 73.6842 79.3296 66.7904 63.8298 82.2742 93.633 88.0658 80.2395 85.3583 86.9671 63.8743 86.1736 97.1429 82.7586 86.5979 48.2759 75.188 44.9438 66.6667 88.2217 81.1133 35.5872 73.6842 81.9048 79.8762 64.5265 84.7599 88.3895 67.3684 90.8752 57.6744 86.4686 0 72.2925 73.0159 81.7518 66.5083 65.8824 76.1905 87.395 84.3373 88.4211 60.6061 72.4566 79.7203 80.3709 76.7347 72.6761 75.395 78.5872 71.09 83.1956 67.9338 59.2593 84.3411 72.0222 86.0606 77.6903 78.6611 88.7469 64.6154 85.6376 79.476 68.7831 81.6327 69.1589 68.4685 80.5031 91.3386 81.6467 83.7209 73.7542 66.3317 91.0299 75.4881 62.7566 70.4626 71.4932 0 81.2183 66.1818 89.8451 72.5234 80.5031 75.2089 76.9231 89.7704 76.0181 87.0871 59.5611 92.8 79.3522 48.2759 68.8525 62.8571 76.5957 75.6219 90.0421 84.6266 81.9048 80.6283 73.1707 79.6117 62.0462 81.2854 81.2785 85.0069 35.2941 65.3358 75.8621 83.6186 81.9753 63.4304 86.7102 81.8505 48.4472 77.9221 55.2381 70.3297 68.3544 72.6115 49.4208 66.2768 82.9077 79.3651 72.956 59.1781 66.1597 53.1792 85.0575 72.7969 76.6839 68.1934 87.9668 88.8889 83.3703 86.9565 80.4938 89.9083 89.9729 73.7752 83.9329 72.2741 72.2323 59.9251 84.8828 92.3077 74.7253 74.7145 72.2689 54.9451 76.7507 91.2281 60.4444 74.0525 73.2297 87.0466 60.0897 78.7402 81.2294 69.6246 84.058 72.2581 82.0202 60.9665 79.6537 75.1486 65.3165 66.0194 70.6617 51.4286 83.1956 79.7241 88.1633 55.0898 86.6792 80.1956 78.9189 77.5665 85.8158 80.7947 83.558 89.4309 88.5012 86.747 77.8013 60.8696 87.1795 84.3882 78.3151 65.8009 75.8621 87.7057 79.8122 64.2202 85.0242 75.9358 68.7324 80.826 64.637 89.6552 76.1062 86.1137 78.5592 78.1116 82.3821 61.8926 84.101 86.4865 80.7175 70.922 84.0183 74.2138 74.6667 79.8206 53.3333 58.3658 87.8412 85.4735 78.534 80.4372 86.7133 80 88.3827 87.3977 66.3212 75.718 59.0038 85.3503 89.6552 50.3497 85.5305 79.3792 89.8129 82.8496 66.3415 59.6306 76.996 51.6129 75.1361 87.619 82.3366 32.381 93.6709 23.5294 76.4818 87.5612 74.225 82.5651 84.4944 90.7801 73.5632 85.078 76.7494 68.9655 56.1265 90.1099 68.1115 73.9274 72.1311 79.1789 77.8135 75.3813 80 39.0244 83.0287 72.9659 82.0513 62.6263 71.6889 57.8313 86.645 76.0626 92.9577 86.4939 87.0993 61.244 80 81.8713 70.8772 79.5181 87.4773 73.7527 59.0308 80.7626 55.814 76.3485 77.9661 85.7143 70.8625 74.2138 58.7413 70.0587 44.3439 71.8447 73.5484 75.9494 51.7162 81.4815 36.4964 71.9212 72.4409 73.161 80.6723 81.7439 62.9482 55.6701 73.3138 63.7037 59.8608 56.621 68.7371 75.5418 85.2336 87.106 92.0078 76.2431 64.8379 78.7879 56.2092 73.5135 73.065 73.7794 84.9438 90.2655 76.1597 89.9924 70.2362 40.613 86.4516 79.868 74.0484 70.2413 87.1795 65.2991 85.9316 81.0304 65.896 88.4354 81.3309 82.9493 71.3043 86.692 79.3932 73.2394 67.8414 57.3099 86.741 78.5276 83.905 93.578 67.8733 78.2007 90.5089 69.6379 74.6269 76.9892 63.9566 79.4007 75.718 86.619 56.5875 77.6573 71.612 71.7508 76.5558 64.8829 67.7165 83.6502 75.3199 75.2475 75.1361 78.2609 81.0256 70.1299 79.7048 85.7531 85.8639 54.7677 64.7273 77.4942 71.4563 80.7646 87.886 84.1871 79.638 64.8649 76.0331 56.9536 83.4783 85.9259 62.9876 80.3604 76.2887 90.6667 86.1314 79.1557 68.9362 63.3663 74.5027 85.8054 53.4799 55.7103 79.8111 73.6842 61.4925 78.1491 84.7237 81.0811 68.4954 0 73.4908 78.2418 66.2474 72.6761 71.3656 80 64.9077 79.7342 48.9796 79.2079 73.8292 90.1554 66.6667 65.6371 83.4109 72.4638 55.0898 72.818 80.3519 66.6667 69.5652 85.4054 64.8871 89.5854 77.8731 60.0823 64.5161 71.3771 83.2536 85.9107 76.6398 77.0318 59.2593 53.202 80 61.5385 84.1791 70.5882 83.6415 56.2674 83.8875 82.0717 0 69.6538 82.1664 82.6176 54.0881 78.6828 73.8462 70.3863 70.7621 65.6546 76.399 86.5154 77.44 74.6177 75.8893 78.1982 78.1609 82.8479 79.8635 83.2 83.0325 83.5165 86.1314 79.7814 76.5432 63.9053 69.0763 86.1619 72.0867 73.1935 74.4939 80.1898 69.5096 75.841 86.747 66.1871 70.5732 74.1104 94.4755 91.9892 92.3077 80.7399 71.8447 60.4651 80 83.1793 60.4288 90.0243 85.4599 78.7879 94.382 72.1311 42.6036 70.632 85.592 83.0573 86.2327 71.1656 52.0548 73.6462 75.7282 62.3853 75.1269 83.8802 84.6847 70.615 74.3455 69.8851 68.4636 75.6164 70.0965 44.0367 79.2313 71.2743 73.3668 67.7966 83.6364 84.6761 85.1064 80.3419 75.5467 73.3624 78.7062 67.1533 76.8473 73.2538 62.1469 55.7185 81.3423 83.6237 84.8485 90.5028 79.564 59.7403 84.0125 57.6803 81.8278 76.6404 73.4007 76.7123 77.193 83.0565 58.4795 65.3465 68.6347 79.8186 64.4391 75.9003 76.5919 73.0159 82.9346 78.0985 49.7354 90.7074 66.2021 74.477 69.8901 77.1084 53.1073 75.5245 79.4702 79.2561 84.8844 73.161 71.3693 64.0777 62.8242 54.8495 76.9231 68.5714 72.788 83.6364 83.6879 75.1678 79.3443 66.9604 80.4598 67.8363 65.9341 74.0214 88.3117 82.2967 75.4639 78.7746 70.5376 74.0741 47.0588 80.2413 72.2955 84.4622 86.653 79.0436 75.0314 75.4491 72.2936 78.3505 42.1941 80.1223 86.4135 82.623 83.1169 90.5089 73.224 69.8885 79.1946 76.0898 76.7677 70.3448 62.9283 77.6529 67.052 63.1579 73.8739 52.1739 73.8155 63.0197 64.8649 81.8462 73.4531 72.3751 86.7257 88.5645 82.6884 81.1502 84.1989 80.1378 84.7375 82.5959 85.0095 67.8663 80.2661 57.2864 81.3891 74.0947 92.1109 81.4815 29.7872 84.8057 67.0807 67.9245 84.7262 0 82.0513 50.8475 65.6604 64.5783 47.3118 71.3178 79.2332 86.5248 78.7879 41.8301 63.1179 79.1444 84.9558 72.1604 44.7552 83.3977 67.6923 62.3053 34.5679 62.8311 90.4564 83.2298 63.0824 70.1571 76.3636 71.0963 73.7475 82.9876 52.9774 46.2243 51.6129 52.0095 67.2199 75.8148 71.6981 90.8738 75.063 81.4815 82.7156 52.8529 96.2963 79.4854 75.3327 85.9429 50.8287 76.6532 84.3882 75.6447 85.0153 72.6944 64.6465 78.3172 87.0813 41.0646 72.2892 66.6667 83.5821 76.841 93.575 77.3455 67.1533 62.069 78.6885 67.5624 79.4411 75.174 63.5322 61.597 75.6184 76.9231 53.2319 83.2184 77.4775 82.2511 81.8565 79.0698 68.8995 85.7671 87.0994 70.5531 76.6061 69.434 85.7143 82.24 77.3869 75.3792 62.8803 71.5232 61.8705 30.5221 81.4913 62.7737 81.791 84.8 87.6356 61.461 85.8006 55.5809 76.8627 60.8924 86.8914 78.9668 77.2028 85.3933 67.0554 77.0713 87.781 49.4915 73.2919 76.1446 66.1123 43.7647 77.1619 72.9483 59.8131 63.1111 73.2203 74.0741 66.6667 78.4053 72.2408 80.7396 77.7643 74.5491 78.607 77.1084 65.1685 73.8255 74.6269 81.0631 43.2 75.1236 78.2503 84.2975 97.2973 66.0633 72.2063 74.0741 93.2826 74.2857 80.6653 84.1629 89.6309 71.4617 81.376 75.1092 87.6768 71.3124 61.4232 63.9175 50.2283 71.8232 73.2673 54.0541 85.7739 79.5812 74.8718 67.1463 59.5041 62.9696 63.2727 80.3519 82.2811 84.492 60.8924 79.046 77.4468 74.7384 76.7816 38.2514 74.2729 75.5877 79.9263 37.5286 65.8635 74.3516 79.7407 67.0433 69.4981 81.9113 39.0244 72.1003 76.2089 82.1589 66.4615 81.8848 72.4919 77.9932 55.2381 86.3082 80.402 81.5433 70.1299 77.956 69.0196 61.6541 56.1404 60.1504 56.6038 84.6753 91.8519 79.5096 67.7346 70.1299 87.8873 66.4242 80.415 68.6869 81.0127 77.7448 51.7572 85.8086 82.5279 57.7778 81.2749 63.9053 82.9404 78.0952 72.5061 70.9122 61.5836 61.0012 34.965 67.5585 58.5551 45.6621 93.7853 69.6486 68.5083 70.2703 72.9198 82.7586 78.8204 81.9394 68.535 63.9175 70.7395 81.5427 80.376 73.2673 74.6667 83.2215 45.7143 51.2702 79.646 76.0259 66.8407 85.2575 79.322 70.3812 77.3414 84.7282 85.8447 90.5812 84.3806 82.9337 57.7181 71.8499 75.9825 80.4233 80.4928 71.9068 80 63.0491 71.2088 62.3377 57.8616 87.4036 84.5361 79.659 74.8092 81.9876 73.9726 36.1624 47.5138 59.8608 80.8511 75.4717 54.2056 85.744 91.7115 30.4 54.6584 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 0.72027 (Xent), [AvgXent: 0.72027, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 79.7418% <<

