nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=3.125e-05 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter11_learnrate6.25e-05_tr0.6979_cv1.7033 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter12 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975001
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.81539, max 8.96107, mean 0.00568746, stddev 0.99447, skewness 0.129835, kurtosis 2.1535 ) 
[1] output of <AffineTransform> ( min -29.4011, max 24.9526, mean -3.40431, stddev 4.09987, skewness 0.122771, kurtosis 1.2372 ) 
[2] output of <Sigmoid> ( min 1.70315e-13, max 1, mean 0.205097, stddev 0.314725, skewness 1.50075, kurtosis 0.781342 ) 
[3] output of <AffineTransform> ( min -29.4017, max 15.1978, mean -4.07337, stddev 2.74689, skewness -0.0580021, kurtosis 2.17508 ) 
[4] output of <Sigmoid> ( min 1.70224e-13, max 1, mean 0.0956463, stddev 0.19008, skewness 2.94397, kurtosis 8.62399 ) 
[5] output of <AffineTransform> ( min -14.1385, max 10.6896, mean -3.08547, stddev 1.93782, skewness 0.529445, kurtosis 2.1252 ) 
[6] output of <Sigmoid> ( min 7.2399e-07, max 0.999977, mean 0.113598, stddev 0.185661, skewness 2.74863, kurtosis 7.75405 ) 
[7] output of <AffineTransform> ( min -20.573, max 17.3893, mean -2.74898, stddev 2.26225, skewness 0.520938, kurtosis 2.4325 ) 
[8] output of <Sigmoid> ( min 1.1621e-09, max 1, mean 0.157333, stddev 0.233499, skewness 2.03267, kurtosis 3.41995 ) 
[9] output of <AffineTransform> ( min -16.6485, max 17.2559, mean -2.81455, stddev 2.86423, skewness 1.30175, kurtosis 2.42816 ) 
[10] output of <Sigmoid> ( min 5.88369e-08, max 1, mean 0.18029, stddev 0.293127, skewness 1.7486, kurtosis 1.69059 ) 
[11] output of <AffineTransform> ( min -31.0548, max 25.4796, mean -3.66451, stddev 3.66357, skewness 0.961293, kurtosis 3.03662 ) 
[12] output of <Sigmoid> ( min 3.25882e-14, max 1, mean 0.152269, stddev 0.298021, skewness 2.01074, kurtosis 2.5019 ) 
[13] output of <AffineTransform> ( min -15.1475, max 24.6163, mean -0.0192504, stddev 3.69158, skewness 0.520711, kurtosis 0.921299 ) 
[14] output of <Softmax> ( min 4.94626e-16, max 0.999961, mean 0.000657832, stddev 0.0195248, skewness 40.1943, kurtosis 1736.85 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -2.28214, max 0.962402, mean -0.0002852, stddev 0.0528601, skewness -1.0161, kurtosis 55.6202 ) 
[1] diff-output of <AffineTransform> ( min -0.413958, max 0.400688, mean 1.32089e-05, stddev 0.0100021, skewness 0.466798, kurtosis 94.2651 ) 
[2] diff-output of <Sigmoid> ( min -1.72668, max 1.99328, mean 0.000448294, stddev 0.0907321, skewness 0.239596, kurtosis 20.1233 ) 
[3] diff-output of <AffineTransform> ( min -0.411655, max 0.480156, mean -1.03967e-06, stddev 0.0113587, skewness 0.185213, kurtosis 118.132 ) 
[4] diff-output of <Sigmoid> ( min -2.23186, max 2.14588, mean 0.000284223, stddev 0.124721, skewness -0.0270669, kurtosis 17.4585 ) 
[5] diff-output of <AffineTransform> ( min -0.532103, max 0.366441, mean 1.58993e-05, stddev 0.0118722, skewness -0.13243, kurtosis 84.2207 ) 
[6] diff-output of <Sigmoid> ( min -2.1867, max 1.91641, mean 0.000404632, stddev 0.101473, skewness -0.0310723, kurtosis 17.2903 ) 
[7] diff-output of <AffineTransform> ( min -0.280309, max 0.22405, mean 1.57714e-05, stddev 0.00956371, skewness -0.149919, kurtosis 50.1875 ) 
[8] diff-output of <Sigmoid> ( min -1.36598, max 1.16492, mean 0.000211824, stddev 0.0700862, skewness -0.0285605, kurtosis 16.088 ) 
[9] diff-output of <AffineTransform> ( min -0.255202, max 0.15801, mean 1.41373e-05, stddev 0.00698639, skewness -0.464674, kurtosis 59.3803 ) 
[10] diff-output of <Sigmoid> ( min -1.13887, max 0.813006, mean 0.000234322, stddev 0.0533249, skewness -0.107819, kurtosis 19.0949 ) 
[11] diff-output of <AffineTransform> ( min -0.192691, max 0.217456, mean -3.01778e-06, stddev 0.00773363, skewness -0.202211, kurtosis 65.9163 ) 
[12] diff-output of <Sigmoid> ( min -2.21938, max 1.25293, mean -0.000498012, stddev 0.0815373, skewness -0.197115, kurtosis 11.5491 ) 
[13] diff-output of <AffineTransform> ( min -0.996361, max 0.910521, mean -4.38212e-09, stddev 0.0154319, skewness -27.056, kurtosis 2337.41 ) 
[14] diff-output of <Softmax> ( min -0.996361, max 0.910521, mean -4.38212e-09, stddev 0.0154319, skewness -27.056, kurtosis 2337.41 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.71101, max 1.9918, mean -0.000742, stddev 0.159833, skewness 0.0158479, kurtosis 2.23384 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.508883, max 0.513561, mean 0.0033815, stddev 0.149861, skewness -0.126166, kurtosis 0.357932 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.830006, max 0.818187, mean 8.07693e-05, stddev 0.0687544, skewness 0.0333258, kurtosis 5.8967 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.733713, max 0.888193, mean -0.000266155, stddev 0.175128, skewness 0.120688, kurtosis 1.92782 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.75442, max 0.64872, mean 0.000432131, stddev 0.0395526, skewness -0.138497, kurtosis 11.5224 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.76532, max 0.661396, mean 0.00407016, stddev 0.168382, skewness 0.049898, kurtosis 1.83709 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.46333, max 0.452501, mean 0.000541805, stddev 0.0324707, skewness -0.053151, kurtosis 8.84778 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.690631, max 0.494523, mean 0.00403749, stddev 0.13749, skewness -0.140773, kurtosis 2.11784 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.448332, max 0.278069, mean 0.000536144, stddev 0.030734, skewness -0.0986204, kurtosis 6.82424 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.423579, max 0.37929, mean 0.00361916, stddev 0.10251, skewness -0.00970703, kurtosis 1.97137 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.495, max 0.364229, mean -1.20116e-05, stddev 0.0421746, skewness -0.149407, kurtosis 7.20847 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.667115, max 0.411763, mean -0.000772536, stddev 0.119399, skewness -0.21508, kurtosis 2.35687 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.11291, max 1.90107, mean -2.37808e-08, stddev 0.0839211, skewness -4.38373, kurtosis 75.6675 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.6309, max 1.19984, mean -1.09798e-08, stddev 0.245665, skewness -1.60844, kurtosis 10.1057 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 342784 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -6.78548, max 7.66488, mean 0.00618661, stddev 0.998336, skewness 0.126755, kurtosis 2.01683 ) 
[1] output of <AffineTransform> ( min -29.2782, max 24.8293, mean -3.37534, stddev 4.13152, skewness 0.142607, kurtosis 1.21298 ) 
[2] output of <Sigmoid> ( min 1.92602e-13, max 1, mean 0.208173, stddev 0.317658, skewness 1.47777, kurtosis 0.698916 ) 
[3] output of <AffineTransform> ( min -31.3457, max 18.1414, mean -4.08135, stddev 2.78933, skewness -0.0560159, kurtosis 2.19207 ) 
[4] output of <Sigmoid> ( min 2.43621e-14, max 1, mean 0.0974662, stddev 0.19333, skewness 2.90147, kurtosis 8.29545 ) 
[5] output of <AffineTransform> ( min -13.7866, max 11.2931, mean -3.08931, stddev 1.96504, skewness 0.530427, kurtosis 2.19925 ) 
[6] output of <Sigmoid> ( min 1.02931e-06, max 0.999988, mean 0.114699, stddev 0.187741, skewness 2.72367, kurtosis 7.55838 ) 
[7] output of <AffineTransform> ( min -21.1771, max 16.954, mean -2.74564, stddev 2.28551, skewness 0.523053, kurtosis 2.44488 ) 
[8] output of <Sigmoid> ( min 6.35163e-10, max 1, mean 0.158706, stddev 0.235483, skewness 2.0178, kurtosis 3.33546 ) 
[9] output of <AffineTransform> ( min -16.5863, max 17.3429, mean -2.80635, stddev 2.88513, skewness 1.30973, kurtosis 2.46609 ) 
[10] output of <Sigmoid> ( min 6.26116e-08, max 1, mean 0.181737, stddev 0.294939, skewness 1.73172, kurtosis 1.61624 ) 
[11] output of <AffineTransform> ( min -27.9634, max 22.4595, mean -3.66667, stddev 3.67163, skewness 0.97108, kurtosis 2.97592 ) 
[12] output of <Sigmoid> ( min 7.17225e-13, max 1, mean 0.153062, stddev 0.299149, skewness 1.99894, kurtosis 2.44898 ) 
[13] output of <AffineTransform> ( min -15.8157, max 23.1728, mean -0.0185814, stddev 3.68825, skewness 0.545288, kurtosis 0.982877 ) 
[14] output of <Softmax> ( min 1.64853e-15, max 0.998088, mean 0.000657834, stddev 0.0193711, skewness 39.539, kurtosis 1687.87 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.04057, max 1.24375, mean -0.000319509, stddev 0.0460932, skewness 0.242072, kurtosis 29.9238 ) 
[1] diff-output of <AffineTransform> ( min -0.240929, max 0.308012, mean 2.85281e-05, stddev 0.00873031, skewness 0.335102, kurtosis 73.0282 ) 
[2] diff-output of <Sigmoid> ( min -1.63296, max 1.57764, mean -0.000133138, stddev 0.0792954, skewness -0.0154426, kurtosis 17.6641 ) 
[3] diff-output of <AffineTransform> ( min -0.270182, max 0.373243, mean 2.32331e-05, stddev 0.00981147, skewness 0.276172, kurtosis 93.8599 ) 
[4] diff-output of <Sigmoid> ( min -1.4964, max 1.58302, mean -2.45055e-05, stddev 0.106033, skewness -0.0029756, kurtosis 12.914 ) 
[5] diff-output of <AffineTransform> ( min -0.275344, max 0.286251, mean 2.20633e-05, stddev 0.0101841, skewness -0.069639, kurtosis 61.2194 ) 
[6] diff-output of <Sigmoid> ( min -1.19603, max 1.42733, mean 5.39262e-05, stddev 0.0880402, skewness 0.0213461, kurtosis 13.8176 ) 
[7] diff-output of <AffineTransform> ( min -0.217025, max 0.233812, mean 1.61375e-05, stddev 0.00832841, skewness 0.181756, kurtosis 50.796 ) 
[8] diff-output of <Sigmoid> ( min -0.889741, max 0.954202, mean 0.000210988, stddev 0.0614025, skewness 0.0123685, kurtosis 15.0468 ) 
[9] diff-output of <AffineTransform> ( min -0.154209, max 0.134937, mean 1.02581e-05, stddev 0.00615905, skewness -0.358469, kurtosis 54.4342 ) 
[10] diff-output of <Sigmoid> ( min -0.856113, max 0.768595, mean 8.9243e-05, stddev 0.0472719, skewness -0.128103, kurtosis 19.8444 ) 
[11] diff-output of <AffineTransform> ( min -0.241436, max 0.215589, mean -4.62489e-07, stddev 0.00696306, skewness -0.425293, kurtosis 86.3126 ) 
[12] diff-output of <Sigmoid> ( min -2.64895, max 2.09719, mean 0.00023327, stddev 0.0746106, skewness -0.263102, kurtosis 24.115 ) 
[13] diff-output of <AffineTransform> ( min -0.999955, max 0.95751, mean -5.61122e-09, stddev 0.0137464, skewness -25.0454, kurtosis 2416.1 ) 
[14] diff-output of <Softmax> ( min -0.999955, max 0.95751, mean -5.61122e-09, stddev 0.0137464, skewness -25.0454, kurtosis 2416.1 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.40601, max 1.61222, mean -0.00115013, stddev 0.133739, skewness -0.0122684, kurtosis 2.08025 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.662301, max 0.657585, mean 0.00730318, stddev 0.157569, skewness -0.0248563, kurtosis 1.03882 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.613743, max 0.772633, mean 0.0013863, stddev 0.0614988, skewness 0.0464229, kurtosis 6.32743 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.815355, max 0.892039, mean 0.00594766, stddev 0.178654, skewness 0.129041, kurtosis 2.79338 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.767559, max 0.664389, mean 0.000574405, stddev 0.037307, skewness -0.0642972, kurtosis 13.9238 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.10843, max 0.746525, mean 0.00564821, stddev 0.195257, skewness -0.161239, kurtosis 3.05411 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.47948, max 0.480258, mean 0.000489202, stddev 0.0311443, skewness -0.133074, kurtosis 10.1028 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.768728, max 0.744947, mean 0.00413121, stddev 0.155721, skewness -0.146497, kurtosis 2.14789 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.434378, max 0.373396, mean 0.000379767, stddev 0.0295683, skewness -0.329574, kurtosis 9.02557 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.639807, max 0.562775, mean 0.0026261, stddev 0.111927, skewness -0.393565, kurtosis 3.86928 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.517946, max 0.47887, mean 3.59353e-05, stddev 0.0404049, skewness -0.138787, kurtosis 9.84377 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.62211, max 0.56323, mean -0.000118403, stddev 0.125122, skewness -0.1436, kurtosis 3.60177 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.5611, max 3.11266, mean -1.4067e-08, stddev 0.0778985, skewness -3.09477, kurtosis 131.547 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.22188, max 2.12992, mean -7.52901e-09, stddev 0.235406, skewness -1.2374, kurtosis 23.3199 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0781226 min, processing 73129.5 frames per sec; i/o time 5.08122%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14111 120 114 116 102 29 147 431 139 624 262 548 95 133 232 62 162 188 145 264 293 157 210 252 206 227 177 121 194 213 59 160 138 41 524 149 489 359 331 244 27 18 144 252 121 124 944 114 5399 17569 1561 284 471 20 632 126 26 94 273 190 263 30 128 442 158 105 525 11 77 78 552 418 679 528 1016 172 727 226 492 148 41 38 347 273 210 329 186 75 361 141 50 229 14 179 16 260 399 380 208 348 168 179 81 181 88 1263 98 58 160 98 115 54 66 62 11 119 350 151 110 448 126 190 86 63 70 151 159 154 147 99 51 457 174 395 129 114 299 480 34 300 110 192 230 423 223 68 294 243 288 142 120 14 444 408 166 105 144 162 529 125 74 223 6 210 64 142 100 249 210 274 130 35 152 111 628 206 146 284 105 10 20 172 279 270 107 661 122 308 130 173 423 220 622 85 221 292 20 66 211 128 191 614 140 15 160 183 392 155 147 70 20 125 365 508 342 43 242 266 181 354 229 517 160 211 158 92 236 201 194 33 15 451 392 162 89 139 99 401 98 88 71 358 242 87 117 16 197 149 150 216 426 191 185 158 110 313 96 94 154 130 118 114 166 121 21 289 100 381 83 90 18 148 268 118 186 92 525 93 176 196 123 174 146 156 68 60 152 179 13 146 212 95 173 135 298 16 240 157 78 116 133 150 196 69 70 269 161 182 203 142 109 580 111 212 100 113 81 22 106 188 435 309 183 96 159 180 813 140 117 84 160 60 136 105 93 279 49 323 115 81 187 130 220 198 248 229 121 138 321 339 134 107 289 145 381 16 122 414 251 218 14 704 214 173 295 205 31 188 148 232 127 78 197 214 102 228 131 158 286 12 325 95 342 165 147 125 128 38 240 479 145 74 148 97 75 288 83 71 221 75 341 213 744 497 119 182 123 166 206 71 174 21 369 305 186 525 28 62 137 211 161 86 153 69 98 289 226 97 32 248 67 432 171 470 200 262 113 68 112 237 175 493 28 74 192 110 147 76 178 359 200 35 65 15 148 172 163 12 106 46 106 215 128 158 115 37 61 128 34 180 113 80 227 21 80 215 103 113 91 332 175 93 103 339 102 197 194 276 33 250 439 144 479 88 246 22 155 155 186 44 355 235 212 135 123 240 272 212 71 252 101 106 188 76 61 17 82 47 139 27 164 88 260 223 132 257 98 177 282 25 59 247 184 238 139 298 77 80 278 302 61 410 162 317 174 79 22 160 279 126 205 160 228 522 176 162 39 25 152 251 223 86 286 122 166 15 119 81 176 132 85 109 289 78 185 137 361 29 347 417 364 180 85 89 269 23 149 133 121 83 160 410 95 466 17 101 145 14 66 44 19 216 251 140 66 52 161 311 239 133 142 268 107 151 0 355 94 68 210 42 10 178 124 47 82 201 71 323 122 177 221 226 105 181 815 94 322 180 82 190 119 1408 32 372 114 94 24 267 55 79 63 291 21 150 99 752 230 170 140 110 8 98 137 290 267 238 179 97 239 110 166 159 62 123 14 30 87 117 100 356 341 52 95 143 51 151 264 109 363 8 275 14 204 202 154 229 140 80 115 52 45 276 235 129 256 254 94 238 182 131 86 130 130 96 196 120 148 225 34 202 54 553 173 208 160 275 133 618 6 45 306 59 45 178 28 112 171 289 96 111 63 455 146 103 77 247 134 346 420 197 51 400 17 181 362 122 83 799 204 92 131 1688 75 185 61 630 124 236 80 58 118 320 115 14 516 106 54 103 280 177 169 213 101 56 536 291 116 201 195 336 18 111 70 109 79 37 111 187 128 201 1008 95 457 71 152 219 305 96 191 130 235 14 71 155 225 240 189 307 189 632 15 275 157 359 52 39 8 261 510 564 249 222 352 43 224 221 130 126 45 161 151 30 170 155 229 37 61 191 190 136 49 411 41 153 223 35 366 639 104 127 85 142 456 275 230 113 288 21 120 29 17 214 79 214 255 110 257 77 118 218 13 68 101 63 251 59 183 125 145 170 202 215 109 241 161 267 174 256 90 200 49 76 92 161 276 222 56 463 654 317 130 77 151 144 186 175 292 131 213 86 220 270 108 57 131 395 106 113 85 403 81 189 54 110 144 363 179 368 232 184 400 191 489 231 230 350 465 586 149 317 131 273 50 275 11 97 38 135 368 286 204 137 215 257 418 210 224 110 55 60 75 172 202 525 277 145 337 68 189 117 50 276 313 136 179 423 28 167 194 461 203 601 9 190 227 238 177 113 47 189 451 171 151 181 96 142 129 322 103 83 200 170 55 11 92 243 494 291 121 170 693 104 145 434 141 13 101 57 58 167 42 351 179 195 376 0 245 378 244 79 288 97 116 1082 263 205 374 312 163 126 277 43 154 146 187 138 227 205 91 202 84 124 191 184 214 123 421 234 163 207 69 392 407 805 555 331 459 257 193 152 270 256 205 168 82 44 30 84 134 350 392 468 81 109 138 51 163 98 350 55 219 95 217 185 182 155 54 676 231 99 147 82 316 70 292 251 114 185 205 101 293 88 170 372 143 247 89 183 269 159 159 470 190 148 36 484 150 85 151 135 220 209 180 557 157 313 294 94 360 143 119 227 207 88 71 75 349 843 251 120 51 173 149 253 192 299 302 211 74 152 113 43 85 136 421 115 104 242 228 232 13 59 331 189 125 243 355 398 250 272 145 118 163 1961 152 115 363 91 134 74 378 346 72 160 400 86 256 55 11 200 228 129 162 250 490 56 205 245 156 452 435 409 169 263 194 225 99 561 179 234 364 164 141 80 185 173 8 19 29 132 207 139 64 156 211 16 76 131 93 282 224 71 388 32 160 40 547 120 241 139 286 192 752 249 120 243 218 46 211 120 291 79 257 198 13 1281 166 13 738 488 437 90 370 118 174 163 276 49 154 104 131 124 316 100 468 303 218 68 14 30 260 250 215 829 131 141 45 131 217 166 115 118 64 313 270 608 334 412 132 73 312 298 428 246 226 69 124 375 68 167 62 230 198 165 219 127 190 133 948 357 222 171 259 511 147 80 207 240 212 225 164 53 112 147 121 25 150 149 324 411 249 100 41 133 521 301 150 62 303 411 60 18 110 174 40 394 52 240 331 284 215 421 114 247 430 133 48 109 90 50 18 1198 95 97 208 60 279 137 170 245 280 190 293 117 334 217 91 223 276 271 218 124 173 308 265 129 146 20 159 258 333 162 477 154 438 52 1106 298 479 38 841 127 66 85 66 26 192 67 285 218 115 177 412 385 148 434 168 156 454 403 22 125 84 360 157 205 290 170 429 71 149 131 109 88 156 90 129 330 14 559 412 392 145 155 181 425 252 187 74 157 216 56 231 191 281 147 170 165 579 328 249 278 354 74 559 114 283 243 343 212 193 227 115 79 194 48 410 65 80 109 135 90 215 117 185 53 480 464 62 80 ]
@@@ Loss per-class: [ 0.306037 0.691677 0.729056 0.755205 0.5209 0.811429 1.53561 0.479548 0.458379 0.420548 0.214845 0.454626 0.477724 0.454217 0.810004 0.680436 0.645158 0.778622 0.568638 0.42829 0.357036 0.598225 0.332679 0.717504 0.873243 0.356825 0.729445 0.45738 0.633829 0.351784 0.787092 0.776147 0.844198 0.663287 0.188043 0.393499 0.172471 0.245556 0.449164 1.18535 1.15495 1.02614 0.341714 0.931576 0.781266 0.334892 0.768736 0.648308 0.407107 0.211922 0.442041 1.21898 0.336043 0.759835 0.420297 0.56093 1.35741 0.688425 0.261406 1.10157 0.698408 0.467509 0.570455 0.249222 1.05337 0.734684 0.997181 0.764543 0.447804 0.616171 0.49696 0.330618 0.626185 0.509453 0.197389 0.560527 0.536486 0.792863 0.273637 0.901267 0.811191 0.978979 0.316787 0.416388 0.346086 0.792733 0.393491 0.362294 0.693588 0.948433 0.540759 0.517339 1.08231 0.533625 1.32372 0.639819 0.652957 0.416985 0.968337 0.36647 0.402408 1.23425 1.14495 0.54159 0.601389 0.416829 0.548062 0.725643 0.477949 0.867783 0.755563 1.19461 0.532826 0.741256 1.67729 0.674274 0.425504 0.363361 1.20717 0.83843 0.545602 0.590021 0.569711 1.31759 0.634936 0.620164 0.621398 1.10821 0.671551 1.12278 0.82907 0.999287 0.84925 0.510264 0.756203 0.533824 0.700039 0.808049 0.754229 0.319468 1.01942 0.481127 0.375206 0.564488 1.14661 0.753655 1.2078 0.569135 0.345041 1.22987 0.466398 1.2115 0.227515 0.455044 0.676431 0.477695 1.20877 0.833533 0.442487 0.873421 0.627417 0.840349 1.99029 0.629432 0.57841 0.558666 0.759652 0.300277 0.877928 0.591802 0.654647 0.855231 0.642476 0.394933 0.309389 0.342225 0.600019 0.581208 1.17064 1.55418 0.508132 0.48144 0.749423 0.903395 0.846227 0.680338 0.702584 0.387399 0.440106 0.855538 0.481228 1.19191 0.360911 0.695604 0.459365 0.200145 1.12634 1.05389 0.352476 0.725893 0.473378 0.317988 0.686309 0.618863 1.44262 1.29863 0.87276 0.98641 0.728442 0.860247 0.30266 1.07433 0.638905 1.20078 0.508935 0.446802 0.318979 0.666275 0.794745 0.420796 0.581541 0.471464 1.39666 0.902547 0.752961 0.537968 0.482656 0.507764 0.999276 1.00371 0.923549 0.771066 0.927208 0.618006 0.828757 0.47668 1.11049 0.490217 0.553444 0.741649 0.313763 0.409757 0.536988 0.384652 0.669361 1.00724 0.307459 0.547841 0.645861 0.481353 0.491184 0.621122 1.27652 0.687029 0.494158 0.529504 0.842936 0.896563 1.00791 0.709098 0.856213 0.321196 1.24938 0.374851 1.10178 0.535144 0.742298 0.555686 0.635803 0.698444 0.47437 0.779137 0.453658 0.500988 0.621618 0.520773 0.384326 0.796722 0.480437 0.291425 0.481649 0.466378 0.396994 0.991426 0.730089 1.7818 0.466603 0.51891 1.06205 0.770946 0.264286 0.87898 0.431376 0.641453 0.336006 2.04722 0.663346 1.5019 0.920189 0.441149 0.871973 0.842214 1.34259 1.23794 1.0776 1.07173 0.917759 0.448535 0.472043 0.576938 0.651862 0.425457 0.524856 0.945998 1.07868 0.857176 0.627531 0.858174 1.18585 0.817952 0.345612 0.406466 0.580976 0.488583 1.39115 0.704368 0.398889 0.820878 0.421165 0.924917 0.524141 0.434754 0.751344 1.46931 0.603368 0.663813 0.986162 1.05641 0.673761 1.10637 0.82027 0.42918 0.366255 0.533565 0.433131 0.772164 0.957373 0.370701 1.05922 0.866766 0.843501 0.687874 1.21054 0.50208 1.06491 1.35963 0.792109 0.407873 0.849221 0.594408 1.68613 0.340678 1.10755 1.032 0.724491 0.627717 1.45384 0.850013 0.701241 0.499412 0.821305 0.420535 1.13839 0.747339 1.31709 0.457448 0.774232 0.686723 0.520472 1.47021 0.511551 1.42564 0.428539 0.600151 0.677158 1.00307 0.644116 0.543659 0.369577 0.413716 1.10709 0.612391 0.773436 0.694836 0.757912 0.64913 0.471442 0.71369 0.67859 1.00917 0.432918 0.676266 0.416294 0.273407 1.45889 0.471006 0.491915 0.636254 0.775587 0.786197 1.36896 1.3418 0.476715 0.415935 0.786312 0.5667 1.46589 1.00456 0.34806 0.805742 0.766264 0.820103 1.04026 0.652188 3.10048 0.399167 0.339224 1.88346 0.624961 0.508735 1.72294 0.821419 0.692655 0.36271 1.02723 0.684144 1.19271 0.366428 1.09406 0.762695 0.973455 0.564186 1.02483 1.2264 0.309068 0.817726 0.55791 0.502628 0.715471 0.604341 1.16361 0.723359 0.542874 0.519937 0.404031 1.15815 0.474686 0.56889 0.493529 1.34204 0.580361 0.964649 0.447279 1.21124 0.606975 0.707342 0.690381 0.855889 0.909106 0.881202 0.543564 0.528544 0.387358 0.715102 0.494486 0.963044 0.750939 0.827753 0.383259 0.523092 0.394887 1.26193 0.7896 0.695382 0.493451 0.860606 0.625267 0.447362 1.04464 0.673143 0.540492 1.1759 0.732574 0.487319 0.568021 0.745294 0.863284 1.02949 0.880399 1.15001 0.715542 0.591027 0.719001 1.01322 1.00363 0.94337 0.686518 0.601809 0.571039 0.580983 0.670297 1.41948 0.824659 0.560363 1.08783 1.62325 0.795721 0.768524 1.12582 0.852476 0.317781 0.501137 1.13786 0.73098 0.404089 0.971418 1.16665 0.935799 0.685684 2.00414 0.6907 0.731066 0.620444 0.653885 0.527041 0.449949 1.21255 1.75788 0.573361 0.640284 1.64403 0.499127 1.4368 0.796387 0.521014 0.751195 1.11965 0.829141 0.931864 0.766748 1.24476 0.693386 0.523767 0.598089 0.764276 0.964735 1.82687 1.09046 0.663743 1.05365 0.806408 0.634085 0.264335 1.02104 0.849927 0.979902 1.1319 0.657724 0.601018 0.906451 1.40313 1.00978 0.746161 1.06612 0.580821 0.404986 0.62358 1.77362 0.587767 0.810988 0.914468 0.603755 0.819557 0.795458 1.02946 1.19377 0.593054 0.332764 0.392119 0.905291 0.725498 0.431005 1.02253 0.554684 0.254217 0.607844 0.566382 1.62896 0.823602 2.11112 1.21177 0.330056 0.631698 2.03884 0.88939 0.696453 0.56687 1.12095 0.546353 0.341515 1.0452 0.34502 1.35426 0.576732 0 0.75575 0.93571 0.59639 1.24042 0.983892 0.832611 0.450679 0.738463 0.521377 1.30543 0.96216 0.54905 0.676183 0.700228 0.758425 0.883321 0.876228 0.810823 0.659575 0.873617 0.975452 0.463247 0.862467 0.566785 0.805776 0.730243 0.386604 0.889418 0.510576 0.72517 1.1049 0.754655 0.912102 1.03424 0.763805 0.378215 0.766189 0.889416 0.837666 1.2272 0.329345 0.676918 1.33159 0.922874 0.92152 2.72758 0.767691 1.28939 0.48545 0.969939 0.655194 0.871486 0.730898 0.342666 0.686828 0.41215 1.48913 0.554015 0.643286 0.996389 1.70511 1.15955 0.683499 0.870288 0.42165 0.486305 0.711003 0.728048 0.803505 0.855514 1.16486 0.584312 0.51712 0.608469 1.44566 1.01071 0.941718 0.523721 0.621482 1.14649 0.468467 0.653311 1.69229 0.735891 1.11612 0.858895 1.09763 0.927 2.06069 1.28661 0.601132 0.795231 0.877256 1.3621 0.975026 1.75941 0.433786 1.04262 0.850899 1.15945 0.434113 0.44824 0.628255 0.713815 0.66813 0.507101 0.374008 0.819521 0.591466 0.873933 0.933196 1.10273 0.540537 1.10131 1.10188 0.850374 0.650278 1.61608 0.7953 0.649766 1.44355 0.853515 0.825461 0.52563 1.08068 0.863577 0.722354 1.13572 0.572786 0.991707 0.742427 1.1788 0.669325 0.814274 1.14891 1.18454 0.994409 1.56049 0.700759 0.630227 0.531806 1.19071 0.457065 0.733928 0.547615 0.852096 0.462028 0.71552 0.551302 0.450773 0.406718 0.546988 0.736841 0.975465 0.662351 0.526095 0.675116 0.902033 0.949238 0.442956 0.651215 1.06136 0.554332 0.920733 1.10375 0.607993 1.27594 0.539591 0.857873 0.469082 0.755916 0.86221 0.686806 1.19304 0.656286 0.790245 0.797874 0.785658 0.494349 0.917549 0.894318 0.735781 1.12636 1.21098 0.638593 0.492874 0.59563 0.793341 0.636277 0.626291 0.423908 0.580753 0.966465 0.8933 1.04478 0.535767 0.447462 1.54146 0.576136 0.710081 0.389356 0.527289 1.04814 1.33781 0.801637 1.41057 0.926653 0.502064 0.779944 1.88194 0.368539 1.73412 0.730786 0.513618 0.920102 0.680569 0.7154 0.347827 1.14451 0.467951 0.86838 1.04217 1.62068 0.675721 1.16896 0.919167 0.915202 0.639431 0.79029 0.965077 0.791378 2.44597 0.646331 0.816037 0.638476 1.06428 0.918245 1.12772 0.485515 0.753754 0.38218 0.427447 0.369299 1.27 0.649367 0.588044 0.934274 0.811161 0.467148 0.874968 1.60876 0.654998 1.5216 0.870419 0.90568 0.94022 0.904964 0.818657 1.27417 1.02662 1.79301 0.931297 0.851206 0.79669 1.39287 0.635724 1.95593 0.947683 1.04232 0.857326 1.16352 0.609737 1.2283 1.67987 0.84233 1.16675 1.39053 1.6024 1.0863 0.929566 0.592464 0.37914 0.45672 0.926798 1.06975 0.798934 1.23512 0.721666 0.93829 0.797333 0.531135 0.414552 0.833964 0.315467 1.2949 1.66753 0.433038 0.705291 0.883789 0.909458 0.35654 1.09057 0.445477 0.660937 0.949156 0.408047 0.743411 0.549819 1.15226 0.533452 0.795859 0.915182 1.18682 1.12724 0.549307 0.632654 0.450695 0.245548 1.04733 0.80603 0.318747 0.948066 0.832023 0.850116 1.12054 0.637085 0.898665 0.508256 1.19133 0.71753 0.916692 0.884615 0.770274 1.39252 1.25848 0.572946 0.64352 0.890567 0.801375 0.818978 0.822424 1.0172 0.691102 0.549706 0.534934 1.24641 1.0028 0.889666 1.00607 0.725752 0.501319 0.726178 0.747865 1.53866 0.793495 1.6032 0.66333 0.563601 1.12091 0.698824 0.772963 0.281918 0.563479 0.750472 0.901071 0.769924 0.825226 0.549967 1.72915 1.53105 0.767002 1.07066 1.20302 0.781995 0.558508 0.63426 1.13519 3.74518 0.834001 0.757607 1.12232 1.0194 1.0119 1.22525 1.19256 0.818289 1.60168 0.650131 0.794795 0.663114 1.07447 0.942736 0.563764 0.915853 1.37896 0.607777 0.655001 1.17814 0.988652 0.578385 1.07714 0.32646 0.857094 1.47619 1.32811 0.91894 0.698192 0.585603 0.719609 0.80179 1.54091 1.47632 0.657779 1.28709 0.652863 1.25929 0.497916 1.29284 0.641213 0.62249 0 1.10011 0.593306 0.612819 1.29856 0.686711 0.944921 0.909751 0.794471 0.976828 0.79549 0.453055 0.67286 0.951118 0.92403 0.746764 0.786786 0.598288 0.91584 0.758188 0.678091 0.637469 0.686105 0.696615 0.702422 1.14106 1.01019 0.636453 0.996395 0.987488 0.747878 0.640323 0.807735 0.840377 0.611775 0.860785 0.936105 0.994491 0.192871 0.283874 0.354573 0.728975 0.966008 1.16694 0.603976 0.610043 1.16358 0.398162 0.516569 0.592444 0.46446 0.812543 1.77327 1.12631 0.623074 0.601135 0.469369 1.10974 1.25167 0.930048 0.919087 1.21669 0.846687 0.518673 0.605754 1.0062 0.985435 0.916863 0.927067 1.01239 1.0075 1.92062 0.717233 0.92455 0.929177 1.13801 0.640777 0.461356 0.643374 0.814074 0.701924 1.01739 0.787766 0.907852 0.769163 0.784644 1.34326 1.4744 0.693208 0.611446 0.693261 0.487866 0.735966 1.34119 0.594572 1.2322 0.611835 1.04478 1.06211 1.33089 0.829159 0.600777 1.34785 1.24576 1.05634 0.730476 1.29524 0.687866 0.664709 0.932789 0.632064 0.800382 1.69905 0.5351 0.966351 0.965102 1.27613 0.678805 1.28557 0.744395 0.790177 0.64617 0.463949 0.875291 0.992381 1.13819 1.43906 1.46025 0.873829 1.09358 0.929355 0.578184 0.498401 1.01229 0.7594 0.97572 0.587923 0.809263 1.03584 0.857446 0.527156 0.768826 0.880949 0.716689 0.896483 1.0822 1.83744 0.624659 0.96156 0.541008 0.557816 0.731675 0.901759 1.02746 1.00386 0.785466 1.60455 0.853058 0.456658 0.641307 0.668057 0.410482 0.928679 0.986871 0.858993 0.700805 0.784856 1.07815 1.2263 0.746415 1.03799 1.21546 1.26762 1.88942 1.01013 1.28613 1.15403 0.744545 0.811223 0.818613 0.661015 0.655215 0.822137 0.694939 0.545686 0.550024 0.577116 0.732847 0.562432 1.02408 0.766776 1.26398 0.609426 0.93479 0.265885 0.604914 2.45399 0.55111 1.24127 0.965478 0.542624 3.21171 0.645244 1.28682 0.969194 1.25957 1.77913 0.828735 0.742496 0.590098 0.677415 1.69086 1.22286 0.765053 0.516161 0.958166 2.05455 0.603945 0.990904 1.37646 2.22861 1.02754 0.312166 0.550803 1.32624 0.96631 0.745336 0.824034 1.00398 0.646486 1.61284 1.75841 1.11518 1.49064 1.13892 0.774899 0.988837 0.312611 0.934331 0.74251 0.630912 1.26004 0.789064 0.665495 0.700517 0.517896 1.38206 0.801907 0.650422 0.962161 0.608851 0.791655 1.0761 0.805557 0.531796 2.26786 0.916902 1.03328 0.61338 0.835672 0.295082 0.716324 0.940318 1.23072 0.796749 1.00006 0.795306 0.873223 1.06472 1.29094 0.680319 0.739949 1.56996 0.599096 0.798533 0.596124 0.676862 0.731748 1.1344 0.413282 0.467698 0.789345 0.788749 1.18723 0.697647 0.626671 0.719203 0.762426 1.14965 1.17277 1.44217 2.31351 0.659589 1.07201 0.67469 0.95732 0.609716 1.32441 0.438086 1.49926 0.766824 1.44156 0.517309 0.74968 0.752387 0.512469 1.0218 0.675667 0.424362 1.46962 1.18181 1.05602 1.08683 1.53381 0.768516 0.996793 1.25085 1.42499 0.728122 1.02729 1.26708 0.784112 0.757092 0.711832 0.763768 0.743387 0.714069 0.958293 1.04526 1.01621 0.992257 0.80484 1.98166 0.982969 0.688976 0.60379 0.444038 1.26244 1.08562 0.764399 0.352239 0.861096 0.617706 0.577269 0.538066 0.934398 0.720563 0.907289 0.460301 0.883038 1.31391 1.64571 1.51059 0.999938 1.05681 1.05395 0.49473 0.619209 0.611024 1.3774 1.3746 1.28428 1.40357 0.830284 0.717268 0.509528 1.35343 0.737774 0.821922 0.902107 0.752744 1.8961 0.812554 0.788552 0.851901 2.11224 1.18067 1.06262 0.750438 1.06897 0.964869 0.741395 1.73064 1.16445 1.02407 0.658836 1.14985 0.789001 0.792967 0.824972 1.17875 0.456022 0.759368 0.773795 1.06008 0.789043 1.29894 1.47436 1.42617 1.31497 1.39799 0.641779 0.412821 0.718707 1.05192 1.32586 0.466793 1.24105 0.715724 1.01983 0.754828 0.762239 1.49633 0.618777 0.628543 1.35757 0.863319 1.37655 0.554397 0.810224 0.925673 0.886763 1.28348 1.33427 2.12497 1.04891 1.43333 1.5128 0.284466 1.08431 1.0062 0.984002 0.913565 0.578617 0.736912 0.662468 1.04846 1.25272 0.861162 0.762267 0.66048 0.892997 1.08791 0.527878 2.01032 1.59877 0.815145 1.09046 1.19932 0.555727 0.77799 0.973005 0.819275 0.507266 0.547471 0.315635 0.571363 0.620807 1.14623 0.933654 0.728862 0.718718 0.746696 1.0234 0.643591 1.25952 0.904672 1.22805 1.20306 0.44836 0.646385 0.707512 0.824928 0.655158 0.917076 1.97383 1.50732 1.41506 0.663052 0.776391 1.17575 0.616257 0.321928 2.44329 1.48833 ]
@@@ Frame-accuracy per-class: [ 88.0488 79.668 80.3493 71.2446 88.7805 77.9661 58.9831 87.6014 88.8889 88.2306 96.381 85.3236 91.0995 91.3858 77.4194 80 80.6154 78.5146 82.4742 87.7127 90.971 80.6349 87.4109 82.3762 73.6077 88.3516 79.4366 87.2428 81.7481 90.3981 72.2689 77.8816 80.1444 86.747 95.5195 88.9632 96.0163 94.0195 88.6878 67.0757 61.8182 91.8919 88.5813 68.1188 79.8354 89.9598 63.4198 85.5895 87.4896 93.355 85.6228 56.5905 92.4708 78.0488 89.17 86.9565 37.7358 82.5397 92.5046 65.0919 77.4194 95.082 84.0467 94.9153 75.0789 80.5687 69.0771 78.2609 90.3226 87.8981 88.8688 91.2784 80.3532 86.8496 94.7368 80 86.1856 78.1457 91.5736 73.4007 77.1084 67.5325 92.3741 89.2139 94.5368 79.8179 89.008 90.0662 79.1148 76.3251 87.1287 83.2244 68.9655 80.7799 42.4242 82.1497 85.8573 90.4074 70.5036 89.8135 90.8012 61.8384 57.6687 85.9504 83.6158 88.1678 87.3096 82.0513 89.0966 75.1269 73.5931 56.8807 84.2105 80 43.4783 85.3556 89.5863 92.4092 67.8733 79.5987 83.7945 85.0394 91.3295 58.2677 85.1064 89.1089 84.0125 56.3107 83.3898 74.3719 77.6699 69.071 75.0716 85.4614 73.3591 79.476 80.4674 76.5869 84.058 93.178 74.2081 87.2727 92.4078 85.242 67.1141 74.4526 66.2139 83.7782 90.8146 65.2632 86.3071 68.9655 93.1384 89.8409 78.0781 90.9953 69.2042 77.5385 90.2738 78.0876 85.906 78.7472 0 85.0356 82.1705 80.7018 81.592 93.7876 79.3349 79.7814 78.9272 76.0563 79.3443 92.3767 93.397 91.5254 84.6416 82.9525 63.5071 38.0952 92.6829 88.6957 82.2898 75.4159 73.4884 80.2721 82.449 90.4376 85.8238 78.9625 86.6588 64.8526 87.5502 78.3626 86.6817 97.4359 82.9268 58.6466 90.7801 77.0428 87.7285 93.2465 81.1388 96.7742 61.6822 63.2153 74.9045 72.0257 79.322 75.1773 92.6829 75.6972 83.9945 68.4366 84.0876 89.6552 89.8969 85.1782 80.4408 87.4471 84.0959 86.57 60.4361 79.4326 78.2334 83.2432 89.6406 89.33 66.838 65.6716 83.871 79.7342 74.1401 80.6154 88.2682 87.4552 71.3568 89.4147 86.2944 79.096 93.7063 88.7029 87.0103 90.2857 84.2553 78.7879 93.1646 85.6187 83.0565 88.6836 85.1114 76.7624 55.5256 77.6025 89.5928 85.8054 74.6114 73.0159 69.2557 81.2261 72.5738 90.8297 45.6456 91.358 69.7674 86.3558 76.6169 83.6173 88.6228 82.8729 91.8919 76.0943 88.6406 84.3882 84.7185 84.3243 91.1513 72.7273 87.8187 94.1476 89.8785 91.6905 92.1502 76.6773 83.2117 66.1157 87.2131 84.1226 59.2593 79.1809 92.7059 75.3927 90.4899 81.1808 92.1273 30.303 84.4075 55.873 73.8854 92.7039 76.4045 79.0698 52.9262 58.9928 72.3404 65.6772 72.4458 88.7671 87.9607 79.2982 82.1918 89.9225 89.6861 71.5294 63.6816 78.4141 83.4356 66.6667 62.9108 78.5146 91.8485 87.2375 82.2888 90.1554 53.9185 83.6565 90.5962 74.7331 85.9574 81.6568 85.9813 89.2562 73.2601 56.872 83.4225 83.7209 72.7273 68.9335 82.2511 62.5767 76.2667 91.1877 88.4354 86.6499 88.9336 76.6885 73.251 90.2527 69.3624 74.2268 75.8364 85.5814 66.3212 87.9725 70.5111 54.5455 79.1837 86.6104 73.161 82.3799 55.1724 90.4187 71.7949 68.5879 81.5567 82.7251 60.3175 76.9231 79.4613 86.8817 81.5686 90.4459 68.3544 74.5921 59.5122 90.1532 78.327 82.0189 86.2129 64 85.4071 57.5916 89.927 83.3837 82.7119 80.4781 84.0467 90.9091 91.4761 89.0511 65.2921 83.2215 76.7677 82.0513 80.7947 80.4159 91.018 81.1189 81.2641 74.1722 88.4334 84.3091 90.6649 92.2613 60.251 87.6712 84.2105 86.4865 77.9661 81.1189 59.0258 51.1628 86.6035 87.725 82.0375 83.3492 66.6667 72 88.7273 75.6501 76.7802 77.4566 68.4039 87.7698 11.1675 89.4646 90.5077 52.3077 92.3077 83.7022 47.4074 79.3064 81.6327 88.8417 66.3342 82.6667 66.9604 90.5109 64 79.5789 65.5271 86.9301 80.7018 60.4027 94.026 76.9231 87.4576 84.9673 80.6723 82.3366 64.3392 78.8732 82.4427 96.7742 91.5825 62.029 86.2385 96 92.0188 60.2151 82.6291 68.2135 86.3813 59.9369 83.9827 80 74.7967 74.7082 72.4638 72.0222 87.2247 85.7143 91.8681 88.3721 90.6832 66.3573 85.0242 78.4141 91.8033 87.218 90.5983 60.9626 80.1932 80.4124 86.8293 75.443 81.7481 89.6926 65.6716 82.6347 86.917 62.2837 79.2492 85.8757 83.9757 80 73.955 73.955 78.2842 67.4157 80.7314 79.4055 78.5882 76.0148 74.4939 74.4283 80.367 82.3529 83.9161 84.3564 82.7586 61.9718 75.3316 83.6601 69.9187 57.1429 76.3636 80 68.1004 76.3636 89.9696 85.8757 66.0269 84.1163 88.3019 74.9515 63.9594 78.3099 82.1239 47.0588 77.3109 80 87.2629 80.5031 87.4552 85.0921 55.4839 50.9317 86.1759 83.3058 47.1545 86.7235 57.8462 76.8504 89.3983 77.9874 62.2222 78.5047 74.7764 79.8419 65.6934 80.3738 87.0897 84.0191 81.0198 70.1538 55.6962 74.5098 80 67.5944 80.5369 79.7688 93.5428 68.5714 76.2763 70.9677 71.9665 80.9816 81.5864 72.4528 64.3275 73.0594 82.5561 66.242 81.9407 90.9091 79.668 47.4576 84.8921 72.3353 73.5254 82.5485 77.193 79.3296 69.0167 76.5957 82.9431 92.8839 91.358 68.2635 85.9813 86.9671 64.9215 84.6731 97.1429 82.7586 85.9107 48.2759 73.6842 42.6966 66.6667 89.1455 81.5109 37.0107 78.1955 81.9048 81.1146 65.1685 84.7599 90.6367 70.1754 92.365 53.9535 80.5281 0 72.8551 75.1323 83.2117 66.9834 65.8824 66.6667 89.0756 82.7309 88.4211 60.6061 74.4417 79.7203 80.0618 75.102 73.8028 74.0406 79.4702 74.8815 83.1956 70.6315 65.6085 88.3721 73.6842 88.4848 78.2152 78.6611 88.7469 70.7692 85.6376 85.5895 71.9577 81.6327 72.1495 64.8649 79.2453 94.4882 81.9897 83.7209 77.0764 66.3317 91.4286 76.3557 64.5161 71.8861 73.3032 0 79.1878 67.6364 90.1893 72.1495 80.9224 76.3231 82.0513 89.3528 80.543 87.6877 62.6959 89.6 80.1619 55.1724 68.8525 65.1429 75.7447 78.607 90.6031 86.6764 81.9048 81.6754 75.2613 79.6117 62.7063 83.9319 86.758 85.282 47.0588 66.4247 75.8621 87.0416 82.963 63.4304 85.8388 83.274 44.7205 76.1905 53.3333 74.7253 66.5461 73.8854 51.7375 66.2768 84.8723 80.4233 75.4717 62.4658 71.4829 46.2428 87.3563 76.6284 77.7202 68.1934 88.7967 89.5623 82.4834 86.9565 80.9877 89.9083 89.6116 74.928 85.8513 75.3894 74.7731 64.4195 86.1762 92.3077 72.5275 76.6721 77.3109 57.1429 80.6723 91.2281 62.2222 75.8017 73.5751 87.0466 64.574 81.8898 82.3271 70.3072 87.9227 70.9677 82.0202 63.197 80.8081 74.673 66.3291 69.9029 70.6617 57.1429 84.2975 83.3103 87.3469 58.6826 88.3052 81.1736 81.0811 76.8061 86.5857 84.7682 84.097 89.4309 89.1356 88.3534 79.9154 63.354 88.8889 85.2321 79.8752 71.8615 62.069 89.8354 78.8732 71.5596 84.058 77.3619 72.1127 83.7758 66.0422 88.67 77.8761 86.4865 79.2453 81.5451 82.3821 63.4271 82.6152 86.4865 81.6143 80.8511 85.8447 77.9874 74.6667 77.13 59.2 53.6965 85.3598 86.465 79.5812 81.7486 83.9161 80.6557 87.9271 87.3977 71.5026 79.3734 65.1341 84.5011 82.7586 55.9441 85.5305 80.7095 90.6445 84.9604 67.6423 60.686 79.0514 58.0645 77.314 85.0794 83.7274 40 91.1392 35.2941 78.0115 86.9736 74.9336 83.3667 81.3483 90.2128 73.5632 87.3051 73.5892 70.4981 58.498 90.1099 68.1115 74.5875 78.6885 78.5924 77.8135 77.5599 80 42.2764 80.4178 74.0157 82.7839 66.6667 72.661 62.6506 87.2964 78.7472 92.9577 86.4939 89.2885 65.0718 83.9216 84.2105 69.4737 80.6134 87.1143 77.6573 61.674 83.1889 55.814 80.4979 74.5763 85.7143 72.2611 77.9874 60.1399 70.8415 47.9638 74.1748 74.8387 77.6371 52.6316 81.4815 42.3358 70.936 74.0157 72.7634 78.9916 82.2888 66.9323 57.732 75.0733 66.1728 59.8608 58.4475 67.4948 74.3034 87.8505 87.6791 91.2281 80.663 64.8379 82.8283 57.5163 81.0811 74.3034 74.8644 85.3933 93.8053 77.2384 90.6035 70.8661 43.6782 89.0323 81.8482 72.6644 70.2413 92.8775 65.9829 88.2129 81.4988 61.2717 88.8889 82.0702 82.9493 69.5652 85.9316 78.6346 76.0563 66.9604 60.8187 87.2367 80.9816 83.905 91.7431 68.7783 82.3529 91.3343 72.4234 76.2551 77.4194 67.7507 79.4007 74.6736 86.619 57.8834 76.3557 74.1797 75.8324 78.9429 65.5518 67.4016 82.8897 78.245 77.2277 77.314 78.2609 80 67.5325 77.4908 86.2958 87.6091 56.7237 64.7273 77.0302 73.7864 81.4815 89.7862 80.6236 79.638 57.6577 77.686 58.2781 83.4783 85.4321 64.51 81.0811 79.0378 90.963 87.5912 78.628 70.6383 69.3069 75.5877 88.0383 50.5495 58.4958 80.5195 70.1754 62.6866 78.1491 86.0238 81.0811 70.1579 0 75.5906 80 67.5052 73.8028 75.7709 88.4211 68.0739 80.3987 47.8134 78.5479 77.135 86.0104 65.2632 66.4093 83.4109 74.3961 58.6826 77.3067 80.9384 68.4685 69.5652 85.4054 68.5832 89.7877 75.8148 60.0823 65.6891 71.5213 84.2105 87.9725 78.481 81.2721 59.2593 54.1872 80 61.5385 81.791 70.5882 87.34 57.3816 82.8645 82.3373 0 68.8391 82.959 83.8446 55.3459 81.1092 73.8462 73.8197 72.3326 67.1727 76.399 85.9813 80.32 75.841 75.8893 80.3604 85.0575 85.4369 75.7679 81.6 80.8664 83.5165 81.7518 80.8743 79.0123 68.6391 72.2892 84.5953 70.4607 74.1259 73.6842 80.427 72.4947 77.6758 87.7108 67.6259 73.6306 74.8466 95.0962 92.1692 92.911 82.2633 71.068 64.0827 83.2787 84.2884 67.0565 90.5109 84.8665 83.6364 89.8876 81.9672 44.9704 70.632 87.0185 84.586 86.2327 71.1656 54.7945 72.2022 73.7864 67.8899 76.1421 83.5949 86.4865 70.615 77.4869 68.5057 61.9946 73.9726 72.0257 40.367 80.8574 69.5464 77.3869 69.8305 83.6364 85.94 80.8511 77.9487 75.9443 78.6026 82.4798 70.073 75.8621 75.9796 68.9266 56.305 76.2416 87.8049 84.0404 90.5028 80.109 58.6271 84.6395 57.6803 83.5282 77.6903 72.7273 79.4521 75.9546 80.3987 63.1579 64.6865 67.8967 79.8186 66.3484 76.4543 76.9507 74.2857 84.2105 79.1171 48.6772 89.043 68.2927 76.1506 69.011 80 57.6271 78.3217 76.8212 81.2589 86.3071 74.3539 73.029 67.9612 67.4352 54.1806 75.3452 70.1299 73.1219 82.6446 86.052 76.5101 80.6557 67.8414 80.4598 70.1754 69.5971 75.6821 86.5801 81.3397 77.5258 77.0241 71.3978 81.4815 45.3782 81.1463 72.2955 83.6653 85.4209 79.3249 74.7804 74.2515 74.8624 79.0378 48.1013 80.1223 87.79 85.9016 82.2511 91.3343 76.5027 70.632 81.8792 78.7318 77.9221 74.4828 64.7975 80.8989 70.5202 65.1072 73.8739 52.1739 75.8105 63.0197 67.9537 80.6154 74.6507 74.0061 88.4956 87.1046 82.6884 81.1502 85.5249 81.0563 88.4005 84.9558 85.7685 71.4653 79.8226 55.2764 81.0329 74.0947 89.9787 82.5789 32.2188 85.5124 73.2919 68.4636 86.4553 0 87.1795 50.8475 73.2075 64.0964 53.0466 74.4186 77.9553 87.9433 84.8485 44.4444 66.1597 77.0053 86.0177 73.4967 46.1538 84.1699 67.6923 66.6667 37.037 61.5525 92.9461 84.472 65.233 71.2042 77.9221 72.5581 74.5491 82.1577 54.6201 45.7666 58.0645 55.3191 63.9004 76.8439 67.9245 92.8155 75.5668 88.8889 81.389 56.4565 88.8889 82.0582 77.9939 86.6286 51.9337 77.193 85.2321 74.4986 88.685 72.6944 66.6667 78.9644 88.0383 44.8669 73.8956 68.5624 85.5721 77.9082 93.9044 77.8032 68.6131 68.9655 88.5246 68.3301 80.6387 77.0302 64.135 54.7529 77.7385 68.1319 55.5133 83.2184 80.4805 83.1169 82.7004 79.0698 66.3477 88.3549 85.1274 70.852 79.0303 67.9245 84.3537 83.84 77.7219 77.2462 64.0974 73.2892 63.3094 30.5221 81.4913 59.854 84.7761 78.4 88.0694 62.4685 89.426 55.1253 79.2157 62.4672 86.8914 80.6537 78.3217 87.191 66.4723 78.2274 87.781 52.8814 73.2919 76.6265 65.2807 48 79.8226 72.3404 61.6822 65.7778 77.9661 75.7202 66.6667 79.0698 76.2542 81.0478 78.7363 75.3507 81.592 81.9277 65.9176 74.4008 75.9536 81.0631 49.6 74.4646 79.7084 82.6446 97.2973 65.1584 70.4871 71.6049 94.2966 80 82.7443 85.9729 89.2794 71.9258 80.427 78.6026 86.4646 71.5447 62.9213 63.9175 52.0548 71.8232 69.3069 54.0541 85.6904 82.7225 80 69.0647 59.5041 64.0429 61.0909 79.1789 81.4664 85.5615 58.2677 80.0681 83.4043 76.2332 77.2414 39.3443 73.8255 75.9494 79.558 43.9359 65.0602 76.0807 81.3614 68.1733 74.9035 81.9113 43.9024 73.3542 72.7273 82.4588 67.6923 82.0942 70.5502 79.1334 55.2381 87.6638 82.0771 80.9176 64.9351 79.5009 65.098 55.6391 61.9883 61.6541 52.8302 85.1948 94.8148 80.5604 68.6499 71.8615 88.4507 67.6364 82.4903 69.3603 81.9333 80.7122 54.9521 86.0286 82.7757 62.2222 84.4622 69.8225 84.3273 74.9206 73.4793 71.9449 62.7566 61.9325 33.5664 68.2274 59.3156 46.5753 94.9153 67.7316 71.8232 75.6757 74.7352 82.7586 80.7864 84.3636 68.535 65.2921 71.3826 78.2369 81.3161 76.0396 73.6 84.5638 50.1587 50.3464 81.4159 75.162 65.7963 86.3233 79.322 68.0352 79.1541 85.4185 85.2359 92.5852 85.0987 83.78 56.3758 72.5648 78.6026 82.5397 81.3142 71.0335 82.3529 65.1163 72.967 61.4719 55.3459 89.4602 88.6598 80.877 77.8626 84.472 71.2329 40.5904 51.9337 60.3248 83.4043 78.1671 54.2056 85.1197 91.7115 28.8 54.6584 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 0.695357 (Xent), [AvgXent: 0.695357, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 80.5583% <<

