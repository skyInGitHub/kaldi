nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.000125 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter09_learnrate0.00025_tr0.7089_cv1.7136 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter10 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975016
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
ali-to-post ark:- ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.81539, max 8.96107, mean 0.00568746, stddev 0.99447, skewness 0.129835, kurtosis 2.1535 ) 
[1] output of <AffineTransform> ( min -29.3725, max 24.9501, mean -3.40386, stddev 4.09789, skewness 0.1227, kurtosis 1.24042 ) 
[2] output of <Sigmoid> ( min 1.75265e-13, max 1, mean 0.205, stddev 0.314627, skewness 1.50163, kurtosis 0.784611 ) 
[3] output of <AffineTransform> ( min -29.4936, max 15.1547, mean -4.07598, stddev 2.74905, skewness -0.0587882, kurtosis 2.17805 ) 
[4] output of <Sigmoid> ( min 1.55273e-13, max 1, mean 0.0956143, stddev 0.190147, skewness 2.94507, kurtosis 8.62891 ) 
[5] output of <AffineTransform> ( min -14.1419, max 10.7239, mean -3.08878, stddev 1.93868, skewness 0.531146, kurtosis 2.12847 ) 
[6] output of <Sigmoid> ( min 7.21553e-07, max 0.999978, mean 0.113427, stddev 0.185658, skewness 2.75179, kurtosis 7.76965 ) 
[7] output of <AffineTransform> ( min -20.4746, max 17.2588, mean -2.75225, stddev 2.26092, skewness 0.520376, kurtosis 2.42531 ) 
[8] output of <Sigmoid> ( min 1.28232e-09, max 1, mean 0.157014, stddev 0.233309, skewness 2.03648, kurtosis 3.43662 ) 
[9] output of <AffineTransform> ( min -16.7738, max 17.2495, mean -2.81872, stddev 2.86221, skewness 1.30227, kurtosis 2.43424 ) 
[10] output of <Sigmoid> ( min 5.19071e-08, max 1, mean 0.179905, stddev 0.292891, skewness 1.75221, kurtosis 1.70324 ) 
[11] output of <AffineTransform> ( min -31.0555, max 25.3481, mean -3.66569, stddev 3.65807, skewness 0.96254, kurtosis 3.03273 ) 
[12] output of <Sigmoid> ( min 3.25661e-14, max 1, mean 0.152059, stddev 0.297805, skewness 2.01332, kurtosis 2.51327 ) 
[13] output of <AffineTransform> ( min -15.1443, max 24.7773, mean -0.0190909, stddev 3.68333, skewness 0.522779, kurtosis 0.92655 ) 
[14] output of <Softmax> ( min 4.5964e-16, max 0.999963, mean 0.000657833, stddev 0.019479, skewness 40.1847, kurtosis 1738.15 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.74634, max 1.51236, mean -0.000170603, stddev 0.0534591, skewness -0.303377, kurtosis 40.0478 ) 
[1] diff-output of <AffineTransform> ( min -0.423469, max 0.344903, mean 1.19101e-05, stddev 0.0101008, skewness 0.274393, kurtosis 90.2146 ) 
[2] diff-output of <Sigmoid> ( min -1.7643, max 1.80423, mean 0.000483607, stddev 0.0915401, skewness 0.175698, kurtosis 18.0751 ) 
[3] diff-output of <AffineTransform> ( min -0.421863, max 0.495007, mean -4.85538e-06, stddev 0.011466, skewness 0.106484, kurtosis 114.727 ) 
[4] diff-output of <Sigmoid> ( min -2.2751, max 2.0295, mean 0.000338439, stddev 0.126048, skewness -0.0153961, kurtosis 16.8615 ) 
[5] diff-output of <AffineTransform> ( min -0.533821, max 0.34602, mean 1.35454e-05, stddev 0.0119977, skewness -0.112168, kurtosis 84.1641 ) 
[6] diff-output of <Sigmoid> ( min -2.18407, max 1.82366, mean 0.00040858, stddev 0.102612, skewness -0.0210077, kurtosis 17.0138 ) 
[7] diff-output of <AffineTransform> ( min -0.285045, max 0.228736, mean 1.7689e-05, stddev 0.00966973, skewness -0.185744, kurtosis 50.0586 ) 
[8] diff-output of <Sigmoid> ( min -1.38042, max 1.16072, mean 0.000226853, stddev 0.0709277, skewness -0.0306223, kurtosis 16.0269 ) 
[9] diff-output of <AffineTransform> ( min -0.257164, max 0.158252, mean 1.53356e-05, stddev 0.00707219, skewness -0.387627, kurtosis 58.7668 ) 
[10] diff-output of <Sigmoid> ( min -1.1387, max 0.794699, mean 0.000220757, stddev 0.0539907, skewness -0.101737, kurtosis 19.0296 ) 
[11] diff-output of <AffineTransform> ( min -0.222548, max 0.214042, mean 8.77955e-07, stddev 0.00781428, skewness -0.309688, kurtosis 66.2715 ) 
[12] diff-output of <Sigmoid> ( min -2.17947, max 1.34039, mean -0.000471386, stddev 0.0823416, skewness -0.187214, kurtosis 11.2297 ) 
[13] diff-output of <AffineTransform> ( min -0.995923, max 0.935719, mean -4.43113e-09, stddev 0.0155715, skewness -26.9188, kurtosis 2304.75 ) 
[14] diff-output of <Softmax> ( min -0.995923, max 0.935719, mean -4.43113e-09, stddev 0.0155715, skewness -26.9188, kurtosis 2304.75 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.75824, max 1.61053, mean -0.000464068, stddev 0.161064, skewness 0.00348432, kurtosis 2.09654 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.483938, max 0.545466, mean 0.003049, stddev 0.150011, skewness -0.072488, kurtosis 0.393013 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.927859, max 0.852879, mean -0.000159542, stddev 0.0690252, skewness -6.9308e-05, kurtosis 6.04208 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.813821, max 0.87847, mean -0.00124298, stddev 0.175202, skewness 0.0531422, kurtosis 1.9149 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.779741, max 0.666721, mean 0.000371079, stddev 0.0399788, skewness -0.115981, kurtosis 11.9043 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.921807, max 0.650419, mean 0.00346762, stddev 0.171717, skewness -0.0170418, kurtosis 1.96049 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.427208, max 0.440861, mean 0.000578494, stddev 0.0328483, skewness -0.0437892, kurtosis 8.85903 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.635539, max 0.484207, mean 0.00452835, stddev 0.140631, skewness -0.12956, kurtosis 1.88042 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.444896, max 0.312499, mean 0.000562077, stddev 0.031006, skewness -0.0785274, kurtosis 6.78468 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.441103, max 0.353956, mean 0.00392594, stddev 0.104021, skewness -0.036154, kurtosis 1.88195 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.576369, max 0.361999, mean 0.000156936, stddev 0.04247, skewness -0.135144, kurtosis 7.24322 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.664877, max 0.40824, mean 0.000224773, stddev 0.12101, skewness -0.199387, kurtosis 2.38318 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.19742, max 2.01748, mean -1.81605e-08, stddev 0.0844965, skewness -4.41823, kurtosis 75.5251 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.61787, max 1.37971, mean -6.90159e-09, stddev 0.24801, skewness -1.61588, kurtosis 10.2146 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 342784 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -6.78548, max 7.66488, mean 0.00618661, stddev 0.998336, skewness 0.126755, kurtosis 2.01683 ) 
[1] output of <AffineTransform> ( min -29.2669, max 24.8149, mean -3.37517, stddev 4.13065, skewness 0.142626, kurtosis 1.21464 ) 
[2] output of <Sigmoid> ( min 1.94786e-13, max 1, mean 0.208125, stddev 0.31761, skewness 1.47822, kurtosis 0.700526 ) 
[3] output of <AffineTransform> ( min -31.3804, max 18.1415, mean -4.0821, stddev 2.79076, skewness -0.0565245, kurtosis 2.19284 ) 
[4] output of <Sigmoid> ( min 2.35315e-14, max 1, mean 0.0974984, stddev 0.19341, skewness 2.90063, kurtosis 8.28843 ) 
[5] output of <AffineTransform> ( min -13.7927, max 11.2998, mean -3.09073, stddev 1.96601, skewness 0.530935, kurtosis 2.19792 ) 
[6] output of <Sigmoid> ( min 1.02304e-06, max 0.999988, mean 0.11466, stddev 0.187802, skewness 2.72441, kurtosis 7.5604 ) 
[7] output of <AffineTransform> ( min -21.1892, max 16.9417, mean -2.74685, stddev 2.28585, skewness 0.522644, kurtosis 2.44292 ) 
[8] output of <Sigmoid> ( min 6.2752e-10, max 1, mean 0.158631, stddev 0.235475, skewness 2.01863, kurtosis 3.33851 ) 
[9] output of <AffineTransform> ( min -16.5977, max 17.3522, mean -2.80776, stddev 2.88555, skewness 1.30949, kurtosis 2.46608 ) 
[10] output of <Sigmoid> ( min 6.19006e-08, max 1, mean 0.181669, stddev 0.29494, skewness 1.73214, kurtosis 1.61735 ) 
[11] output of <AffineTransform> ( min -27.9536, max 22.3879, mean -3.66669, stddev 3.67048, skewness 0.970911, kurtosis 2.97063 ) 
[12] output of <Sigmoid> ( min 7.24266e-13, max 1, mean 0.153069, stddev 0.299155, skewness 1.99887, kurtosis 2.44878 ) 
[13] output of <AffineTransform> ( min -15.8557, max 23.292, mean -0.0186028, stddev 3.68626, skewness 0.545816, kurtosis 0.98407 ) 
[14] output of <Softmax> ( min 1.71279e-15, max 0.997733, mean 0.000657834, stddev 0.0193819, skewness 39.5497, kurtosis 1688.72 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.11493, max 1.30382, mean -0.000281879, stddev 0.0456505, skewness 0.181724, kurtosis 31.705 ) 
[1] diff-output of <AffineTransform> ( min -0.24046, max 0.323001, mean 2.91201e-05, stddev 0.00863172, skewness 0.399337, kurtosis 73.8181 ) 
[2] diff-output of <Sigmoid> ( min -1.38563, max 1.53885, mean -0.000126304, stddev 0.0783865, skewness 0.0012925, kurtosis 17.0154 ) 
[3] diff-output of <AffineTransform> ( min -0.267428, max 0.361699, mean 2.62594e-05, stddev 0.00970465, skewness 0.357145, kurtosis 93.1407 ) 
[4] diff-output of <Sigmoid> ( min -1.46809, max 1.51258, mean -1.29987e-05, stddev 0.104982, skewness -0.00368392, kurtosis 12.6305 ) 
[5] diff-output of <AffineTransform> ( min -0.282335, max 0.270905, mean 2.51521e-05, stddev 0.0100828, skewness 0.00592414, kurtosis 59.611 ) 
[6] diff-output of <Sigmoid> ( min -1.1986, max 1.40205, mean 7.68391e-05, stddev 0.0873276, skewness 0.0279487, kurtosis 13.6597 ) 
[7] diff-output of <AffineTransform> ( min -0.228974, max 0.227732, mean 1.96079e-05, stddev 0.00826652, skewness 0.205019, kurtosis 50.0268 ) 
[8] diff-output of <Sigmoid> ( min -0.927121, max 0.938439, mean 0.000227786, stddev 0.0610594, skewness 0.0108019, kurtosis 15.0293 ) 
[9] diff-output of <AffineTransform> ( min -0.158468, max 0.13368, mean 1.16272e-05, stddev 0.00612591, skewness -0.34077, kurtosis 54.3021 ) 
[10] diff-output of <Sigmoid> ( min -0.883952, max 0.773952, mean 8.8169e-05, stddev 0.0470663, skewness -0.121933, kurtosis 19.8841 ) 
[11] diff-output of <AffineTransform> ( min -0.242572, max 0.216544, mean -3.0593e-07, stddev 0.00693641, skewness -0.410273, kurtosis 85.8912 ) 
[12] diff-output of <Sigmoid> ( min -2.64501, max 2.19131, mean 0.000242735, stddev 0.0744541, skewness -0.242109, kurtosis 24.5829 ) 
[13] diff-output of <AffineTransform> ( min -0.99995, max 0.958516, mean -5.66146e-09, stddev 0.0137337, skewness -25.0121, kurtosis 2412.86 ) 
[14] diff-output of <Softmax> ( min -0.99995, max 0.958516, mean -5.66146e-09, stddev 0.0137337, skewness -25.0121, kurtosis 2412.86 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.46602, max 1.67262, mean -0.0010545, stddev 0.132441, skewness -0.00820609, kurtosis 2.16232 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.647265, max 0.643086, mean 0.00745473, stddev 0.153552, skewness -0.012845, kurtosis 1.10042 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.580876, max 0.757834, mean 0.00154813, stddev 0.0603122, skewness 0.080017, kurtosis 6.09307 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.795704, max 0.887508, mean 0.00672243, stddev 0.172649, skewness 0.167954, kurtosis 2.76531 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.746847, max 0.66095, mean 0.000652693, stddev 0.0365606, skewness -0.00537207, kurtosis 13.1567 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.06208, max 0.772271, mean 0.00643893, stddev 0.187836, skewness -0.0938187, kurtosis 3.05633 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.457214, max 0.44939, mean 0.000593379, stddev 0.0305848, skewness -0.0865813, kurtosis 9.61991 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.722655, max 0.669444, mean 0.00501963, stddev 0.150302, skewness -0.0965385, kurtosis 1.97474 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.429988, max 0.367121, mean 0.00043212, stddev 0.0291516, skewness -0.257385, kurtosis 8.809 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.625244, max 0.562191, mean 0.00297657, stddev 0.109005, skewness -0.298329, kurtosis 3.91512 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.503887, max 0.484091, mean 4.47215e-05, stddev 0.0401919, skewness -0.130165, kurtosis 9.72101 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.600862, max 0.555315, mean -7.83259e-05, stddev 0.123437, skewness -0.140732, kurtosis 3.5162 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.4685, max 3.06361, mean -2.34858e-08, stddev 0.0777763, skewness -2.97351, kurtosis 129.014 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.08661, max 2.08287, mean -9.72497e-09, stddev 0.233982, skewness -1.15847, kurtosis 22.0367 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0782419 min, processing 73018 frames per sec; i/o time 5.17222%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14111 120 114 116 102 29 147 431 139 624 262 548 95 133 232 62 162 188 145 264 293 157 210 252 206 227 177 121 194 213 59 160 138 41 524 149 489 359 331 244 27 18 144 252 121 124 944 114 5399 17569 1561 284 471 20 632 126 26 94 273 190 263 30 128 442 158 105 525 11 77 78 552 418 679 528 1016 172 727 226 492 148 41 38 347 273 210 329 186 75 361 141 50 229 14 179 16 260 399 380 208 348 168 179 81 181 88 1263 98 58 160 98 115 54 66 62 11 119 350 151 110 448 126 190 86 63 70 151 159 154 147 99 51 457 174 395 129 114 299 480 34 300 110 192 230 423 223 68 294 243 288 142 120 14 444 408 166 105 144 162 529 125 74 223 6 210 64 142 100 249 210 274 130 35 152 111 628 206 146 284 105 10 20 172 279 270 107 661 122 308 130 173 423 220 622 85 221 292 20 66 211 128 191 614 140 15 160 183 392 155 147 70 20 125 365 508 342 43 242 266 181 354 229 517 160 211 158 92 236 201 194 33 15 451 392 162 89 139 99 401 98 88 71 358 242 87 117 16 197 149 150 216 426 191 185 158 110 313 96 94 154 130 118 114 166 121 21 289 100 381 83 90 18 148 268 118 186 92 525 93 176 196 123 174 146 156 68 60 152 179 13 146 212 95 173 135 298 16 240 157 78 116 133 150 196 69 70 269 161 182 203 142 109 580 111 212 100 113 81 22 106 188 435 309 183 96 159 180 813 140 117 84 160 60 136 105 93 279 49 323 115 81 187 130 220 198 248 229 121 138 321 339 134 107 289 145 381 16 122 414 251 218 14 704 214 173 295 205 31 188 148 232 127 78 197 214 102 228 131 158 286 12 325 95 342 165 147 125 128 38 240 479 145 74 148 97 75 288 83 71 221 75 341 213 744 497 119 182 123 166 206 71 174 21 369 305 186 525 28 62 137 211 161 86 153 69 98 289 226 97 32 248 67 432 171 470 200 262 113 68 112 237 175 493 28 74 192 110 147 76 178 359 200 35 65 15 148 172 163 12 106 46 106 215 128 158 115 37 61 128 34 180 113 80 227 21 80 215 103 113 91 332 175 93 103 339 102 197 194 276 33 250 439 144 479 88 246 22 155 155 186 44 355 235 212 135 123 240 272 212 71 252 101 106 188 76 61 17 82 47 139 27 164 88 260 223 132 257 98 177 282 25 59 247 184 238 139 298 77 80 278 302 61 410 162 317 174 79 22 160 279 126 205 160 228 522 176 162 39 25 152 251 223 86 286 122 166 15 119 81 176 132 85 109 289 78 185 137 361 29 347 417 364 180 85 89 269 23 149 133 121 83 160 410 95 466 17 101 145 14 66 44 19 216 251 140 66 52 161 311 239 133 142 268 107 151 0 355 94 68 210 42 10 178 124 47 82 201 71 323 122 177 221 226 105 181 815 94 322 180 82 190 119 1408 32 372 114 94 24 267 55 79 63 291 21 150 99 752 230 170 140 110 8 98 137 290 267 238 179 97 239 110 166 159 62 123 14 30 87 117 100 356 341 52 95 143 51 151 264 109 363 8 275 14 204 202 154 229 140 80 115 52 45 276 235 129 256 254 94 238 182 131 86 130 130 96 196 120 148 225 34 202 54 553 173 208 160 275 133 618 6 45 306 59 45 178 28 112 171 289 96 111 63 455 146 103 77 247 134 346 420 197 51 400 17 181 362 122 83 799 204 92 131 1688 75 185 61 630 124 236 80 58 118 320 115 14 516 106 54 103 280 177 169 213 101 56 536 291 116 201 195 336 18 111 70 109 79 37 111 187 128 201 1008 95 457 71 152 219 305 96 191 130 235 14 71 155 225 240 189 307 189 632 15 275 157 359 52 39 8 261 510 564 249 222 352 43 224 221 130 126 45 161 151 30 170 155 229 37 61 191 190 136 49 411 41 153 223 35 366 639 104 127 85 142 456 275 230 113 288 21 120 29 17 214 79 214 255 110 257 77 118 218 13 68 101 63 251 59 183 125 145 170 202 215 109 241 161 267 174 256 90 200 49 76 92 161 276 222 56 463 654 317 130 77 151 144 186 175 292 131 213 86 220 270 108 57 131 395 106 113 85 403 81 189 54 110 144 363 179 368 232 184 400 191 489 231 230 350 465 586 149 317 131 273 50 275 11 97 38 135 368 286 204 137 215 257 418 210 224 110 55 60 75 172 202 525 277 145 337 68 189 117 50 276 313 136 179 423 28 167 194 461 203 601 9 190 227 238 177 113 47 189 451 171 151 181 96 142 129 322 103 83 200 170 55 11 92 243 494 291 121 170 693 104 145 434 141 13 101 57 58 167 42 351 179 195 376 0 245 378 244 79 288 97 116 1082 263 205 374 312 163 126 277 43 154 146 187 138 227 205 91 202 84 124 191 184 214 123 421 234 163 207 69 392 407 805 555 331 459 257 193 152 270 256 205 168 82 44 30 84 134 350 392 468 81 109 138 51 163 98 350 55 219 95 217 185 182 155 54 676 231 99 147 82 316 70 292 251 114 185 205 101 293 88 170 372 143 247 89 183 269 159 159 470 190 148 36 484 150 85 151 135 220 209 180 557 157 313 294 94 360 143 119 227 207 88 71 75 349 843 251 120 51 173 149 253 192 299 302 211 74 152 113 43 85 136 421 115 104 242 228 232 13 59 331 189 125 243 355 398 250 272 145 118 163 1961 152 115 363 91 134 74 378 346 72 160 400 86 256 55 11 200 228 129 162 250 490 56 205 245 156 452 435 409 169 263 194 225 99 561 179 234 364 164 141 80 185 173 8 19 29 132 207 139 64 156 211 16 76 131 93 282 224 71 388 32 160 40 547 120 241 139 286 192 752 249 120 243 218 46 211 120 291 79 257 198 13 1281 166 13 738 488 437 90 370 118 174 163 276 49 154 104 131 124 316 100 468 303 218 68 14 30 260 250 215 829 131 141 45 131 217 166 115 118 64 313 270 608 334 412 132 73 312 298 428 246 226 69 124 375 68 167 62 230 198 165 219 127 190 133 948 357 222 171 259 511 147 80 207 240 212 225 164 53 112 147 121 25 150 149 324 411 249 100 41 133 521 301 150 62 303 411 60 18 110 174 40 394 52 240 331 284 215 421 114 247 430 133 48 109 90 50 18 1198 95 97 208 60 279 137 170 245 280 190 293 117 334 217 91 223 276 271 218 124 173 308 265 129 146 20 159 258 333 162 477 154 438 52 1106 298 479 38 841 127 66 85 66 26 192 67 285 218 115 177 412 385 148 434 168 156 454 403 22 125 84 360 157 205 290 170 429 71 149 131 109 88 156 90 129 330 14 559 412 392 145 155 181 425 252 187 74 157 216 56 231 191 281 147 170 165 579 328 249 278 354 74 559 114 283 243 343 212 193 227 115 79 194 48 410 65 80 109 135 90 215 117 185 53 480 464 62 80 ]
@@@ Loss per-class: [ 0.309242 0.702988 0.736823 0.800662 0.54286 0.812339 1.55327 0.487415 0.45305 0.431613 0.216223 0.461457 0.483795 0.461338 0.818904 0.686885 0.64764 0.783879 0.575175 0.431851 0.360856 0.608324 0.325067 0.729627 0.884962 0.349981 0.74071 0.462206 0.638277 0.35096 0.800758 0.800919 0.846044 0.686911 0.188637 0.3913 0.173837 0.248215 0.455998 1.21021 1.17749 1.02109 0.348826 0.944183 0.806572 0.343519 0.757286 0.668514 0.413182 0.214148 0.445439 1.22892 0.334986 0.757906 0.432565 0.569317 1.30168 0.696718 0.266691 1.11646 0.688778 0.477277 0.570482 0.251544 1.06531 0.735592 0.998016 0.789292 0.448236 0.620229 0.503244 0.334278 0.608815 0.505008 0.193909 0.585526 0.539093 0.809731 0.276986 0.899443 0.810418 0.980959 0.316472 0.420506 0.347635 0.801347 0.396226 0.363517 0.710476 0.954011 0.550415 0.523773 1.13179 0.531931 1.31498 0.641328 0.658391 0.418886 0.976845 0.374007 0.404405 1.25684 1.14396 0.538884 0.605823 0.419087 0.558533 0.754778 0.490813 0.871656 0.769959 1.19664 0.549031 0.736836 1.68843 0.67762 0.427548 0.368403 1.21062 0.856743 0.546899 0.595957 0.568298 1.34495 0.653518 0.617948 0.606495 1.12376 0.677346 1.12975 0.841355 1.00931 0.862865 0.50492 0.759555 0.528014 0.703278 0.816306 0.763353 0.326524 1.02643 0.488057 0.378793 0.553035 1.15157 0.756502 1.21972 0.572423 0.354104 1.25875 0.473734 1.23947 0.236875 0.451102 0.684144 0.487363 1.21354 0.845859 0.441785 0.882749 0.630341 0.838149 1.97093 0.637838 0.587893 0.566928 0.776624 0.3065 0.884799 0.604118 0.658823 0.863058 0.646989 0.4021 0.315312 0.340174 0.606334 0.585539 1.1602 1.64527 0.528215 0.493362 0.756164 0.902262 0.854981 0.686712 0.703666 0.391075 0.446852 0.863941 0.485272 1.20937 0.3624 0.707386 0.458233 0.203082 1.16641 1.0674 0.356019 0.736619 0.476629 0.321444 0.69718 0.641522 1.45515 1.29631 0.871261 0.987516 0.735906 0.874154 0.31783 1.0978 0.649023 1.20013 0.517958 0.446404 0.325783 0.670872 0.806183 0.430197 0.589135 0.470554 1.42545 0.905092 0.763432 0.534683 0.488425 0.512572 1.00557 1.00058 0.904265 0.780632 0.935032 0.62477 0.845035 0.486298 1.12212 0.494951 0.558152 0.75132 0.316033 0.409855 0.542814 0.387902 0.676394 1.01622 0.307875 0.552339 0.646815 0.489649 0.49678 0.630266 1.2896 0.690852 0.502549 0.544109 0.841999 0.89513 1.01983 0.715523 0.845637 0.325446 1.23066 0.378249 1.09482 0.543343 0.764499 0.558844 0.653095 0.69437 0.477156 0.783581 0.457038 0.513431 0.625399 0.52395 0.38421 0.805481 0.489558 0.295594 0.485563 0.465733 0.408341 1.00972 0.743706 1.80229 0.466506 0.528674 1.0921 0.781934 0.268991 0.88136 0.437069 0.647522 0.344077 2.0722 0.675413 1.52133 0.910667 0.439175 0.879581 0.848326 1.35816 1.27134 1.095 1.06612 0.928284 0.445068 0.470514 0.589851 0.658188 0.42921 0.524564 0.960429 1.09089 0.872763 0.637681 0.853797 1.19482 0.820367 0.348079 0.415553 0.596457 0.488589 1.40472 0.713147 0.404097 0.838944 0.429031 0.955534 0.534655 0.433857 0.749925 1.4973 0.61653 0.665204 0.977503 1.06313 0.692551 1.10778 0.83344 0.432928 0.371899 0.542835 0.44302 0.779396 0.973579 0.374345 1.07058 0.875737 0.858341 0.693488 1.22407 0.505216 1.07363 1.37414 0.808579 0.40705 0.85326 0.594851 1.7097 0.342112 1.12009 1.03328 0.733064 0.641405 1.45665 0.863254 0.699918 0.504249 0.828094 0.422208 1.15239 0.762231 1.33435 0.464116 0.789618 0.692802 0.527122 1.51873 0.525614 1.41891 0.436285 0.604502 0.679556 1.01552 0.643951 0.54985 0.373899 0.412098 1.12305 0.615092 0.785894 0.704769 0.758374 0.627087 0.466362 0.74484 0.684788 1.04438 0.440397 0.679355 0.422362 0.272287 1.48335 0.480813 0.508084 0.640727 0.781224 0.792445 1.3799 1.34899 0.48872 0.413331 0.796357 0.579148 1.44636 1.02551 0.360648 0.806406 0.772512 0.825778 1.06417 0.666579 3.10424 0.39877 0.344431 1.90991 0.644761 0.518817 1.74218 0.829477 0.702432 0.364754 1.03204 0.682344 1.20682 0.371301 1.11472 0.76831 0.967871 0.569158 1.04198 1.24269 0.309745 0.825883 0.565637 0.505769 0.73238 0.607456 1.17805 0.726709 0.552514 0.519 0.401962 1.15815 0.480001 0.590753 0.497347 1.34279 0.578756 0.978857 0.45427 1.21537 0.613106 0.717145 0.716685 0.862369 0.876447 0.893126 0.541726 0.544721 0.39411 0.731768 0.501656 0.975899 0.774215 0.829166 0.39846 0.524712 0.400649 1.27358 0.798506 0.699996 0.496346 0.875732 0.634278 0.454742 1.07816 0.68039 0.5392 1.17596 0.743635 0.495874 0.57457 0.768406 0.87336 1.03588 0.890584 1.163 0.724186 0.603292 0.729259 1.03209 1.0182 0.948319 0.700322 0.603397 0.566208 0.58662 0.684867 1.42973 0.837142 0.569202 1.12115 1.5621 0.800301 0.768839 1.13725 0.861079 0.323232 0.499715 1.15226 0.748655 0.408894 0.975319 1.18548 0.95442 0.70203 1.98555 0.689529 0.741377 0.621843 0.660955 0.533291 0.442303 1.21948 1.77357 0.581152 0.644292 1.66415 0.506174 1.44726 0.800857 0.528416 0.751953 1.10216 0.836819 0.938787 0.784224 1.25765 0.70052 0.525188 0.605536 0.76803 0.979008 1.83986 1.07708 0.650092 1.0666 0.811061 0.654465 0.261538 1.03577 0.863912 0.981085 1.14564 0.665673 0.614456 0.92203 1.42783 1.01856 0.762991 1.0796 0.585871 0.404335 0.633182 1.76105 0.585675 0.799656 0.926629 0.610212 0.832051 0.793958 1.05268 1.21676 0.595887 0.33296 0.400792 0.879541 0.722647 0.434788 1.03256 0.561749 0.260261 0.618722 0.5668 1.57796 0.830985 2.135 1.22056 0.328811 0.64436 2.07225 0.899295 0.694782 0.574773 1.14004 0.569649 0.347277 1.06751 0.353807 1.36393 0.572997 0 0.759699 0.925961 0.602967 1.24674 0.986363 0.838661 0.460583 0.748354 0.524352 1.33227 0.956498 0.554715 0.678738 0.711157 0.766457 0.887206 0.892334 0.815476 0.666928 0.876752 0.992154 0.47563 0.87512 0.577979 0.792009 0.752337 0.385716 0.913183 0.522618 0.737656 1.1248 0.769298 0.918924 1.02861 0.783094 0.386037 0.769725 0.893609 0.846057 1.23368 0.332188 0.686 1.35563 0.943235 0.906519 2.83189 0.776523 1.29098 0.491248 0.986614 0.663532 0.870569 0.738671 0.345356 0.693329 0.425368 1.51119 0.554749 0.650083 0.98149 1.72747 1.16775 0.692865 0.883414 0.431943 0.495922 0.715196 0.717433 0.812306 0.845209 1.18886 0.592682 0.527629 0.6104 1.45841 1.02275 0.941756 0.532479 0.622602 1.17576 0.471691 0.667442 1.71971 0.742473 1.10462 0.869952 1.09683 0.946797 2.0857 1.30161 0.607034 0.813881 0.887376 1.39081 0.98962 1.76597 0.449144 1.03621 0.843868 1.16589 0.436087 0.455779 0.636937 0.722138 0.663819 0.513496 0.372705 0.824649 0.602348 0.876589 0.950766 1.12257 0.544329 1.12448 1.12949 0.863871 0.663456 1.63606 0.808847 0.673044 1.45407 0.865639 0.838694 0.529149 1.09592 0.87009 0.733228 1.14794 0.583794 1.00174 0.766596 1.19315 0.670777 0.822292 1.15006 1.20559 0.997302 1.54991 0.710617 0.629816 0.536762 1.19647 0.47029 0.741578 0.554542 0.871234 0.472558 0.731448 0.562395 0.452587 0.407756 0.557158 0.747407 0.989216 0.65573 0.531735 0.691953 0.920662 0.928291 0.447465 0.653719 1.08312 0.547053 0.930623 1.12579 0.628822 1.28129 0.538686 0.859368 0.469357 0.75848 0.867168 0.699133 1.21381 0.658679 0.804471 0.797749 0.791719 0.506825 0.934002 0.905029 0.738359 1.14541 1.21331 0.63451 0.497908 0.601241 0.808822 0.640937 0.625386 0.430611 0.584962 0.96578 0.919019 1.0584 0.544611 0.452905 1.54609 0.576962 0.72309 0.399328 0.529161 1.06174 1.36197 0.805638 1.41791 0.940017 0.51706 0.793054 1.89715 0.37039 1.8404 0.73902 0.522232 0.930031 0.696425 0.718106 0.351222 1.16939 0.474101 0.877327 1.05603 1.62087 0.66029 1.17558 0.922979 0.952763 0.65222 0.79962 0.98594 0.812968 2.48272 0.638709 0.829899 0.640294 1.08766 0.927629 1.13721 0.491012 0.753082 0.387657 0.428319 0.373858 1.27856 0.66426 0.603603 0.927191 0.830052 0.46424 0.888807 1.61899 0.677978 1.5204 0.889106 0.92127 0.923041 0.91732 0.838787 1.28148 1.03121 1.82027 0.95368 0.863001 0.787169 1.41379 0.665652 1.97706 0.973873 1.04199 0.87129 1.19712 0.619181 1.22412 1.72049 0.84538 1.18706 1.42202 1.62525 1.09372 0.944965 0.595505 0.38514 0.459514 0.943132 1.07104 0.852667 1.24078 0.721603 0.945929 0.804942 0.534783 0.431431 0.838985 0.317535 1.30238 1.68341 0.43197 0.713092 0.887659 0.927901 0.36828 1.09461 0.44275 0.670432 0.958673 0.418738 0.745881 0.548367 1.14268 0.534139 0.789412 0.923731 1.18243 1.14505 0.553519 0.641217 0.447707 0.24382 1.05242 0.82088 0.323233 0.957617 0.835691 0.862158 1.14898 0.64201 0.905056 0.521502 1.19123 0.715918 0.928959 0.904529 0.78235 1.37314 1.28331 0.569878 0.655696 0.883272 0.810279 0.845899 0.82567 1.02552 0.698081 0.566348 0.541328 1.2534 1.02585 0.901645 1.0104 0.733815 0.519795 0.723971 0.747909 1.45878 0.809037 1.61877 0.668625 0.568549 1.13713 0.706826 0.77377 0.280372 0.577119 0.760313 0.912465 0.810079 0.836166 0.559554 1.74054 1.54359 0.777153 1.04935 1.21877 0.787336 0.563257 0.635492 1.14867 3.60873 0.852458 0.771596 1.12412 1.0303 1.04105 1.23208 1.19966 0.812829 1.61843 0.652665 0.802264 0.665697 1.07239 0.953018 0.577441 0.916448 1.40399 0.626806 0.650486 1.18618 1.01136 0.587308 1.08726 0.326408 0.864516 1.47316 1.34241 0.928289 0.732278 0.590418 0.737808 0.811372 1.53756 1.47233 0.661951 1.24945 0.662884 1.27901 0.505122 1.3089 0.648065 0.636443 0 1.1066 0.598186 0.612004 1.32512 0.693367 0.947716 0.925476 0.806268 0.986141 0.812693 0.465604 0.694027 0.951306 0.951814 0.765967 0.792622 0.609884 0.944457 0.767889 0.68257 0.629395 0.687761 0.706163 0.708443 1.14322 1.03134 0.64066 1.01666 0.994989 0.752931 0.625815 0.816888 0.84874 0.615753 0.868259 0.957981 0.992668 0.197846 0.282696 0.357439 0.739132 0.970993 1.18219 0.608512 0.614802 1.19137 0.400783 0.525125 0.601473 0.46989 0.854513 1.8322 1.14836 0.619801 0.610331 0.472561 1.12177 1.2565 0.944944 0.936235 1.23788 0.853516 0.537131 0.615845 1.00582 0.995244 0.917562 0.924492 1.02398 1.00759 1.94353 0.728562 0.925237 0.946457 1.14814 0.639386 0.465037 0.639768 0.819024 0.701921 1.02512 0.798359 0.921412 0.77395 0.792014 1.35997 1.48198 0.709712 0.607667 0.696627 0.487799 0.744679 1.35878 0.60817 1.24836 0.617513 1.05232 1.05096 1.36398 0.835963 0.605584 1.35971 1.24342 1.07568 0.736421 1.32223 0.701662 0.669859 0.949924 0.632181 0.793066 1.73694 0.543761 0.974244 0.970867 1.28959 0.691437 1.31127 0.752412 0.764947 0.650704 0.472849 0.884606 0.999334 1.13613 1.47109 1.48155 0.869079 1.10217 0.943772 0.575201 0.514575 1.00775 0.760402 0.992849 0.592802 0.819275 1.05664 0.875731 0.522617 0.78576 0.891732 0.720981 0.912891 1.06223 1.86168 0.636596 0.978898 0.547039 0.530187 0.742893 0.905258 1.01416 1.01548 0.795862 1.63222 0.86771 0.458129 0.651381 0.677078 0.421836 0.943206 1.00214 0.865559 0.717092 0.801457 1.09851 1.24683 0.751232 1.0764 1.23336 1.26267 1.9035 1.01567 1.30051 1.18012 0.738765 0.821485 0.835371 0.661257 0.661157 0.803641 0.704105 0.547787 0.557228 0.587106 0.743425 0.57393 1.04044 0.778109 1.28718 0.603492 0.943634 0.27031 0.608127 2.48055 0.559047 1.25286 0.97643 0.537605 3.14297 0.667497 1.30386 0.990196 1.27676 1.80425 0.840794 0.749389 0.590748 0.698007 1.70434 1.24284 0.755376 0.514647 0.972612 2.04728 0.611863 1.01593 1.38961 2.22643 1.06023 0.315746 0.558505 1.33827 0.978778 0.739312 0.836974 1.01055 0.660603 1.62948 1.77827 1.14074 1.50346 1.14278 0.78418 1.01279 0.314731 0.942062 0.759986 0.622724 1.2663 0.770711 0.671559 0.712754 0.525111 1.397 0.800408 0.671509 0.974491 0.613323 0.804733 1.10514 0.819207 0.537353 2.27628 0.919744 1.04464 0.616805 0.840175 0.297764 0.723865 0.958117 1.25978 0.805 1.00932 0.806154 0.873471 1.05436 1.26981 0.684716 0.738965 1.57348 0.601944 0.804403 0.602929 0.682092 0.741339 1.15256 0.420844 0.461098 0.791188 0.795315 1.18588 0.719225 0.632086 0.725655 0.76557 1.16459 1.16723 1.4557 2.33875 0.670009 1.07456 0.690064 0.9448 0.619086 1.32767 0.450905 1.51258 0.769938 1.44715 0.521953 0.759166 0.750129 0.521128 1.01779 0.678734 0.429613 1.48534 1.16402 1.06328 1.08856 1.55214 0.788591 1.01882 1.27007 1.44198 0.734361 1.04153 1.26486 0.791293 0.778007 0.722063 0.782622 0.751233 0.709965 0.971761 1.06188 1.02935 1.00264 0.802222 2.0015 0.978864 0.688165 0.600019 0.453919 1.26337 1.08983 0.783572 0.357353 0.85087 0.635449 0.579285 0.540412 0.952396 0.718998 0.914691 0.446576 0.889569 1.31181 1.6552 1.55087 1.00608 1.0587 1.05516 0.506968 0.626281 0.620386 1.38665 1.38857 1.28564 1.42764 0.835305 0.732241 0.509407 1.37077 0.760398 0.833674 0.916732 0.763996 1.90615 0.817994 0.792545 0.845088 2.12577 1.21494 1.07436 0.759507 1.08167 0.98239 0.746684 1.78199 1.18037 1.01144 0.668179 1.15383 0.784007 0.811076 0.814814 1.1949 0.459673 0.757655 0.781659 1.08074 0.795187 1.29266 1.45543 1.45 1.33496 1.42435 0.647499 0.425759 0.72123 1.06148 1.35791 0.463758 1.23964 0.730425 1.00881 0.767707 0.769941 1.49851 0.619366 0.636563 1.38425 0.85158 1.3853 0.56074 0.804453 0.938663 0.904769 1.30197 1.35347 2.13901 1.06507 1.45919 1.52888 0.285136 1.09004 1.0116 1.01911 0.936399 0.592173 0.748431 0.677261 1.05798 1.26158 0.866909 0.767014 0.671345 0.908947 1.0862 0.528987 2.01511 1.61589 0.804215 1.07989 1.19437 0.542668 0.800887 0.982688 0.834782 0.511561 0.562164 0.321264 0.570088 0.632809 1.1546 0.93386 0.741523 0.710946 0.75334 1.00835 0.650926 1.26652 0.91553 1.23061 1.21854 0.459492 0.651088 0.719239 0.825084 0.669682 0.922628 2.01035 1.52092 1.42669 0.669599 0.783418 1.20559 0.615779 0.324372 2.46695 1.49739 ]
@@@ Frame-accuracy per-class: [ 87.9991 79.668 81.2227 69.5279 88.7805 74.5763 58.3051 87.1379 90.3226 87.4299 96.381 84.7767 91.0995 90.6367 77.4194 80 80.6154 78.5146 83.1615 88.4688 91.3118 80 88.361 80.396 73.6077 89.2308 79.4366 87.2428 82.2622 90.8665 70.5882 76.6355 79.4224 86.747 95.9009 90.301 96.0163 94.2976 88.3861 65.8487 58.1818 91.8919 87.8893 67.7228 81.4815 89.1566 63.6316 84.7162 87.3599 93.2639 85.2386 57.2935 92.2587 82.9268 88.3794 86.9565 41.5094 80.4233 92.1389 63.5171 78.1784 95.082 84.0467 95.1412 72.5552 82.4645 68.1256 78.2609 90.3226 86.6242 88.3258 91.0394 81.3834 86.6604 95.3271 78.2609 86.0481 78.1457 91.5736 73.4007 77.1084 70.1299 92.0863 89.2139 94.5368 78.9074 87.9357 90.0662 78.8382 74.2049 85.1485 83.6601 68.9655 80.7799 42.4242 82.5336 86.3579 90.6702 70.024 89.5265 91.3947 61.8384 60.1227 86.5014 84.7458 88.3261 86.2944 82.0513 89.0966 77.1574 72.7273 56.8807 84.2105 80 43.4783 84.5188 89.5863 92.4092 66.0633 79.3757 83.7945 85.0394 91.3295 56.6929 86.5248 87.1287 84.0125 56.9579 83.3898 73.3668 77.6699 68.6339 72.7794 85.9671 73.3591 79.476 80.8013 77.0031 84.058 93.178 74.2081 87.2727 92.4078 84.7698 65.7718 72.9927 64.8557 84.5996 91.1612 64.5614 85.4772 68.9655 93.1384 89.5961 76.2763 89.0995 69.2042 76.3077 90.085 77.2908 87.2483 80.5369 0 85.5107 82.1705 80.7018 80.597 93.7876 79.81 79.4171 78.1609 76.0563 79.3443 90.583 93.0788 91.0412 84.6416 84.3585 62.5592 28.5714 92.6829 89.2754 82.2898 75.0462 74.4186 80.4233 83.2653 90.4376 86.59 78.3862 86.1865 63.9456 87.2289 74.8538 86.2302 97.094 78.0488 55.6391 90.7801 76.2646 88.2507 93.7347 82.5623 90.3226 61.6822 63.2153 74.9045 72.0257 80.678 76.5957 92.6829 74.1036 83.9945 68.8299 83.5036 87.3563 89.8969 85.5535 79.8898 86.6008 83.2244 86.1836 59.8131 78.9598 79.4953 84.3243 90.4863 88.8337 65.8098 62.6866 83.871 79.7342 73.3758 81.8462 88.2682 87.4552 70.3518 88.9166 86.2944 77.9661 93.7063 87.8661 86.1856 91.4286 84.2553 72.7273 93.1646 84.9498 82.392 88.2217 85.1114 76.7624 54.9865 77.6025 89.5928 84.8485 76.6839 73.0159 69.9029 78.9272 70.8861 89.9563 46.8468 90.535 69.7674 87.0466 78.607 83.6173 87.4251 86.1878 91.8919 76.7677 88.6406 83.5443 86.3271 84.3243 91.7222 71.6578 86.119 93.6387 89.0688 91.1175 92.1502 76.0383 81.7518 67.7686 87.2131 83.5655 59.2593 79.8635 92.7059 75.3927 89.9135 79.7048 90.7873 30.303 82.3285 53.9683 75.1592 92.7039 75.6554 77.7409 53.944 57.554 72.3404 64.9351 72.4458 89.3151 87.9607 82.1053 82.1918 89.9225 89.6861 70.5882 65.6716 74.0088 82.2086 66.6667 62.9108 77.4536 91.8485 87.5606 82.2888 90.1554 54.5455 83.6565 90.4733 76.1566 85.9574 79.2899 84.7352 89.2562 71.0623 55.9242 82.3529 83.3631 72.7273 69.8609 80.5195 61.3497 75.2 90.4215 87.5283 86.1461 89.7384 76.6885 72.428 89.5307 68.7403 74.2268 76.5799 84.6512 66.6667 87.9725 71.0354 54.5455 79.1837 86.8516 73.161 81.4645 55.1724 90.5607 71.7949 67.4352 82.2335 81.2652 57.1429 76.9231 78.7879 86.8817 80.7843 91.7197 68.3544 74.5921 58.5366 89.7155 76.8061 81.388 85.5148 64 86.0215 56.5445 90.5109 83.3837 82.7119 78.8845 81.7121 90.9091 91.4761 89.2596 65.2921 83.2215 75.4209 82.0513 80.7947 80.4159 89.8204 81.1189 81.2641 75.4967 87.8477 84.3091 89.9933 92.8643 59.4142 86.5753 84.2105 87.0871 78.9346 79.7203 59.0258 60.4651 86.3329 88.3797 80.429 83.1589 66.6667 72 88.7273 75.6501 76.7802 78.6127 69.0554 87.7698 8.12183 88.4283 91.8322 51.2821 89.2308 83.2998 47.4074 79.0751 81.0496 89.4793 67.8304 82.2857 65.1982 91.9708 63.1111 79.5789 65.5271 86.5248 80.7018 57.7181 94.026 76.0181 86.7797 86.2745 79.5518 82.3366 61.8454 78.8732 80.916 96.7742 91.5825 62.6087 85.0153 88 91.0798 58.0645 82.6291 67.7494 86.3813 61.1987 84.8485 80 73.1707 75.4864 72.4638 72.0222 86.3436 85.7143 91.8681 88.3721 90.6832 65.8933 85.0242 77.533 88.5246 86.9173 91.1681 56.6845 81.1594 81.296 87.8049 76.4557 81.7481 90.4159 62.6866 84.2315 86.4619 62.9758 78.8321 85.8757 83.9757 80 74.5981 73.3119 77.2118 67.4157 79.0436 79.4055 78.5882 76.0148 74.4939 74.0125 80.7339 82.8235 85.3147 84.3564 81.7734 63.8498 74.8011 83.6601 69.9187 62.8571 76.3636 80 67.3835 76.3636 90.5775 85.8757 65.643 80.9843 87.5472 74.1748 61.9289 75.493 81.0619 47.0588 77.3109 77.9798 86.1789 81.761 88.8889 85.4271 60.6452 50.9317 85.0987 82.314 48.7805 86.2363 56.6154 77.1654 88.8252 77.9874 57.7778 77.8816 74.4186 79.8419 65.2068 80.3738 87.0897 83.445 78.187 69.5385 58.2278 78.4314 78.6885 66.7992 80.5369 78.6127 94.9389 67.7551 75.0751 70.9677 71.9665 80.9816 81.0198 72.4528 64.3275 70.3196 81.5199 64.9682 83.0189 90.9091 79.3914 47.4576 85.4676 71.8563 72.7023 81.9945 74.8538 80.4469 67.9035 63.8298 83.612 92.8839 90.535 71.8563 86.6044 87.2107 64.9215 84.6731 97.1429 83.7438 87.2852 48.2759 73.6842 40.4494 66.6667 89.1455 81.5109 35.5872 75.188 83.8095 81.1146 64.8475 85.1775 89.8876 70.1754 91.6201 56.7442 84.4884 0 72.5738 75.1323 83.2117 67.4584 65.8824 66.6667 88.5154 84.3373 88.4211 60.6061 74.4417 79.7203 79.4436 75.102 72.6761 74.4921 77.7042 75.8294 83.1956 69.6505 65.6085 87.4419 71.4681 88.4848 78.2152 78.6611 89.0309 67.6923 85.906 82.0961 69.8413 77.551 71.7757 66.6667 80.5031 92.9134 81.6467 83.7209 77.0764 66.3317 91.1628 75.9219 65.1026 72.5979 72.3982 0 79.1878 69.0909 89.5009 72.5234 80.9224 76.3231 82.0513 88.9353 79.638 87.0871 62.6959 91.2 78.5425 62.069 68.8525 65.1429 77.4468 76.6169 90.6031 86.6764 80 80.6283 73.8676 79.6117 61.3861 83.9319 85.8447 84.7318 58.8235 65.3358 75.8621 86.5526 82.4691 63.4304 86.7102 83.9858 43.4783 76.1905 57.1429 76.9231 68.3544 72.6115 50.1931 65.4971 84.0864 78.3069 74.6331 60.274 70.7224 45.0867 87.3563 73.5632 78.7565 66.6667 88.7967 89.5623 82.0399 86.9565 80.4938 88.0734 89.4309 74.928 85.8513 74.1433 74.7731 62.1723 86.1762 92.3077 72.5275 77.3246 75.6303 57.1429 80.112 91.2281 63.1111 74.0525 73.2297 87.0466 61.8834 81.8898 81.888 69.6246 87.9227 70.9677 81.2121 61.71 79.6537 75.3864 65.8228 67.9612 71.6604 57.1429 84.2975 82.7586 87.3469 57.485 87.1795 81.6626 82.1622 76.0456 85.9343 83.4437 83.0189 91.0569 88.8184 87.5502 79.9154 64.5963 88.8889 85.2321 78.3151 70.9957 68.9655 89.2546 79.8122 71.5596 85.9903 77.0053 71.5493 83.1858 65.5738 90.6404 76.1062 86.3001 78.5592 78.1116 82.3821 63.4271 82.9123 86.4865 80.7175 80.8511 85.8447 77.9874 74.6667 77.13 58.1333 54.4747 85.3598 86.465 80.6283 81.0929 86.7133 79.3443 87.9271 88.3797 69.4301 77.8068 64.3678 84.5011 89.6552 54.5455 84.8875 79.3792 90.6445 85.4881 66.3415 59.6306 78.5771 58.0645 76.951 85.7143 83.7274 38.0952 91.1392 35.2941 77.6291 86.7777 75.1107 83.3667 84.0449 90.4965 73.5632 86.4143 73.5892 69.7318 58.498 90.1099 67.4923 75.2475 81.9672 78.5924 77.8135 77.1242 80 40.6504 83.0287 74.5407 82.0513 62.6263 72.175 65.0602 87.9479 79.1946 92.9577 86.7667 88.8194 63.1579 80.7843 83.0409 69.4737 80.3943 87.1143 76.3557 59.9119 81.8024 60.4651 78.0083 74.5763 91.4286 72.7273 75.4717 59.6737 69.6673 47.0588 72.6214 73.5484 77.6371 51.7162 81.4815 42.3358 67.9803 74.0157 73.5586 75.6303 83.3787 66.9323 57.0447 75.6598 64.1975 58.9327 57.5342 67.4948 74.9226 86.3551 87.106 90.4483 78.453 64.8379 82.8283 53.5948 78.9189 73.065 73.4177 84.4944 92.0354 77.2384 90.6035 70.2362 43.6782 89.0323 82.5083 72.6644 69.7051 88.8889 65.641 88.2129 80.0937 61.2717 88.4354 81.3309 83.871 71.3043 86.692 80.4046 74.1784 67.8414 59.6491 86.741 80.9816 83.905 91.7431 69.6833 80.9689 91.8845 71.8663 75.9837 77.8495 65.0407 79.9001 73.6292 86.619 58.3153 76.7896 73.3238 74.3287 78.6019 66.8896 66.7717 82.8897 77.8793 77.2277 77.314 78.2609 81.0256 70.1299 77.4908 86.2958 86.562 55.7457 64 77.0302 71.8447 81.7204 89.3112 81.5145 79.638 63.0631 79.3388 56.9536 84.058 84.9383 63.5585 81.8018 79.0378 91.5556 84.6715 79.6834 69.7872 69.3069 74.8644 87.4003 52.0147 58.4958 80.9917 70.1754 62.0896 77.635 86.2405 81.0811 69.1604 0 74.0157 79.5604 67.086 74.3662 74.0088 88.4211 67.5462 79.7342 48.9796 79.2079 74.9311 89.1192 64.5614 66.4093 83.7209 72.4638 58.6826 75.8105 80.3519 66.6667 69.5652 86.4865 66.5298 90.1921 76.5009 60.0823 64.5161 71.3771 81.3397 87.9725 78.0207 79.1519 59.2593 52.2167 81.7391 61.5385 81.791 72.9412 86.202 56.2674 83.376 81.2749 0 68.8391 83.2232 83.8446 55.3459 80.0693 75.8974 71.2446 71.4088 68.3112 75.9124 85.9813 79.68 75.2294 75.0988 79.2793 85.0575 85.4369 73.7201 81.6 80.8664 83.956 81.7518 80.8743 78.5185 68.6391 71.4859 84.5953 71.5447 72.7273 73.6842 80.1898 72.0682 77.0642 88.1928 69.0647 72.6115 75.092 94.9721 92.3492 92.911 81.6104 71.8447 63.0491 83.2787 83.549 63.9376 90.9976 83.6795 81.2121 92.1348 75.4098 42.6036 69.8885 87.8745 84.3312 86.4461 72.3926 52.968 72.2022 73.7864 66.055 75.1269 82.7389 86.4865 69.7039 75.3927 68.9655 63.6119 73.4247 72.0257 44.0367 79.9704 70.8423 77.3869 68.4746 84.8485 86.2559 82.2695 78.6325 75.9443 76.8559 80.8625 71.0462 74.8768 77.0017 67.7966 58.0645 74.094 86.4111 84.8485 90.5028 80.109 59.3692 84.6395 55.7994 83.1031 79.2651 69.3603 76.7123 76.3674 83.0565 60.8187 64.0264 67.8967 79.8186 64.4391 75.9003 77.4888 73.6508 84.2105 79.1171 48.6772 89.043 67.5958 76.9874 69.011 80.4819 56.4972 76.9231 78.1457 81.2589 85.4772 73.5586 70.5394 64.0777 64.5533 54.1806 76.9231 69.0909 73.1219 82.9752 85.1064 76.5101 80 68.7225 82.7586 70.1754 68.1319 74.4958 88.3117 81.3397 77.1134 77.0241 70.5376 74.0741 47.0588 80.543 72.8232 85.259 84.1889 78.7623 75.0314 75.8483 73.7615 78.3505 47.2574 80.1223 87.637 85.9016 83.1169 90.784 75.4098 71.3755 83.2215 77.1466 77.9221 73.1034 64.7975 79.9001 69.3642 64.7173 73.8739 60.8696 75.8105 63.895 67.1815 80.6154 74.2515 72.579 86.7257 87.5912 82.6884 81.7891 84.8619 81.5155 87.6679 84.9558 85.0095 69.9229 78.9357 56.2814 81.5672 73.5376 90.8316 82.8532 29.7872 85.5124 70.8075 67.9245 86.4553 0 82.0513 50.8475 70.1887 62.1687 51.6129 72.8682 79.2332 87.9433 78.7879 45.7516 66.1597 80.2139 84.9558 73.0512 46.1538 83.6551 67.6923 67.2897 34.5679 61.1872 92.9461 84.058 63.7993 72.2513 77.9221 72.5581 74.9499 82.9876 50.924 45.7666 58.0645 54.3735 64.7303 76.5009 67.9245 92.8155 75.5668 88.8889 81.0769 55.2553 88.8889 81.1104 77.9939 86.8571 53.0387 76.3833 85.2321 73.3524 88.0734 71.2477 68.6869 79.6117 87.0813 44.8669 73.0924 67.9305 84.5771 77.6948 93.9044 77.3455 68.6131 62.069 88.5246 67.9463 79.4411 76.1021 64.4967 57.0342 78.4452 68.1319 57.0342 83.2184 79.2793 81.3853 82.7004 79.0698 66.9856 87.9852 85.2917 71.151 78.303 67.1698 84.3537 83.2 78.057 75.846 62.8803 72.4062 63.3094 31.3253 81.7577 61.3139 84.1791 80 88.0694 62.4685 90.0302 55.1253 80 63.5171 86.8914 80.5482 79.1608 87.6404 67.0554 77.0713 87.781 52.8814 72.0497 76.6265 65.2807 46.1176 79.3792 72.9483 59.8131 66.6667 77.2881 74.0741 70.5882 79.7342 74.9164 79.8151 78.0073 76.1523 83.5821 81.9277 65.9176 74.209 74.9585 80.3987 46.4 75.1236 79.7084 84.2975 97.2973 67.8733 71.6332 71.6049 93.2826 78.0952 81.9127 85.6712 89.6309 71.9258 81.1388 78.6026 87.2727 71.5447 63.6704 63.9175 52.0548 72.9282 69.3069 54.0541 85.1064 80.6283 81.0256 67.6259 59.5041 63.6852 64 79.7654 82.2811 85.5615 59.3176 79.3867 83.4043 74.7384 76.7816 38.2514 73.3781 76.6727 79.9263 42.5629 63.4538 74.928 80.7131 66.6667 74.9035 81.9113 39.0244 73.3542 71.9536 82.1589 67.6923 82.3037 71.1974 80.0456 55.2381 86.8504 81.407 80.5005 72.7273 79.2632 66.6667 57.1429 59.6491 60.1504 52.8302 85.1948 94.8148 80.5604 69.5652 70.9957 87.8873 67.6364 82.2309 68.6869 81.473 79.5252 53.6741 86.2486 83.0235 62.2222 84.4622 69.8225 83.4951 76.1905 73.4793 71.6007 60.9971 60.7683 36.3636 66.8896 57.7947 44.7489 93.7853 67.7316 71.8232 71.8147 73.8275 82.7586 80.9651 82.4242 69.0446 64.6048 72.0257 78.2369 81.3161 75.2475 75.2 84.5638 48.8889 48.9607 79.646 75.162 67.3629 87.389 80 68.6217 77.9456 85.591 85.5403 91.3828 85.0987 83.4979 57.7181 73.4584 76.8559 82.5397 81.3142 71.3246 81.4118 64.0827 72.0879 63.2035 55.3459 88.946 86.5979 79.659 77.8626 83.2298 73.0594 40.5904 50.8287 61.2529 83.4043 78.1671 48.5981 85.9521 91.4962 30.4 54.6584 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 0.702111 (Xent), [AvgXent: 0.702111, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 80.3328% <<

