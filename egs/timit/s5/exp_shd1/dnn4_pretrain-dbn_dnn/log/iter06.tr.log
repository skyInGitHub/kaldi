nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.002 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter05_learnrate0.004_tr0.8831_cv1.8771 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter06 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975016
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.81539, max 8.96107, mean 0.00568746, stddev 0.99447, skewness 0.129835, kurtosis 2.1535 ) 
[1] output of <AffineTransform> ( min -28.8767, max 25.1314, mean -3.39071, stddev 4.0608, skewness 0.125747, kurtosis 1.28847 ) 
[2] output of <Sigmoid> ( min 2.87743e-13, max 1, mean 0.203649, stddev 0.313253, skewness 1.51443, kurtosis 0.830746 ) 
[3] output of <AffineTransform> ( min -30.2515, max 15.8554, mean -4.11384, stddev 2.79672, skewness -0.0396135, kurtosis 2.19706 ) 
[4] output of <Sigmoid> ( min 7.27711e-14, max 1, mean 0.0962472, stddev 0.193633, skewness 2.93309, kurtosis 8.45494 ) 
[5] output of <AffineTransform> ( min -14.6551, max 11.1056, mean -3.14035, stddev 1.96925, skewness 0.563904, kurtosis 2.2081 ) 
[6] output of <Sigmoid> ( min 4.31889e-07, max 0.999985, mean 0.111624, stddev 0.187211, skewness 2.78754, kurtosis 7.90952 ) 
[7] output of <AffineTransform> ( min -20.2383, max 17.0853, mean -2.81684, stddev 2.26297, skewness 0.550764, kurtosis 2.5157 ) 
[8] output of <Sigmoid> ( min 1.62418e-09, max 1, mean 0.151637, stddev 0.231333, skewness 2.10759, kurtosis 3.74288 ) 
[9] output of <AffineTransform> ( min -17.2138, max 17.719, mean -2.85934, stddev 2.83777, skewness 1.32059, kurtosis 2.54547 ) 
[10] output of <Sigmoid> ( min 3.34289e-08, max 1, mean 0.175306, stddev 0.289837, skewness 1.79967, kurtosis 1.88248 ) 
[11] output of <AffineTransform> ( min -29.9525, max 25.6932, mean -3.71074, stddev 3.59837, skewness 0.96472, kurtosis 3.09617 ) 
[12] output of <Sigmoid> ( min 9.81325e-14, max 1, mean 0.147752, stddev 0.293413, skewness 2.06411, kurtosis 2.73957 ) 
[13] output of <AffineTransform> ( min -14.497, max 24.5514, mean -0.0174237, stddev 3.55794, skewness 0.548046, kurtosis 0.966212 ) 
[14] output of <Softmax> ( min 2.87218e-15, max 0.999975, mean 0.000657824, stddev 0.0186099, skewness 40.2965, kurtosis 1776.31 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.13984, max 1.32769, mean -0.000287557, stddev 0.0610201, skewness -0.365199, kurtosis 27.1875 ) 
[1] diff-output of <AffineTransform> ( min -0.401071, max 0.351211, mean 1.66363e-05, stddev 0.0110122, skewness -0.425731, kurtosis 86.0863 ) 
[2] diff-output of <Sigmoid> ( min -1.927, max 2.17168, mean 0.000770748, stddev 0.0989823, skewness 0.229859, kurtosis 20.0246 ) 
[3] diff-output of <AffineTransform> ( min -0.435034, max 0.401695, mean -1.48848e-05, stddev 0.0123638, skewness -0.386547, kurtosis 108.384 ) 
[4] diff-output of <Sigmoid> ( min -2.29403, max 3.3061, mean 0.000456957, stddev 0.132457, skewness 0.14072, kurtosis 16.6583 ) 
[5] diff-output of <AffineTransform> ( min -0.550425, max 0.640951, mean 3.06447e-05, stddev 0.0129066, skewness 0.606843, kurtosis 122.442 ) 
[6] diff-output of <Sigmoid> ( min -2.32927, max 3.24192, mean 0.000659516, stddev 0.11038, skewness 0.236369, kurtosis 19.101 ) 
[7] diff-output of <AffineTransform> ( min -0.273601, max 0.389118, mean 3.02035e-05, stddev 0.0105881, skewness 0.338506, kurtosis 66.7134 ) 
[8] diff-output of <Sigmoid> ( min -1.39884, max 1.87141, mean 0.000261719, stddev 0.0781541, skewness 0.10897, kurtosis 16.2824 ) 
[9] diff-output of <AffineTransform> ( min -0.211016, max 0.34247, mean 3.3824e-05, stddev 0.00785389, skewness 0.327849, kurtosis 67.5216 ) 
[10] diff-output of <Sigmoid> ( min -1.14086, max 1.3701, mean 0.000244685, stddev 0.0600614, skewness 0.096532, kurtosis 17.5781 ) 
[11] diff-output of <AffineTransform> ( min -0.489034, max 0.197864, mean 3.2838e-05, stddev 0.00877574, skewness -1.13016, kurtosis 109.241 ) 
[12] diff-output of <Sigmoid> ( min -2.29662, max 1.16366, mean -0.000177708, stddev 0.0925932, skewness -0.304983, kurtosis 10.603 ) 
[13] diff-output of <AffineTransform> ( min -0.999786, max 0.883127, mean -4.5598e-09, stddev 0.0176724, skewness -23.5511, kurtosis 1894.82 ) 
[14] diff-output of <Softmax> ( min -0.999786, max 0.883127, mean -4.5598e-09, stddev 0.0176724, skewness -23.5511, kurtosis 1894.82 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.43126, max 2.44064, mean 0.000894393, stddev 0.172448, skewness 0.037123, kurtosis 2.62972 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.974758, max 0.734238, mean 0.00425889, stddev 0.183555, skewness -0.208667, kurtosis 1.48928 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.934623, max 0.884913, mean -0.000841725, stddev 0.0758259, skewness -0.0778947, kurtosis 6.42383 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.09403, max 0.93114, mean -0.00381052, stddev 0.209316, skewness -0.221984, kurtosis 2.5673 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -1.07553, max 1.11633, mean 0.00073255, stddev 0.045436, skewness 0.278416, kurtosis 16.5128 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.12765, max 1.01474, mean 0.00784503, stddev 0.21887, skewness 0.0661925, kurtosis 2.63555 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.538842, max 0.672618, mean 0.000881805, stddev 0.0380635, skewness 0.289161, kurtosis 11.3008 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.693596, max 0.693175, mean 0.0077321, stddev 0.183404, skewness 0.183826, kurtosis 1.82251 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.461448, max 0.603919, mean 0.00120048, stddev 0.0360212, skewness 0.407714, kurtosis 8.28954 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.628835, max 0.659523, mean 0.00865886, stddev 0.137025, skewness 0.342798, kurtosis 2.62804 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -1.1576, max 0.633526, mean 0.00159846, stddev 0.0492606, skewness -0.121048, kurtosis 13.871 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.19622, max 0.7698, mean 0.00840655, stddev 0.15588, skewness -0.233319, kurtosis 5.44513 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -4.31278, max 2.38335, mean -1.9765e-08, stddev 0.0972356, skewness -4.11306, kurtosis 99.2399 ) , lr-coef 1, max-norm 0
  bias_grad ( min -4.12507, max 2.28095, mean -1.12935e-08, stddev 0.307785, skewness -2.13771, kurtosis 29.2538 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 342784 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -6.78548, max 7.66488, mean 0.00618661, stddev 0.998336, skewness 0.126755, kurtosis 2.01683 ) 
[1] output of <AffineTransform> ( min -28.8851, max 24.5932, mean -3.37036, stddev 4.11388, skewness 0.145174, kurtosis 1.24676 ) 
[2] output of <Sigmoid> ( min 2.85347e-13, max 1, mean 0.207279, stddev 0.316841, skewness 1.48633, kurtosis 0.727606 ) 
[3] output of <AffineTransform> ( min -31.3532, max 18.4588, mean -4.09952, stddev 2.81755, skewness -0.0411954, kurtosis 2.20405 ) 
[4] output of <Sigmoid> ( min 2.4181e-14, max 1, mean 0.0980181, stddev 0.195473, skewness 2.89014, kurtosis 8.17283 ) 
[5] output of <AffineTransform> ( min -14.1289, max 10.9918, mean -3.11913, stddev 1.98628, skewness 0.54931, kurtosis 2.22987 ) 
[6] output of <Sigmoid> ( min 7.30952e-07, max 0.999983, mean 0.11385, stddev 0.188955, skewness 2.73922, kurtosis 7.60389 ) 
[7] output of <AffineTransform> ( min -21.0292, max 17.401, mean -2.77664, stddev 2.29187, skewness 0.538502, kurtosis 2.46999 ) 
[8] output of <Sigmoid> ( min 7.36471e-10, max 1, mean 0.156415, stddev 0.235086, skewness 2.04722, kurtosis 3.45205 ) 
[9] output of <AffineTransform> ( min -16.7591, max 17.7407, mean -2.82526, stddev 2.88272, skewness 1.31547, kurtosis 2.50423 ) 
[10] output of <Sigmoid> ( min 5.26784e-08, max 1, mean 0.180049, stddev 0.29418, skewness 1.7479, kurtosis 1.67333 ) 
[11] output of <AffineTransform> ( min -26.9518, max 22.4836, mean -3.6797, stddev 3.65121, skewness 0.974706, kurtosis 2.97365 ) 
[12] output of <Sigmoid> ( min 1.97239e-12, max 1, mean 0.151918, stddev 0.298021, skewness 2.01236, kurtosis 2.50648 ) 
[13] output of <AffineTransform> ( min -15.3088, max 24, mean -0.0176124, stddev 3.63243, skewness 0.551048, kurtosis 0.999081 ) 
[14] output of <Softmax> ( min 3.10855e-15, max 0.999693, mean 0.000657833, stddev 0.01949, skewness 39.9057, kurtosis 1716.99 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.74424, max 1.90774, mean -8.61768e-05, stddev 0.0451419, skewness 0.603099, kurtosis 76.5158 ) 
[1] diff-output of <AffineTransform> ( min -0.279567, max 0.478426, mean 1.54182e-05, stddev 0.00826487, skewness 1.24694, kurtosis 126.468 ) 
[2] diff-output of <Sigmoid> ( min -1.83995, max 1.98093, mean -0.000154017, stddev 0.0751813, skewness 0.236119, kurtosis 24.5051 ) 
[3] diff-output of <AffineTransform> ( min -0.281613, max 0.41714, mean 2.04554e-05, stddev 0.00932634, skewness 0.839432, kurtosis 119.409 ) 
[4] diff-output of <Sigmoid> ( min -1.49525, max 2.30081, mean -1.51453e-05, stddev 0.0996148, skewness 0.0686886, kurtosis 15.3398 ) 
[5] diff-output of <AffineTransform> ( min -0.298302, max 0.354757, mean 2.85596e-05, stddev 0.00963864, skewness 0.136006, kurtosis 72.2054 ) 
[6] diff-output of <Sigmoid> ( min -1.2312, max 1.94362, mean 9.51668e-06, stddev 0.0836663, skewness 0.071425, kurtosis 15.7254 ) 
[7] diff-output of <AffineTransform> ( min -0.185275, max 0.31517, mean 2.26213e-05, stddev 0.00797645, skewness 0.235591, kurtosis 58.2554 ) 
[8] diff-output of <Sigmoid> ( min -0.896796, max 1.32605, mean 0.00017347, stddev 0.0596725, skewness 0.0450335, kurtosis 17.1755 ) 
[9] diff-output of <AffineTransform> ( min -0.132505, max 0.19072, mean 1.39201e-05, stddev 0.00599585, skewness -0.174465, kurtosis 60.9491 ) 
[10] diff-output of <Sigmoid> ( min -0.970663, max 0.936545, mean 4.05465e-05, stddev 0.0460943, skewness -0.155161, kurtosis 20.9565 ) 
[11] diff-output of <AffineTransform> ( min -0.248879, max 0.212485, mean 8.58359e-06, stddev 0.00679027, skewness -0.548458, kurtosis 82.7227 ) 
[12] diff-output of <Sigmoid> ( min -2.5723, max 1.92568, mean 0.000196834, stddev 0.0728667, skewness -0.332824, kurtosis 20.5045 ) 
[13] diff-output of <AffineTransform> ( min -0.999962, max 0.9733, mean -6.81091e-09, stddev 0.013747, skewness -26.1596, kurtosis 2463.8 ) 
[14] diff-output of <Softmax> ( min -0.999962, max 0.9733, mean -6.81091e-09, stddev 0.013747, skewness -26.1596, kurtosis 2463.8 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -2.05385, max 2.2533, mean -0.000802902, stddev 0.130787, skewness 0.0628242, kurtosis 3.89446 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.523097, max 0.741267, mean 0.00394708, stddev 0.13758, skewness 0.150962, kurtosis 1.19396 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.604183, max 0.780753, mean 0.00128962, stddev 0.0575617, skewness 0.184291, kurtosis 6.66333 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.742422, max 0.944185, mean 0.0052366, stddev 0.156951, skewness 0.231851, kurtosis 3.10654 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.553002, max 0.55015, mean 0.000783742, stddev 0.0351903, skewness 0.217666, kurtosis 11.5094 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.925069, max 0.762359, mean 0.00731124, stddev 0.171276, skewness 0.127492, kurtosis 2.76714 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.452359, max 0.397045, mean 0.000734745, stddev 0.0293061, skewness 0.0564604, kurtosis 8.86072 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.626105, max 0.537233, mean 0.00579104, stddev 0.137466, skewness 0.0480911, kurtosis 1.68965 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.385745, max 0.314736, mean 0.000560666, stddev 0.0279043, skewness 0.0315616, kurtosis 7.42348 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.444444, max 0.446283, mean 0.00356359, stddev 0.100858, skewness 0.0462977, kurtosis 2.65145 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.428311, max 0.478822, mean 0.000518094, stddev 0.0382689, skewness -0.0805039, kurtosis 8.98092 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.588856, max 0.547325, mean 0.00219736, stddev 0.113452, skewness -0.120688, kurtosis 3.58281 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.19314, max 2.49664, mean -4.31007e-08, stddev 0.0756669, skewness -2.8272, kurtosis 111.121 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.00735, max 2.10803, mean -8.47013e-09, stddev 0.222447, skewness -1.02912, kurtosis 18.7909 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0782822 min, processing 72980.4 frames per sec; i/o time 5.22884%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14111 120 114 116 102 29 147 431 139 624 262 548 95 133 232 62 162 188 145 264 293 157 210 252 206 227 177 121 194 213 59 160 138 41 524 149 489 359 331 244 27 18 144 252 121 124 944 114 5399 17569 1561 284 471 20 632 126 26 94 273 190 263 30 128 442 158 105 525 11 77 78 552 418 679 528 1016 172 727 226 492 148 41 38 347 273 210 329 186 75 361 141 50 229 14 179 16 260 399 380 208 348 168 179 81 181 88 1263 98 58 160 98 115 54 66 62 11 119 350 151 110 448 126 190 86 63 70 151 159 154 147 99 51 457 174 395 129 114 299 480 34 300 110 192 230 423 223 68 294 243 288 142 120 14 444 408 166 105 144 162 529 125 74 223 6 210 64 142 100 249 210 274 130 35 152 111 628 206 146 284 105 10 20 172 279 270 107 661 122 308 130 173 423 220 622 85 221 292 20 66 211 128 191 614 140 15 160 183 392 155 147 70 20 125 365 508 342 43 242 266 181 354 229 517 160 211 158 92 236 201 194 33 15 451 392 162 89 139 99 401 98 88 71 358 242 87 117 16 197 149 150 216 426 191 185 158 110 313 96 94 154 130 118 114 166 121 21 289 100 381 83 90 18 148 268 118 186 92 525 93 176 196 123 174 146 156 68 60 152 179 13 146 212 95 173 135 298 16 240 157 78 116 133 150 196 69 70 269 161 182 203 142 109 580 111 212 100 113 81 22 106 188 435 309 183 96 159 180 813 140 117 84 160 60 136 105 93 279 49 323 115 81 187 130 220 198 248 229 121 138 321 339 134 107 289 145 381 16 122 414 251 218 14 704 214 173 295 205 31 188 148 232 127 78 197 214 102 228 131 158 286 12 325 95 342 165 147 125 128 38 240 479 145 74 148 97 75 288 83 71 221 75 341 213 744 497 119 182 123 166 206 71 174 21 369 305 186 525 28 62 137 211 161 86 153 69 98 289 226 97 32 248 67 432 171 470 200 262 113 68 112 237 175 493 28 74 192 110 147 76 178 359 200 35 65 15 148 172 163 12 106 46 106 215 128 158 115 37 61 128 34 180 113 80 227 21 80 215 103 113 91 332 175 93 103 339 102 197 194 276 33 250 439 144 479 88 246 22 155 155 186 44 355 235 212 135 123 240 272 212 71 252 101 106 188 76 61 17 82 47 139 27 164 88 260 223 132 257 98 177 282 25 59 247 184 238 139 298 77 80 278 302 61 410 162 317 174 79 22 160 279 126 205 160 228 522 176 162 39 25 152 251 223 86 286 122 166 15 119 81 176 132 85 109 289 78 185 137 361 29 347 417 364 180 85 89 269 23 149 133 121 83 160 410 95 466 17 101 145 14 66 44 19 216 251 140 66 52 161 311 239 133 142 268 107 151 0 355 94 68 210 42 10 178 124 47 82 201 71 323 122 177 221 226 105 181 815 94 322 180 82 190 119 1408 32 372 114 94 24 267 55 79 63 291 21 150 99 752 230 170 140 110 8 98 137 290 267 238 179 97 239 110 166 159 62 123 14 30 87 117 100 356 341 52 95 143 51 151 264 109 363 8 275 14 204 202 154 229 140 80 115 52 45 276 235 129 256 254 94 238 182 131 86 130 130 96 196 120 148 225 34 202 54 553 173 208 160 275 133 618 6 45 306 59 45 178 28 112 171 289 96 111 63 455 146 103 77 247 134 346 420 197 51 400 17 181 362 122 83 799 204 92 131 1688 75 185 61 630 124 236 80 58 118 320 115 14 516 106 54 103 280 177 169 213 101 56 536 291 116 201 195 336 18 111 70 109 79 37 111 187 128 201 1008 95 457 71 152 219 305 96 191 130 235 14 71 155 225 240 189 307 189 632 15 275 157 359 52 39 8 261 510 564 249 222 352 43 224 221 130 126 45 161 151 30 170 155 229 37 61 191 190 136 49 411 41 153 223 35 366 639 104 127 85 142 456 275 230 113 288 21 120 29 17 214 79 214 255 110 257 77 118 218 13 68 101 63 251 59 183 125 145 170 202 215 109 241 161 267 174 256 90 200 49 76 92 161 276 222 56 463 654 317 130 77 151 144 186 175 292 131 213 86 220 270 108 57 131 395 106 113 85 403 81 189 54 110 144 363 179 368 232 184 400 191 489 231 230 350 465 586 149 317 131 273 50 275 11 97 38 135 368 286 204 137 215 257 418 210 224 110 55 60 75 172 202 525 277 145 337 68 189 117 50 276 313 136 179 423 28 167 194 461 203 601 9 190 227 238 177 113 47 189 451 171 151 181 96 142 129 322 103 83 200 170 55 11 92 243 494 291 121 170 693 104 145 434 141 13 101 57 58 167 42 351 179 195 376 0 245 378 244 79 288 97 116 1082 263 205 374 312 163 126 277 43 154 146 187 138 227 205 91 202 84 124 191 184 214 123 421 234 163 207 69 392 407 805 555 331 459 257 193 152 270 256 205 168 82 44 30 84 134 350 392 468 81 109 138 51 163 98 350 55 219 95 217 185 182 155 54 676 231 99 147 82 316 70 292 251 114 185 205 101 293 88 170 372 143 247 89 183 269 159 159 470 190 148 36 484 150 85 151 135 220 209 180 557 157 313 294 94 360 143 119 227 207 88 71 75 349 843 251 120 51 173 149 253 192 299 302 211 74 152 113 43 85 136 421 115 104 242 228 232 13 59 331 189 125 243 355 398 250 272 145 118 163 1961 152 115 363 91 134 74 378 346 72 160 400 86 256 55 11 200 228 129 162 250 490 56 205 245 156 452 435 409 169 263 194 225 99 561 179 234 364 164 141 80 185 173 8 19 29 132 207 139 64 156 211 16 76 131 93 282 224 71 388 32 160 40 547 120 241 139 286 192 752 249 120 243 218 46 211 120 291 79 257 198 13 1281 166 13 738 488 437 90 370 118 174 163 276 49 154 104 131 124 316 100 468 303 218 68 14 30 260 250 215 829 131 141 45 131 217 166 115 118 64 313 270 608 334 412 132 73 312 298 428 246 226 69 124 375 68 167 62 230 198 165 219 127 190 133 948 357 222 171 259 511 147 80 207 240 212 225 164 53 112 147 121 25 150 149 324 411 249 100 41 133 521 301 150 62 303 411 60 18 110 174 40 394 52 240 331 284 215 421 114 247 430 133 48 109 90 50 18 1198 95 97 208 60 279 137 170 245 280 190 293 117 334 217 91 223 276 271 218 124 173 308 265 129 146 20 159 258 333 162 477 154 438 52 1106 298 479 38 841 127 66 85 66 26 192 67 285 218 115 177 412 385 148 434 168 156 454 403 22 125 84 360 157 205 290 170 429 71 149 131 109 88 156 90 129 330 14 559 412 392 145 155 181 425 252 187 74 157 216 56 231 191 281 147 170 165 579 328 249 278 354 74 559 114 283 243 343 212 193 227 115 79 194 48 410 65 80 109 135 90 215 117 185 53 480 464 62 80 ]
@@@ Loss per-class: [ 0.350095 0.773911 0.846608 0.797152 0.569243 1.05209 1.72871 0.571935 0.544027 0.511908 0.2702 0.541254 0.55936 0.517535 0.892806 0.777923 0.740438 0.909665 0.657479 0.459908 0.416215 0.71723 0.327898 0.814801 0.991622 0.394652 0.831076 0.566497 0.719494 0.403287 0.925455 0.766692 0.92773 0.831645 0.221503 0.460125 0.203329 0.286871 0.556154 1.34303 1.24472 1.03939 0.382984 1.08803 0.896799 0.361194 0.842947 0.730145 0.503205 0.24539 0.471864 1.30625 0.367787 0.977378 0.466334 0.613406 1.2816 0.728007 0.295255 1.20339 0.718933 0.632749 0.676928 0.289715 1.13346 0.847286 1.09788 1.41836 0.535579 0.711334 0.586537 0.401614 0.559208 0.574432 0.209647 0.597582 0.621685 0.908726 0.345096 1.00119 0.905817 1.12552 0.370184 0.469568 0.36645 0.886121 0.434639 0.405792 0.801247 1.072 0.65774 0.629341 1.1293 0.595209 1.42648 0.736625 0.734723 0.478596 1.12373 0.407022 0.477936 1.43216 1.3074 0.614756 0.722873 0.471068 0.623602 0.83074 0.586432 1.01141 0.812684 1.40958 0.580158 0.897384 2.13691 0.802983 0.494608 0.399642 1.37396 0.977382 0.626322 0.769057 0.660322 1.57256 0.727837 0.678516 0.645963 1.2047 0.774517 1.27128 0.934671 1.13461 1.01414 0.599061 0.851962 0.470793 0.784008 0.912779 0.912567 0.394044 1.05311 0.575033 0.429602 0.630204 1.3295 0.948587 1.22647 0.630554 0.375378 1.32244 0.559591 1.18857 0.248972 0.506692 0.809274 0.588036 1.32158 0.871937 0.510692 0.950318 0.710562 0.910894 2.34942 0.770468 0.707994 0.566378 0.835702 0.377547 0.930466 0.610528 0.616481 0.996805 0.739871 0.484021 0.384209 0.414388 0.694749 0.675316 1.17147 2.06583 0.5499 0.550365 0.858942 1.03189 0.936694 0.776828 0.755459 0.435485 0.517061 1.01064 0.539218 1.38494 0.416913 0.819141 0.485283 0.225987 1.29754 1.2531 0.398136 0.873334 0.554941 0.392831 0.818573 0.66367 1.61385 1.40566 0.979447 1.02559 0.852372 0.990311 0.409668 1.19699 0.770558 1.31029 0.591293 0.480052 0.36582 0.741017 0.948496 0.500331 0.72435 0.524185 1.59751 1.04263 0.834354 0.571112 0.555447 0.532906 1.12441 1.05316 0.939849 0.893509 1.08666 0.744648 0.889837 0.596523 1.23228 0.547361 0.593007 0.891903 0.362427 0.488821 0.64322 0.428365 0.765083 1.14587 0.309088 0.624408 0.728996 0.559967 0.568722 0.765873 1.46169 0.842117 0.521644 0.606091 0.943117 1.00215 1.13364 0.823663 0.935513 0.382477 1.25247 0.436742 1.26864 0.626342 0.76469 0.592607 0.726052 0.787136 0.516078 0.858801 0.525643 0.579221 0.731243 0.523298 0.443481 0.895912 0.581919 0.331697 0.543072 0.502864 0.471419 1.06719 0.787647 1.90235 0.482283 0.626197 1.18015 0.90968 0.316148 0.894238 0.468416 0.691281 0.428889 2.37677 0.773891 1.69697 0.968339 0.502552 1.00954 0.946202 1.44236 1.43284 1.2265 1.20361 1.11818 0.469889 0.505373 0.741298 0.762418 0.494118 0.640817 1.01408 1.20452 0.963285 0.781721 0.980505 1.32828 0.945978 0.415486 0.49703 0.709159 0.582621 1.5494 0.793896 0.476521 0.938098 0.513235 1.11281 0.63115 0.466297 0.838964 1.66625 0.759835 0.777285 1.14972 1.18635 0.754968 1.18503 0.932533 0.440331 0.424693 0.669324 0.489734 0.905851 1.09976 0.431882 1.18367 1.01437 0.914638 0.801177 1.378 0.555928 1.15799 1.60366 0.951578 0.471497 0.941367 0.639865 2.1084 0.401417 1.28285 1.14526 0.828759 0.751777 1.44139 0.979579 0.748747 0.584773 0.950394 0.523318 1.29646 0.844305 1.36707 0.579591 0.861651 0.801068 0.605881 1.78726 0.588645 1.44543 0.507365 0.670211 0.753923 1.18516 0.754392 0.651227 0.439036 0.464696 1.313 0.65638 0.884106 0.807137 0.788356 0.701376 0.558529 0.878078 0.792244 1.15573 0.483001 0.82548 0.501614 0.318594 1.67855 0.511234 0.572785 0.626777 0.880869 0.858662 1.56156 1.35915 0.563053 0.483066 0.821547 0.70101 1.55638 1.23964 0.42454 0.896388 0.87738 0.95228 1.22683 0.743392 3.38008 0.455152 0.394029 2.11628 0.834263 0.592885 1.95931 0.973086 0.814632 0.381594 1.14301 0.720316 1.30124 0.422344 1.26719 0.865461 0.987844 0.637099 1.14239 1.38455 0.396899 0.997082 0.605154 0.546442 0.881709 0.727846 1.31508 0.85156 0.636799 0.666043 0.473781 1.2722 0.533278 0.715204 0.587222 1.23708 0.54998 1.10923 0.552817 1.3152 0.670641 0.764087 0.757129 0.921977 0.857212 0.983064 0.57194 0.54774 0.437483 0.872559 0.591845 0.986486 0.918238 0.970933 0.499877 0.633554 0.524621 1.4096 0.913665 0.803793 0.604845 1.02563 0.710227 0.521389 1.24518 0.719768 0.580577 1.34301 0.78309 0.522493 0.69186 0.919246 0.962928 1.17103 1.02521 1.31828 0.850025 0.715335 0.84082 1.18146 1.17205 1.10793 0.773499 0.669588 0.654279 0.68427 0.7915 1.55341 0.917844 0.662714 1.03249 1.61111 0.778499 0.907515 1.2426 1.00096 0.393562 0.524112 1.32095 0.8518 0.479147 1.10396 1.31531 1.08833 0.785749 2.21381 0.811323 0.864942 0.676453 0.77859 0.614573 0.481402 1.32906 1.95639 0.674316 0.775813 1.92997 0.600056 1.63125 0.942576 0.5451 0.770814 0.991048 0.964733 1.05255 0.920791 1.40937 0.855695 0.589143 0.680096 0.896963 1.01219 2.00048 1.20608 0.73022 1.17784 0.966412 0.678046 0.281626 1.16946 0.99461 1.0962 1.32353 0.719879 0.731996 1.09952 1.30945 1.16214 0.850203 1.27613 0.58597 0.462475 0.747297 1.8501 0.695352 0.907685 1.01652 0.695389 0.914242 0.883431 1.18377 1.52986 0.71629 0.357994 0.499886 0.766982 0.888502 0.512732 1.26204 0.595002 0.315706 0.724668 0.629759 1.64688 0.882584 2.04928 1.25706 0.392292 0.711768 2.3022 1.04422 0.800313 0.702367 1.26602 0.634473 0.408493 1.13669 0.373816 1.56575 0.607998 0 0.870643 1.00311 0.740121 1.29196 1.08689 0.963786 0.551679 0.873325 0.554762 1.53124 1.04797 0.613015 0.728781 0.76658 0.878643 0.949102 0.972495 0.877624 0.755408 0.976224 0.991462 0.526221 0.971272 0.722803 0.867876 0.84357 0.431137 1.12543 0.584051 0.8151 1.06101 0.783554 1.05041 1.08513 0.837023 0.454476 0.871199 1.1108 0.961274 1.3153 0.339595 0.802903 1.56041 1.06926 0.99135 3.41 0.905123 1.45591 0.554 1.13147 0.733564 0.901861 0.92121 0.404054 0.773784 0.471933 1.69748 0.626215 0.756619 0.976587 1.81371 1.36126 0.665898 1.00281 0.492975 0.571695 0.757136 0.723418 0.957009 0.905074 1.17431 0.683605 0.631083 0.666478 2.15855 1.11229 1.12146 0.638631 0.683166 1.22999 0.573088 0.785912 1.90545 0.789455 1.17287 0.950869 1.16133 1.04898 2.34892 1.46478 0.718698 0.822939 1.05749 1.52723 1.16998 1.91487 0.553699 1.15372 0.965948 1.31349 0.507866 0.496902 0.704485 0.838216 0.737189 0.617092 0.420424 0.943279 0.727685 0.969648 1.12832 1.23666 0.63222 1.03957 1.29135 0.972999 0.805422 1.75725 0.983468 0.742635 1.61855 1.00129 0.927028 0.65707 1.16614 0.905357 0.826815 1.19629 0.695561 1.19908 0.795121 1.19824 0.762589 0.923646 1.26105 1.38941 1.09943 2.02012 0.808489 0.742316 0.626566 1.37224 0.538266 0.77818 0.724252 0.933451 0.5484 0.797076 0.620001 0.511223 0.466005 0.652482 0.869418 1.17654 0.766777 0.586733 0.797785 1.05609 0.916249 0.515836 0.725945 1.19752 0.58308 1.06977 1.24647 0.744416 1.39467 0.613505 0.910128 0.558441 0.905303 0.968762 0.78656 1.33033 0.760691 0.917486 0.935747 0.881451 0.574025 1.07694 1.03689 0.792504 1.3186 1.37992 0.684072 0.570594 0.680971 0.875001 0.792124 0.699816 0.488386 0.619736 1.07836 1.05148 1.19244 0.612829 0.614876 1.74392 0.668777 0.776215 0.442266 0.610877 1.20886 1.55549 0.942452 1.8185 1.05174 0.535894 0.858327 2.07662 0.440379 2.38829 0.861999 0.611975 1.02455 0.770075 0.729217 0.400479 1.22558 0.58235 0.889779 1.18614 1.72566 0.728224 1.32259 1.00724 1.01908 0.774822 0.869072 1.10458 0.827493 2.77677 0.750068 0.966546 0.760442 1.21028 1.07593 1.26219 0.573487 0.902651 0.442772 0.515407 0.440931 1.50878 0.830851 0.649573 0.993674 0.946371 0.495499 1.05914 1.76087 0.766997 1.84247 1.03707 0.951869 1.03096 1.07066 1.02996 1.43305 1.15051 2.00559 1.02891 0.992577 0.820241 1.62207 0.748674 2.19025 0.989058 1.21543 0.976984 1.2045 0.72643 1.36244 1.84239 0.930384 1.3472 1.58823 1.89275 1.23014 1.01395 0.706325 0.443849 0.473118 1.11033 1.23693 0.94388 1.38252 0.793092 1.05343 0.910645 0.602711 0.471256 0.987807 0.386437 1.4943 1.96414 0.466167 0.77409 0.969265 0.997173 0.460506 1.22762 0.529888 0.765185 0.997393 0.465241 0.836562 0.594181 1.32519 0.563215 0.837087 0.934776 1.27705 1.30619 0.627281 0.783717 0.501467 0.271093 1.17956 0.933897 0.354817 1.07122 0.957608 0.965627 1.32714 0.709031 1.05495 0.60584 1.32935 0.754055 1.04746 1.0679 0.92172 1.47779 1.30631 0.607886 0.721429 0.921525 0.92688 1.10953 0.951206 1.13498 0.792668 0.628035 0.57945 1.40342 1.18954 1.01854 1.13994 0.821805 0.569472 0.845294 0.782749 1.14752 0.937861 1.77597 0.779737 0.652677 1.2861 0.808898 0.886374 0.323824 0.681418 0.895625 1.02988 0.880533 0.935771 0.65647 1.89751 1.68966 0.83542 1.1995 1.3892 0.873879 0.629982 0.716016 1.2497 2.93193 0.939736 0.869413 1.32484 1.13841 1.13184 1.46937 1.35383 0.88283 1.79798 0.760748 0.934749 0.706641 1.14145 1.13087 0.637435 1.00536 1.55233 0.762311 0.695418 1.27216 1.17373 0.697438 1.24581 0.385393 0.968327 1.5798 1.49765 1.03502 0.836659 0.698816 0.828771 0.94153 1.73133 1.5685 0.726827 1.18346 0.646181 1.1805 0.589837 1.56652 0.788191 0.70662 0 1.22337 0.720002 0.696161 1.60694 0.77174 1.10489 1.02199 0.901628 1.13683 0.897551 0.51715 0.770525 1.03667 1.0236 0.777099 0.94284 0.687588 0.807249 0.807379 0.801678 0.723954 0.746321 0.835916 0.79319 1.31409 1.22185 0.673724 1.11009 1.10127 0.782919 0.659365 0.940086 0.824442 0.706934 1.04793 1.04403 1.11721 0.220787 0.332427 0.395884 0.816745 1.05886 1.31153 0.702491 0.739097 1.29505 0.455799 0.641053 0.679847 0.480009 1.10933 2.02525 1.04936 0.683849 0.711757 0.521127 1.26832 1.36201 1.03865 0.931931 1.42715 0.971239 0.599334 0.835699 1.02518 1.13642 1.02612 0.879103 1.14162 1.1315 2.06271 0.823127 1.02635 1.07306 1.21301 0.740197 0.532124 0.67882 0.883616 0.813961 1.03555 0.771622 0.993919 0.860107 0.904336 1.43551 1.57079 0.561686 0.667261 0.795211 0.518189 0.860551 1.46954 0.699614 1.39087 0.739754 1.1476 1.11615 1.57602 0.945324 0.645098 1.46027 1.37923 1.16835 0.825734 1.4071 0.809574 0.768 1.1126 0.732903 0.872922 1.88009 0.559324 1.11162 1.04642 1.41008 0.770778 1.54092 0.892881 0.843104 0.76253 0.552893 0.965611 1.14911 1.25109 1.66095 1.63585 0.951518 1.16207 1.09469 0.678381 0.575273 1.17638 0.81911 1.15433 0.716909 0.945019 1.16273 0.953935 0.587618 0.870362 1.07899 0.799265 1.09847 1.1682 2.05794 0.733441 1.0081 0.634062 0.570095 0.812264 1.04108 1.07987 1.20818 0.917683 1.80614 0.980535 0.517291 0.753715 0.794724 0.452972 1.05824 1.13522 0.994506 0.833286 0.921241 1.33503 1.37212 0.880758 1.1901 1.43315 1.41418 2.31715 1.16428 1.44793 1.19134 0.795985 0.88465 0.893105 0.704761 0.721594 0.844859 0.719321 0.656592 0.634846 0.673486 0.874064 0.632066 1.14879 0.896847 1.38999 0.64814 0.955337 0.333117 0.655326 2.72999 0.638926 1.28776 1.04759 0.6628 3.23082 0.759326 1.37251 1.18117 1.39897 1.99991 1.00205 0.897467 0.673866 0.778786 1.98649 1.27121 0.748103 0.58346 1.10668 2.19267 0.723702 1.19204 1.48057 2.14676 1.06645 0.378258 0.677574 1.42703 1.11863 0.821612 0.963102 1.12574 0.780174 1.74122 2.01952 1.15862 1.60348 1.20874 0.911403 0.924585 0.36907 1.10488 0.91387 0.63904 1.39568 0.95098 0.775035 0.821614 0.600605 1.68018 0.888977 0.767538 1.0771 0.732057 0.890078 1.21747 0.951913 0.60289 2.47053 1.06065 1.21132 0.694059 0.9556 0.361599 0.788287 1.06406 1.64914 1.08966 1.12372 0.810548 0.993306 1.14688 1.21548 0.771862 0.830152 1.76263 0.632059 0.951853 0.703674 0.800075 0.829273 1.27563 0.525723 0.426942 0.916861 0.918867 1.27884 0.731778 0.728815 0.892661 0.906136 1.3201 1.29038 1.65957 2.49178 0.791409 1.21208 0.837331 0.976742 0.698062 1.459 0.513126 1.69233 0.814422 1.62274 0.595731 0.858926 0.820244 0.606105 1.12255 0.772952 0.503946 1.68416 1.13374 1.19258 1.08182 1.78649 0.904378 1.12591 1.22279 1.58508 0.868336 1.07186 1.31917 0.875312 0.839038 0.809815 0.886467 0.839898 0.852428 1.1042 1.20341 1.1424 1.1613 0.922771 2.14372 1.03951 0.785713 0.611856 0.540159 1.40003 1.13048 0.932306 0.378308 0.964139 0.696931 0.671092 0.558089 1.07494 0.782646 1.10692 0.502764 0.984237 1.48448 1.86547 1.65072 1.0609 1.17069 1.20955 0.543287 0.74754 0.731024 1.52391 1.61014 1.40805 1.55455 0.876705 0.815163 0.556021 1.54601 0.836554 1.02261 1.0121 0.870605 2.1541 0.96518 0.89733 0.875804 2.36436 1.31884 1.26042 0.876079 1.18566 1.11038 0.807699 1.9081 1.28935 1.02611 0.762485 1.28114 0.816919 0.85276 0.901657 1.38474 0.55101 0.817997 0.834409 1.18279 0.87428 1.46435 1.4985 1.69534 1.47386 1.45238 0.693902 0.516582 0.823526 1.17056 1.47465 0.474757 1.39226 0.794036 1.07038 0.842926 0.888707 1.62196 0.67765 0.702527 1.53242 0.922848 1.48908 0.668628 0.916441 1.07583 1.01192 1.44075 1.51891 2.42065 1.21189 1.61207 1.67991 0.321656 1.08737 1.17281 1.05092 1.06135 0.708292 0.812676 0.761702 1.16386 1.39424 1.0029 0.819737 0.731834 0.962286 1.17681 0.582555 2.16305 1.77101 0.855003 1.17539 1.32165 0.565385 0.844412 1.06044 0.921282 0.610725 0.604198 0.331323 0.664076 0.684815 1.26138 1.03485 0.761032 0.793648 0.879377 1.08725 0.749026 1.37413 1.05019 1.40943 1.3116 0.538459 0.774125 0.808587 0.904156 0.817403 1.00562 2.18243 1.68241 1.55006 0.746326 0.907152 1.19348 0.684994 0.351803 2.7415 1.65541 ]
@@@ Frame-accuracy per-class: [ 86.0362 81.3278 75.9825 78.97 86.8293 61.0169 52.8814 85.2839 87.4552 85.6685 94.4762 82.2242 89.0052 85.3933 75.6989 73.6 75.6923 72.679 82.4742 89.9811 89.2675 76.8254 90.2613 77.2277 72.155 86.5934 72.1127 85.5967 79.1774 91.3349 68.9076 79.7508 77.2563 79.5181 95.5195 86.9565 95.6078 93.185 84.4646 60.1227 65.4545 81.0811 86.5052 64.5545 77.3663 89.9598 60.1376 79.476 83.3225 92.302 83.7016 56.5905 91.4104 82.9268 88.0632 83.7945 45.283 80.4233 92.5046 66.1417 78.1784 85.2459 77.0428 93.1073 68.1388 73.9336 67.1741 52.1739 89.0323 86.6242 85.9729 88.411 82.2664 84.579 94.8352 82.3188 83.9863 75.0552 90.3553 72.0539 77.1084 62.3377 88.9209 90.3108 95.0119 73.7481 89.008 90.0662 75.5187 69.258 83.1683 79.7386 75.8621 80.2228 54.5455 77.9271 83.3542 88.042 66.6667 90.1004 86.0534 57.9387 57.6687 82.0937 81.3559 85.8726 82.2335 82.0513 86.6044 67.0051 73.5931 60.5505 85.7143 75.2 26.087 82.0084 85.3067 90.429 66.9683 74.0245 81.4229 78.7402 82.0809 50.3937 82.2695 85.1485 86.5204 53.0744 82.0339 68.3417 75.7282 66.0109 67.6218 86.22 72.5869 85.5895 77.4624 74.5057 78.2609 91.1814 73.3032 86.2338 89.8048 83.5891 60.4027 62.7737 64.5161 82.9569 92.201 58.9474 86.3071 68.9655 94.7132 89.5961 74.4745 87.2038 63.6678 78.1538 85.7413 74.1036 79.1946 75.6152 0 82.1853 77.5194 81.4035 81.592 90.982 74.5843 78.3242 83.5249 73.2394 76.7213 89.6861 91.1695 88.1356 81.2287 79.4376 65.4028 28.5714 82.9268 88.1159 75.8497 69.8706 73.4884 78.9116 76.7347 91.41 85.0575 74.3516 85.4782 60.3175 86.9076 73.6842 87.5847 95.7265 63.4146 51.1278 87.9433 71.5953 85.1175 91.2937 80.427 96.7742 54.2056 59.4005 69.2994 73.3119 75.2542 70.922 92.6829 72.51 80.4378 64.8968 81.4599 89.6552 89.0722 77.6735 73.2782 86.6008 78.8671 84.6377 56.0748 76.5957 78.8644 77.8378 86.6808 89.8263 62.7249 68.6567 70.9677 75.7475 67.5159 72 84.9162 81.0036 63.3166 86.4259 84.264 75.7062 92.3077 85.9135 82.8866 91.4286 81.7021 66.6667 94.6835 80.9365 79.7342 86.836 83.2356 74.6736 48.5175 72.5552 88.6878 84.2105 69.4301 74.0741 67.9612 75.0958 69.1983 87.3362 55.8559 88.8889 65.1163 80.1382 80.597 83.3552 86.2275 81.768 86.4865 76.0943 84.9162 86.0759 79.8928 83.2432 88.6775 66.3102 81.5864 91.6031 87.4494 89.3983 88.0546 77.3163 78.8321 62.8099 86.5574 81.337 44.4444 78.4983 91.7647 76.4398 89.9135 81.1808 89.1122 30.303 76.5073 46.9841 68.7898 88.412 73.4082 75.0831 49.8728 53.2374 69.5035 58.9981 68.1115 89.3151 85.9951 74.386 76.7123 86.3049 85.2018 70.5882 60.6965 71.3656 80.9816 71.1111 52.5822 73.7401 89.5522 83.6834 77.9292 87.0466 53.9185 81.4404 87.646 72.5979 81.7021 75.7396 82.243 89.2562 69.5971 44.5498 82.3529 79.0698 60.6061 63.3694 71.8615 61.3497 73.0667 91.954 87.9819 81.1083 85.7143 72.3312 67.4897 87.3646 64.0747 68.6303 72.8625 77.2093 63.5579 84.5361 69.7248 54.5455 75.9184 84.6803 71.9682 77.8032 48.2759 88.4315 65.7343 63.9769 77.1574 77.8589 53.9683 75.3316 72.7273 86.0215 77.6471 90.4459 63.2911 74.5921 60.4878 85.3392 73.0038 74.4479 82.7225 56 86.3287 56.5445 87.2993 78.5498 80 72.51 77.0428 83.1169 89.3971 88.4254 58.4192 79.1946 72.0539 78.9744 82.1192 82.149 83.8323 72.7273 77.6524 66.2252 86.0908 78.2201 88.3815 91.0553 56.9038 86.0274 80.1619 84.0841 75.5448 74.1259 57.3066 55.814 84.1678 86.0884 77.2118 78.2112 63.1579 65.6 83.6364 75.6501 69.969 70.5202 64.4951 79.1367 7.1066 85.6649 90.0662 46.1538 73.8462 83.2998 41.4815 73.9884 78.7172 87.9915 64.8379 83.8095 66.0793 90.5109 56 76.2105 68.9459 83.4853 80.7018 52.349 90.3896 69.6833 84.0678 83.6601 73.9496 79.2768 59.8504 78.8732 80.916 90.3226 86.8687 62.029 83.1804 80 84.507 64.5161 79.8122 60.7889 83.2685 58.6751 85.7143 74.6667 71.5447 70.8171 78.2609 69.8061 83.7004 85.7143 87.4725 83.7209 84.472 70.0696 78.2609 71.3656 81.9672 82.7068 87.7493 53.4759 81.1594 75.6996 83.9024 69.3671 79.6915 86.7993 56.7164 82.6347 85.7793 56.0554 76.9552 82.4859 80.7302 80 72.6688 67.5241 74.5308 60.6742 77.3558 75.5839 71.5294 72.3247 69.6356 70.2703 79.2661 80.9412 81.1189 80.7921 75.8621 62.9108 68.9655 82.3529 58.5366 62.8571 78.7879 71.5789 63.0824 69.0909 89.9696 85.8757 64.4914 77.8523 87.5472 67.9612 57.868 74.3662 78.5841 43.1373 80.6723 76.3636 81.8428 78.826 87.4552 85.4271 50.3226 47.205 81.149 78.0165 39.0244 82.5822 54.7692 71.4961 87.106 77.9874 66.6667 74.1433 73.3453 77.4704 61.8005 76.6355 82.2757 80.5742 75.3541 70.1538 45.5696 66.6667 76.7213 64.4135 74.2729 84.3931 92.4956 60.4082 67.8679 58.0645 70.2929 76.0736 78.187 64.1509 65.4971 57.5342 78.7565 61.1465 85.7143 87.2727 75.242 30.5085 81.7266 67.5449 71.6049 82.5485 76.0234 74.8603 66.0482 68.0851 76.9231 91.3858 87.2428 79.0419 80.9969 84.7747 60.733 85.1018 97.1429 80.7882 84.5361 48.2759 75.188 49.4382 66.6667 87.2979 79.1252 34.1637 73.6842 76.1905 75.5418 61.3162 84.7599 88.3895 62.4561 88.6406 51.1628 82.5083 0 69.4796 74.0741 83.2117 64.133 68.2353 66.6667 86.2745 79.5181 88.4211 55.7576 72.9529 81.1189 77.898 78.3673 71.5493 72.2348 75.0552 71.09 81.5427 64.0098 68.7831 83.7209 70.9141 80 74.0157 80.3347 87.2559 61.5385 83.2215 77.7293 70.8995 69.3878 63.9252 64.8649 80.5031 85.0394 77.53 74.4186 72.4252 66.3317 90.0997 72.885 62.7566 65.4804 69.6833 0 76.1421 58.9091 87.7797 68.0374 77.9874 74.0947 70.7692 88.9353 76.9231 88.2883 57.0533 89.6 77.7328 68.9655 52.459 61.7143 80 73.6318 86.676 80.8199 76.1905 82.7225 68.9895 71.8447 63.3663 77.1267 82.1918 84.7318 11.7647 63.8838 68.9655 80.6846 83.9506 58.8997 83.2244 80.427 43.4783 73.5931 55.2381 70.3297 67.2694 69.6391 44.0154 60.039 78.5855 78.3069 68.7631 60.274 65.3992 45.0867 81.9923 69.7318 73.5751 66.6667 86.3071 88.2155 82.0399 84.058 78.5185 86.2385 88.1662 72.6225 82.494 67.9128 67.1506 60.6742 82.1342 92.3077 70.3297 74.7145 72.2689 52.7473 73.3894 84.2105 51.5556 70.5539 69.4301 83.9378 57.3991 77.1654 79.034 63.4812 83.0918 56.7742 81.6162 65.4275 75.6133 72.2949 63.7975 64.0777 66.6667 34.2857 80.9917 78.3448 86.5306 51.497 84.0525 81.6626 78.9189 75.2852 84.5129 74.1722 84.097 86.1789 87.8668 85.1406 72.7273 59.6273 83.7607 81.0127 73.6349 63.2035 62.069 87.5121 79.8122 67.8899 85.0242 72.7273 66.4789 77.8761 59.0164 86.6995 77.8761 82.945 77.53 75.5365 78.4119 59.8465 82.0208 75.6757 73.5426 66.6667 84.0183 71.6981 69.3333 77.13 51.2 51.3619 83.3747 82.4988 80.6283 76.9399 79.7203 81.3115 85.6492 85.761 71.5026 73.107 61.3027 85.3503 89.6552 46.1538 81.0289 78.0488 87.3181 80.2111 62.7642 53.2982 73.834 45.1613 73.6842 85.0794 78.9986 34.2857 93.6709 23.5294 75.3346 85.2106 71.2135 79.3587 80.4494 89.078 78.1609 81.9599 76.7494 64.3678 53.7549 85.7143 65.0155 71.2871 62.2951 76.2463 77.1704 73.2026 80 37.3984 77.8068 69.8163 80.5861 60.6061 67.8007 50.6024 83.3876 72.9306 87.3239 84.5839 85.2228 63.1579 80 76.0234 68.7719 76.2322 85.6624 70.7158 57.2687 77.2964 55.814 72.1992 84.7458 85.7143 67.5991 66.6667 57.3427 66.1448 44.3439 74.1748 70.9677 77.6371 48.5126 81.4815 27.7372 73.8916 69.2913 72.7634 75.6303 83.9237 60.5578 57.0447 72.7273 61.7284 53.8283 50.2283 63.7681 74.3034 80.3738 87.106 90.0585 72.9282 62.8429 72.7273 53.5948 78.9189 69.969 72.3327 83.5955 90.2655 72.7077 87.395 65.1969 37.5479 91.6129 80.5281 72.6644 68.0965 88.8889 64.2735 85.1711 77.2834 71.6763 87.5283 80.2218 80.1843 59.1304 82.1293 78.3818 73.2394 64.3172 50.2924 85.5019 73.6196 82.8496 93.578 65.1584 76.8166 89.1334 66.2953 68.9281 72.6882 62.3306 79.1511 71.0183 83.1461 54.4276 78.9588 69.9001 69.8174 73.3163 60.8696 70.5512 81.3688 72.0293 73.2673 71.8693 78.2609 71.7949 62.3377 73.8007 85.2103 86.911 52.3227 61.8182 72.8538 69.1262 78.1362 84.5606 78.3964 76.0181 73.8739 69.4215 47.6821 80.5797 84.4444 58.4206 75.6757 76.2887 90.0741 86.1314 75.9894 69.7872 69.3069 72.3327 83.2536 50.5495 52.9248 78.6305 66.6667 60.8955 76.6067 82.1235 79.6069 66.3342 10.5263 71.3911 76.4835 64.1509 73.2394 66.0793 71.5789 61.2137 79.5127 47.2303 73.9274 72.7273 87.0466 65.2632 61.0039 79.6899 73.43 51.497 70.8229 82.1114 57.6577 69.5652 77.8378 64.4764 87.9676 74.0995 55.9671 60.4106 67.3396 82.2967 83.1615 74.3383 76.3251 51.8519 54.1872 71.3043 61.5385 86.5672 68.2353 80.7966 52.3677 79.2839 80.2125 0 68.0244 77.9392 82.2086 52.8302 77.9896 63.5897 66.0944 67.9908 64.5161 72.5061 84.6462 78.4 70.3364 74.3083 77.4775 73.5632 84.1424 79.1809 79.4667 80.1444 84.3956 83.2117 77.5956 73.0864 61.5385 62.6506 85.6397 71.0027 69.4639 72.0648 80.6643 67.3774 77.0642 84.8193 58.9928 70.0637 70.184 94.2272 89.829 91.4027 79.6518 69.1262 56.8475 76.7213 79.4824 64.3275 87.1046 80.7122 83.6364 92.1348 72.1311 49.7041 75.8364 83.5949 80.7643 83.2444 67.4847 51.1416 72.9242 77.6699 57.4924 72.0812 82.7389 81.0811 70.615 71.2042 65.2874 72.2372 67.3973 68.1672 38.5321 77.901 68.6825 71.3568 68.4746 81.2121 82.1485 83.6879 80.3419 75.9443 73.3624 78.1671 66.6667 73.8916 70.8688 59.887 58.0645 82.4161 85.7143 82.8283 87.1508 75.7493 56.7718 82.1317 57.6803 78.2147 75.5906 65.9933 63.0137 72.6522 83.0565 57.3099 65.3465 64.9446 77.551 62.0525 70.9141 73.0045 65.3968 78.7879 77.0798 49.7354 87.9334 66.2021 71.1297 65.0549 78.0723 51.9774 69.9301 78.1457 76.1087 83.8174 69.5825 68.8797 66.0194 64.5533 50.1672 74.1617 66.4935 70.4508 82.6446 84.1608 69.7987 81.9672 60.793 78.1609 69.0058 65.2015 73.3096 86.5801 79.4258 72.1649 76.1488 64.9462 51.8519 42.0168 74.8115 70.7124 83.6653 83.7782 77.6371 71.7691 71.8563 64.5872 74.9141 42.1941 77.6758 85.5468 79.3443 78.7879 88.3081 77.5956 63.9405 75.1678 72.1268 75.3247 59.3103 61.0592 76.4045 67.052 58.0897 68.4685 26.087 72.3192 63.0197 67.1815 75.6923 71.8563 73.8022 81.4159 84.1849 79.4297 84.345 80.884 79.2193 81.5629 78.4661 84.63 65.8098 75.8315 51.2563 80.1425 72.9805 91.258 80.1097 24.924 83.3922 69.5652 67.3854 82.4207 0 82.0513 44.0678 64.9057 57.3494 45.8781 65.1163 77.9553 86.052 78.7879 40.5229 66.1597 78.0749 82.1239 69.4878 43.3566 81.3385 61.5385 59.19 39.5062 64.6575 88.7967 82.8157 59.4982 68.7609 74.2857 66.711 69.7395 73.029 48.0493 43.0206 58.0645 51.5366 64.7303 70.3259 70.4403 89.7087 71.0327 66.6667 81.7792 52.2523 59.2593 76.9127 73.695 84.8 48.6188 75.5735 78.481 73.9255 84.4037 67.2694 58.5859 72.4919 84.2105 36.5019 70.6827 60.6635 80.597 76.2006 90.939 77.8032 64.2336 68.9655 62.2951 67.9463 78.2435 75.6381 60.88 63.1179 78.4452 74.7253 45.6274 84.5977 75.0751 78.7879 80.1688 74.4186 64.7528 83.9187 88.0855 64.8729 74.4242 63.3962 80.2721 81.92 72.6968 73.2789 60.4462 69.3157 57.554 32.1285 78.5619 65.6934 80 78.4 85.9002 59.4458 85.8006 53.7585 77.6471 55.1181 83.8951 76.0148 76.0839 82.6966 63.5569 75.1445 86.4125 48.8136 75.7764 68.9157 64.4491 44.2353 74.9446 67.4772 59.8131 61.3333 73.8983 70.7819 66.6667 75.7475 76.9231 77.0416 75.3341 73.7475 77.6119 77.1084 62.1723 70.5657 70.6468 76.412 44.8 72.8171 75.8202 84.2975 97.2973 60.6335 72.2063 71.6049 93.0292 72.381 79.0021 82.3529 89.2794 66.8213 77.8173 74.2358 85.6566 70.8479 58.427 57.732 49.3151 69.6133 69.3069 43.2432 84.7726 75.3927 74.8718 64.2686 56.1983 60.8229 59.6364 80.3519 76.1711 83.779 55.1181 79.046 72.3404 76.5321 74.023 31.694 69.7987 74.141 79.1897 32.9519 63.4538 66.2824 77.7958 66.29 65.6371 79.1809 39.0244 64.5768 73.8878 79.7601 59.6923 81.6754 71.8447 74.1163 49.5238 83.7777 80.067 77.7894 64.9351 75.817 62.7451 57.1429 53.8012 57.1429 56.6038 83.1169 84.4444 76.7075 62.7002 67.5325 87.8873 64.2424 79.3774 69.3603 78.0207 75.9644 54.9521 84.7085 80.2974 53.3333 74.9004 65.0888 80.7212 74.9206 68.1265 67.1256 56.305 57.5087 33.5664 64.8829 52.4715 47.4886 92.6554 67.7316 66.2983 69.4981 71.407 82.7586 77.748 80 65.2229 58.4192 69.4534 79.3388 78.2609 70.8911 72 83.2215 40 47.5751 83.1858 73.8661 62.141 84.1918 76.6102 70.9677 72.5076 83.0026 84.9315 93.3868 83.3034 80.677 63.0872 69.1689 77.7293 82.1869 75.9754 69.869 75.7647 60.4651 68.1319 58.0087 60.3774 83.8046 82.4742 77.2229 68.7023 77.0186 72.1461 35.4244 46.4088 55.2204 80.8511 72.2372 57.9439 82.8304 90.2045 25.6 53.4161 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 0.786277 (Xent), [AvgXent: 0.786277, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 77.6612% <<

