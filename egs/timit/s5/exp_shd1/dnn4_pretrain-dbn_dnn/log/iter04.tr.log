nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.008 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter03_learnrate0.008_tr1.2793_cv1.9888 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter04 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975032
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.81539, max 8.96107, mean 0.00568746, stddev 0.99447, skewness 0.129835, kurtosis 2.1535 ) 
[1] output of <AffineTransform> ( min -26.3125, max 23.1865, mean -3.31765, stddev 3.69801, skewness 0.137816, kurtosis 1.41377 ) 
[2] output of <Sigmoid> ( min 3.73802e-12, max 1, mean 0.191241, stddev 0.298302, skewness 1.62606, kurtosis 1.26654 ) 
[3] output of <AffineTransform> ( min -30.2088, max 16.2133, mean -4.02582, stddev 2.71332, skewness -0.0139849, kurtosis 2.42923 ) 
[4] output of <Sigmoid> ( min 7.59412e-14, max 1, mean 0.0961768, stddev 0.192546, skewness 2.95765, kurtosis 8.62825 ) 
[5] output of <AffineTransform> ( min -15.1668, max 11.3796, mean -3.20018, stddev 1.97862, skewness 0.62298, kurtosis 2.40157 ) 
[6] output of <Sigmoid> ( min 2.58915e-07, max 0.999989, mean 0.107969, stddev 0.186925, skewness 2.87466, kurtosis 8.38986 ) 
[7] output of <AffineTransform> ( min -19.7456, max 17.2772, mean -2.96235, stddev 2.23004, skewness 0.606108, kurtosis 2.85448 ) 
[8] output of <Sigmoid> ( min 2.65813e-09, max 1, mean 0.137809, stddev 0.222374, skewness 2.30754, kurtosis 4.73075 ) 
[9] output of <AffineTransform> ( min -16.3473, max 16.2701, mean -2.95418, stddev 2.70298, skewness 1.36728, kurtosis 2.8273 ) 
[10] output of <Sigmoid> ( min 7.9514e-08, max 1, mean 0.161756, stddev 0.27716, skewness 1.95197, kurtosis 2.52816 ) 
[11] output of <AffineTransform> ( min -29.8447, max 25.1574, mean -3.71841, stddev 3.34835, skewness 1.00583, kurtosis 3.42668 ) 
[12] output of <Sigmoid> ( min 1.09303e-13, max 1, mean 0.137921, stddev 0.280469, skewness 2.19625, kurtosis 3.37368 ) 
[13] output of <AffineTransform> ( min -11.9611, max 21.1356, mean -0.0172624, stddev 3.14755, skewness 0.627082, kurtosis 1.14822 ) 
[14] output of <Softmax> ( min 1.75734e-13, max 0.999878, mean 0.000657799, stddev 0.0173335, skewness 40.6462, kurtosis 1844.62 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.970458, max 1.13022, mean -0.000100612, stddev 0.0556953, skewness -0.166616, kurtosis 21.5295 ) 
[1] diff-output of <AffineTransform> ( min -0.327284, max 0.357649, mean 3.15561e-05, stddev 0.0103068, skewness -0.23889, kurtosis 70.942 ) 
[2] diff-output of <Sigmoid> ( min -1.62022, max 2.0175, mean 0.000834205, stddev 0.0894233, skewness 0.191199, kurtosis 16.7685 ) 
[3] diff-output of <AffineTransform> ( min -0.343573, max 0.321177, mean 1.41855e-05, stddev 0.0110629, skewness -0.243445, kurtosis 83.1842 ) 
[4] diff-output of <Sigmoid> ( min -1.60637, max 2.63961, mean 0.000225092, stddev 0.115031, skewness 0.125942, kurtosis 12.8488 ) 
[5] diff-output of <AffineTransform> ( min -0.412977, max 0.588339, mean 5.5208e-05, stddev 0.0114598, skewness 0.387727, kurtosis 97.7369 ) 
[6] diff-output of <Sigmoid> ( min -1.65212, max 2.40067, mean 0.000699311, stddev 0.0993176, skewness 0.144303, kurtosis 12.933 ) 
[7] diff-output of <AffineTransform> ( min -0.234428, max 0.339389, mean 3.68333e-05, stddev 0.00984526, skewness 0.100508, kurtosis 50.0478 ) 
[8] diff-output of <Sigmoid> ( min -1.0913, max 1.38968, mean 0.000267539, stddev 0.0758104, skewness 0.0645861, kurtosis 11.297 ) 
[9] diff-output of <AffineTransform> ( min -0.188783, max 0.187511, mean 3.50668e-05, stddev 0.00770548, skewness 0.126144, kurtosis 42.9206 ) 
[10] diff-output of <Sigmoid> ( min -0.946909, max 1.14881, mean 0.000191329, stddev 0.059859, skewness 0.0546784, kurtosis 13.7506 ) 
[11] diff-output of <AffineTransform> ( min -0.43742, max 0.227796, mean 4.56533e-05, stddev 0.00902609, skewness -0.889269, kurtosis 81.4017 ) 
[12] diff-output of <Sigmoid> ( min -1.96201, max 1.15875, mean 0.000172243, stddev 0.0977032, skewness -0.229336, kurtosis 7.09954 ) 
[13] diff-output of <AffineTransform> ( min -0.999925, max 0.956203, mean -7.75203e-09, stddev 0.0201181, skewness -22.9007, kurtosis 1598.44 ) 
[14] diff-output of <Softmax> ( min -0.999925, max 0.956203, mean -7.75203e-09, stddev 0.0201181, skewness -22.9007, kurtosis 1598.44 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.43891, max 1.43416, mean -6.52789e-05, stddev 0.159855, skewness -0.0294828, kurtosis 2.07725 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.887219, max 0.702112, mean 0.00807835, stddev 0.176224, skewness -0.257795, kurtosis 1.63242 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.790271, max 0.747791, mean 0.000820825, stddev 0.0640605, skewness 0.00612495, kurtosis 7.03263 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.05019, max 0.805259, mean 0.00363142, stddev 0.183038, skewness -0.186101, kurtosis 2.74682 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.619179, max 1.0248, mean 0.00139638, stddev 0.0400186, skewness 0.489587, kurtosis 16.7896 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.854528, max 1.06952, mean 0.0141332, stddev 0.190192, skewness 0.284521, kurtosis 3.17384 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.481073, max 0.610773, mean 0.00107935, stddev 0.0349564, skewness 0.348386, kurtosis 11.2771 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.583848, max 0.623067, mean 0.00942936, stddev 0.166707, skewness 0.182401, kurtosis 1.52769 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.441163, max 0.44942, mean 0.00121115, stddev 0.0334536, skewness 0.398652, kurtosis 8.36718 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.633848, max 0.636832, mean 0.00897703, stddev 0.132234, skewness 0.335828, kurtosis 2.38764 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -1.03957, max 0.600941, mean 0.00205523, stddev 0.0483079, skewness 0.0634009, kurtosis 11.6765 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.12251, max 0.736933, mean 0.0116872, stddev 0.160826, skewness -0.184674, kurtosis 4.31031 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -5.29411, max 3.23201, mean -5.75622e-09, stddev 0.107666, skewness -3.8636, kurtosis 116.482 ) , lr-coef 1, max-norm 0
  bias_grad ( min -5.30326, max 3.21718, mean -4.39192e-09, stddev 0.364251, skewness -2.14725, kurtosis 38.5587 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 342784 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -6.78548, max 7.66488, mean 0.00618661, stddev 0.998336, skewness 0.126755, kurtosis 2.01683 ) 
[1] output of <AffineTransform> ( min -29.11, max 23.6712, mean -3.34089, stddev 4.03417, skewness 0.156201, kurtosis 1.32963 ) 
[2] output of <Sigmoid> ( min 2.2788e-13, max 1, mean 0.204598, stddev 0.314025, skewness 1.51247, kurtosis 0.820622 ) 
[3] output of <AffineTransform> ( min -32.2452, max 18.3499, mean -4.13836, stddev 2.86082, skewness -0.02905, kurtosis 2.24999 ) 
[4] output of <Sigmoid> ( min 9.90985e-15, max 1, mean 0.0983001, stddev 0.198546, skewness 2.88656, kurtosis 8.07114 ) 
[5] output of <AffineTransform> ( min -15.0107, max 11.096, mean -3.19349, stddev 2.02012, skewness 0.584895, kurtosis 2.30208 ) 
[6] output of <Sigmoid> ( min 3.02638e-07, max 0.999985, mean 0.110794, stddev 0.190158, skewness 2.80012, kurtosis 7.8885 ) 
[7] output of <AffineTransform> ( min -21.0303, max 17.8194, mean -2.89053, stddev 2.2812, skewness 0.597101, kurtosis 2.65403 ) 
[8] output of <Sigmoid> ( min 7.35621e-10, max 1, mean 0.146264, stddev 0.230203, skewness 2.18662, kurtosis 4.08355 ) 
[9] output of <AffineTransform> ( min -17.0481, max 17.3635, mean -2.91331, stddev 2.80888, skewness 1.35581, kurtosis 2.75611 ) 
[10] output of <Sigmoid> ( min 3.94549e-08, max 1, mean 0.169242, stddev 0.285758, skewness 1.86452, kurtosis 2.13407 ) 
[11] output of <AffineTransform> ( min -25.9683, max 23.3922, mean -3.7861, stddev 3.50454, skewness 0.977658, kurtosis 3.18841 ) 
[12] output of <Sigmoid> ( min 5.27384e-12, max 1, mean 0.140611, stddev 0.286088, skewness 2.15307, kurtosis 3.14402 ) 
[13] output of <AffineTransform> ( min -13.3977, max 22.8116, mean -0.016428, stddev 3.38528, skewness 0.606026, kurtosis 1.12777 ) 
[14] output of <Softmax> ( min 1.92498e-14, max 0.99977, mean 0.000657819, stddev 0.019176, skewness 40.4697, kurtosis 1775.17 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.53919, max 0.920037, mean -0.000249792, stddev 0.0455729, skewness -0.397577, kurtosis 38.1658 ) 
[1] diff-output of <AffineTransform> ( min -0.247142, max 0.346301, mean 2.23835e-05, stddev 0.00815591, skewness 0.729801, kurtosis 78.1771 ) 
[2] diff-output of <Sigmoid> ( min -1.65124, max 1.99984, mean 0.000101943, stddev 0.0740479, skewness 0.199821, kurtosis 18.4387 ) 
[3] diff-output of <AffineTransform> ( min -0.234107, max 0.419639, mean 2.16643e-05, stddev 0.00921094, skewness 0.45189, kurtosis 109.545 ) 
[4] diff-output of <Sigmoid> ( min -1.34952, max 2.27076, mean 8.65819e-05, stddev 0.0972357, skewness 0.0588905, kurtosis 13.5028 ) 
[5] diff-output of <AffineTransform> ( min -0.29774, max 0.254178, mean 3.63947e-05, stddev 0.00961861, skewness -0.00363439, kurtosis 63.7478 ) 
[6] diff-output of <Sigmoid> ( min -1.19273, max 1.30731, mean 0.000132974, stddev 0.0840336, skewness 0.0228252, kurtosis 12.3503 ) 
[7] diff-output of <AffineTransform> ( min -0.210205, max 0.249338, mean 3.24482e-05, stddev 0.00822544, skewness 0.0890401, kurtosis 51.3458 ) 
[8] diff-output of <Sigmoid> ( min -0.965287, max 1.16517, mean 0.000169335, stddev 0.0633047, skewness -0.0387274, kurtosis 13.4641 ) 
[9] diff-output of <AffineTransform> ( min -0.148757, max 0.132539, mean 1.62294e-05, stddev 0.00642401, skewness -0.182533, kurtosis 48.0443 ) 
[10] diff-output of <Sigmoid> ( min -0.883784, max 0.712323, mean 3.79835e-05, stddev 0.0502976, skewness -0.180288, kurtosis 16.2534 ) 
[11] diff-output of <AffineTransform> ( min -0.253646, max 0.174264, mean 2.30185e-05, stddev 0.00744541, skewness -0.170416, kurtosis 62.1798 ) 
[12] diff-output of <Sigmoid> ( min -2.31164, max 1.957, mean 0.000382591, stddev 0.0816472, skewness -0.162303, kurtosis 12.1029 ) 
[13] diff-output of <AffineTransform> ( min -0.999969, max 0.978859, mean -8.18829e-09, stddev 0.016206, skewness -23.875, kurtosis 2119.06 ) 
[14] diff-output of <Softmax> ( min -0.999969, max 0.978859, mean -8.18829e-09, stddev 0.016206, skewness -23.875, kurtosis 2119.06 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.2361, max 1.19675, mean -0.000753781, stddev 0.133273, skewness -0.00372722, kurtosis 2.07205 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.468485, max 0.573056, mean 0.00573015, stddev 0.142804, skewness 0.304149, kurtosis 0.447124 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.627548, max 0.686322, mean 0.00139161, stddev 0.0585451, skewness 0.0588022, kurtosis 5.53545 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.70659, max 0.6871, mean 0.00554602, stddev 0.160241, skewness 0.0584868, kurtosis 1.58918 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.605342, max 0.606632, mean 0.000954409, stddev 0.0363247, skewness 0.306982, kurtosis 11.608 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.657867, max 0.872027, mean 0.00931704, stddev 0.174063, skewness 0.385317, kurtosis 2.38631 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.398023, max 0.557957, mean 0.00102973, stddev 0.030714, skewness 0.302242, kurtosis 8.7523 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.526534, max 0.540276, mean 0.0083068, stddev 0.142515, skewness 0.313914, kurtosis 1.43195 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.417914, max 0.312488, mean 0.000619766, stddev 0.0297494, skewness 0.0201471, kurtosis 7.02308 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.462295, max 0.436722, mean 0.00415479, stddev 0.110319, skewness -0.0266746, kurtosis 2.00203 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.428199, max 0.523237, mean 0.0012278, stddev 0.0413911, skewness 0.238598, kurtosis 8.10905 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.561865, max 0.492491, mean 0.00589272, stddev 0.12356, skewness 0.102021, kurtosis 2.16509 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.14376, max 2.45695, mean -1.92947e-08, stddev 0.0852364, skewness -2.39784, kurtosis 100.581 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.88715, max 2.45838, mean -8.78384e-09, stddev 0.256203, skewness -0.635407, kurtosis 14.1941 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0786645 min, processing 72625.8 frames per sec; i/o time 5.20112%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14111 120 114 116 102 29 147 431 139 624 262 548 95 133 232 62 162 188 145 264 293 157 210 252 206 227 177 121 194 213 59 160 138 41 524 149 489 359 331 244 27 18 144 252 121 124 944 114 5399 17569 1561 284 471 20 632 126 26 94 273 190 263 30 128 442 158 105 525 11 77 78 552 418 679 528 1016 172 727 226 492 148 41 38 347 273 210 329 186 75 361 141 50 229 14 179 16 260 399 380 208 348 168 179 81 181 88 1263 98 58 160 98 115 54 66 62 11 119 350 151 110 448 126 190 86 63 70 151 159 154 147 99 51 457 174 395 129 114 299 480 34 300 110 192 230 423 223 68 294 243 288 142 120 14 444 408 166 105 144 162 529 125 74 223 6 210 64 142 100 249 210 274 130 35 152 111 628 206 146 284 105 10 20 172 279 270 107 661 122 308 130 173 423 220 622 85 221 292 20 66 211 128 191 614 140 15 160 183 392 155 147 70 20 125 365 508 342 43 242 266 181 354 229 517 160 211 158 92 236 201 194 33 15 451 392 162 89 139 99 401 98 88 71 358 242 87 117 16 197 149 150 216 426 191 185 158 110 313 96 94 154 130 118 114 166 121 21 289 100 381 83 90 18 148 268 118 186 92 525 93 176 196 123 174 146 156 68 60 152 179 13 146 212 95 173 135 298 16 240 157 78 116 133 150 196 69 70 269 161 182 203 142 109 580 111 212 100 113 81 22 106 188 435 309 183 96 159 180 813 140 117 84 160 60 136 105 93 279 49 323 115 81 187 130 220 198 248 229 121 138 321 339 134 107 289 145 381 16 122 414 251 218 14 704 214 173 295 205 31 188 148 232 127 78 197 214 102 228 131 158 286 12 325 95 342 165 147 125 128 38 240 479 145 74 148 97 75 288 83 71 221 75 341 213 744 497 119 182 123 166 206 71 174 21 369 305 186 525 28 62 137 211 161 86 153 69 98 289 226 97 32 248 67 432 171 470 200 262 113 68 112 237 175 493 28 74 192 110 147 76 178 359 200 35 65 15 148 172 163 12 106 46 106 215 128 158 115 37 61 128 34 180 113 80 227 21 80 215 103 113 91 332 175 93 103 339 102 197 194 276 33 250 439 144 479 88 246 22 155 155 186 44 355 235 212 135 123 240 272 212 71 252 101 106 188 76 61 17 82 47 139 27 164 88 260 223 132 257 98 177 282 25 59 247 184 238 139 298 77 80 278 302 61 410 162 317 174 79 22 160 279 126 205 160 228 522 176 162 39 25 152 251 223 86 286 122 166 15 119 81 176 132 85 109 289 78 185 137 361 29 347 417 364 180 85 89 269 23 149 133 121 83 160 410 95 466 17 101 145 14 66 44 19 216 251 140 66 52 161 311 239 133 142 268 107 151 0 355 94 68 210 42 10 178 124 47 82 201 71 323 122 177 221 226 105 181 815 94 322 180 82 190 119 1408 32 372 114 94 24 267 55 79 63 291 21 150 99 752 230 170 140 110 8 98 137 290 267 238 179 97 239 110 166 159 62 123 14 30 87 117 100 356 341 52 95 143 51 151 264 109 363 8 275 14 204 202 154 229 140 80 115 52 45 276 235 129 256 254 94 238 182 131 86 130 130 96 196 120 148 225 34 202 54 553 173 208 160 275 133 618 6 45 306 59 45 178 28 112 171 289 96 111 63 455 146 103 77 247 134 346 420 197 51 400 17 181 362 122 83 799 204 92 131 1688 75 185 61 630 124 236 80 58 118 320 115 14 516 106 54 103 280 177 169 213 101 56 536 291 116 201 195 336 18 111 70 109 79 37 111 187 128 201 1008 95 457 71 152 219 305 96 191 130 235 14 71 155 225 240 189 307 189 632 15 275 157 359 52 39 8 261 510 564 249 222 352 43 224 221 130 126 45 161 151 30 170 155 229 37 61 191 190 136 49 411 41 153 223 35 366 639 104 127 85 142 456 275 230 113 288 21 120 29 17 214 79 214 255 110 257 77 118 218 13 68 101 63 251 59 183 125 145 170 202 215 109 241 161 267 174 256 90 200 49 76 92 161 276 222 56 463 654 317 130 77 151 144 186 175 292 131 213 86 220 270 108 57 131 395 106 113 85 403 81 189 54 110 144 363 179 368 232 184 400 191 489 231 230 350 465 586 149 317 131 273 50 275 11 97 38 135 368 286 204 137 215 257 418 210 224 110 55 60 75 172 202 525 277 145 337 68 189 117 50 276 313 136 179 423 28 167 194 461 203 601 9 190 227 238 177 113 47 189 451 171 151 181 96 142 129 322 103 83 200 170 55 11 92 243 494 291 121 170 693 104 145 434 141 13 101 57 58 167 42 351 179 195 376 0 245 378 244 79 288 97 116 1082 263 205 374 312 163 126 277 43 154 146 187 138 227 205 91 202 84 124 191 184 214 123 421 234 163 207 69 392 407 805 555 331 459 257 193 152 270 256 205 168 82 44 30 84 134 350 392 468 81 109 138 51 163 98 350 55 219 95 217 185 182 155 54 676 231 99 147 82 316 70 292 251 114 185 205 101 293 88 170 372 143 247 89 183 269 159 159 470 190 148 36 484 150 85 151 135 220 209 180 557 157 313 294 94 360 143 119 227 207 88 71 75 349 843 251 120 51 173 149 253 192 299 302 211 74 152 113 43 85 136 421 115 104 242 228 232 13 59 331 189 125 243 355 398 250 272 145 118 163 1961 152 115 363 91 134 74 378 346 72 160 400 86 256 55 11 200 228 129 162 250 490 56 205 245 156 452 435 409 169 263 194 225 99 561 179 234 364 164 141 80 185 173 8 19 29 132 207 139 64 156 211 16 76 131 93 282 224 71 388 32 160 40 547 120 241 139 286 192 752 249 120 243 218 46 211 120 291 79 257 198 13 1281 166 13 738 488 437 90 370 118 174 163 276 49 154 104 131 124 316 100 468 303 218 68 14 30 260 250 215 829 131 141 45 131 217 166 115 118 64 313 270 608 334 412 132 73 312 298 428 246 226 69 124 375 68 167 62 230 198 165 219 127 190 133 948 357 222 171 259 511 147 80 207 240 212 225 164 53 112 147 121 25 150 149 324 411 249 100 41 133 521 301 150 62 303 411 60 18 110 174 40 394 52 240 331 284 215 421 114 247 430 133 48 109 90 50 18 1198 95 97 208 60 279 137 170 245 280 190 293 117 334 217 91 223 276 271 218 124 173 308 265 129 146 20 159 258 333 162 477 154 438 52 1106 298 479 38 841 127 66 85 66 26 192 67 285 218 115 177 412 385 148 434 168 156 454 403 22 125 84 360 157 205 290 170 429 71 149 131 109 88 156 90 129 330 14 559 412 392 145 155 181 425 252 187 74 157 216 56 231 191 281 147 170 165 579 328 249 278 354 74 559 114 283 243 343 212 193 227 115 79 194 48 410 65 80 109 135 90 215 117 185 53 480 464 62 80 ]
@@@ Loss per-class: [ 0.493579 1.09811 1.14527 1.11075 0.71266 1.43884 2.23038 0.814553 0.868455 0.742759 0.416519 0.744 0.875971 0.768248 1.17827 1.09174 0.979641 1.24604 0.92706 0.619651 0.586355 1.13129 0.473412 1.12533 1.2833 0.67842 1.26291 0.9083 0.998303 0.617792 1.2058 1.10243 1.30611 1.10462 0.347148 0.763586 0.297301 0.429519 0.879682 1.94404 1.71531 1.25353 0.532196 1.5311 1.20544 0.48962 1.04426 1.07057 0.806542 0.337743 0.614553 1.54721 0.528132 1.69837 0.641425 0.821802 1.51894 1.15726 0.421008 1.59913 0.970098 0.944469 0.943757 0.431551 1.47879 1.10616 1.45149 2.0634 0.673581 0.915104 0.878762 0.579915 0.723113 0.822877 0.291726 0.81486 0.878561 1.42182 0.480092 1.41842 1.24763 1.58909 0.575715 0.66818 0.582942 1.22886 0.690923 0.577431 1.10438 1.4538 0.946296 0.871522 1.17742 0.908188 1.90106 1.08894 0.99175 0.706762 1.45427 0.622139 0.631955 1.90776 1.71494 1.03618 1.13289 0.633768 0.93423 0.883692 0.779389 1.42917 1.11111 2.05996 0.780188 1.2691 2.63834 1.16705 0.747749 0.573714 1.83084 1.33161 0.926299 1.20664 1.02663 2.24001 1.01565 0.947016 0.945885 1.59664 1.12312 1.67844 1.24941 1.52881 1.39277 0.862771 1.01879 0.670571 1.1104 1.21548 1.24725 0.593113 1.46408 0.718879 0.647018 0.88727 1.70169 1.15593 1.53395 0.882168 0.539991 1.83439 0.841278 1.5219 0.392019 0.80324 1.18181 0.983955 1.726 1.1993 0.708299 1.31069 0.996299 1.27318 4.17718 1.12983 0.971118 0.816102 1.09081 0.54442 1.21704 0.802256 0.819922 1.14108 0.972792 0.677934 0.580262 0.666866 0.992953 0.872887 1.50759 3.28922 0.73237 0.81089 1.24038 1.39924 1.20235 1.07326 0.975035 0.679758 0.76087 1.31631 0.763915 1.89659 0.612517 1.19132 0.694683 0.401363 1.46028 1.78331 0.593672 1.23506 0.729312 0.585576 1.17595 1.2247 2.06789 1.91172 1.36633 1.36207 1.19022 1.24871 0.62625 1.75401 1.12 1.65002 0.868543 0.779508 0.50177 1.00984 1.4049 0.71855 1.05411 0.765499 2.17486 1.32983 1.20131 0.775492 0.81164 0.785443 1.51234 1.19001 1.58819 1.2214 1.46943 1.13124 1.1469 0.888931 1.5377 0.827571 0.84209 1.15815 0.568179 0.695106 0.903982 0.601127 1.04307 1.50086 0.508188 0.95459 1.03031 0.830876 0.797074 1.15146 1.94957 1.05612 0.832986 0.864332 1.39714 1.27771 1.57251 1.14262 1.35958 0.642314 1.58353 0.603465 1.7401 0.844832 0.962501 0.812292 0.908392 1.1992 0.841027 1.18534 0.74074 0.849898 1.10572 0.764274 0.638713 1.2778 0.898708 0.495638 0.870488 0.795687 0.68322 1.48495 1.12268 2.38893 0.747967 0.926398 1.48602 1.38461 0.454155 1.21718 0.729056 0.910368 0.632036 2.94448 1.0761 2.31147 1.40797 0.834259 1.45015 1.16984 1.84664 1.75456 1.68439 1.63496 1.61389 0.657571 0.728722 1.10138 1.05276 0.706604 0.941606 1.36816 1.71412 1.27471 1.18168 1.2999 1.77249 1.35618 0.619581 0.714235 1.0321 0.82005 1.9527 1.14982 0.723588 1.4078 0.744166 1.46278 0.905064 0.670476 1.11194 2.30393 1.15832 1.08064 1.69813 1.57234 1.02463 1.58717 1.20185 0.645196 0.636162 0.962185 0.706205 1.34641 1.43213 0.631377 1.62461 1.38108 1.2531 1.10127 1.82764 0.806109 1.52027 2.28021 1.35113 0.678313 1.26873 0.832979 2.6055 0.57018 1.68638 1.52653 1.20598 1.03921 1.77523 1.36586 0.994893 0.862025 1.25802 0.815791 1.77646 1.0826 1.70884 0.869151 1.14036 1.06057 0.945913 2.03127 0.916012 1.92719 0.759116 0.961046 1.07274 1.64024 1.08641 1.0149 0.651088 0.649799 1.76341 0.986366 1.18268 1.04806 1.07968 1.00583 0.699354 1.13463 1.10648 1.48502 0.675187 1.14195 0.726033 0.490605 2.41386 0.736222 0.776994 0.82531 1.15102 1.33087 2.23067 1.73331 0.875 0.719372 1.09083 0.940422 2.20546 1.62081 0.633383 1.241 1.29233 1.35542 1.58948 1.07172 4.0658 0.691671 0.585228 2.76724 0.940581 0.757021 2.68386 1.32843 1.12281 0.535109 1.54878 0.968868 1.79298 0.681918 1.75157 1.1674 1.36129 0.866838 1.78557 1.79392 0.641483 1.39598 0.827538 0.808131 1.24536 0.979659 1.62965 1.26307 0.994134 0.828182 0.711517 1.69381 0.750166 1.55102 0.831693 1.29759 0.778782 1.49154 0.850833 1.71709 0.978407 1.05168 0.966993 1.28719 0.808575 1.39896 0.786284 0.733158 0.612129 1.01036 0.845311 1.32057 1.17827 1.39672 0.71575 0.960281 0.876906 1.84376 1.1927 1.14612 0.880842 1.43263 0.992231 0.770596 1.74162 0.970026 0.800443 1.87419 1.03762 0.644547 0.981683 1.28496 1.32119 1.64612 1.3314 1.76245 1.15056 1.04249 1.20881 1.5932 1.59375 1.54393 1.04358 0.895617 1.00382 1.01734 1.16367 2.01171 1.2894 1.02401 1.15518 2.49693 1.04267 1.25024 1.65902 1.30405 0.605625 0.869431 1.75015 1.24279 0.684829 1.51636 1.80243 1.51827 1.0134 3.06702 1.20842 1.24706 0.880543 1.14537 0.782805 0.713365 1.71298 2.66271 0.987581 1.08704 2.44291 0.899053 2.18394 1.33494 0.761849 1.0175 1.54061 1.3725 1.32911 1.24919 1.90146 1.23769 0.800094 0.942876 1.25248 1.35652 2.35759 1.71368 1.04348 1.55396 1.40249 0.952393 0.372611 1.55838 1.45432 1.52889 1.77974 1.11842 1.03833 1.54061 1.65139 1.56623 1.15875 1.72946 0.815444 0.637189 1.05527 2.6836 1.00096 1.20414 1.34625 0.921876 1.43556 1.23784 1.58441 2.02013 1.10928 0.620802 0.69817 0.829829 1.34689 0.697894 1.73953 0.835028 0.678775 1.03564 0.967704 2.14606 1.18327 2.60434 1.82166 0.551531 0.998704 3.05605 1.2652 1.09168 0.991784 1.65708 0.888439 0.509741 1.62396 0.555774 1.99328 0.86415 0 1.21501 1.5098 1.05191 1.65539 1.46626 1.71179 0.773186 1.16549 0.745176 2.05377 1.33435 0.85219 0.961056 1.03852 1.31905 1.27223 1.32203 1.16488 1.0014 1.25306 1.35862 0.746322 1.29924 1.09174 1.24638 1.16172 0.603359 1.49385 0.801954 1.08255 1.41441 1.12566 1.50128 1.42913 1.12371 0.790487 1.23545 1.67983 1.41544 1.76941 0.469614 1.14376 2.12251 1.47779 1.48502 4.40458 1.25197 1.94391 0.821391 1.55593 0.989863 1.199 1.34743 0.553176 1.14051 0.704554 2.14732 0.956132 1.04684 1.48552 1.97319 1.87451 0.825372 1.34345 0.724372 0.868491 1.07219 1.02667 1.37398 1.13891 1.48026 1.12056 0.973239 0.925143 3.43519 1.59828 1.73251 0.920025 0.945453 1.62747 0.877792 1.1083 2.42987 1.0308 1.46571 1.30459 1.6198 1.38674 3.01497 2.01622 1.02588 1.06119 1.4639 2.02554 1.65899 2.46741 0.730072 1.70742 1.27615 1.8246 0.736396 0.697916 0.96206 1.05363 1.07571 0.971693 0.633864 1.33206 1.05814 1.29267 1.54476 1.77813 0.854554 2.0265 1.57125 1.3277 1.17933 2.33849 1.35265 1.00848 2.26136 1.42098 1.2533 1.10878 1.61323 1.12282 1.16184 1.59597 1.02633 1.66341 1.02641 1.66161 1.06119 1.30952 1.60792 1.89327 1.46841 2.95955 1.11818 1.03101 0.914932 2.04972 0.746421 1.06612 1.00478 1.28694 0.757884 1.07508 0.886197 0.718336 0.68018 0.900875 1.22011 1.61978 1.03577 0.914843 1.13842 1.40543 1.4643 0.748361 1.09789 1.62499 0.780117 1.50134 1.60152 0.997601 1.85608 0.998022 1.34759 0.850821 1.22117 1.3515 0.997299 1.79347 1.07535 1.74718 1.3807 1.33029 0.764155 1.37635 1.60735 1.09025 1.795 2.00579 0.949709 0.807712 0.987868 1.24125 1.11899 1.03745 0.791162 0.844572 1.44958 1.39797 1.69084 0.861639 0.858132 2.34915 0.877674 1.03461 0.72907 0.89638 1.57361 2.06111 1.31451 2.02078 1.34704 0.743745 1.14653 2.47958 0.682614 2.74065 1.24223 0.886275 1.33331 1.04838 1.00919 0.60177 1.58281 0.850436 1.1317 1.50643 2.34788 0.89689 1.73216 1.44982 0.959858 1.04806 1.24257 1.4687 1.20367 3.29404 1.12192 1.33589 1.08455 1.69732 1.46163 1.54173 0.891551 1.26593 0.703812 0.823088 0.624979 2.03911 1.14909 0.892283 1.35816 1.32305 0.710963 1.51404 2.31988 1.07654 2.73619 1.43358 1.35817 1.47067 1.5188 1.54688 1.92038 1.57831 2.55972 1.44622 1.4079 1.1625 2.2509 1.19757 2.80304 1.3161 1.67596 1.29257 1.46655 1.0811 1.83757 2.26272 1.32213 1.86656 2.11311 2.62162 1.66062 1.43183 1.0495 0.72723 0.768952 1.49163 1.67599 1.17901 1.84185 1.15291 1.33403 1.25901 0.85631 0.709617 1.36868 0.592002 2.08304 2.5456 0.753036 1.15449 1.24236 1.32344 0.673353 1.5732 0.789218 1.09757 1.31464 0.636383 1.17918 0.811838 1.59333 0.796639 1.03155 1.30915 1.75521 1.74127 0.897634 1.094 0.740604 0.380737 1.63349 1.2898 0.513184 1.42179 1.31411 1.46204 1.76855 1.03211 1.44812 0.871312 1.79878 0.998129 1.47226 1.42622 1.2892 1.85614 1.61859 0.898488 0.942846 1.17646 1.25742 1.7809 1.40309 1.46836 1.15153 0.896091 0.85114 1.74163 1.68703 1.39495 1.573 1.12798 0.751571 1.21935 1.12557 1.26478 1.15989 2.26464 1.03634 1.05584 1.72461 1.18541 1.18469 0.468052 0.930014 1.23935 1.3916 1.17363 1.19004 0.953713 2.3584 2.16212 1.12683 1.48456 1.89199 1.10284 0.892956 0.981835 1.66107 3.42428 1.27673 1.18726 1.8742 1.36258 1.58299 1.96867 1.90307 1.16247 2.23139 1.18015 1.35441 0.941599 1.43561 1.55494 0.874496 1.30455 2.13412 1.1693 0.840569 1.68684 2.11231 1.13344 1.76888 0.57705 1.34547 2.06966 1.96269 1.33364 1.16059 1.00967 1.11777 1.37636 2.28805 1.99719 0.947663 1.63611 0.910955 1.43159 0.805895 2.19671 1.18708 0.984728 0 1.66164 1.06385 0.878722 2.14665 1.08863 1.49384 1.46628 1.21691 1.46626 1.27071 0.756582 1.06885 1.41571 1.41796 1.04892 1.37165 1.00606 1.14013 1.11225 1.21084 1.076 0.983378 1.23322 1.03674 1.78553 1.76677 0.979761 1.50969 1.47954 1.12798 0.851969 1.25297 0.972574 0.971149 1.58504 1.43692 1.51274 0.31827 0.50912 0.578149 1.11332 1.40887 1.72732 1.00195 1.07434 1.73525 0.699309 0.922256 0.966884 0.676586 1.72749 1.95755 1.32135 1.01438 1.05212 0.763541 1.79939 1.79959 1.47466 1.23856 1.86953 1.33047 0.885009 1.23583 1.3883 1.60565 1.45944 1.19742 1.55593 1.50754 2.54722 1.15555 1.42487 1.31976 1.55355 1.07467 0.758636 1.09741 1.18936 1.1722 1.45482 1.14304 1.46691 1.27521 1.26814 1.84467 2.07708 0.737813 0.883107 1.12816 0.734046 1.2698 2.01714 0.959925 1.91418 1.11762 1.53418 1.4946 2.23433 1.25957 0.90263 1.84095 1.75823 1.52601 1.14966 1.86164 1.20747 1.08483 1.51564 1.03164 1.2462 2.449 0.79786 1.54871 1.3971 1.91119 1.12369 2.08787 1.28812 1.20161 1.04042 0.829826 1.33999 1.45414 1.68004 2.23424 2.11423 1.30467 1.53062 1.51211 0.969773 0.792395 1.54828 1.14079 1.43655 1.26939 1.3399 1.63148 1.31348 0.789969 1.10919 1.52752 1.13136 1.5601 1.42198 2.82072 1.01318 1.33539 0.868727 0.814908 1.15464 1.43878 1.40997 1.69399 1.22441 2.18404 1.38681 0.695168 1.02044 1.1135 0.701082 1.45566 1.57147 1.41576 1.19245 1.30925 1.7737 1.8755 1.20277 1.44065 1.90692 1.96471 3.06631 1.52344 1.85105 1.5914 1.11631 1.24348 1.15466 0.876971 1.01843 1.2389 0.898776 0.967331 0.899519 0.880098 1.16405 0.904619 1.61166 1.2753 1.87768 0.880116 1.36974 0.490799 0.884304 3.38057 0.936765 1.69155 1.47856 0.940145 3.99938 1.18519 1.89073 1.59888 1.9595 2.6504 1.32415 1.18528 1.08324 1.34134 2.78369 1.55733 0.975934 0.875893 1.50481 2.72905 1.03023 1.53683 1.8553 2.45031 1.28047 0.603583 0.955084 1.92832 1.54977 1.13169 1.25117 1.49795 1.13751 2.25127 2.67493 1.41457 2.01588 1.44578 1.30528 1.32781 0.589829 1.53129 1.53609 0.807766 1.80384 1.25351 1.07847 1.12882 0.879518 2.22619 1.17135 1.10243 1.48196 1.05704 1.19676 1.49418 1.24516 0.854724 3.11611 1.52713 1.62397 0.954681 1.27399 0.552698 1.07828 1.58714 1.95927 1.46672 1.51598 1.03974 1.31859 1.48391 1.54562 1.12379 1.29187 2.32454 0.904943 1.36543 1.12462 1.06042 1.26578 1.68344 0.713129 0.604584 1.37292 1.2739 1.72076 1.03358 1.0783 1.19835 1.28998 1.84784 1.75125 2.04932 3.00969 1.17499 1.46725 1.28703 1.27877 0.973675 1.82546 0.69964 2.26123 1.17404 2.1169 0.911412 1.21114 1.11215 0.872068 1.57878 1.13992 0.70446 2.21128 1.33037 1.5576 1.35569 2.43343 1.30559 1.55352 1.73146 2.04241 1.27615 1.38681 1.98197 1.28423 1.16892 1.08964 1.22865 1.2219 1.17752 1.61697 1.67803 1.57917 1.53886 1.2463 2.78288 1.33258 1.09761 0.935235 0.978965 1.85551 1.34881 1.46818 0.633862 1.38279 0.936413 0.994816 0.70925 1.48824 1.13861 1.56616 0.712539 1.3743 2.04829 2.90616 2.08383 1.42485 1.61438 1.78824 0.774727 1.033 0.98114 1.90643 2.22164 1.80908 2.09562 1.21505 1.11135 0.696244 2.06703 1.15574 1.56841 1.38155 1.24978 2.96338 1.37469 1.20626 1.14777 3.03504 1.62649 1.70752 1.17729 1.55382 1.45428 1.06673 2.89685 1.69207 1.47468 1.08379 1.74845 1.03221 1.15426 1.19642 1.75766 0.826335 1.08548 1.1042 1.67944 1.15416 2.05807 1.84202 2.31624 1.92537 2.04428 0.890955 0.867767 1.19655 1.5539 1.93099 0.721908 1.81809 1.13271 1.43183 1.15974 1.17681 2.05137 0.969981 0.923793 1.6703 1.21798 1.88912 0.950295 1.2243 1.59475 1.34388 1.99977 2.03387 3.06341 1.79366 2.12059 2.15222 0.449796 1.40193 1.62726 1.33076 1.40631 0.881624 1.10988 1.06077 1.57926 1.87741 1.46164 1.1902 0.974515 1.27639 1.57148 0.830039 2.83081 2.36139 1.32875 1.53957 1.89917 0.795062 1.09684 1.42501 1.29731 0.880276 0.810853 0.477356 0.926972 0.991735 1.86693 1.36824 1.10566 1.08918 1.18738 1.40562 1.01356 1.79871 1.36292 1.97683 1.63512 0.78292 1.13028 1.2089 1.27686 1.18647 1.50937 2.6802 2.3511 2.09083 0.952155 1.2835 1.24936 1.05754 0.5252 3.38204 2.12312 ]
@@@ Frame-accuracy per-class: [ 81.3308 70.5394 69.869 66.9528 81.9512 50.8475 41.3559 80.1854 67.3835 78.1425 88.7619 74.9316 75.3927 74.1573 66.6667 60.8 66.4615 61.5385 76.9759 82.0416 84.1567 68.5714 85.0356 68.1188 58.1114 76.9231 57.4648 72.428 65.2956 82.904 63.8655 66.6667 67.87 72.2892 89.2278 74.9164 91.7263 89.0125 71.7949 44.1718 50.9091 70.2703 80.9689 48.7129 62.5514 85.1406 50.8205 75.1092 71.5437 88.9098 76.4009 49.2091 86.9565 58.5366 83.3202 77.4704 41.5094 61.3757 88.117 51.4436 70.5882 72.1311 73.1518 89.2655 58.6751 70.1422 56.5176 52.1739 86.4516 78.9809 75.6561 81.2425 77.9985 74.1722 92.179 75.3623 74.5017 58.7196 86.4975 57.2391 65.0602 44.1558 83.741 83.7294 87.4109 65.2504 80.9651 86.0927 65.2835 57.9505 73.2673 73.2026 75.8621 68.5237 60.6061 62.572 73.0914 80.6833 58.5132 82.3529 83.6795 43.454 47.8528 62.8099 70.0565 80.649 61.9289 80.3419 79.7508 55.8376 64.0693 36.6972 76.6917 67.2 26.087 66.1088 77.0328 79.868 51.5837 59.7547 73.5178 61.4173 69.3642 37.7953 73.7589 76.5677 78.9969 43.3657 62.3729 53.2663 66.0194 50.7104 57.3066 73.5777 67.1815 79.476 68.1135 63.0593 52.1739 85.5241 61.5385 80.5195 77.6573 72.4911 45.6376 55.4745 58.0645 75.5647 85.9619 42.1053 77.1784 62.069 87.5141 78.0906 63.6637 70.1422 50.519 70.7692 81.2087 60.5578 73.8255 59.5078 0 69.3587 55.814 73.6842 66.6667 87.7756 64.133 70.3097 72.7969 67.6056 64.2623 82.5112 84.1687 79.9031 75.7679 75.5712 54.0284 19.0476 73.1707 80.5797 65.8318 59.1497 61.3953 70.1436 71.8367 83.6305 75.8621 63.9769 79.1027 47.1655 81.7671 61.9883 79.4582 90.2564 68.2927 43.609 82.7423 58.3658 79.3734 84.6216 66.1922 77.4194 41.7445 46.3215 58.8535 61.0932 67.7966 60.9929 78.0488 54.1833 71.409 53.884 70.9489 71.2644 82.4742 70.9193 58.9532 80.1128 69.281 77.6812 42.9907 66.6667 65.6151 73.5135 73.5729 78.4119 49.8715 68.6567 45.1613 64.8948 56.5605 67.0769 75.9777 76.7025 57.2864 74.7198 75.1269 66.6667 86.7133 79.219 76.701 85.7143 69.7872 60.6061 85.0633 72.2408 70.4319 77.1363 75.7327 61.6188 36.1186 66.2461 75.1131 74.9601 56.9948 60.3175 51.1327 62.8352 59.0717 76.8559 48.048 80.6584 51.1628 76.3385 74.6269 77.3263 82.6347 62.9834 75.6757 63.9731 79.3296 74.2616 69.1689 74.5946 82.7783 52.4064 70.8215 84.9873 74.4939 82.5215 80.5461 61.9808 61.3139 52.8926 78.0328 72.4234 59.2593 51.1945 88.4706 56.5445 81.8444 73.0627 80.402 36.3636 68.1913 34.9206 57.3248 75.5365 62.9213 70.4319 37.659 46.0432 52.4823 46.7532 53.87 80.5479 79.1155 68.0702 66.6667 80.2756 70.852 61.6471 45.7711 60.793 69.9387 71.1111 44.1315 57.2944 82.6636 76.8982 64.8501 77.7202 45.768 72.0222 80.1475 59.7865 74.8936 67.4556 74.1433 80.9917 61.5385 39.8104 65.2406 68.3363 50.5051 53.7867 70.1299 40.4908 65.6 81.9923 80.7256 71.5365 80.0805 59.695 59.2593 85.1986 51.3219 60.6775 58.7361 70.6977 50.0864 75.6014 59.2398 42.4242 62.8571 78.1665 57.6541 75.0572 27.5862 83.6054 53.1469 50.1441 66.3283 73.4793 50.7937 60.4775 68.0135 76.5591 67.451 75.1592 46.0759 62.4709 56.5854 74.8359 63.8783 63.0915 73.2984 48 71.8894 54.4503 80 65.861 69.1525 55.7769 64.5914 77.9221 82.3285 82.3775 47.4227 71.1409 63.9731 70.7692 75.4967 72.0971 79.0419 69.9301 67.7201 59.6026 79.063 71.1944 81.1283 85.8291 38.4937 81.6438 75.3036 79.2793 64.891 58.7413 37.2493 55.814 70.9066 78.8871 71.8499 70.4091 42.1053 46.4 79.2727 61.9385 61.9195 55.4913 53.4202 69.0647 2.03046 79.7927 81.2362 37.9487 76.9231 75.2515 29.6296 65.6647 65.8892 84.1658 52.3691 71.2381 49.3392 80.292 40 67.3684 56.9801 73.9615 52.6316 45.6376 85.7143 66.9683 76.6102 78.4314 61.0644 71.4882 51.8703 64.7887 67.1756 70.9677 77.4411 52.7536 78.2875 56 76.0563 73.1183 73.2394 49.1879 72.3735 42.2713 72.7273 72 68.2927 66.1479 75.3623 56.5097 75.7709 79.5031 81.7582 79.0698 79.5031 58.0046 69.5652 53.7445 74.3169 74.5865 71.7949 41.7112 72.4638 63.3284 76.0976 54.6835 69.9229 79.2043 41.791 76.6467 80.091 35.9862 69.0302 82.4859 68.5598 75.5556 62.3794 51.4469 65.4155 38.2022 69.1983 65.3928 59.2941 56.8266 49.3927 52.3909 68.2569 72.4706 72.7273 70.495 66.9951 46.0094 58.3554 65.3595 69.9187 40 69.0909 67.3684 54.4803 65.4545 84.4985 77.9661 49.904 63.5347 80.7547 57.8641 49.7462 52.9577 70.4425 15.6863 63.8655 64.2424 75.8808 67.5052 80.2867 75.7119 45.1613 28.5714 70.377 69.4215 32.5203 73.8124 41.8462 62.6772 76.7908 65.4088 57.7778 62.9283 62.6118 67.1937 48.1752 70.405 71.3348 73.11 62.8895 62.7692 45.5696 58.8235 69.5082 56.0636 60.4027 71.6763 90.4014 44.898 54.0541 51.6129 57.7406 61.3497 64.5892 55.8491 63.1579 49.3151 68.7392 49.6815 74.9326 77.8182 67.7732 20.339 71.6547 57.485 60.631 72.0222 59.6491 64.8045 50.4638 59.5745 63.5452 83.1461 82.3045 74.2515 63.5514 79.659 46.0733 75.4555 80 73.8916 69.4158 48.2759 67.6692 38.2022 30.7692 81.7552 71.173 19.9288 73.6842 68.5714 68.1115 50.4013 74.739 83.8951 47.0175 82.3091 41.8605 74.5875 0 60.4782 59.2593 75.9124 54.1568 51.7647 47.619 81.7927 68.2731 82.1053 46.0606 62.0347 76.9231 69.2427 70.2041 61.4085 63.6569 64.0177 62.5592 73.8292 56.775 55.0265 76.5891 62.0499 65.4545 66.6667 67.7824 80.8662 64.6154 75.7047 75.9825 58.2011 61.2245 50.0935 43.2432 72.956 77.1654 66.2093 60.4651 57.8073 50.2513 87.309 63.3406 47.5073 58.363 51.5837 0 69.0355 53.0909 76.7642 53.8318 65.4088 64.0669 63.5897 82.6722 58.8235 76.8769 45.1411 75.2 63.9676 55.1724 52.459 46.8571 73.1915 69.6517 79.6634 69.6925 70.4762 76.4398 62.0209 69.9029 57.4257 66.1626 70.3196 75.9285 11.7647 48.6388 55.1724 70.9046 74.5679 51.7799 69.281 67.6157 33.5404 65.8009 47.619 63.7363 50.2712 56.4756 24.7104 46.3938 68.3694 76.1905 59.5388 45.4795 53.2319 26.5896 78.9272 59.0038 64.2487 50.8906 78.8382 84.8485 75.8315 78.2609 63.2099 77.0642 79.3135 57.6369 73.3813 54.2056 53.3575 46.4419 75.9903 30.7692 54.9451 63.2953 65.5462 32.967 66.6667 80.7018 39.1111 61.8076 62.1762 67.3575 47.5336 61.4173 67.618 53.2423 70.5314 37.4194 70.7071 45.3532 66.3781 60.6421 56.2025 52.4272 55.4307 17.1429 71.0744 68.4138 75.9184 31.1377 75.172 67.9707 67.027 60.8365 77.2283 63.5762 73.3154 81.3008 81.2054 77.9116 61.7336 54.6584 75.2137 69.1983 62.7145 58.8745 48.2759 79.9613 68.5446 47.7064 81.1594 60.6061 53.5211 71.3864 51.0539 70.936 63.7168 73.2526 65.1801 60.9442 72.9529 46.0358 71.9168 48.6486 57.3991 68.0851 79.4521 64.1509 58.6667 63.6771 40.5333 40.4669 68.9826 75.062 73.2984 66.4481 65.7343 69.5082 76.082 77.5777 54.9223 59.53 44.4444 73.0361 68.9655 34.965 73.955 71.8404 76.0915 69.1293 52.3577 35.8839 63.7154 45.1613 66.4247 81.2698 69.2629 30.4762 86.0759 23.5294 63.0975 75.2204 63.5961 71.3427 75.0562 83.6879 66.6667 73.9421 66.3657 59.0038 36.3636 74.7253 50.774 62.0462 68.8525 66.2757 62.3794 63.6166 72 29.2683 68.9295 62.4672 65.2015 52.5253 55.164 50.6024 69.0554 60.4027 73.2394 74.4884 80.3753 46.89 72.9412 71.345 58.2456 64.184 81.6697 52.4946 44.0529 70.7106 32.5581 55.6017 67.7966 62.8571 54.0793 60.3774 45.2214 48.1409 34.3891 56.3107 60.6452 68.3544 34.3249 81.4815 23.3577 60.0985 51.9685 60.0398 68.9076 70.8447 51.7928 44.6735 60.4106 50.3704 44.5476 33.79 52.1739 65.6347 71.7757 78.51 77.9727 68.5083 52.3691 64.6465 43.1373 58.3784 62.5387 59.6745 73.2584 84.9558 59.9784 80.9778 50.7087 30.6513 81.2903 63.3663 59.5156 56.3003 75.7835 53.3333 76.0456 71.6628 60.1156 83.4467 68.3919 74.6544 55.6522 77.5665 69.5322 69.4836 44.9339 40.9357 76.0843 65.0307 78.628 91.7431 51.5837 67.128 84.1816 58.4958 54.8168 61.9355 52.0325 64.1698 60.5744 74.9745 40.1728 71.1497 57.0613 58.6466 63.5976 54.1806 63.937 73.7643 68.3729 61.3861 63.5209 60.8696 54.359 64.9351 60.5166 76.5265 79.5812 46.9438 52.3636 60.3248 55.1456 69.5341 80.7601 65.9243 61.5385 70.2703 67.7686 47.6821 73.6232 70.1235 46.6223 66.3063 62.543 85.9259 80.292 63.3245 56.1702 63.3663 63.6528 74.3222 42.4908 47.3538 68.0047 52.6316 47.7612 65.8098 75.4063 71.2531 54.0316 21.0526 62.9921 67.2527 49.0566 65.3521 54.6256 48.4211 50.1319 69.9889 35.5685 64.0264 61.157 78.7565 59.6491 50.1931 71.6279 64.7343 37.1257 59.8504 75.6598 52.2523 43.4783 65.9459 48.0493 82.3054 59.0051 43.6214 46.3343 55.6597 71.7703 70.1031 66.7434 64.311 29.6296 41.3793 60.8696 52.9915 73.4328 68.2353 75.6757 38.9972 69.5652 74.3692 0 55.3971 63.9366 73.6196 35.2201 66.5511 52.3077 55.794 56.2587 55.0285 60.3406 76.1015 68.16 58.7156 64.0316 67.7477 64.3678 73.1392 73.0375 71.4667 66.426 74.2857 72.5061 66.6667 67.6543 50.8876 47.3896 69.4517 59.6206 60.1399 63.1579 75.2076 61.4072 74.0061 78.0723 37.4101 55.7962 58.4049 90.9994 85.1485 85.6712 72.0348 54.7573 47.5452 73.4426 70.2403 54.191 81.2652 73.5905 73.9394 83.1461 52.459 46.1538 63.9405 73.3238 70.828 74.92 51.5337 40.1826 58.4838 62.1359 48.318 58.8832 68.1883 70.2703 58.3144 58.6387 51.4943 61.9946 55.8904 52.7331 23.8532 68.1449 53.5637 71.3568 56.9492 73.9394 74.5656 72.3404 68.7179 62.0278 62.0087 70.0809 49.1484 64.0394 57.2402 62.1469 38.7097 76.2416 79.4425 67.0707 83.7989 64.8501 41.5584 75.2351 42.0063 67.1626 66.6667 54.5455 52.0548 63.5707 78.4053 63.1579 50.8251 56.8266 64.3991 51.5513 58.1717 66.1883 59.0476 70.4944 63.1579 31.746 80.1664 51.5679 59.4142 52.7473 63.6145 41.8079 55.9441 72.8477 67.8112 72.9105 61.6302 68.0498 64.0777 43.2277 36.1204 60.7495 52.987 55.7596 69.7521 78.0142 60.4027 70.8197 51.9824 48.2759 45.614 58.6081 57.414 80.5195 72.7273 56.0825 63.4573 55.914 59.2593 20.1681 67.8733 66.4908 78.0876 78.0287 65.8228 60.9787 62.2754 49.5413 69.4158 34.5992 58.104 79.531 72.7869 70.1299 79.7799 59.0164 54.2751 68.4564 62.0872 62.6263 53.7931 46.729 64.9189 64.7399 41.7154 55.8559 17.3913 60.3491 52.954 51.7375 66.4615 59.481 64.2202 74.3363 74.4526 67.2098 72.8435 73.3702 72.5603 76.1905 70.2065 76.2808 45.2442 66.0754 35.1759 72.3063 62.3955 84.0085 70.7819 21.8845 74.9117 57.1429 54.4474 74.928 0 66.6667 33.8983 49.0566 44.8193 28.6738 60.4651 70.2875 72.8132 60.6061 24.8366 58.5551 74.8663 75.0442 57.461 32.1678 70.5277 58.4615 53.5826 39.5062 57.1689 81.3278 73.2919 48.7455 55.4974 64.4156 56.8771 60.1202 60.5809 39.0144 29.7483 51.6129 36.4066 58.0913 59.3482 60.3774 83.4951 57.4307 51.8519 75.9266 43.2432 66.6667 66.4861 64.0737 75.6571 33.1492 64.5074 66.6667 59.0258 72.7829 59.3128 54.5455 64.7249 78.4689 21.2928 57.0281 48.0253 73.6318 65.5283 86.6557 70.9382 48.1752 48.2759 45.9016 58.3493 73.4531 66.3573 50.1507 53.2319 65.7244 57.1429 31.1787 72.6437 59.4595 61.4719 73.4177 65.1163 50.0797 79.4824 81.8406 50.8221 60.1212 57.3585 69.3878 68.8 64.6566 59.5099 43.8134 53.4216 46.0432 22.49 67.3768 54.0146 62.0896 64 75.4881 49.8741 80.9668 39.6355 69.0196 41.4698 68.9139 65.9989 63.4965 74.1573 49.5627 63.5838 79.3744 39.322 74.5342 55.4217 62.7859 28.2353 56.7627 57.7508 48.5981 49.7778 62.3729 65.0206 47.0588 61.1296 64.8829 69.0293 64.1555 59.7194 63.6816 48.1928 54.6816 60.5944 62.3549 65.7807 22.4 62.9325 66.3426 77.686 64.8649 50.6787 66.4756 54.321 83.6502 59.0476 70.6861 72.6998 83.6555 51.5081 67.8529 61.1354 77.1717 55.5168 43.4457 41.2371 41.0959 64.0884 65.3465 32.4324 77.2632 67.0157 66.6667 57.0743 36.3636 51.1628 44.3636 69.2082 67.2098 75.2228 40.9449 72.2317 56.1702 63.3782 62.9885 19.6721 57.2707 62.5678 69.2449 24.2563 53.8153 57.0605 70.6645 58.7571 59.4595 71.6724 34.1463 52.0376 57.6402 69.8651 45.5385 73.089 65.3722 66.3626 40 75.1017 70.6868 69.2388 51.9481 67.3797 43.1373 49.6241 42.1053 42.1053 41.5094 80 78.5185 67.951 48.5126 51.9481 77.7465 52.3636 70.8171 58.5859 66.9735 74.184 44.7284 73.2673 75.3408 57.7778 66.9323 55.6213 67.6838 65.3968 52.5547 53.012 44.5748 43.3062 26.5734 53.5117 43.346 36.5297 90.3955 60.0639 53.0387 65.6371 61.4221 82.7586 69.1689 68.8485 54.7771 48.11 53.3762 65.5647 71.4454 66.9307 65.0667 73.8255 27.3016 35.5658 61.9469 62.203 42.8198 75.6661 69.1525 58.0645 64.0483 68.8525 80.3653 89.3788 74.6858 69.6756 44.2953 60.4111 67.2489 68.7831 65.7084 60.5531 69.6471 50.1292 60.2198 45.8874 44.0252 78.6632 74.2268 64.799 64.1221 69.5652 57.5342 26.5683 33.1492 43.1555 69.7872 60.9164 65.4206 70.3434 85.8988 20.8 43.4783 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 1.08391 (Xent), [AvgXent: 1.08391, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 68.4449% <<

