nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.008 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter02_learnrate0.008_tr1.5671_cv2.0311 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter03 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975032
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.81539, max 8.96107, mean 0.00568746, stddev 0.99447, skewness 0.129835, kurtosis 2.1535 ) 
[1] output of <AffineTransform> ( min -25.2011, max 19.7367, mean -3.26898, stddev 3.33507, skewness 0.139643, kurtosis 1.52079 ) 
[2] output of <Sigmoid> ( min 1.13575e-11, max 1, mean 0.176816, stddev 0.280321, skewness 1.76836, kurtosis 1.87236 ) 
[3] output of <AffineTransform> ( min -29.8003, max 16.3759, mean -3.91893, stddev 2.6023, skewness 0.0151907, kurtosis 2.63283 ) 
[4] output of <Sigmoid> ( min 1.14256e-13, max 1, mean 0.0956682, stddev 0.189444, skewness 2.99932, kurtosis 8.96518 ) 
[5] output of <AffineTransform> ( min -15.0902, max 11.2381, mean -3.20324, stddev 1.97069, skewness 0.690142, kurtosis 2.64811 ) 
[6] output of <Sigmoid> ( min 2.79526e-07, max 0.999987, mean 0.106841, stddev 0.186989, skewness 2.91873, kurtosis 8.64299 ) 
[7] output of <AffineTransform> ( min -19.9998, max 17.5147, mean -3.05758, stddev 2.21518, skewness 0.622357, kurtosis 3.13743 ) 
[8] output of <Sigmoid> ( min 2.06163e-09, max 1, mean 0.129415, stddev 0.216597, skewness 2.44537, kurtosis 5.46229 ) 
[9] output of <AffineTransform> ( min -16.8901, max 15.5942, mean -3.01414, stddev 2.61786, skewness 1.39258, kurtosis 2.99671 ) 
[10] output of <Sigmoid> ( min 4.62066e-08, max 1, mean 0.153384, stddev 0.268963, skewness 2.05573, kurtosis 2.99902 ) 
[11] output of <AffineTransform> ( min -29.7294, max 24.067, mean -3.61559, stddev 3.19983, skewness 1.05598, kurtosis 3.62084 ) 
[12] output of <Sigmoid> ( min 1.22654e-13, max 1, mean 0.137301, stddev 0.276356, skewness 2.21585, kurtosis 3.50186 ) 
[13] output of <AffineTransform> ( min -11.3708, max 18.7381, mean -0.0181967, stddev 2.8634, skewness 0.671309, kurtosis 1.27563 ) 
[14] output of <Softmax> ( min 1.37211e-12, max 0.999536, mean 0.000657778, stddev 0.0163085, skewness 41.1301, kurtosis 1923.32 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.19445, max 1.07428, mean -1.27353e-05, stddev 0.048775, skewness 0.0622255, kurtosis 21.8468 ) 
[1] diff-output of <AffineTransform> ( min -0.262717, max 0.257216, mean 4.23838e-05, stddev 0.0096715, skewness -0.205874, kurtosis 60.4199 ) 
[2] diff-output of <Sigmoid> ( min -1.38934, max 1.47511, mean 0.000803477, stddev 0.0827856, skewness 0.0666991, kurtosis 13.9355 ) 
[3] diff-output of <AffineTransform> ( min -0.268665, max 0.267201, mean 3.57517e-05, stddev 0.0101474, skewness -0.251962, kurtosis 72.4619 ) 
[4] diff-output of <Sigmoid> ( min -1.37284, max 1.84421, mean 0.000199158, stddev 0.103434, skewness 0.0676666, kurtosis 9.55175 ) 
[5] diff-output of <AffineTransform> ( min -0.341621, max 0.421649, mean 7.57208e-05, stddev 0.0103435, skewness 0.318709, kurtosis 64.8351 ) 
[6] diff-output of <Sigmoid> ( min -1.37031, max 1.68899, mean 0.000759631, stddev 0.0894477, skewness 0.0837835, kurtosis 9.69136 ) 
[7] diff-output of <AffineTransform> ( min -0.185762, max 0.253721, mean 5.67702e-05, stddev 0.00901105, skewness 0.123635, kurtosis 41.2064 ) 
[8] diff-output of <Sigmoid> ( min -0.920751, max 1.18041, mean 0.000316129, stddev 0.0712992, skewness 0.0492869, kurtosis 8.85468 ) 
[9] diff-output of <AffineTransform> ( min -0.141966, max 0.152563, mean 4.68944e-05, stddev 0.00730035, skewness 0.127954, kurtosis 35.5392 ) 
[10] diff-output of <Sigmoid> ( min -0.880418, max 0.982246, mean 0.000199401, stddev 0.0571619, skewness 0.0260596, kurtosis 11.4027 ) 
[11] diff-output of <AffineTransform> ( min -0.34911, max 0.166767, mean 6.52079e-05, stddev 0.0088705, skewness -0.436289, kurtosis 50.1273 ) 
[12] diff-output of <Sigmoid> ( min -1.60505, max 1.06362, mean 0.000327814, stddev 0.0967299, skewness -0.150211, kurtosis 4.20842 ) 
[13] diff-output of <AffineTransform> ( min -0.999942, max 0.944864, mean -9.30832e-09, stddev 0.0212083, skewness -24.2576, kurtosis 1475.77 ) 
[14] diff-output of <Softmax> ( min -0.999942, max 0.944864, mean -9.30832e-09, stddev 0.0212083, skewness -24.2576, kurtosis 1475.77 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.38776, max 1.42876, mean -0.000536646, stddev 0.151183, skewness -0.0349335, kurtosis 2.60049 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.730723, max 1.13053, mean 0.0108502, stddev 0.16415, skewness 0.0925087, kurtosis 3.18933 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.739079, max 0.651268, mean 0.00186583, stddev 0.0559015, skewness 0.100341, kurtosis 8.12092 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.842941, max 0.755237, mean 0.00915248, stddev 0.172364, skewness 0.052074, kurtosis 2.90324 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.635485, max 0.845746, mean 0.00194433, stddev 0.0356973, skewness 0.552972, kurtosis 15.5853 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.699818, max 0.808603, mean 0.0193847, stddev 0.17033, skewness 0.288779, kurtosis 2.25029 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.477458, max 0.561311, mean 0.00163318, stddev 0.0319454, skewness 0.442198, kurtosis 12.0498 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.625064, max 0.574437, mean 0.0145331, stddev 0.151805, skewness 0.21724, kurtosis 1.7992 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.383545, max 0.400821, mean 0.00159141, stddev 0.0303962, skewness 0.445013, kurtosis 8.82396 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.50532, max 0.50212, mean 0.012005, stddev 0.122086, skewness 0.279257, kurtosis 2.0941 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.853903, max 0.527283, mean 0.00272817, stddev 0.045617, skewness 0.263608, kurtosis 9.64639 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.912208, max 0.719717, mean 0.0166932, stddev 0.154375, skewness -0.090669, kurtosis 3.2554 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -5.13692, max 3.27823, mean -7.51811e-09, stddev 0.11266, skewness -3.87694, kurtosis 100.607 ) , lr-coef 1, max-norm 0
  bias_grad ( min -5.2072, max 3.20104, mean 2.50967e-09, stddev 0.382878, skewness -1.94824, kurtosis 30.8768 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 342784 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -6.78548, max 7.66488, mean 0.00618661, stddev 0.998336, skewness 0.126755, kurtosis 2.01683 ) 
[1] output of <AffineTransform> ( min -27.9492, max 21.3591, mean -3.28752, stddev 3.72951, skewness 0.157851, kurtosis 1.42105 ) 
[2] output of <Sigmoid> ( min 7.27445e-13, max 1, mean 0.194186, stddev 0.301452, skewness 1.60519, kurtosis 1.18091 ) 
[3] output of <AffineTransform> ( min -32.0106, max 18.4189, mean -4.03398, stddev 2.75881, skewness -0.0120155, kurtosis 2.4843 ) 
[4] output of <Sigmoid> ( min 1.25308e-14, max 1, mean 0.09794, stddev 0.195655, skewness 2.91776, kurtosis 8.32844 ) 
[5] output of <AffineTransform> ( min -15.4698, max 11.1041, mean -3.20591, stddev 2.00908, skewness 0.621988, kurtosis 2.45078 ) 
[6] output of <Sigmoid> ( min 1.91221e-07, max 0.999985, mean 0.109109, stddev 0.18914, skewness 2.84737, kurtosis 8.17945 ) 
[7] output of <AffineTransform> ( min -21.0963, max 17.4062, mean -2.95986, stddev 2.25902, skewness 0.61279, kurtosis 2.83955 ) 
[8] output of <Sigmoid> ( min 6.88672e-10, max 1, mean 0.139402, stddev 0.224966, skewness 2.28712, kurtosis 4.60152 ) 
[9] output of <AffineTransform> ( min -16.9516, max 17.2933, mean -2.94533, stddev 2.73295, skewness 1.37258, kurtosis 2.85791 ) 
[10] output of <Sigmoid> ( min 4.34533e-08, max 1, mean 0.163606, stddev 0.279549, skewness 1.92861, kurtosis 2.41842 ) 
[11] output of <AffineTransform> ( min -26.7849, max 22.9344, mean -3.7165, stddev 3.36591, skewness 1.01825, kurtosis 3.33859 ) 
[12] output of <Sigmoid> ( min 2.33049e-12, max 1, mean 0.139022, stddev 0.281793, skewness 2.18083, kurtosis 3.30069 ) 
[13] output of <AffineTransform> ( min -11.9179, max 20.729, mean -0.0168146, stddev 3.14716, skewness 0.640869, kurtosis 1.20446 ) 
[14] output of <Softmax> ( min 1.47602e-13, max 0.998913, mean 0.000657802, stddev 0.0184875, skewness 40.7571, kurtosis 1812.64 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -3.37646, max 0.899164, mean -0.000499556, stddev 0.0456197, skewness -5.49096, kurtosis 388.435 ) 
[1] diff-output of <AffineTransform> ( min -0.248192, max 0.849544, mean 1.74539e-05, stddev 0.00839488, skewness 5.24965, kurtosis 518.101 ) 
[2] diff-output of <Sigmoid> ( min -3.39808, max 3.57877, mean -6.06051e-05, stddev 0.0735827, skewness 0.508743, kurtosis 91.1291 ) 
[3] diff-output of <AffineTransform> ( min -0.463194, max 0.793061, mean 1.96673e-05, stddev 0.0090671, skewness 2.19807, kurtosis 342.053 ) 
[4] diff-output of <Sigmoid> ( min -2.37136, max 3.18449, mean -3.37617e-05, stddev 0.0929731, skewness 0.0568208, kurtosis 19.896 ) 
[5] diff-output of <AffineTransform> ( min -0.325914, max 0.373725, mean 4.15016e-05, stddev 0.00927017, skewness 0.211418, kurtosis 82.6476 ) 
[6] diff-output of <Sigmoid> ( min -1.47043, max 2.46043, mean 0.000145067, stddev 0.0807539, skewness 0.15097, kurtosis 16.6364 ) 
[7] diff-output of <AffineTransform> ( min -0.183638, max 0.335924, mean 3.02396e-05, stddev 0.00802871, skewness 0.170589, kurtosis 58.854 ) 
[8] diff-output of <Sigmoid> ( min -0.948134, max 1.81812, mean 0.000132628, stddev 0.0627801, skewness 0.0259741, kurtosis 15.2837 ) 
[9] diff-output of <AffineTransform> ( min -0.15102, max 0.253976, mean 1.65128e-05, stddev 0.00639468, skewness 0.176371, kurtosis 56.3903 ) 
[10] diff-output of <Sigmoid> ( min -0.776624, max 1.04108, mean 8.17035e-05, stddev 0.0498492, skewness -0.14451, kurtosis 15.3648 ) 
[11] diff-output of <AffineTransform> ( min -0.263132, max 0.157721, mean 1.69086e-05, stddev 0.00750563, skewness -0.262306, kurtosis 55.9874 ) 
[12] diff-output of <Sigmoid> ( min -2.00004, max 1.79562, mean 0.000448327, stddev 0.0819548, skewness -0.117887, kurtosis 9.17588 ) 
[13] diff-output of <AffineTransform> ( min -0.999982, max 0.966506, mean -7.69444e-09, stddev 0.017156, skewness -24.9336, kurtosis 1982.97 ) 
[14] diff-output of <Softmax> ( min -0.999982, max 0.966506, mean -7.69444e-09, stddev 0.017156, skewness -24.9336, kurtosis 1982.97 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -2.89753, max 1.63032, mean -0.000674306, stddev 0.136123, skewness -0.108909, kurtosis 5.48156 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.476321, max 0.903831, mean 0.00446819, stddev 0.149983, skewness 0.485011, kurtosis 1.7725 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.623561, max 0.983426, mean 0.00104053, stddev 0.0554267, skewness 0.237599, kurtosis 9.4277 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.612253, max 0.663911, mean 0.00503485, stddev 0.160498, skewness 0.0300045, kurtosis 1.62193 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.535696, max 0.587955, mean 0.00103234, stddev 0.035125, skewness 0.363381, kurtosis 12.452 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.651824, max 0.899273, mean 0.0106244, stddev 0.175856, skewness 0.364595, kurtosis 2.47903 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.441396, max 0.484188, mean 0.000927295, stddev 0.0301173, skewness 0.310293, kurtosis 9.43937 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.56597, max 0.631332, mean 0.00774127, stddev 0.144482, skewness 0.270666, kurtosis 1.43611 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.408324, max 0.299821, mean 0.000591132, stddev 0.0291096, skewness 0.113729, kurtosis 7.61955 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.447783, max 0.490645, mean 0.00422727, stddev 0.113156, skewness 0.0275433, kurtosis 2.04744 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.434816, max 0.453292, mean 0.000947315, stddev 0.0411419, skewness 0.215424, kurtosis 8.1483 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.545046, max 0.531581, mean 0.00432855, stddev 0.126277, skewness 0.124643, kurtosis 2.00085 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.24403, max 2.48933, mean -1.12718e-08, stddev 0.0891446, skewness -2.60943, kurtosis 95.1338 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.90113, max 2.43229, mean -6.27417e-09, stddev 0.271921, skewness -0.768522, kurtosis 12.6122 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0782963 min, processing 72967.3 frames per sec; i/o time 5.26507%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14111 120 114 116 102 29 147 431 139 624 262 548 95 133 232 62 162 188 145 264 293 157 210 252 206 227 177 121 194 213 59 160 138 41 524 149 489 359 331 244 27 18 144 252 121 124 944 114 5399 17569 1561 284 471 20 632 126 26 94 273 190 263 30 128 442 158 105 525 11 77 78 552 418 679 528 1016 172 727 226 492 148 41 38 347 273 210 329 186 75 361 141 50 229 14 179 16 260 399 380 208 348 168 179 81 181 88 1263 98 58 160 98 115 54 66 62 11 119 350 151 110 448 126 190 86 63 70 151 159 154 147 99 51 457 174 395 129 114 299 480 34 300 110 192 230 423 223 68 294 243 288 142 120 14 444 408 166 105 144 162 529 125 74 223 6 210 64 142 100 249 210 274 130 35 152 111 628 206 146 284 105 10 20 172 279 270 107 661 122 308 130 173 423 220 622 85 221 292 20 66 211 128 191 614 140 15 160 183 392 155 147 70 20 125 365 508 342 43 242 266 181 354 229 517 160 211 158 92 236 201 194 33 15 451 392 162 89 139 99 401 98 88 71 358 242 87 117 16 197 149 150 216 426 191 185 158 110 313 96 94 154 130 118 114 166 121 21 289 100 381 83 90 18 148 268 118 186 92 525 93 176 196 123 174 146 156 68 60 152 179 13 146 212 95 173 135 298 16 240 157 78 116 133 150 196 69 70 269 161 182 203 142 109 580 111 212 100 113 81 22 106 188 435 309 183 96 159 180 813 140 117 84 160 60 136 105 93 279 49 323 115 81 187 130 220 198 248 229 121 138 321 339 134 107 289 145 381 16 122 414 251 218 14 704 214 173 295 205 31 188 148 232 127 78 197 214 102 228 131 158 286 12 325 95 342 165 147 125 128 38 240 479 145 74 148 97 75 288 83 71 221 75 341 213 744 497 119 182 123 166 206 71 174 21 369 305 186 525 28 62 137 211 161 86 153 69 98 289 226 97 32 248 67 432 171 470 200 262 113 68 112 237 175 493 28 74 192 110 147 76 178 359 200 35 65 15 148 172 163 12 106 46 106 215 128 158 115 37 61 128 34 180 113 80 227 21 80 215 103 113 91 332 175 93 103 339 102 197 194 276 33 250 439 144 479 88 246 22 155 155 186 44 355 235 212 135 123 240 272 212 71 252 101 106 188 76 61 17 82 47 139 27 164 88 260 223 132 257 98 177 282 25 59 247 184 238 139 298 77 80 278 302 61 410 162 317 174 79 22 160 279 126 205 160 228 522 176 162 39 25 152 251 223 86 286 122 166 15 119 81 176 132 85 109 289 78 185 137 361 29 347 417 364 180 85 89 269 23 149 133 121 83 160 410 95 466 17 101 145 14 66 44 19 216 251 140 66 52 161 311 239 133 142 268 107 151 0 355 94 68 210 42 10 178 124 47 82 201 71 323 122 177 221 226 105 181 815 94 322 180 82 190 119 1408 32 372 114 94 24 267 55 79 63 291 21 150 99 752 230 170 140 110 8 98 137 290 267 238 179 97 239 110 166 159 62 123 14 30 87 117 100 356 341 52 95 143 51 151 264 109 363 8 275 14 204 202 154 229 140 80 115 52 45 276 235 129 256 254 94 238 182 131 86 130 130 96 196 120 148 225 34 202 54 553 173 208 160 275 133 618 6 45 306 59 45 178 28 112 171 289 96 111 63 455 146 103 77 247 134 346 420 197 51 400 17 181 362 122 83 799 204 92 131 1688 75 185 61 630 124 236 80 58 118 320 115 14 516 106 54 103 280 177 169 213 101 56 536 291 116 201 195 336 18 111 70 109 79 37 111 187 128 201 1008 95 457 71 152 219 305 96 191 130 235 14 71 155 225 240 189 307 189 632 15 275 157 359 52 39 8 261 510 564 249 222 352 43 224 221 130 126 45 161 151 30 170 155 229 37 61 191 190 136 49 411 41 153 223 35 366 639 104 127 85 142 456 275 230 113 288 21 120 29 17 214 79 214 255 110 257 77 118 218 13 68 101 63 251 59 183 125 145 170 202 215 109 241 161 267 174 256 90 200 49 76 92 161 276 222 56 463 654 317 130 77 151 144 186 175 292 131 213 86 220 270 108 57 131 395 106 113 85 403 81 189 54 110 144 363 179 368 232 184 400 191 489 231 230 350 465 586 149 317 131 273 50 275 11 97 38 135 368 286 204 137 215 257 418 210 224 110 55 60 75 172 202 525 277 145 337 68 189 117 50 276 313 136 179 423 28 167 194 461 203 601 9 190 227 238 177 113 47 189 451 171 151 181 96 142 129 322 103 83 200 170 55 11 92 243 494 291 121 170 693 104 145 434 141 13 101 57 58 167 42 351 179 195 376 0 245 378 244 79 288 97 116 1082 263 205 374 312 163 126 277 43 154 146 187 138 227 205 91 202 84 124 191 184 214 123 421 234 163 207 69 392 407 805 555 331 459 257 193 152 270 256 205 168 82 44 30 84 134 350 392 468 81 109 138 51 163 98 350 55 219 95 217 185 182 155 54 676 231 99 147 82 316 70 292 251 114 185 205 101 293 88 170 372 143 247 89 183 269 159 159 470 190 148 36 484 150 85 151 135 220 209 180 557 157 313 294 94 360 143 119 227 207 88 71 75 349 843 251 120 51 173 149 253 192 299 302 211 74 152 113 43 85 136 421 115 104 242 228 232 13 59 331 189 125 243 355 398 250 272 145 118 163 1961 152 115 363 91 134 74 378 346 72 160 400 86 256 55 11 200 228 129 162 250 490 56 205 245 156 452 435 409 169 263 194 225 99 561 179 234 364 164 141 80 185 173 8 19 29 132 207 139 64 156 211 16 76 131 93 282 224 71 388 32 160 40 547 120 241 139 286 192 752 249 120 243 218 46 211 120 291 79 257 198 13 1281 166 13 738 488 437 90 370 118 174 163 276 49 154 104 131 124 316 100 468 303 218 68 14 30 260 250 215 829 131 141 45 131 217 166 115 118 64 313 270 608 334 412 132 73 312 298 428 246 226 69 124 375 68 167 62 230 198 165 219 127 190 133 948 357 222 171 259 511 147 80 207 240 212 225 164 53 112 147 121 25 150 149 324 411 249 100 41 133 521 301 150 62 303 411 60 18 110 174 40 394 52 240 331 284 215 421 114 247 430 133 48 109 90 50 18 1198 95 97 208 60 279 137 170 245 280 190 293 117 334 217 91 223 276 271 218 124 173 308 265 129 146 20 159 258 333 162 477 154 438 52 1106 298 479 38 841 127 66 85 66 26 192 67 285 218 115 177 412 385 148 434 168 156 454 403 22 125 84 360 157 205 290 170 429 71 149 131 109 88 156 90 129 330 14 559 412 392 145 155 181 425 252 187 74 157 216 56 231 191 281 147 170 165 579 328 249 278 354 74 559 114 283 243 343 212 193 227 115 79 194 48 410 65 80 109 135 90 215 117 185 53 480 464 62 80 ]
@@@ Loss per-class: [ 0.559185 1.38156 1.33719 1.43901 0.937033 2.01781 2.4312 0.984709 1.03985 0.867393 0.50489 0.88668 1.11197 0.934692 1.36964 1.41809 1.16588 1.42143 1.16101 0.76462 0.712301 1.35256 0.609755 1.31036 1.4607 0.84287 1.48715 1.05738 1.16427 0.751738 1.4128 1.28768 1.57543 1.36644 0.439413 0.927612 0.344609 0.52325 1.05656 2.27792 2.49874 1.65617 0.639107 1.76056 1.47889 0.633512 1.14957 1.26276 0.971377 0.372985 0.674655 1.74418 0.653433 2.26354 0.747123 1.03187 2.18603 1.51556 0.516098 1.89787 1.1344 1.44673 1.19962 0.544785 1.70683 1.31944 1.66386 3.41298 0.800385 1.19595 1.01016 0.707798 0.85821 0.94019 0.358446 0.981926 1.02662 1.73791 0.559915 1.71534 1.58804 1.92081 0.725492 0.825567 0.747992 1.43966 0.829555 0.698814 1.26165 1.72434 1.25903 1.03665 1.83258 1.0802 3.06649 1.26879 1.17364 0.82953 1.6746 0.741104 0.730524 2.23229 2.00335 1.27023 1.47812 0.719034 1.16589 1.11235 1.00077 1.73312 1.34522 2.37261 1.02082 1.59409 3.82251 1.38548 0.879406 0.69642 2.05489 1.49771 1.12274 1.40156 1.3089 2.65416 1.32846 1.17886 1.16003 1.8414 1.27942 1.98801 1.56815 1.70097 1.64351 1.02665 1.21531 0.886084 1.28611 1.37438 1.66188 0.743145 1.83698 0.895463 0.735847 1.02777 1.92758 1.32439 1.76804 1.01773 0.654481 2.13818 1.02205 2.30873 0.497806 0.994794 1.40663 1.17232 1.95346 1.50263 0.83471 1.49969 1.26625 1.47219 6.57012 1.4017 1.1741 0.965361 1.34382 0.676768 1.41175 0.965094 1.07152 1.70856 1.1381 0.835821 0.682032 0.809033 1.19262 1.0021 1.77782 4.92003 1.20886 1.00941 1.47864 1.63718 1.44472 1.23208 1.13852 0.79062 0.950308 1.48768 0.894999 2.19766 0.713769 1.40689 0.877888 0.53423 2.01543 2.11682 0.707813 1.4555 0.902576 0.688307 1.39138 2.02846 2.36311 2.24854 1.57826 1.62929 1.41138 1.40525 0.944422 2.22441 1.30473 1.81911 1.05896 1.02818 0.590935 1.15503 1.67388 0.871622 1.27446 0.929536 2.46743 1.53286 1.41016 0.971447 0.924643 0.941251 1.733 1.64694 2.34975 1.37711 1.6767 1.3397 1.37782 1.10311 1.83426 0.996937 1.10333 1.48469 0.688459 0.823627 1.08641 0.840722 1.26694 2.14696 0.657351 1.15236 1.20767 0.96448 0.935141 1.32047 2.2551 1.21633 1.05953 0.979609 1.74417 1.57897 1.84379 1.32654 1.5702 0.80499 1.86787 0.710893 2.49457 0.983345 1.25341 0.94934 1.16616 1.49187 1.45039 1.46591 0.871344 1.10132 1.33191 0.948786 0.736563 1.41606 1.10421 0.594647 1.16111 0.973333 0.831979 1.83944 1.32631 2.77243 0.905102 1.13183 2.14447 1.6935 0.531025 1.54786 0.917485 1.08952 0.766609 3.76919 1.25251 2.61557 1.73661 1.02194 1.75484 1.33157 2.0513 2.05821 1.97052 1.83747 1.8421 0.848225 0.939495 1.36414 1.29561 0.7988 1.22205 1.60186 2.06192 1.44971 1.46619 1.90655 2.01716 1.59564 0.744984 0.84534 1.24812 1.02515 2.20271 1.37662 0.867893 1.70825 0.865959 1.77095 1.08091 0.843398 1.26336 2.7887 1.48388 1.30661 1.892 1.8056 1.25681 1.88651 1.4181 0.8547 0.74733 1.17805 0.84796 1.55939 1.75514 0.736562 1.82669 1.5886 1.54442 1.32246 2.0346 0.991502 1.76519 3.32166 1.65632 0.824394 1.43792 0.982126 4.0643 0.665218 1.97034 1.7728 1.40077 1.25031 2.3909 1.55218 1.17403 1.10094 1.44348 0.982055 2.08538 1.23198 2.05957 1.065 1.3554 1.19232 1.11052 3.27969 1.10615 2.28832 0.923314 1.12717 1.34593 1.89998 1.28603 1.31414 0.788909 0.794811 1.97466 1.22073 1.37882 1.30866 1.36907 1.17517 0.956712 1.35913 1.31366 1.8101 0.816659 1.35201 0.867352 0.602588 2.92504 0.918218 1.02663 1.05564 1.32159 1.58451 2.67591 2.45281 1.09155 0.872567 1.29861 1.10505 2.77967 1.86474 0.735938 1.39421 1.47523 1.68791 1.8353 1.29402 4.54589 0.861215 0.716797 3.26629 1.28684 0.851167 3.10133 1.53677 1.28039 0.647903 1.77489 1.14266 2.16851 0.847759 2.09916 1.42334 1.52996 0.990599 2.38636 2.14189 0.809612 1.67994 1.03336 1.03539 1.50974 1.10378 1.87106 1.62879 1.24632 1.30466 0.845483 1.95852 0.937245 2.44834 0.966993 1.65455 1.02633 1.71018 1.1068 1.95769 1.24212 1.53493 1.24654 1.51872 1.13737 1.67857 0.937625 0.904885 0.719792 1.49937 1.05027 1.54453 1.53791 1.67576 0.922647 1.17142 1.09856 2.12999 1.43863 1.36961 1.08772 1.6829 1.21522 0.92445 2.1348 1.1612 0.930296 2.1715 1.20586 0.88376 1.20753 1.92911 1.54483 1.92883 1.51497 2.08147 1.29623 1.24685 1.39643 1.88678 1.82333 1.7868 1.24834 1.02335 1.23606 1.21023 1.44911 2.32724 1.51725 1.27812 1.47278 3.42247 1.4045 1.54011 1.97241 1.83923 0.726978 1.05875 2.01426 1.50444 0.823039 1.70394 2.12685 1.79418 1.22022 3.69198 1.46783 1.46919 1.06558 1.39731 0.928782 0.864632 2.06537 3.08348 1.16396 1.29828 2.94491 1.07568 2.49083 1.5756 0.940498 1.16972 2.49107 1.56062 1.51869 1.60426 2.21844 1.52812 0.957717 1.09543 1.4802 1.59273 2.75141 2.38472 1.23884 1.82158 1.66821 1.28809 0.473128 1.83358 1.77283 2.35706 2.03125 1.36355 1.25083 1.81416 2.11367 1.82329 1.35535 2.13477 1.04862 0.771834 1.23318 3.3883 1.22707 1.35847 1.58651 1.07973 1.8628 1.44892 1.79285 2.65097 1.27538 0.81594 0.863043 1.10941 1.65728 0.830024 2.05525 0.990753 1.01914 1.2391 1.21141 3.22384 1.44352 3.06595 2.48624 0.674211 1.1411 3.6349 1.46469 1.39397 1.11645 1.90732 1.10665 0.689218 2.00326 0.661199 2.35805 1.09329 0 1.41682 1.79331 1.25012 1.921 1.80581 2.74236 0.927202 1.40096 0.983869 2.37715 1.50182 1.0774 1.10131 1.29221 1.66315 1.4634 1.66089 1.33852 1.14055 1.41918 1.69054 0.898593 1.48192 1.35599 1.53842 1.38283 0.684493 2.10467 0.915919 1.24692 1.80792 1.59308 1.71838 1.74945 1.41878 0.954968 1.49409 2.58361 1.72446 2.17768 0.535411 1.32353 2.43688 1.76195 1.92117 6.28715 1.57765 2.33225 1.00083 1.76894 1.16248 1.47884 1.68085 0.69822 1.39116 0.894024 2.39759 1.33167 1.26706 2.37173 2.77546 2.21355 1.06036 1.5918 0.882499 1.03162 1.41168 1.26294 1.6766 1.40614 1.82832 1.40258 1.16945 1.12863 6.21803 1.89494 2.49621 1.07114 1.14588 1.84989 1.01062 1.41048 2.81241 1.24776 1.72965 1.64824 1.90646 1.57681 3.43247 2.36307 1.179 1.35351 1.72301 2.30058 2.03045 2.90828 0.893151 2.1462 1.49857 2.15721 0.906122 0.904419 1.08965 1.43778 1.27369 1.30086 0.760282 1.50315 1.37731 1.47466 1.80745 2.07884 0.985837 4.1726 1.94975 1.54721 1.47799 2.84873 1.58671 1.33278 2.62727 1.63824 1.4225 1.38784 1.93615 1.35188 1.34909 1.87239 1.26258 1.99659 1.23479 2.10454 1.2603 1.49222 1.85649 2.36772 1.71762 3.9958 1.38071 1.1843 1.16784 2.50495 0.846082 1.29491 1.23615 1.59554 0.852061 1.34545 1.0367 0.885954 0.783176 1.10183 1.44773 1.88079 1.33218 1.09719 1.31608 1.67643 2.36447 0.889584 1.33088 1.79229 0.944652 1.75752 1.93201 1.17879 2.11969 1.3694 1.72 1.01564 1.41584 1.7359 1.17147 2.0757 1.23193 2.62055 1.72376 1.62879 0.912016 1.69164 2.02793 1.30478 2.06637 2.39763 1.1919 0.92528 1.21416 1.46182 1.48591 1.28982 0.982397 1.00391 1.7722 1.67668 2.00149 1.09543 1.55365 2.64531 1.03919 1.20688 0.866727 1.05909 1.75003 2.36402 1.5033 3.19854 1.58183 0.886524 1.36208 3.08963 0.972785 5.08669 1.43692 1.04232 1.50571 1.24363 1.21436 0.739167 1.87727 1.10839 1.34414 1.74659 2.74756 1.28601 2.0054 1.81869 1.29989 1.22245 1.45409 1.66271 1.6688 3.76294 1.28066 1.64128 1.33441 2.08512 1.63268 1.9859 1.03941 1.47282 1.02099 0.989421 0.733259 2.55034 1.4404 1.17018 1.54074 1.56773 0.864256 1.80787 2.76805 1.31887 3.52709 1.70929 1.92148 2.18777 1.78691 1.95214 2.21353 1.82243 3.09282 1.75551 1.85811 1.38815 2.57093 2.3237 3.38003 1.53896 2.11779 1.49589 1.97056 1.3448 2.15216 2.65678 1.56099 2.13365 2.48736 3.08132 1.83476 1.67171 1.22481 0.875002 0.938258 1.84835 1.91574 1.56222 2.2525 1.38382 1.52401 1.45095 1.04028 0.949605 1.57827 0.698361 2.50813 2.91406 0.983449 1.35037 1.42815 1.51887 0.825577 1.74921 1.04183 1.32103 1.64226 0.783157 1.41185 1.02737 2.01466 1.0419 1.19319 1.66539 2.08071 2.02533 1.09227 1.33448 0.893668 0.550939 1.85305 1.53581 0.627819 1.65233 1.52864 1.78913 2.15061 1.21898 1.64089 1.01554 2.036 1.16955 1.68268 1.63745 1.45795 2.27776 1.89063 1.14555 1.10411 1.42697 1.52116 2.85661 1.64153 1.86389 1.37377 1.07441 1.03827 1.93543 1.93086 1.65038 1.776 1.32945 0.91461 1.48915 1.32581 1.7911 1.37063 2.80194 1.23337 1.27322 1.92469 1.39689 1.34213 0.560942 1.25596 1.42613 1.55217 1.57247 1.4229 1.12317 2.60392 2.42355 1.32863 2.08522 2.15418 1.22914 1.06862 1.15853 1.88699 5.00438 1.52414 1.33996 2.22437 1.51036 1.95999 2.56163 2.2712 1.31341 2.54154 1.37309 1.65715 1.24601 1.68918 1.77297 1.01829 1.54616 2.49744 1.39049 1.01209 2.15522 3.82901 1.48777 2.04399 0.692733 1.55035 2.52272 2.25873 1.49387 1.48421 1.22951 1.26252 1.71767 3.85862 2.31471 1.25184 1.96312 1.13934 1.93614 0.945296 2.49586 1.43319 1.16773 0 1.90345 1.23164 1.01693 2.51679 1.32089 1.7038 1.76929 1.37194 1.7363 1.50216 0.91171 1.23911 1.64779 1.83776 1.19775 1.6113 1.16818 1.45194 1.29872 1.47659 1.32075 1.25197 1.66934 1.17598 2.17192 2.08835 1.17699 1.80054 1.74714 1.3691 1.00219 1.46341 1.08828 1.21716 1.93062 1.67944 1.75938 0.38539 0.638918 0.732428 1.30187 1.61457 1.99044 1.20055 1.25196 2.09564 0.856899 1.15545 1.23367 0.92458 2.22201 2.26898 1.64921 1.20974 1.25313 0.895036 2.23584 2.11833 1.76019 1.59064 2.18297 1.59056 1.05283 1.5761 1.59156 1.95908 1.72219 1.45507 1.83125 1.7408 3.0441 1.33316 1.66767 1.6459 1.8729 1.36811 0.8717 1.38222 1.39458 1.34841 1.85007 1.45477 1.738 1.51978 1.45779 2.27385 2.37157 0.892826 1.17175 1.37183 0.928344 1.51094 2.31649 1.18195 2.18334 1.27841 1.81057 1.74708 2.89541 1.47476 1.0948 2.1416 2.14861 1.92016 1.34401 2.1522 1.46494 1.25093 1.7157 1.25734 1.45473 2.81099 0.9359 1.80169 1.60216 2.22095 1.31296 2.47483 1.60782 1.4632 1.19242 0.971925 1.62716 1.67356 2.15146 2.66377 2.38047 1.55129 1.81985 1.8135 1.13748 0.913591 1.7752 1.43114 1.59272 1.78946 1.55892 2.01364 1.56641 1.06051 1.41765 1.81368 1.30517 1.78996 2.1551 3.19319 1.16715 1.55415 1.08091 0.981297 1.40313 1.70005 1.64732 1.96493 1.42924 2.51216 1.69711 0.784641 1.24048 1.34863 0.849808 1.93925 1.85259 1.69865 1.38294 1.51395 2.18023 2.31278 1.39559 1.79974 2.12899 2.52763 4.34919 1.71238 2.15337 1.92593 1.32498 1.47377 1.35197 1.16749 1.21168 1.56733 1.13177 1.17261 1.04817 1.01521 1.39378 1.05419 1.7989 1.49901 2.14592 1.03633 1.72346 0.585269 1.01581 3.80588 1.16661 2.1142 1.77343 1.20394 5.50008 1.83371 2.3998 1.89084 2.34664 3.02926 1.62297 1.42707 1.39109 2.10434 3.30801 1.80241 1.22463 1.06687 1.76075 3.13463 1.18766 2.10213 2.17784 3.14771 1.4479 0.766697 1.16044 2.24689 1.76279 1.27557 1.41473 1.67744 1.40518 2.61103 3.03468 1.80892 2.33034 1.79604 1.51973 1.86251 0.717581 1.82218 2.77891 0.909285 2.00986 2.10802 1.22879 1.28321 1.03705 2.70706 1.33428 1.37861 1.76289 1.23992 1.36428 1.99049 1.55303 1.07125 3.52387 1.90493 1.85688 1.25151 1.42212 0.704346 1.23391 1.96771 3.09917 2.09824 1.79033 1.22538 1.50697 1.652 1.82219 1.35758 1.75411 2.60711 1.09826 1.67113 1.40808 1.29794 1.56588 1.94265 0.86869 0.752786 1.60783 1.46474 2.10708 1.36007 1.32949 1.40022 1.4727 2.08758 2.07845 2.55509 3.3396 1.44029 1.86549 1.577 1.6388 1.19288 2.12364 0.884851 2.62858 1.49967 2.35493 1.15949 1.39477 1.31535 1.04389 1.8516 1.31439 0.843391 2.49656 1.83884 1.77418 1.57619 2.77634 1.56921 1.88726 2.31731 2.42425 1.51052 1.61823 2.76508 1.52572 1.4537 1.28945 1.39943 1.38227 1.47785 2.03348 1.94632 1.84992 1.8418 1.51682 3.27607 1.55738 1.27228 1.18958 1.64159 2.14027 1.57224 1.92886 0.826629 1.81731 1.11609 1.18623 0.861795 1.67442 1.31394 1.83443 0.840648 1.59316 2.4149 3.70971 2.40311 1.76951 2.19876 2.56654 0.899636 1.23994 1.25699 2.24497 2.65373 2.06464 2.51633 1.4816 1.31549 0.81161 2.33814 1.34828 1.87712 1.638 1.49601 3.38149 1.58354 1.38901 1.39012 3.44056 1.8559 2.13391 1.40573 1.85614 1.67751 1.29537 4.0025 2.10619 1.82223 1.26685 2.07344 1.22674 1.33433 1.42217 2.21565 0.966337 1.3128 1.26813 2.28316 1.33245 2.44681 2.38738 2.76411 2.22755 2.89994 1.08431 1.17504 1.42082 1.85791 2.28482 0.934179 2.06919 1.34239 1.7373 1.34148 1.43044 2.43901 1.17565 1.0519 2.71065 1.51514 2.28153 1.11593 1.49188 1.8311 1.48036 2.31049 2.29209 3.47258 2.13102 2.51662 2.48124 0.535155 1.66499 1.93918 1.59181 1.64056 1.61298 1.29437 1.21604 1.79945 2.18017 1.71235 1.4273 1.14784 1.46407 1.90365 1.12255 3.26076 2.69759 1.65284 1.82382 2.29271 0.934419 1.26651 1.70619 1.55162 1.01811 0.960653 0.61693 1.09189 1.20855 2.34365 1.57851 1.37712 1.32983 1.37353 1.64049 1.20194 2.02865 1.65211 2.29467 1.877 0.969911 1.40936 1.45772 1.51299 1.51777 1.87871 3.02995 2.78769 2.45399 1.15291 1.49621 1.61856 1.30688 0.643322 3.91344 2.44256 ]
@@@ Frame-accuracy per-class: [ 79.049 61.4108 67.2489 56.6524 78.0488 40.678 37.2881 76.9409 64.5161 71.257 88 69.0975 70.1571 71.9101 64.086 49.6 62.1538 58.8859 71.4777 79.3951 82.1124 63.4921 81.7102 62.5743 53.2688 72.967 51.2676 67.4897 60.1542 79.1569 50.4202 58.567 59.2058 57.8313 86.7493 69.5652 91.3177 85.9527 66.9683 35.9918 32.7273 70.2703 80.2768 42.7723 57.6132 85.9438 43.4092 69.869 64.7838 88.5626 73.6471 43.2337 82.7147 43.9024 79.2095 69.5652 33.9623 47.619 84.0951 46.7192 67.5522 62.2951 66.1479 85.8757 49.2114 60.6635 51.3796 34.7826 80 64.9682 73.4842 77.8973 74.3194 72.4693 89.9164 68.4058 71.0653 50.7726 84.264 49.1582 53.012 36.3636 79.4245 78.245 82.1853 62.519 75.067 80.7947 58.9212 53.0035 61.3861 70.1525 62.069 67.4095 30.303 57.1977 67.8348 75.9527 54.1966 78.0488 80.1187 37.3259 41.7178 58.9532 59.887 79.4618 55.8376 75.2137 74.7664 49.7462 57.1429 31.1927 72.1805 60.8 8.69565 59.4142 73.0385 75.2475 46.1538 54.6265 67.9842 55.1181 58.9595 28.3465 65.2482 71.9472 73.3542 36.246 61.6949 50.2513 56.3107 47.6503 52.149 69.7851 56.3707 74.2358 65.4424 58.4807 37.6812 81.198 49.7738 72.2078 75.9219 70.366 42.0582 49.635 49.5756 71.8686 82.149 36.4912 73.8589 34.4828 85.2643 73.929 57.0571 65.4028 45.6747 62.1538 77.8093 54.9801 63.0872 53.6913 0 59.3824 52.7132 71.5789 63.6816 82.5651 58.4323 64.1166 64.3678 56.338 62.9508 73.5426 81.3047 76.9976 68.2594 71.3533 45.4976 0 58.5366 71.3043 60.1073 52.8651 54.8837 64.3991 67.7551 79.7407 68.9655 60.5187 73.6718 39.9093 79.5181 53.8012 74.4921 85.812 63.4146 39.0977 79.9054 55.2529 77.2846 80.8788 61.9217 58.0645 34.891 36.5123 53.2484 55.9486 64.4068 56.7376 73.1707 45.4183 68.3995 48.9676 63.3577 57.4713 80.8247 68.2927 56.1983 77.292 63.6166 74.3961 35.514 63.8298 59.9369 69.1892 72.3044 74.938 44.2159 56.7164 32.2581 62.0155 50.9554 62.1538 71.5084 69.5341 48.2412 68.2441 70.0508 51.9774 83.9161 74.198 71.3402 81.1429 66.383 42.4242 78.9873 62.8763 65.7807 73.903 70.5744 59.0078 29.1105 64.3533 64.2534 74.0032 40.4145 55.0265 42.0712 59.7701 50.6329 76.8559 36.6366 77.3663 46.5116 70.1209 69.6517 71.8218 69.4611 55.2486 64.8649 54.5455 75.2328 67.5105 63.2708 69.1892 78.9724 48.1283 62.3229 80.4071 66.3968 81.9484 77.1331 54.3131 58.3942 49.5868 70.1639 66.8524 44.4444 47.7816 86.1176 47.1204 75.5043 67.1587 77.3869 6.06061 62.7859 30.4762 53.5032 72.103 47.9401 65.7807 33.0789 34.5324 45.3901 40.4453 50.1548 76.1644 70.7617 59.6491 64.8402 78.3807 66.3677 59.7647 37.8109 60.793 57.6687 40 38.4977 55.1724 77.8416 72.6979 59.9455 72.5389 39.4984 63.7119 75.968 53.3808 69.7872 56.8047 71.028 77.686 57.8755 22.7488 52.4064 64.0429 46.4646 46.677 63.2035 34.3558 62.9333 77.3946 78.0045 66.4987 77.2636 55.7734 50.2058 77.9783 45.1011 54.4919 54.2751 61.3953 46.2867 72.8522 55.8322 12.1212 59.5918 74.0651 57.6541 69.1076 13.7931 81.6182 46.1538 46.6859 57.5296 65.6934 44.4444 55.1724 61.9529 70.9677 62.7451 64.9682 38.481 57.8089 44.878 69.5842 60.8365 58.0442 69.459 32 67.8955 49.2147 74.7445 62.2356 63.0508 54.1833 58.3658 67.5325 80.6653 78.6236 41.2371 63.0872 57.9125 64.6154 59.6026 64.1248 74.2515 58.7413 58.6907 46.3576 76.7204 64.637 76.6958 82.2111 27.6151 73.4247 69.6356 74.4745 54.7215 44.7552 28.6533 46.5116 66.0352 72.9951 65.9517 63.9391 35.0877 43.2 77.8182 57.2104 53.2508 48.5549 48.2085 67.6259 0 70.4663 77.2627 28.7179 61.5385 73.2394 28.1481 60.578 60.6414 81.4028 46.384 66.6667 44.0529 75.9124 32 63.5789 51.2821 70.5167 42.1053 40.2685 79.4805 59.7285 71.1864 70.5882 53.7815 69.2629 44.8878 61.9718 59.542 64.5161 73.4007 41.1594 69.7248 48 72.3005 62.3656 68.5446 45.0116 66.1479 35.3312 68.3983 53.3333 53.6585 56.8093 72.4638 47.0914 73.1278 78.2609 76.4835 69.7674 70.8075 53.8283 60.8696 49.3392 73.224 69.7744 65.5271 34.2246 67.6329 57.732 69.2683 52.6582 64.7815 72.3327 29.8507 71.4571 77.3606 31.8339 65.6934 73.4463 63.6917 57.7778 54.6624 46.3023 61.6622 29.2135 65.8228 63.6943 55.5294 46.4945 41.2955 46.1538 64.9541 68.2353 71.3287 66.5347 54.1872 38.4977 53.5809 57.5163 65.0407 22.8571 60.6061 56.8421 46.595 58.1818 79.0274 74.5763 38.7716 57.2707 78.4906 52.8155 44.6701 42.2535 64.4248 0 57.1429 57.7778 67.7507 61.2159 78.853 71.3568 36.129 23.6025 65.3501 64.7934 29.2683 70.4019 35.0769 53.5433 69.341 59.1195 31.1111 57.9439 59.034 56.917 38.9294 62.9283 69.1466 68.8995 60.6232 52.9231 30.3797 47.0588 63.6066 48.5089 50.1119 63.5838 87.6091 35.9184 41.4414 38.7097 51.8828 56.4417 60.0567 49.8113 51.462 44.7489 64.9396 36.9427 68.4636 75.6364 63.6238 6.77966 64.4604 52.2156 58.4362 67.036 43.2749 61.4525 44.1558 51.0638 60.8696 74.9064 76.5432 67.0659 54.8287 75.5177 45.0262 69.6677 68.5714 70.936 61.8557 34.4828 58.6466 33.7079 20.5128 77.5982 69.5825 10.6762 69.1729 64.7619 66.2539 46.87 70.1461 74.1573 37.193 78.9572 32.5581 66.6667 0 55.1336 45.5026 74.4526 48.9311 49.4118 28.5714 78.9916 65.8635 73.6842 37.5758 57.072 68.5315 67.0788 66.1224 51.831 58.6907 53.4216 60.6635 73.8292 50.6438 40.2116 72.5581 55.9557 64.2424 59.3176 61.0879 78.8072 46.1538 71.9463 75.9825 50.7937 48.9796 47.4766 34.2342 59.1195 67.7165 61.0635 51.1628 45.8472 39.196 85.7143 57.7007 37.5367 50.5338 40.724 0 62.9442 45.0909 73.3219 46.729 59.9581 52.9248 51.2821 77.6618 56.1086 71.4715 42.6332 62.4 59.919 34.4828 32.7869 41.1429 69.7872 61.6915 77.1388 62.3719 60.9524 69.1099 48.7805 62.1359 41.5842 58.2231 68.4932 71.8019 0 40.6534 41.3793 67.4817 67.1605 43.3657 64.9237 61.21 24.8447 59.7403 45.7143 46.1538 41.953 53.5032 18.5328 35.8674 64.833 70.8995 51.153 42.1918 46.3878 18.4971 75.0958 46.7433 60.1036 40.7125 74.6888 76.7677 72.2838 69.5652 55.3086 64.2202 77.1454 50.1441 62.8297 47.9751 49.7278 41.1985 73.5651 15.3846 41.7582 56.77 50.4202 21.978 63.8655 73.6842 31.1111 55.3936 58.3765 56.9948 39.4619 51.9685 61.6905 43.686 63.7681 25.8065 64.6465 39.4052 58.2973 55.4102 51.6456 44.6602 49.9376 17.1429 66.1157 65.6552 64.4898 15.5689 73.1707 62.5917 60.5405 50.9506 73.4972 58.2781 70.6199 79.6748 77.5575 74.6988 54.1226 40.9938 63.2479 66.6667 58.3463 47.619 41.3793 77.8316 61.9718 47.7064 76.3285 53.1194 43.9437 67.8466 44.9649 62.069 60.177 67.6608 61.4065 54.0773 67.4938 40.9207 67.4591 43.2432 49.3274 53.9007 72.1461 59.1195 48 59.1928 34.1333 34.2412 59.5533 72.2856 67.0157 59.4536 60.1399 60.9836 71.5262 73.3224 46.6321 54.8303 37.5479 69.2144 62.069 27.972 70.0965 62.9712 69.8545 66.4908 44.878 30.6069 58.498 25.8065 60.2541 78.0952 60.3616 15.2381 70.8861 0 56.2141 71.4985 60.9389 66.9339 70.1124 79.4326 59.7701 68.5969 60.4966 52.1073 26.087 57.1429 47.678 56.1056 62.2951 61.5836 55.9486 59.2593 53.3333 21.1382 64.752 54.0682 59.3407 38.3838 52.9769 48.1928 63.1922 53.2438 70.4225 70.9413 76.7787 40.1914 64.3137 63.1579 55.4386 60.46 78.0399 44.2516 34.3612 63.7782 9.30233 52.2822 50.8475 51.4286 48.951 50.3145 37.7622 42.2701 29.8643 50.8738 49.0323 62.4473 26.5446 44.4444 13.1387 54.1872 44.0945 54.4732 63.8655 65.3951 42.2311 37.8007 53.3724 38.5185 37.587 24.6575 49.2754 57.5851 67.2897 76.2178 72.9045 46.4088 43.3915 60.6061 35.2941 51.8919 53.2508 54.2495 68.764 74.3363 56.9579 77.6165 40.315 26.0536 80 58.0858 55.3633 52.0107 75.7835 46.1538 68.4411 61.3583 52.0231 79.3651 61.3678 71.8894 45.2174 72.2433 66.4981 56.338 41.4097 35.0877 70.8798 60.1227 69.657 80.7339 47.0588 59.5156 80.8803 51.2535 50.2035 54.1935 42.2764 60.9238 56.3969 71.7058 35.4212 68.1128 50.214 50.6982 59.676 42.8094 57.3228 63.8783 63.2541 51.4851 55.1724 43.4783 47.1795 51.9481 58.3026 72.7273 71.2042 44.9878 46.5455 50.116 46.9903 66.1888 73.6342 60.5791 60.6335 57.6577 67.7686 37.0861 67.8261 66.1728 42.0552 61.2613 61.1684 80.5926 72.9927 55.409 48.5106 55.4455 58.9512 67.9426 36.63 44.0111 63.2822 45.614 41.194 61.6967 71.2893 65.3563 49.0441 0 57.2178 62.4176 40.6709 63.0986 46.696 35.7895 41.1609 67.3311 29.1545 55.4455 52.3416 71.5026 52.6316 45.5598 68.5271 58.9372 31.1377 52.8678 73.3138 39.6396 8.69565 50.8108 41.0678 79.4742 55.2316 37.037 41.0557 51.1896 64.1148 63.2302 62.8308 53.7102 14.8148 33.4975 52.1739 39.3162 68.6567 58.8235 72.2617 33.9833 62.4041 69.8539 0 51.3238 59.9736 70.3476 31.4465 62.3917 51.2821 43.7768 52.8406 48.5769 54.5012 71.5621 63.04 48.9297 53.7549 64.5045 52.8736 71.8447 64.8464 66.6667 62.0939 65.9341 66.6667 55.7377 63.7037 37.8698 38.5542 66.3185 52.5745 52.6807 56.6802 72.8351 57.1429 71.5596 70.8434 28.777 51.2102 53.2515 87.8957 80.288 82.6546 65.0707 49.3204 41.8605 64.918 65.8041 45.614 76.399 64.6884 65.4545 83.1461 52.459 41.4201 53.5316 67.903 66.4968 70.8645 36.8098 31.9635 50.5415 58.2524 39.7554 55.8376 62.7675 66.6667 51.4806 50.2618 46.8966 51.2129 44.9315 47.5884 14.6789 63.4146 45.7883 64.3216 49.4915 65.4545 72.9858 59.5745 65.641 58.0517 51.5284 57.6819 46.2287 62.069 52.1295 48.5876 35.7771 68.9933 74.5645 61.0101 83.7989 57.2207 33.7662 69.5925 39.4984 63.762 60.3675 47.8114 32.8767 57.5851 70.4319 49.1228 35.6436 45.7565 60.3175 42.9594 53.1856 60.6278 48.8889 64.4338 57.0458 25.3968 76.8377 48.7805 54.3933 43.5165 58.7952 31.6384 47.5524 70.1987 63.5193 69.2353 49.7018 59.751 44.6602 32.853 28.0936 53.2544 45.7143 49.0818 63.4711 76.1229 55.0336 63.6066 52.8634 34.4828 39.7661 49.0842 50.5338 74.4589 66.9856 49.4845 60.3939 49.0323 51.8519 20.1681 61.5385 59.1029 73.3068 73.5113 58.2278 54.2033 55.489 45.5046 62.543 27.0042 51.3761 77.3388 69.5082 64.9351 73.7276 51.3661 46.0967 63.0872 53.1044 55.6999 37.2414 38.6293 58.6767 54.3353 37.4269 41.4414 0 57.8554 45.0766 47.1042 63.3846 50.2994 59.3272 65.4867 72.9927 61.0998 65.1757 68.9503 69.3456 73.0159 65.4867 68.6907 42.1594 61.1973 26.1307 68.0321 50.6964 81.8763 69.9588 14.5897 65.7244 48.4472 46.3612 68.0115 0 51.2821 27.1186 43.0189 32.7711 23.6559 51.1628 64.5367 67.6123 54.5455 14.3791 48.6692 63.1016 69.7345 51.6704 22.3776 65.3797 46.1538 47.9751 27.1605 47.4886 76.3485 68.7371 45.8781 49.9127 61.8182 51.8272 57.7154 56.4315 27.5154 23.7986 38.7097 29.3144 48.1328 53.5163 46.5409 81.9417 52.3929 29.6296 73.5076 37.8378 29.6296 64.8612 61.2078 70.4 27.6243 59.3792 59.0717 54.4413 63.6086 57.8662 46.4646 58.2524 72.7273 17.4905 49.7992 43.2859 66.6667 61.2593 83.0313 67.7346 42.3358 34.4828 45.9016 49.904 71.0579 62.181 44.0024 48.6692 58.6572 46.1538 29.6578 68.9655 55.2553 57.1429 65.8228 58.9147 44.0191 77.2643 78.2251 44.2451 54.7879 46.7925 59.8639 63.68 59.2965 53.4422 38.1339 45.9161 33.0935 16.0643 59.6538 43.7956 53.1343 51.2 70.282 40.806 75.5287 30.9795 57.2549 34.1207 61.4232 60.7275 57.6224 70.5618 44.3149 59.3449 75.4643 33.2203 62.1118 51.0843 54.0541 23.5294 52.7716 51.6717 37.3832 40 57.6271 59.2593 27.451 53.1561 61.5385 65.0231 61.9684 55.3106 54.7264 38.5542 47.191 51.582 55.7214 56.4784 8 57.3311 63.1835 71.0744 48.6486 40.724 57.3066 44.4444 79.5944 49.5238 65.6965 67.8733 79.7891 46.4037 64.5314 53.2751 75.9596 50.4065 37.4532 18.5567 30.137 53.0387 47.5248 27.027 72.5073 60.733 57.4359 47.9616 23.1405 44.7227 34.1818 64.5161 63.1365 70.2317 35.1706 66.0988 46.8085 55.3064 57.0115 8.74317 50.1119 58.2278 62.9834 17.3913 46.5863 46.6859 66.4506 51.9774 50.9653 68.942 0 45.1411 48.7427 65.6672 36.9231 69.7382 60.1942 59.293 36.1905 71.2155 65.6616 64.8592 36.3636 63.8146 34.5098 31.5789 37.4269 37.594 30.1887 70.6494 62.2222 63.3975 41.6476 43.29 73.2394 45.0909 64.0726 45.7912 62.1404 63.5015 40.2556 69.967 69.6406 31.1111 57.3705 48.5207 63.5229 60.9524 47.6886 50.6024 35.1906 38.6496 20.979 44.1472 38.7833 30.137 85.8757 51.7572 44.1989 57.9151 52.9501 55.1724 65.2368 64.2424 47.8981 39.1753 45.6592 57.8512 67.4501 60.9901 56 64.4295 21.5873 27.2517 56.6372 56.5875 35.5091 71.7584 63.7288 50.4399 59.8187 62.9853 77.0167 84.9699 71.4542 63.7518 34.8993 53.2618 63.7555 62.0811 60.3696 52.984 64.9412 42.8941 50.989 38.961 37.7358 73.0077 63.9175 58.9525 54.9618 65.8385 51.1416 22.8782 27.6243 38.9791 63.8298 56.6038 52.3364 62.435 83.5307 12.8 38.5093 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 1.27932 (Xent), [AvgXent: 1.27932, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 63.3606% <<

