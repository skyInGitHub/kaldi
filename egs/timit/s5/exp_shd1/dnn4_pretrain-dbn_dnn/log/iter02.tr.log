nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.008 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter01_learnrate0.008_tr2.6560_cv2.2160 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter02 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975032
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
ali-to-post ark:- ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.81539, max 8.96107, mean 0.00568746, stddev 0.99447, skewness 0.129835, kurtosis 2.1535 ) 
[1] output of <AffineTransform> ( min -24.5003, max 15.1045, mean -3.22888, stddev 2.88278, skewness 0.136971, kurtosis 1.68774 ) 
[2] output of <Sigmoid> ( min 2.28898e-11, max 1, mean 0.156355, stddev 0.25404, skewness 2.00234, kurtosis 2.97917 ) 
[3] output of <AffineTransform> ( min -28.4197, max 15.999, mean -3.78047, stddev 2.47076, skewness 0.0689528, kurtosis 2.85981 ) 
[4] output of <Sigmoid> ( min 4.54462e-13, max 1, mean 0.0956929, stddev 0.186594, skewness 3.05099, kurtosis 9.38002 ) 
[5] output of <AffineTransform> ( min -14.9096, max 10.9733, mean -3.2049, stddev 1.97939, skewness 0.798707, kurtosis 3.0016 ) 
[6] output of <Sigmoid> ( min 3.34829e-07, max 0.999983, mean 0.106441, stddev 0.189336, skewness 2.95327, kurtosis 8.77268 ) 
[7] output of <AffineTransform> ( min -21.6691, max 18.461, mean -3.21031, stddev 2.20938, skewness 0.664551, kurtosis 3.64556 ) 
[8] output of <Sigmoid> ( min 3.88337e-10, max 1, mean 0.117569, stddev 0.209447, skewness 2.66389, kurtosis 6.66576 ) 
[9] output of <AffineTransform> ( min -17.5196, max 14.4813, mean -3.14375, stddev 2.49964, skewness 1.45178, kurtosis 3.38784 ) 
[10] output of <Sigmoid> ( min 2.46232e-08, max 0.999999, mean 0.138476, stddev 0.255793, skewness 2.2591, kurtosis 3.95894 ) 
[11] output of <AffineTransform> ( min -29.7985, max 22.9677, mean -3.45215, stddev 3.02533, skewness 1.11687, kurtosis 3.89517 ) 
[12] output of <Sigmoid> ( min 1.14464e-13, max 1, mean 0.138314, stddev 0.27207, skewness 2.22501, kurtosis 3.59867 ) 
[13] output of <AffineTransform> ( min -9.8719, max 16.1069, mean -0.0199889, stddev 2.44965, skewness 0.744913, kurtosis 1.48415 ) 
[14] output of <Softmax> ( min 2.81717e-11, max 0.997051, mean 0.000657766, stddev 0.0145415, skewness 43.0347, kurtosis 2179.66 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.16344, max 0.975724, mean 0.000153277, stddev 0.039176, skewness -0.0677115, kurtosis 26.528 ) 
[1] diff-output of <AffineTransform> ( min -0.279778, max 0.342641, mean 4.91001e-05, stddev 0.00860919, skewness -0.423441, kurtosis 72.9698 ) 
[2] diff-output of <Sigmoid> ( min -1.62756, max 1.37766, mean 0.000701505, stddev 0.0716618, skewness -0.0242689, kurtosis 15.6752 ) 
[3] diff-output of <AffineTransform> ( min -0.280182, max 0.307202, mean 4.91422e-05, stddev 0.00861581, skewness -0.480882, kurtosis 84.9747 ) 
[4] diff-output of <Sigmoid> ( min -1.31864, max 1.5154, mean 0.00013898, stddev 0.0847697, skewness -0.0214121, kurtosis 9.65723 ) 
[5] diff-output of <AffineTransform> ( min -0.258242, max 0.252559, mean 9.0762e-05, stddev 0.00850703, skewness -0.00034924, kurtosis 59.9659 ) 
[6] diff-output of <Sigmoid> ( min -1.16734, max 1.75874, mean 0.000821368, stddev 0.0730705, skewness 0.0181416, kurtosis 10.4482 ) 
[7] diff-output of <AffineTransform> ( min -0.185612, max 0.208412, mean 6.6619e-05, stddev 0.00758555, skewness -0.285644, kurtosis 47.5325 ) 
[8] diff-output of <Sigmoid> ( min -0.766875, max 1.40005, mean 0.000329164, stddev 0.0626991, skewness -0.0172483, kurtosis 9.05162 ) 
[9] diff-output of <AffineTransform> ( min -0.144216, max 0.236127, mean 6.71489e-05, stddev 0.0065509, skewness 0.149564, kurtosis 42.6196 ) 
[10] diff-output of <Sigmoid> ( min -0.778062, max 0.949451, mean 0.000405904, stddev 0.0531371, skewness -0.0611487, kurtosis 10.3797 ) 
[11] diff-output of <AffineTransform> ( min -0.238018, max 0.14702, mean 7.45514e-05, stddev 0.00874141, skewness -0.22168, kurtosis 32.6149 ) 
[12] diff-output of <Sigmoid> ( min -1.12606, max 0.935244, mean 0.000466813, stddev 0.095638, skewness -0.102938, kurtosis 2.35297 ) 
[13] diff-output of <AffineTransform> ( min -0.999994, max 0.885876, mean -5.58303e-09, stddev 0.0223198, skewness -27.6418, kurtosis 1434.86 ) 
[14] diff-output of <Softmax> ( min -0.999994, max 0.885876, mean -5.58303e-09, stddev 0.0223198, skewness -27.6418, kurtosis 1434.86 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.63165, max 1.61747, mean -0.00111806, stddev 0.134192, skewness -0.0328095, kurtosis 3.2188 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.623202, max 0.680861, mean 0.0125696, stddev 0.146903, skewness -0.102229, kurtosis 1.69461 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.659515, max 0.535786, mean 0.00211537, stddev 0.0424308, skewness -0.00634327, kurtosis 8.84498 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.676818, max 0.595133, mean 0.0125805, stddev 0.149457, skewness -0.0883633, kurtosis 2.47743 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.483185, max 0.557845, mean 0.00230066, stddev 0.0288018, skewness 0.594065, kurtosis 15.3996 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.609835, max 0.780963, mean 0.0232351, stddev 0.141641, skewness 0.349067, kurtosis 3.37892 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.530799, max 0.498069, mean 0.00187356, stddev 0.0267368, skewness 0.26328, kurtosis 13.6242 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.583799, max 0.532825, mean 0.0170544, stddev 0.126279, skewness 0.0118863, kurtosis 2.72143 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.379731, max 0.390385, mean 0.00207327, stddev 0.0255526, skewness 0.524983, kurtosis 10.2258 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.454543, max 0.464985, mean 0.0171901, stddev 0.10603, skewness 0.345159, kurtosis 2.91644 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.67068, max 0.48552, mean 0.00279079, stddev 0.0420421, skewness 0.376708, kurtosis 9.094 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.808067, max 0.675724, mean 0.0190851, stddev 0.149513, skewness 0.0555079, kurtosis 2.26393 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -5.32645, max 2.60247, mean -1.04207e-08, stddev 0.116804, skewness -4.59245, kurtosis 95.691 ) , lr-coef 1, max-norm 0
  bias_grad ( min -5.39675, max 2.2996, mean -4.39192e-09, stddev 0.397538, skewness -2.3889, kurtosis 28.0767 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 342784 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -6.78548, max 7.66488, mean 0.00618661, stddev 0.998336, skewness 0.126755, kurtosis 2.01683 ) 
[1] output of <AffineTransform> ( min -26.6743, max 19.1291, mean -3.24139, stddev 3.36648, skewness 0.154252, kurtosis 1.54928 ) 
[2] output of <Sigmoid> ( min 2.60324e-12, max 1, mean 0.179832, stddev 0.283758, skewness 1.74294, kurtosis 1.75801 ) 
[3] output of <AffineTransform> ( min -31.7606, max 18.2698, mean -3.92961, stddev 2.64769, skewness 0.0153462, kurtosis 2.71858 ) 
[4] output of <Sigmoid> ( min 1.60891e-14, max 1, mean 0.0972321, stddev 0.192195, skewness 2.963, kurtosis 8.69169 ) 
[5] output of <AffineTransform> ( min -15.3909, max 11.1215, mean -3.20914, stddev 1.99718, skewness 0.689746, kurtosis 2.69106 ) 
[6] output of <Sigmoid> ( min 2.06917e-07, max 0.999985, mean 0.107785, stddev 0.18883, skewness 2.89505, kurtosis 8.46142 ) 
[7] output of <AffineTransform> ( min -22.33, max 17.1055, mean -3.05637, stddev 2.24023, skewness 0.629101, kurtosis 3.11201 ) 
[8] output of <Sigmoid> ( min 2.0054e-10, max 1, mean 0.130818, stddev 0.218945, skewness 2.42229, kurtosis 5.31335 ) 
[9] output of <AffineTransform> ( min -16.5854, max 17.0548, mean -3.00748, stddev 2.64487, skewness 1.39927, kurtosis 3.03412 ) 
[10] output of <Sigmoid> ( min 6.26692e-08, max 1, mean 0.15509, stddev 0.271183, skewness 2.03046, kurtosis 2.87721 ) 
[11] output of <AffineTransform> ( min -27.5759, max 22.0108, mean -3.61246, stddev 3.21692, skewness 1.06729, kurtosis 3.50944 ) 
[12] output of <Sigmoid> ( min 1.05672e-12, max 1, mean 0.138486, stddev 0.277879, skewness 2.20011, kurtosis 3.42383 ) 
[13] output of <AffineTransform> ( min -10.8204, max 18.7069, mean -0.0174664, stddev 2.86271, skewness 0.684729, kurtosis 1.32299 ) 
[14] output of <Softmax> ( min 2.09135e-12, max 0.995912, mean 0.000657779, stddev 0.0174, skewness 41.1268, kurtosis 1872.54 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.92904, max 0.779816, mean -0.00063351, stddev 0.0411702, skewness -1.87864, kurtosis 87.2157 ) 
[1] diff-output of <AffineTransform> ( min -0.193133, max 0.525303, mean 2.74694e-05, stddev 0.00820832, skewness 2.34771, kurtosis 171.187 ) 
[2] diff-output of <Sigmoid> ( min -1.97046, max 2.2222, mean 5.3248e-07, stddev 0.0698269, skewness 0.150051, kurtosis 25.8963 ) 
[3] diff-output of <AffineTransform> ( min -0.270867, max 0.479752, mean 2.32886e-05, stddev 0.0085512, skewness 0.349386, kurtosis 133.215 ) 
[4] diff-output of <Sigmoid> ( min -1.64892, max 1.99854, mean -4.16455e-05, stddev 0.0863319, skewness -0.0349398, kurtosis 12.0024 ) 
[5] diff-output of <AffineTransform> ( min -0.225455, max 0.269701, mean 4.24701e-05, stddev 0.00865155, skewness 0.111318, kurtosis 63.1316 ) 
[6] diff-output of <Sigmoid> ( min -1.03628, max 1.61536, mean 0.000180305, stddev 0.0748272, skewness 0.0160456, kurtosis 11.0515 ) 
[7] diff-output of <AffineTransform> ( min -0.173432, max 0.258131, mean 2.24792e-05, stddev 0.00758358, skewness -0.123007, kurtosis 48.6654 ) 
[8] diff-output of <Sigmoid> ( min -0.902584, max 1.04404, mean 9.54563e-05, stddev 0.060747, skewness -0.0693821, kurtosis 10.4516 ) 
[9] diff-output of <AffineTransform> ( min -0.125243, max 0.142651, mean 1.13213e-05, stddev 0.00623303, skewness 0.00484951, kurtosis 41.4625 ) 
[10] diff-output of <Sigmoid> ( min -0.702445, max 0.681071, mean 0.000120021, stddev 0.0489395, skewness -0.159081, kurtosis 12.5006 ) 
[11] diff-output of <AffineTransform> ( min -0.259097, max 0.163348, mean 1.4368e-05, stddev 0.00760513, skewness -0.256283, kurtosis 46.726 ) 
[12] diff-output of <Sigmoid> ( min -1.60221, max 1.33045, mean 0.000507711, stddev 0.0830098, skewness -0.0892974, kurtosis 5.67375 ) 
[13] diff-output of <AffineTransform> ( min -0.999993, max 0.964075, mean -6.90159e-09, stddev 0.0183937, skewness -26.0969, kurtosis 1802.9 ) 
[14] diff-output of <Softmax> ( min -0.999993, max 0.964075, mean -6.90159e-09, stddev 0.0183937, skewness -26.0969, kurtosis 1802.9 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.80759, max 1.66235, mean -0.000803028, stddev 0.135515, skewness -0.0419522, kurtosis 3.82195 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.469409, max 0.722809, mean 0.00703217, stddev 0.152039, skewness 0.265863, kurtosis 1.3284 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.55259, max 1.01047, mean 0.0010867, stddev 0.0503425, skewness 0.298542, kurtosis 8.51306 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.564452, max 0.7309, mean 0.00596191, stddev 0.157639, skewness 0.174903, kurtosis 1.72519 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.467952, max 0.612138, mean 0.00106197, stddev 0.0332071, skewness 0.461211, kurtosis 13.6658 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.679312, max 0.878224, mean 0.0108724, stddev 0.173253, skewness 0.281162, kurtosis 2.63053 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.480349, max 0.507651, mean 0.000675614, stddev 0.0291221, skewness 0.269876, kurtosis 11.015 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.618886, max 0.672136, mean 0.00575473, stddev 0.144522, skewness 0.183869, kurtosis 1.9805 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.332735, max 0.329121, mean 0.000394735, stddev 0.0279499, skewness 0.11867, kurtosis 8.25018 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.556367, max 0.499987, mean 0.00289826, stddev 0.115549, skewness -0.0980638, kurtosis 2.28686 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.460786, max 0.429049, mean 0.000829262, stddev 0.0409813, skewness 0.158335, kurtosis 8.24031 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.495322, max 0.576836, mean 0.00367819, stddev 0.132135, skewness 0.0690208, kurtosis 1.92849 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.35878, max 2.74226, mean -1.43855e-09, stddev 0.0950757, skewness -2.67948, kurtosis 94.2234 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.87421, max 2.7449, mean -6.90159e-09, stddev 0.29449, skewness -0.866813, kurtosis 12.5554 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0783078 min, processing 72956.5 frames per sec; i/o time 5.21394%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 14111 120 114 116 102 29 147 431 139 624 262 548 95 133 232 62 162 188 145 264 293 157 210 252 206 227 177 121 194 213 59 160 138 41 524 149 489 359 331 244 27 18 144 252 121 124 944 114 5399 17569 1561 284 471 20 632 126 26 94 273 190 263 30 128 442 158 105 525 11 77 78 552 418 679 528 1016 172 727 226 492 148 41 38 347 273 210 329 186 75 361 141 50 229 14 179 16 260 399 380 208 348 168 179 81 181 88 1263 98 58 160 98 115 54 66 62 11 119 350 151 110 448 126 190 86 63 70 151 159 154 147 99 51 457 174 395 129 114 299 480 34 300 110 192 230 423 223 68 294 243 288 142 120 14 444 408 166 105 144 162 529 125 74 223 6 210 64 142 100 249 210 274 130 35 152 111 628 206 146 284 105 10 20 172 279 270 107 661 122 308 130 173 423 220 622 85 221 292 20 66 211 128 191 614 140 15 160 183 392 155 147 70 20 125 365 508 342 43 242 266 181 354 229 517 160 211 158 92 236 201 194 33 15 451 392 162 89 139 99 401 98 88 71 358 242 87 117 16 197 149 150 216 426 191 185 158 110 313 96 94 154 130 118 114 166 121 21 289 100 381 83 90 18 148 268 118 186 92 525 93 176 196 123 174 146 156 68 60 152 179 13 146 212 95 173 135 298 16 240 157 78 116 133 150 196 69 70 269 161 182 203 142 109 580 111 212 100 113 81 22 106 188 435 309 183 96 159 180 813 140 117 84 160 60 136 105 93 279 49 323 115 81 187 130 220 198 248 229 121 138 321 339 134 107 289 145 381 16 122 414 251 218 14 704 214 173 295 205 31 188 148 232 127 78 197 214 102 228 131 158 286 12 325 95 342 165 147 125 128 38 240 479 145 74 148 97 75 288 83 71 221 75 341 213 744 497 119 182 123 166 206 71 174 21 369 305 186 525 28 62 137 211 161 86 153 69 98 289 226 97 32 248 67 432 171 470 200 262 113 68 112 237 175 493 28 74 192 110 147 76 178 359 200 35 65 15 148 172 163 12 106 46 106 215 128 158 115 37 61 128 34 180 113 80 227 21 80 215 103 113 91 332 175 93 103 339 102 197 194 276 33 250 439 144 479 88 246 22 155 155 186 44 355 235 212 135 123 240 272 212 71 252 101 106 188 76 61 17 82 47 139 27 164 88 260 223 132 257 98 177 282 25 59 247 184 238 139 298 77 80 278 302 61 410 162 317 174 79 22 160 279 126 205 160 228 522 176 162 39 25 152 251 223 86 286 122 166 15 119 81 176 132 85 109 289 78 185 137 361 29 347 417 364 180 85 89 269 23 149 133 121 83 160 410 95 466 17 101 145 14 66 44 19 216 251 140 66 52 161 311 239 133 142 268 107 151 0 355 94 68 210 42 10 178 124 47 82 201 71 323 122 177 221 226 105 181 815 94 322 180 82 190 119 1408 32 372 114 94 24 267 55 79 63 291 21 150 99 752 230 170 140 110 8 98 137 290 267 238 179 97 239 110 166 159 62 123 14 30 87 117 100 356 341 52 95 143 51 151 264 109 363 8 275 14 204 202 154 229 140 80 115 52 45 276 235 129 256 254 94 238 182 131 86 130 130 96 196 120 148 225 34 202 54 553 173 208 160 275 133 618 6 45 306 59 45 178 28 112 171 289 96 111 63 455 146 103 77 247 134 346 420 197 51 400 17 181 362 122 83 799 204 92 131 1688 75 185 61 630 124 236 80 58 118 320 115 14 516 106 54 103 280 177 169 213 101 56 536 291 116 201 195 336 18 111 70 109 79 37 111 187 128 201 1008 95 457 71 152 219 305 96 191 130 235 14 71 155 225 240 189 307 189 632 15 275 157 359 52 39 8 261 510 564 249 222 352 43 224 221 130 126 45 161 151 30 170 155 229 37 61 191 190 136 49 411 41 153 223 35 366 639 104 127 85 142 456 275 230 113 288 21 120 29 17 214 79 214 255 110 257 77 118 218 13 68 101 63 251 59 183 125 145 170 202 215 109 241 161 267 174 256 90 200 49 76 92 161 276 222 56 463 654 317 130 77 151 144 186 175 292 131 213 86 220 270 108 57 131 395 106 113 85 403 81 189 54 110 144 363 179 368 232 184 400 191 489 231 230 350 465 586 149 317 131 273 50 275 11 97 38 135 368 286 204 137 215 257 418 210 224 110 55 60 75 172 202 525 277 145 337 68 189 117 50 276 313 136 179 423 28 167 194 461 203 601 9 190 227 238 177 113 47 189 451 171 151 181 96 142 129 322 103 83 200 170 55 11 92 243 494 291 121 170 693 104 145 434 141 13 101 57 58 167 42 351 179 195 376 0 245 378 244 79 288 97 116 1082 263 205 374 312 163 126 277 43 154 146 187 138 227 205 91 202 84 124 191 184 214 123 421 234 163 207 69 392 407 805 555 331 459 257 193 152 270 256 205 168 82 44 30 84 134 350 392 468 81 109 138 51 163 98 350 55 219 95 217 185 182 155 54 676 231 99 147 82 316 70 292 251 114 185 205 101 293 88 170 372 143 247 89 183 269 159 159 470 190 148 36 484 150 85 151 135 220 209 180 557 157 313 294 94 360 143 119 227 207 88 71 75 349 843 251 120 51 173 149 253 192 299 302 211 74 152 113 43 85 136 421 115 104 242 228 232 13 59 331 189 125 243 355 398 250 272 145 118 163 1961 152 115 363 91 134 74 378 346 72 160 400 86 256 55 11 200 228 129 162 250 490 56 205 245 156 452 435 409 169 263 194 225 99 561 179 234 364 164 141 80 185 173 8 19 29 132 207 139 64 156 211 16 76 131 93 282 224 71 388 32 160 40 547 120 241 139 286 192 752 249 120 243 218 46 211 120 291 79 257 198 13 1281 166 13 738 488 437 90 370 118 174 163 276 49 154 104 131 124 316 100 468 303 218 68 14 30 260 250 215 829 131 141 45 131 217 166 115 118 64 313 270 608 334 412 132 73 312 298 428 246 226 69 124 375 68 167 62 230 198 165 219 127 190 133 948 357 222 171 259 511 147 80 207 240 212 225 164 53 112 147 121 25 150 149 324 411 249 100 41 133 521 301 150 62 303 411 60 18 110 174 40 394 52 240 331 284 215 421 114 247 430 133 48 109 90 50 18 1198 95 97 208 60 279 137 170 245 280 190 293 117 334 217 91 223 276 271 218 124 173 308 265 129 146 20 159 258 333 162 477 154 438 52 1106 298 479 38 841 127 66 85 66 26 192 67 285 218 115 177 412 385 148 434 168 156 454 403 22 125 84 360 157 205 290 170 429 71 149 131 109 88 156 90 129 330 14 559 412 392 145 155 181 425 252 187 74 157 216 56 231 191 281 147 170 165 579 328 249 278 354 74 559 114 283 243 343 212 193 227 115 79 194 48 410 65 80 109 135 90 215 117 185 53 480 464 62 80 ]
@@@ Loss per-class: [ 0.640413 1.88603 1.65413 1.89539 1.341 3.29248 2.72721 1.21898 1.26831 1.03535 0.684782 1.08979 1.50841 1.17491 1.66319 1.96801 1.45852 1.63868 1.49017 1.00848 0.910278 1.64577 0.888446 1.57389 1.77414 1.13447 1.78363 1.3085 1.43082 0.975848 1.80627 1.55975 1.96189 1.99139 0.589432 1.19263 0.421806 0.680701 1.3069 2.74502 3.75487 2.82123 0.811065 2.05251 1.88427 0.942091 1.2862 1.59885 1.19663 0.414969 0.741891 2.00722 0.846726 3.39582 0.887969 1.46945 3.67079 2.05618 0.667114 2.29539 1.35004 2.57716 1.6577 0.746452 2.01991 1.61201 1.92006 7.19113 1.07571 1.70182 1.20173 0.909207 1.00144 1.1004 0.468277 1.24072 1.23135 2.22182 0.676921 2.10435 2.35597 2.52262 0.98451 1.06788 1.02991 1.72439 1.06527 0.969002 1.42637 2.13772 1.96965 1.26028 4.23876 1.29893 6.34329 1.50747 1.39742 1.00743 1.96349 0.928034 0.877895 2.63071 2.4638 1.63946 2.04442 0.829451 1.54014 1.58866 1.34405 2.15884 1.894 2.89997 1.3827 2.20047 6.20552 1.71753 1.06725 0.867461 2.409 1.75292 1.41769 1.6984 1.74829 3.21472 2.08873 1.57619 1.50164 2.15748 1.50986 2.4296 2.1396 1.91009 2.04887 1.25615 1.5367 1.23246 1.52118 1.60973 2.48905 0.985998 2.48719 1.18808 0.892313 1.22221 2.23217 1.65274 2.1008 1.20646 0.839011 2.63456 1.28779 4.20131 0.682423 1.30275 1.72235 1.41719 2.29096 1.95861 1.02886 1.7494 1.84627 1.78567 9.17263 1.82559 1.51798 1.20227 1.82332 0.917722 1.67078 1.21081 1.41155 3.15543 1.42057 1.09975 0.835838 1.01059 1.53079 1.18825 2.1893 7.71528 2.55397 1.34346 1.79082 1.92288 1.82263 1.45891 1.40849 0.954935 1.30964 1.77213 1.09773 2.6034 0.854502 1.73957 1.15721 0.780394 3.55038 2.63815 0.866449 1.78991 1.25058 0.814965 1.68398 3.93792 2.8058 2.7092 1.8823 2.08434 1.76701 1.67917 1.75127 2.9275 1.55722 2.03433 1.31708 1.57135 0.751551 1.34839 2.01631 1.12072 1.57993 1.18307 2.87884 1.83592 1.74934 1.29567 1.09318 1.23099 1.99508 2.62311 3.96162 1.56547 1.95046 1.61798 1.85571 1.42566 2.31888 1.23567 1.67052 2.13616 0.959875 0.981683 1.38093 1.39298 1.63112 3.49594 0.938532 1.49249 1.49189 1.17289 1.13289 1.54959 2.65715 1.42918 1.43999 1.15815 2.29717 2.05917 2.25387 1.63533 1.88068 1.0558 2.20975 0.890401 3.8437 1.15779 1.7345 1.15402 1.6168 1.99108 3.07257 1.91075 1.06459 1.50512 1.63647 1.26591 0.886565 1.68626 1.37352 0.748319 1.61708 1.26723 1.10808 2.32033 1.66395 3.38782 1.16864 1.45256 3.89172 2.20004 0.629394 2.07825 1.29601 1.40674 0.992969 4.93706 1.52174 3.02094 2.31079 1.3406 2.19541 1.56215 2.28045 2.58021 2.40038 2.11921 2.21413 1.18274 1.24061 1.75625 1.68993 0.928755 1.73706 1.9091 2.63064 1.7321 1.97291 3.69536 2.31011 1.92307 0.925388 1.04699 1.6254 1.41226 2.52307 1.71658 1.0674 2.12269 1.04896 2.28942 1.31714 1.24463 1.46417 3.54473 2.05118 1.59323 2.31007 2.12115 1.64737 2.38311 1.7717 1.20836 0.943054 1.50198 1.0596 1.80136 2.17273 0.908942 2.10677 1.87731 2.02458 1.64872 2.32716 1.24351 2.08654 5.85121 2.16795 1.05456 1.65326 1.2187 7.56043 0.808402 2.33372 2.1455 1.70929 1.59254 3.54366 1.75322 1.4654 1.44863 1.69308 1.30217 2.52061 1.43373 2.6546 1.3817 1.70108 1.38305 1.34857 5.93989 1.35696 2.81765 1.18108 1.33474 1.75226 2.24898 1.61334 1.89638 1.00972 0.996275 2.2435 1.71028 1.66889 1.86028 1.81173 1.43261 1.51346 1.82189 1.56662 2.38975 1.01319 1.66845 1.06169 0.777021 3.6336 1.20927 1.42402 1.4596 1.58371 1.92382 3.37832 4.09875 1.39896 1.11529 1.59409 1.34539 3.70786 2.20167 0.918175 1.61336 1.75968 2.17392 2.22807 1.67924 5.2045 1.12693 0.951932 3.93382 2.43234 1.00979 3.70518 1.81186 1.5349 0.819637 2.07772 1.39398 2.75524 1.18427 2.5557 1.84069 1.76343 1.1453 3.36253 2.63761 1.09915 2.08585 1.36799 1.44569 1.85396 1.26613 2.20796 2.31566 1.66339 2.91026 1.09071 2.32011 1.25508 4.96875 1.23307 2.23007 1.44826 2.00886 1.51983 2.31505 1.68227 2.70152 1.77105 1.80619 1.99264 2.04759 1.19271 1.28528 0.889426 2.55673 1.41233 1.99555 2.21195 2.07269 1.2554 1.46451 1.46606 2.49404 1.79602 1.69013 1.44291 1.99791 1.5003 1.15999 2.88671 1.5156 1.11136 2.55014 1.4445 1.4006 1.5289 3.50017 1.84742 2.35841 1.76763 2.62819 1.48298 1.55011 1.64467 2.27582 2.1799 2.08203 1.51343 1.19441 1.57751 1.48977 1.90669 2.82514 1.90252 1.60106 2.06293 5.31821 2.04225 2.11519 2.41808 2.94891 0.928237 1.36736 2.34349 1.92246 1.06753 1.96229 2.57995 2.17467 1.5174 4.64253 1.91735 1.75956 1.35794 1.7738 1.15437 1.11552 2.67819 3.76811 1.4091 1.64673 3.7648 1.30417 2.93773 1.89952 1.22309 1.42995 4.22631 1.81386 1.79828 2.26027 2.68042 1.95856 1.19065 1.33396 1.85026 1.92146 3.41733 3.57172 1.52577 2.17837 2.08227 2.00748 0.639426 2.21637 2.14662 4.43731 2.42201 1.84287 1.57777 2.22236 2.97652 2.18297 1.59853 2.76986 1.44857 1.03723 1.45963 4.34393 1.56308 1.57753 1.90318 1.37699 2.54165 1.76601 2.04179 3.80577 1.5531 1.16843 1.15306 1.75737 2.18188 1.02989 2.48533 1.21285 2.11772 1.52122 1.58146 5.86411 1.89174 3.70822 4.47083 0.86483 1.37709 4.35648 1.80756 1.8679 1.32553 2.30185 1.43546 1.04258 2.50267 0.852131 2.87891 1.41062 0 1.71295 2.16783 1.62861 2.31426 2.36421 5.22857 1.19841 1.7602 1.58029 2.86988 1.74794 1.54053 1.30272 1.72881 2.16545 1.71485 2.16057 1.60835 1.32092 1.61597 2.27118 1.09073 1.74475 1.81219 1.97655 1.82574 0.778405 3.35302 1.07063 1.50111 2.38394 2.56971 2.01381 2.37678 1.90153 1.24415 1.86565 4.93375 2.17665 2.75377 0.628863 1.53748 2.86179 2.20214 2.63791 9.03367 2.19211 2.8924 1.23244 2.01535 1.40899 1.8845 2.10097 0.946311 1.71818 1.17441 2.72742 1.99756 1.61318 4.28562 4.00409 2.65089 1.51474 1.95985 1.1171 1.26751 2.15687 1.6424 2.12364 1.96955 2.32615 1.85038 1.57908 1.41631 9.17707 2.27774 4.2107 1.30087 1.48055 2.10297 1.19356 1.82629 3.34282 1.6065 2.24521 2.35744 2.34811 1.87416 3.94235 2.8342 1.40355 1.83786 2.02077 2.64003 2.60817 3.44419 1.19978 2.82632 1.81431 2.61206 1.21232 1.27649 1.28478 2.48933 1.51346 1.96017 0.957831 1.78788 1.8814 1.75306 2.13885 2.52247 1.16407 7.57965 2.80268 1.84592 1.97568 3.58594 1.96221 2.13132 3.13152 1.94311 1.69092 1.82103 2.40895 1.71462 1.59162 2.31585 1.64163 2.49712 1.60348 2.78038 1.52975 1.77078 2.19764 3.24634 2.03473 5.43753 1.84002 1.43104 1.61968 3.13976 0.979273 1.60108 1.66956 2.05917 0.974337 1.81277 1.25681 1.25324 0.945371 1.52548 1.76053 2.3217 2.02113 1.29581 1.53124 2.11548 4.50896 1.06964 1.72217 2.08515 1.14144 2.10409 2.40683 1.45547 2.46071 2.03579 2.34992 1.23656 1.72162 2.28015 1.40707 2.4619 1.42986 4.00792 2.23663 2.16599 1.16723 2.26975 2.84225 1.72229 2.39283 2.92547 1.53209 1.08933 1.62538 1.73961 2.04997 1.64231 1.28382 1.24479 2.28742 2.05956 2.38751 1.40902 3.77412 3.03589 1.33756 1.47472 1.09049 1.32021 1.99837 2.7045 1.77583 6.58832 1.91967 1.14669 1.67363 3.97129 1.62874 8.93161 1.75166 1.29274 1.72274 1.49524 1.53812 0.955519 2.46263 1.49264 1.67874 2.18095 3.29004 2.21745 2.36031 2.43784 2.15609 1.45719 1.7825 1.95222 2.53211 4.30265 1.51937 2.10298 1.71837 2.63545 1.84567 2.83888 1.26439 1.76854 1.65922 1.19753 0.857276 3.29953 1.87358 1.6797 1.81155 1.88552 1.13484 2.19062 3.48559 1.67655 4.99202 2.10106 2.9947 3.71723 2.1219 2.60486 2.60248 2.1458 3.76882 2.20018 2.52287 1.76756 2.96273 5.3066 4.14659 1.8866 2.89775 1.77106 2.8731 1.7478 2.64768 3.26141 1.88023 2.48959 2.96465 3.70188 2.07259 2.01793 1.48947 1.10297 1.14726 2.44596 2.26161 2.24582 2.86123 1.76163 1.82216 1.69731 1.30959 1.35786 1.88734 0.860713 3.03641 3.39916 1.46503 1.62397 1.65003 1.81829 1.07346 1.99173 1.44428 1.63632 2.24818 1.00824 1.76923 1.41879 2.66735 1.46738 1.41784 2.19722 2.50213 2.48066 1.3833 1.66746 1.09239 1.11336 2.19743 1.92322 0.821451 2.01195 1.83188 2.26416 2.65976 1.46041 1.95001 1.22945 2.35389 1.42693 1.97134 1.9106 1.69157 2.95402 2.22847 1.5463 1.41349 1.96248 1.88799 5.37145 2.06098 2.59866 1.75103 1.33153 1.30999 2.19306 2.27284 2.02726 2.07148 1.60242 1.17314 1.9012 1.6057 2.74897 1.7438 3.59302 1.5236 1.60159 2.17379 1.71291 1.55196 0.717724 2.0102 1.69428 1.79044 2.36535 1.75733 1.39953 2.95195 2.82393 1.58759 3.42511 2.52453 1.38099 1.33977 1.41301 2.17214 7.47653 1.90814 1.58134 2.6898 1.7624 2.52402 3.41801 2.78662 1.50549 2.99043 1.71758 2.1151 1.85611 2.06216 2.06481 1.23127 1.96381 3.0446 1.64927 1.28914 2.9682 7.05508 2.14356 2.42142 0.850436 1.83469 3.15195 2.6922 1.67936 2.04669 1.61024 1.45503 2.2358 7.54839 2.70882 1.84282 2.52347 1.48058 2.88922 1.1745 2.88339 1.80196 1.41437 0 2.34153 1.48029 1.27613 3.06646 1.65957 1.94285 2.24309 1.54342 2.14733 1.81227 1.09696 1.48792 2.05156 2.37892 1.43432 2.10049 1.43256 1.92675 1.55518 1.95236 1.6962 1.68349 2.42416 1.3817 2.78714 2.62805 1.45895 2.24939 2.0966 1.67619 1.20165 1.74356 1.29294 1.61742 2.47425 2.01062 2.06937 0.488546 0.846014 0.986613 1.59467 1.90518 2.31097 1.54332 1.51238 2.53752 1.10612 1.53447 1.71294 1.56755 3.15168 2.82496 2.1436 1.49217 1.57797 1.06675 2.89362 2.60871 2.16105 2.23127 2.62986 2.05861 1.28203 2.40401 1.90221 2.58076 2.08587 1.87598 2.26966 2.14199 3.73787 1.57577 2.0046 2.24844 2.32067 1.9601 1.06166 1.93675 1.67577 1.61247 2.51132 1.92495 2.15778 1.86738 1.73405 3.0006 2.80173 1.12598 1.64752 1.74437 1.34274 1.84783 2.68515 1.53786 2.53949 1.51614 2.2154 2.092 4.03748 1.7795 1.38137 2.60639 2.75772 2.50407 1.60703 2.53417 1.82665 1.47478 2.03012 1.57544 1.7421 3.34011 1.13306 2.13997 1.90678 2.67862 1.56376 3.0919 2.12877 1.93152 1.39545 1.15753 2.0434 2.01669 3.1076 3.28325 2.70899 1.89458 2.25859 2.26284 1.40835 1.15811 2.15786 1.84947 1.86361 2.6883 1.88945 2.54292 1.87676 1.47784 1.96463 2.18187 1.55897 2.12485 3.8703 3.69518 1.38896 1.86945 1.38576 1.23896 1.71721 2.00655 1.95997 2.31221 1.68955 2.99941 2.15386 0.907563 1.60899 1.74836 1.0992 2.80136 2.25715 2.29481 1.64367 1.77681 2.75819 2.88792 1.67114 2.49229 2.4288 3.50879 6.476 1.97325 2.46462 2.41638 1.64189 1.7793 1.60636 1.64404 1.56799 2.04507 1.55765 1.48372 1.27218 1.23614 1.71408 1.26619 2.05627 1.80797 2.54564 1.23732 2.13355 0.753226 1.18969 4.31531 1.56421 2.70425 2.1885 1.62929 7.80764 3.22879 3.32559 2.24496 2.84047 3.4752 2.13248 1.80278 1.90206 3.84102 4.02989 2.13873 1.7671 1.40968 2.07571 3.64275 1.41478 3.11705 2.59194 4.65763 1.6313 1.00082 1.48506 2.67672 2.0755 1.50516 1.59861 1.92976 1.81572 3.10527 3.51636 2.50509 2.7654 2.29439 1.77036 2.68686 0.96664 2.23097 5.81006 1.02287 2.2905 4.33549 1.43565 1.48599 1.25648 3.50363 1.54185 1.85916 2.1467 1.52379 1.61678 2.92586 2.03714 1.35265 4.09457 2.47879 2.18247 1.75748 1.62369 0.963705 1.46007 2.57498 5.59496 3.2688 2.12536 1.47819 1.75101 1.88028 2.22109 1.67258 2.60846 2.95427 1.35219 2.23112 1.87582 1.71405 2.03407 2.28209 1.12661 0.963717 1.95286 1.73191 2.62804 1.92102 1.71508 1.75848 1.74405 2.38887 2.5357 3.25746 3.82024 1.80772 2.58843 1.96153 2.26615 1.52329 2.53977 1.19402 3.08617 2.05322 2.69319 1.57576 1.6419 1.58736 1.29339 2.22376 1.54527 1.04325 2.89828 2.68347 2.07386 1.93413 3.19208 1.95786 2.36851 3.18462 2.95003 1.90884 1.99599 4.06826 1.85986 1.92256 1.55526 1.66135 1.64055 1.99234 2.87673 2.35449 2.16575 2.28119 1.87438 3.9633 1.8573 1.50188 1.58936 3.05737 2.56231 1.89599 2.82768 1.15201 2.42203 1.38915 1.428 1.12461 1.91495 1.53021 2.2352 1.05253 1.88569 2.93238 4.79575 2.9323 2.23949 3.08004 3.84763 1.06085 1.64583 1.74255 2.61915 3.36826 2.3743 3.0837 1.93895 1.60525 0.968299 2.71938 1.62778 2.38615 2.02484 1.81221 3.94199 1.93879 1.64288 1.71038 3.96717 2.21583 2.7438 1.75038 2.27274 1.98492 1.61527 5.42585 2.65929 2.32669 1.5203 2.53182 1.48509 1.59089 1.7302 2.94295 1.16476 1.61295 1.49568 3.24639 1.57634 2.96004 3.23917 3.37817 2.72012 4.21144 1.38712 1.69615 1.74088 2.28704 2.8374 1.3712 2.41809 1.62367 2.26027 1.58865 1.83437 2.95135 1.43205 1.2112 5.86705 2.02001 2.87642 1.29477 1.8462 2.14986 1.64055 2.78772 2.61593 4.01826 2.6569 3.06973 2.9098 0.736809 2.11359 2.38899 1.98246 1.94774 3.61148 1.53013 1.44602 2.11667 2.60869 2.06814 1.83469 1.406 1.70371 2.38451 1.52035 3.84486 3.11467 2.2315 2.1959 2.78177 1.14534 1.51785 2.09574 1.95683 1.20131 1.17655 0.804254 1.34665 1.49026 3.07501 1.83934 1.82892 1.68132 1.6721 1.96321 1.48286 2.34718 1.99654 2.80047 2.2709 1.28886 1.91697 1.81897 1.88449 2.09178 2.41937 3.60127 3.37415 2.89859 1.48267 1.77148 2.52237 1.67606 0.81912 4.63111 2.87002 ]
@@@ Frame-accuracy per-class: [ 76.916 48.1328 58.5153 48.927 63.4146 3.38983 31.1864 72.0742 60.2151 67.2538 80.7619 62.3519 58.6387 66.6667 55.0538 43.2 58.4615 52.5199 63.9175 77.1267 75.2981 53.3333 71.734 53.8614 44.5521 67.6923 45.6338 61.7284 53.9846 73.0679 36.9748 53.5826 49.0975 40.9639 82.7455 57.5251 89.8876 80.1113 60.6335 29.8569 7.27273 48.6486 74.7405 32.4752 49.3827 74.6988 35.3626 62.0087 56.1533 88.1129 70.8934 34.0949 77.8367 24.3902 74.1502 59.2885 22.6415 39.1534 80.0731 36.7454 57.685 32.7869 54.4747 80.904 37.8549 54.0284 44.9096 0 68.3871 53.5032 68.0543 73.1183 71.5232 69.631 87.1618 57.3913 66.6667 39.7351 82.0305 43.771 36.1446 18.1818 71.3669 75.6856 72.209 55.2352 69.7051 75.4967 55.6017 39.576 49.505 64.9237 20.6897 59.61 0 52.975 63.5795 72.7989 48.9209 72.3099 77.1513 28.4123 26.9939 52.8926 44.0678 77.0083 47.7157 63.2479 59.19 43.6548 39.8268 20.1835 61.6541 49.6 0 51.8828 67.3324 69.967 39.819 51.505 62.4506 47.769 48.5549 22.0472 43.9716 60.7261 59.5611 25.89 57.6271 31.1558 38.835 44.153 42.9799 65.9924 49.4208 62.8821 60.7679 52.6535 26.087 73.2113 34.3891 66.4935 72.0174 67.7686 32.6622 48.1752 39.3888 65.2977 79.3761 25.2632 66.39 6.89655 81.4398 64.3819 49.8498 57.8199 38.7543 49.2308 71.7658 49.4024 45.6376 45.6376 0 50.3563 43.4109 63.1579 50.7463 78.1563 50.3563 52.8233 59.0038 19.7183 57.7049 70.852 78.5998 73.1235 60.0683 68.5413 41.7062 0 43.9024 63.7681 53.6673 46.5804 46.5116 55.1776 66.1224 74.8784 59.7701 52.4496 69.1854 31.2925 77.2691 39.7661 70.4289 77.265 34.1463 21.0526 75.1773 47.4708 69.9739 76.1595 55.516 25.8065 28.0374 26.158 48.4076 44.373 58.3051 45.3901 58.5366 27.8884 61.8331 43.4612 59.854 41.3793 76.701 63.7899 44.6281 69.6756 55.7734 67.8261 24.2991 58.156 49.8423 64.8649 68.0761 66.9975 38.5604 38.806 12.9032 55.814 46.1146 54.7692 56.9832 60.2151 45.2261 63.5118 49.7462 44.0678 79.7203 71.6876 64.3299 61.7143 57.0213 12.1212 74.9367 55.5184 56.4784 66.0508 66.1196 48.0418 22.1024 55.5205 59.7285 68.5805 29.0155 38.0952 33.0097 54.4061 44.7257 68.1223 25.2252 74.0741 23.2558 67.7029 55.7214 68.9384 65.8683 40.884 27.027 41.7508 72.6257 59.0717 56.3003 59.4595 75.7374 45.9893 56.0907 75.3181 51.8219 75.0716 73.0375 40.2556 49.635 34.7107 65.5738 57.3816 14.8148 38.2253 86.1176 36.6492 58.2133 60.5166 75.3769 0 56.9647 19.6825 30.5732 71.2446 38.9513 59.1362 29.5165 25.8993 39.7163 32.282 38.3901 70.6849 63.3907 49.8246 55.7078 75.2799 53.8117 55.5294 24.8756 53.7445 39.2638 8.88889 31.9249 48.8064 73.7084 66.2359 46.3215 67.3575 33.8558 52.6316 69.453 44.8399 64.6809 41.4201 63.5514 71.0744 50.5495 5.6872 44.9198 57.6029 30.303 41.7311 56.2771 23.3129 58.6667 73.5632 73.0159 59.4458 73.6419 50.9804 37.037 70.0361 38.5692 48.6009 42.3792 55.814 37.3057 68.0412 47.4443 6.06061 48.1633 67.0688 51.2922 57.2082 0 78.3534 40.5594 40.3458 50.423 56.4477 15.873 53.5809 58.5859 62.3656 58.0392 61.1465 27.8481 53.1469 25.3659 62.5821 53.9924 51.1041 61.082 0 62.0584 25.1309 68.0292 54.9849 54.9153 41.4343 53.6965 57.1429 76.0915 74.6611 30.2405 41.6107 54.5455 55.3846 54.3046 58.9255 65.8683 47.5524 55.079 29.1391 71.1567 59.0164 72.9349 75.3769 16.7364 69.589 63.1579 64.8649 46.9734 43.3566 18.9112 23.2558 56.2923 64.4845 58.445 58.04 21.0526 32 75.6364 51.0638 43.9628 33.526 39.0879 50.3597 1.01523 63.9033 69.3157 20.5128 52.3077 72.4346 22.2222 53.6416 57.7259 79.2774 37.4065 65.1429 30.837 67.1533 22.2222 50.9474 47.8632 69.9088 21.0526 24.1611 71.1688 53.3937 61.0169 53.5948 43.1373 64.8122 40.8978 42.2535 51.9084 45.1613 68.0135 34.7826 62.3853 24 61.9718 49.4624 56.338 38.051 52.9183 30.2839 62.3377 32 42.2764 51.3619 60.8696 38.2271 68.7225 70.8075 69.8901 55.814 65.8385 44.0835 47.343 37.0044 66.6667 63.1579 53.5613 25.6684 57.971 51.8409 58.5366 48.6076 59.126 67.6311 11.9403 67.0659 74.4027 25.6055 60.6882 61.0169 55.1724 17.7778 45.0161 36.6559 54.6917 26.9663 61.8847 53.5032 49.8824 41.3284 38.0567 42.8274 60.5505 62.5882 61.5385 59.802 47.2906 25.3521 46.1538 50.9804 45.5285 5.71429 42.4242 37.8947 32.2581 32.7273 72.9483 61.0169 34.5489 42.953 75.4717 46.9903 33.5025 37.1831 57.6991 0 42.0168 50.5051 59.6206 51.153 75.2688 65.3266 24.5161 12.4224 58.5278 56.1983 9.7561 63.8246 24 44.7244 65.9026 50.3145 0 49.2212 55.814 41.8972 29.6837 50.4673 68.709 62.3923 50.9915 50.4615 10.1266 19.6078 52.459 39.7614 38.9262 42.7746 83.0716 26.9388 34.2342 12.9032 35.9833 49.0798 51.5581 40.7547 35.0877 33.79 59.7582 22.9299 58.7601 66.1818 61.1342 3.38983 57.8417 43.8323 49.9314 63.1579 35.0877 53.6313 37.1058 17.0213 55.5184 67.4157 64.1975 50.2994 44.2368 70.4019 31.4136 65.8092 45.7143 63.0542 51.5464 0 54.1353 20.2247 5.12821 72.5173 62.0278 6.40569 57.1429 49.5238 62.5387 37.2392 62.6305 64.4195 22.4561 75.2328 19.5349 58.0858 0 43.3193 37.037 64.2336 39.4299 40 0 72.8291 54.6185 67.3684 21.8182 53.1017 51.7483 60.5873 54.6939 40.5634 56.4334 43.7086 52.1327 67.7686 45.1257 28.5714 68.8372 47.0914 46.0606 41.9948 50.2092 76.6773 24.6154 67.651 67.2489 35.9788 28.5714 39.2523 23.4234 54.0881 61.4173 53.5163 18.6047 34.5515 25.1256 83.0565 54.6638 24.0469 42.7046 29.8643 0 49.7462 37.0909 66.7814 45.6075 53.2495 45.6825 40 70.1461 50.6787 63.0631 36.3636 49.6 54.251 13.7931 19.6721 27.4286 53.617 50.7463 71.8093 55.6369 36.1905 55.4974 35.5401 46.6019 29.0429 47.259 56.621 61.8982 0 34.4828 27.5862 63.5697 56.2963 36.8932 62.3094 49.1103 11.1801 56.2771 28.5714 28.5714 35.8047 50.5308 10.8108 29.6296 59.725 59.2593 45.7023 36.7123 32.6996 11.5607 67.433 28.3525 55.9585 30.0254 67.2199 68.0135 64.745 40.5797 48.8889 51.3761 71.7254 42.6513 49.8801 41.1215 43.1942 32.9588 69.8464 0 35.1648 51.2235 35.2941 15.3846 51.5406 63.1579 23.1111 50.1458 52.1589 42.487 27.8027 40.9449 56.202 36.1775 58.9372 19.3548 54.5455 20.0743 51.0823 48.5137 43.5443 21.3592 36.7041 0 58.9532 58.7586 56.3265 8.38323 67.9174 54.7677 49.7297 44.1065 70.0622 41.0596 65.7682 65.0407 74.3854 62.6506 48.6258 23.6025 52.9915 64.9789 51.17 32.9004 20.6897 72.7977 51.6432 40.367 69.5652 46.3458 34.9296 61.3569 42.1546 50.2463 42.4779 62.6281 52.4871 42.0601 64.0199 33.2481 61.8128 32.4324 34.0807 41.1348 68.4932 47.7987 26.6667 52.9148 29.8667 24.9027 52.6055 68.2201 57.5916 52.6776 44.7552 53.1148 63.3257 69.3944 36.2694 47.5196 32.1839 60.2972 27.5862 15.3846 66.2379 54.102 61.5385 56.9921 40 24.8021 52.4901 0 54.4465 66.0317 52.2949 5.71429 48.1013 0 47.0363 65.0343 54.9159 59.7194 62.0225 75.1773 41.3793 61.0245 54.6275 39.8467 20.5534 39.5604 43.9628 44.2244 52.459 52.7859 48.2315 53.5948 42.6667 19.5122 58.4856 41.4698 49.0842 22.2222 49.3317 24.0964 56.6775 48.7696 42.2535 66.03 76.1532 26.7943 50.1961 51.462 46.3158 52.3549 69.3285 39.4794 22.0264 56.1525 4.65116 43.1535 33.8983 22.8571 37.296 30.1887 30.303 37.9648 17.1946 41.165 37.4194 55.6962 20.595 0 4.37956 47.2906 22.0472 49.3042 33.6134 57.7657 31.0757 21.9931 46.9208 31.6049 27.3782 20.0913 44.3064 52.0124 58.6916 71.0602 66.6667 32.0442 41.3965 42.4242 16.9935 42.1622 43.9628 48.4629 63.8202 63.7168 48.9752 73.1856 30.8661 15.3257 67.0968 50.8251 46.3668 45.5764 70.0855 42.0513 50.9506 51.5222 28.9017 74.8299 52.8651 58.0645 36.5217 59.3156 61.9469 38.4977 32.5991 28.0702 65.1797 50.3067 63.8522 60.5505 36.1991 47.0588 76.4787 44.0111 41.791 42.5806 27.6423 55.9301 46.9974 63.3299 25.9179 60.3037 42.796 44.4683 55.243 31.4381 48.5039 57.0342 53.3821 37.6238 46.461 8.69565 34.8718 25.974 36.9004 67.0285 67.0157 40.0978 32 39.4432 41.9417 60.2151 71.2589 48.1069 52.4887 34.2342 49.5868 23.8411 63.1884 59.2593 33.8725 55.1351 54.2955 77.9259 48.1752 51.715 43.4043 45.5446 49.5479 62.8389 29.304 36.2117 54.5455 24.5614 33.4328 56.5553 62.8386 57.4939 43.3915 0 46.7192 57.1429 30.1887 56.9014 36.1233 25.2632 29.0237 62.68 22.1574 45.5446 40.7713 56.9948 40 34.749 64.4961 44.4444 20.3593 47.8803 67.4487 19.8198 0 36.7568 33.6756 77.452 49.0566 22.2222 32.8446 46.5753 51.6746 54.2955 58.458 48.0565 0 27.5862 45.2174 27.3504 62.0896 35.2941 64.5804 27.2981 57.289 65.073 0 42.7699 56.2748 61.3497 22.6415 55.4593 48.2051 26.6094 47.6674 37.9507 50.6083 64.3525 57.92 39.7554 38.7352 58.018 39.0805 64.0777 52.5597 57.0667 46.9314 60.6593 59.854 42.623 54.8148 21.3018 23.2932 62.141 35.2304 48.4848 46.9636 69.7509 48.6141 66.055 60.7229 17.2662 43.3121 48.0982 86.1577 75.0675 77.8281 59.63 42.3301 35.1421 58.3607 59.1497 34.308 68.6131 52.2255 58.1818 65.1685 29.5082 27.2189 41.6357 61.9116 59.6178 67.0224 17.1779 27.3973 36.8231 42.7184 35.474 45.6853 56.4907 43.2432 41.4579 37.6963 36.3218 38.814 33.9726 38.5852 7.33945 57.2062 35.4212 48.2412 42.7119 44.8485 66.0348 41.1348 60.8547 53.6779 32.3144 47.4394 37.4696 44.335 48.0409 31.6384 26.393 62.8188 61.324 50.9091 72.6257 50.1362 25.974 58.3072 33.2288 58.4485 54.0682 37.7104 10.9589 51.3932 64.4518 36.2573 19.802 37.6384 51.2472 34.8449 45.9834 56.3229 41.2698 57.0973 49.5756 17.9894 71.5673 39.7213 44.3515 37.3626 56.3855 19.209 30.7692 54.3046 60.372 64.7303 44.1352 49.7925 21.3592 21.902 21.4047 43.3925 34.8052 40.7346 54.2149 66.1939 46.9799 53.1148 45.815 25.2874 32.7485 38.8278 45.7888 69.2641 53.5885 39.1753 56.4551 43.0108 14.8148 10.084 54.902 48.5488 64.5418 69.8152 51.4768 47.1769 47.9042 37.4312 54.9828 15.1899 39.7554 74.2799 58.3607 54.5455 66.2999 31.694 34.9442 52.349 48.3487 47.619 24.8276 27.4143 53.1835 39.3064 30.4094 23.4234 0 54.3641 40.2626 30.888 57.2308 47.1058 51.9878 58.4071 61.3139 48.0652 58.147 62.5414 63.3754 68.1319 55.4572 62.6186 37.018 54.9889 19.0955 62.5111 42.3398 75.4797 65.8436 9.11854 55.8304 39.7516 33.9623 57.6369 0 35.8974 16.9492 35.4717 19.759 17.2043 37.2093 51.7572 53.9007 36.3636 9.15033 39.5437 49.1979 60.531 42.7617 9.79021 62.8057 27.6923 40.4984 4.93827 41.4612 73.029 56.7288 39.4265 42.2339 57.1429 46.3787 49.2986 47.3029 15.6057 15.103 27.957 17.9669 38.1743 49.3997 30.1887 73.3981 38.7909 0 71.6348 31.2312 14.8148 59.174 57.3183 64.6857 20.9945 54.7908 44.7257 48.7106 57.4924 52.0796 26.2626 47.8964 67.9426 8.36502 39.3574 35.0711 54.7264 55.9232 76.771 60.4119 26.2774 6.89655 26.2295 42.6104 66.6667 58.4687 33.9964 38.0228 55.8304 24.1758 21.2928 65.7471 43.8438 46.7532 59.9156 44.9612 37.0016 63.9556 73.1306 36.7713 49.9394 35.4717 43.5374 51.52 51.9263 45.9743 32.86 36.6446 18.705 8.03213 51.3981 21.8978 43.5821 41.6 58.1345 35.2645 66.4653 19.59 45.4902 27.2966 52.4345 54.718 53.986 63.8202 27.9883 53.9499 70.5767 28.4746 36.0248 45.7831 45.3222 16.9412 42.5721 37.0821 13.0841 23.1111 47.4576 48.5597 11.7647 43.8538 48.8294 58.8598 55.164 48.8978 41.791 19.2771 33.7079 45.0623 46.7662 48.505 3.2 50.4119 57.3512 64.4628 27.027 29.8643 48.7106 19.7531 69.962 20.9524 61.5385 63.3484 76.9772 38.051 61.6845 42.7948 71.9192 39.9535 29.9625 4.12371 21.9178 39.779 33.6634 10.8108 68.5857 43.9791 45.1282 41.247 16.5289 34.347 22.5455 53.3724 53.7678 64.5276 25.1969 59.6252 36.5957 47.5336 46.4368 6.55738 41.1633 52.4412 55.2486 10.0686 40.9639 31.7003 57.0502 41.8079 42.471 66.2116 0 33.8558 37.1373 55.1724 24 63.4555 51.7799 50.6271 20.9524 66.9679 57.9564 59.4369 12.987 59.6554 23.5294 15.0376 21.0526 30.0752 3.77358 64.9351 48.8889 59.1944 29.2906 32.0346 60.8451 36.3636 58.8846 34.3434 55.2359 56.3798 33.2268 66.6667 68.4015 0 41.4343 40.2367 59.0846 53.3333 38.4428 47.1601 28.739 29.3364 16.7832 24.7492 31.1787 19.1781 74.5763 39.6166 36.4641 51.7375 44.7806 27.5862 59.5174 58.1818 36.9427 31.6151 36.0129 48.4848 60.1645 57.8218 46.4 49.6644 12.0635 21.709 40.708 42.7646 27.154 69.9822 57.6271 41.0557 53.7764 60.0518 73.9726 78.9579 66.7864 55.8533 8.05369 47.5424 54.1485 50.7937 57.4949 47.7438 59.7647 36.1757 42.6374 32.0346 22.6415 63.7532 51.5464 52.1315 45.8015 54.6584 37.4429 16.2362 11.0497 28.3063 58.7234 50.1348 20.5607 51.4048 80.9473 6.4 23.6025 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 1.56708 (Xent), [AvgXent: 1.56708, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 56.6225% <<

