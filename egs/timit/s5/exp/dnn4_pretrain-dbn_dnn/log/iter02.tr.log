nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.008 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter01_learnrate0.008_tr2.7354_cv2.4282 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter02 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975016
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.86424, max 7.06273, mean -0.000964877, stddev 0.993005, skewness 0.0133901, kurtosis 2.03207 ) 
[1] output of <AffineTransform> ( min -23.6914, max 15.1238, mean -3.16266, stddev 2.89492, skewness 0.127808, kurtosis 1.90185 ) 
[2] output of <Sigmoid> ( min 5.14011e-11, max 1, mean 0.159966, stddev 0.256903, skewness 1.97175, kurtosis 2.83488 ) 
[3] output of <AffineTransform> ( min -30.4746, max 18.761, mean -3.7843, stddev 2.56994, skewness 0.0673229, kurtosis 3.73505 ) 
[4] output of <Sigmoid> ( min 5.82192e-14, max 1, mean 0.0980944, stddev 0.191341, skewness 2.9973, kurtosis 8.93599 ) 
[5] output of <AffineTransform> ( min -14.6582, max 12.867, mean -3.2337, stddev 2.03827, skewness 0.790572, kurtosis 3.22532 ) 
[6] output of <Sigmoid> ( min 4.30546e-07, max 0.999997, mean 0.107326, stddev 0.192333, skewness 2.91947, kurtosis 8.49872 ) 
[7] output of <AffineTransform> ( min -24.7702, max 14.1009, mean -3.21716, stddev 2.25589, skewness 0.642555, kurtosis 3.84646 ) 
[8] output of <Sigmoid> ( min 1.74765e-11, max 0.999999, mean 0.118755, stddev 0.21251, skewness 2.6411, kurtosis 6.4844 ) 
[9] output of <AffineTransform> ( min -16.9982, max 14.6706, mean -3.14536, stddev 2.54578, skewness 1.41871, kurtosis 3.41889 ) 
[10] output of <Sigmoid> ( min 4.14737e-08, max 1, mean 0.14062, stddev 0.258197, skewness 2.21971, kurtosis 3.7632 ) 
[11] output of <AffineTransform> ( min -28.4097, max 18.6314, mean -3.45714, stddev 3.06846, skewness 1.12715, kurtosis 3.99409 ) 
[12] output of <Sigmoid> ( min 4.58997e-13, max 1, mean 0.139029, stddev 0.274127, skewness 2.21368, kurtosis 3.52545 ) 
[13] output of <AffineTransform> ( min -9.80152, max 16.7722, mean -0.00222719, stddev 2.44773, skewness 0.717248, kurtosis 1.49977 ) 
[14] output of <Softmax> ( min 3.91978e-11, max 0.98944, mean 0.000647541, stddev 0.0145056, skewness 42.2156, kurtosis 2090.91 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.725633, max 0.523805, mean -1.66244e-05, stddev 0.0383136, skewness -0.247398, kurtosis 15.7006 ) 
[1] diff-output of <AffineTransform> ( min -0.304958, max 0.225272, mean 7.17957e-05, stddev 0.00830473, skewness -0.134494, kurtosis 53.1025 ) 
[2] diff-output of <Sigmoid> ( min -1.2349, max 1.08296, mean 0.000296949, stddev 0.0682822, skewness 0.0398785, kurtosis 10.2742 ) 
[3] diff-output of <AffineTransform> ( min -0.217882, max 0.18406, mean 8.21641e-05, stddev 0.00817061, skewness -0.14311, kurtosis 58.9956 ) 
[4] diff-output of <Sigmoid> ( min -1.03612, max 1.1564, mean -0.000359077, stddev 0.0804484, skewness -0.0333464, kurtosis 7.21538 ) 
[5] diff-output of <AffineTransform> ( min -0.204402, max 0.175528, mean 0.000133805, stddev 0.00806972, skewness 0.132065, kurtosis 43.5833 ) 
[6] diff-output of <Sigmoid> ( min -0.983867, max 0.999614, mean 0.000435202, stddev 0.0696177, skewness 0.0286728, kurtosis 7.16657 ) 
[7] diff-output of <AffineTransform> ( min -0.194503, max 0.141853, mean 0.000137638, stddev 0.00722446, skewness 0.0598781, kurtosis 36.174 ) 
[8] diff-output of <Sigmoid> ( min -0.852719, max 0.679728, mean 0.000354948, stddev 0.0606163, skewness -0.0281551, kurtosis 6.57305 ) 
[9] diff-output of <AffineTransform> ( min -0.176238, max 0.15219, mean 0.000111188, stddev 0.00631254, skewness 0.0971279, kurtosis 32.6872 ) 
[10] diff-output of <Sigmoid> ( min -0.786626, max 0.653857, mean 0.000298587, stddev 0.0509739, skewness -0.0370507, kurtosis 7.44842 ) 
[11] diff-output of <AffineTransform> ( min -0.188465, max 0.138931, mean 0.000162775, stddev 0.00851335, skewness 0.241413, kurtosis 28.1619 ) 
[12] diff-output of <Sigmoid> ( min -1.19171, max 1.07334, mean 0.00112184, stddev 0.0949366, skewness -0.0413714, kurtosis 2.20912 ) 
[13] diff-output of <AffineTransform> ( min -0.999968, max 0.909999, mean -1.36079e-08, stddev 0.0223239, skewness -26.9057, kurtosis 1418 ) 
[14] diff-output of <Softmax> ( min -0.999968, max 0.909999, mean -1.36079e-08, stddev 0.0223239, skewness -26.9057, kurtosis 1418 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.12733, max 1.34174, mean -0.000612378, stddev 0.1368, skewness 0.019945, kurtosis 2.67354 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.650283, max 0.747573, mean 0.0183797, stddev 0.157208, skewness 0.0801268, kurtosis 1.85236 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.677374, max 0.666737, mean 0.00365529, stddev 0.044439, skewness 0.493548, kurtosis 8.85243 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.586054, max 0.852533, mean 0.0210339, stddev 0.158273, skewness 0.504824, kurtosis 2.91744 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.525589, max 0.591895, mean 0.00353989, stddev 0.0315518, skewness 0.914903, kurtosis 14.9597 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.59721, max 0.937408, mean 0.0342539, stddev 0.164395, skewness 0.562423, kurtosis 3.16744 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.424231, max 0.591072, mean 0.00386509, stddev 0.0294309, skewness 0.990894, kurtosis 13.0903 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.59778, max 0.859519, mean 0.0352355, stddev 0.148806, skewness 0.577685, kurtosis 2.63415 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.450583, max 0.434737, mean 0.00346294, stddev 0.0286573, skewness 0.856757, kurtosis 10.1497 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.467829, max 0.663027, mean 0.0284641, stddev 0.132024, skewness 0.652066, kurtosis 2.7393 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.455071, max 0.558339, mean 0.00608062, stddev 0.0436956, skewness 1.2012, kurtosis 9.33319 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.565344, max 0.774525, mean 0.0416702, stddev 0.151951, skewness 0.82973, kurtosis 2.08259 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.76039, max 3.01504, mean -1.05657e-09, stddev 0.115711, skewness -3.78165, kurtosis 65.0779 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.61297, max 2.64051, mean 4.94132e-09, stddev 0.383801, skewness -1.09435, kurtosis 8.84713 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 331520 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.8171, max 6.44093, mean -0.00429144, stddev 1.00295, skewness -0.0631885, kurtosis 1.97814 ) 
[1] output of <AffineTransform> ( min -27.3187, max 17.9066, mean -3.19786, stddev 3.37954, skewness 0.12714, kurtosis 1.63796 ) 
[2] output of <Sigmoid> ( min 1.36666e-12, max 1, mean 0.182502, stddev 0.284723, skewness 1.72046, kurtosis 1.68247 ) 
[3] output of <AffineTransform> ( min -26.7516, max 18.0634, mean -3.91864, stddev 2.70302, skewness 0.0619685, kurtosis 3.19605 ) 
[4] output of <Sigmoid> ( min 2.40962e-12, max 1, mean 0.0983975, stddev 0.194735, skewness 2.95394, kurtosis 8.5948 ) 
[5] output of <AffineTransform> ( min -14.5596, max 14.4444, mean -3.22299, stddev 2.04099, skewness 0.718967, kurtosis 2.95788 ) 
[6] output of <Sigmoid> ( min 4.75178e-07, max 0.999999, mean 0.108846, stddev 0.191803, skewness 2.86633, kurtosis 8.20752 ) 
[7] output of <AffineTransform> ( min -22.8739, max 15.4051, mean -3.04949, stddev 2.27486, skewness 0.635657, kurtosis 3.30346 ) 
[8] output of <Sigmoid> ( min 1.16407e-10, max 1, mean 0.132194, stddev 0.22196, skewness 2.40821, kurtosis 5.19139 ) 
[9] output of <AffineTransform> ( min -15.4977, max 16.0724, mean -2.99935, stddev 2.69197, skewness 1.38994, kurtosis 3.10885 ) 
[10] output of <Sigmoid> ( min 1.85961e-07, max 1, mean 0.157306, stddev 0.273276, skewness 2.00497, kurtosis 2.76741 ) 
[11] output of <AffineTransform> ( min -27.7109, max 18.8683, mean -3.62279, stddev 3.26394, skewness 1.06331, kurtosis 3.68369 ) 
[12] output of <Sigmoid> ( min 9.2326e-13, max 1, mean 0.138337, stddev 0.278889, skewness 2.20301, kurtosis 3.42378 ) 
[13] output of <AffineTransform> ( min -12.5765, max 19.0267, mean -0.00224604, stddev 2.86911, skewness 0.645301, kurtosis 1.32684 ) 
[14] output of <Softmax> ( min 2.7619e-13, max 0.995542, mean 0.000647556, stddev 0.0171845, skewness 41.676, kurtosis 1942.16 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.957822, max 0.797677, mean 4.34991e-05, stddev 0.0392072, skewness 0.0476496, kurtosis 23.3318 ) 
[1] diff-output of <AffineTransform> ( min -0.191824, max 0.342223, mean 5.14225e-05, stddev 0.00794417, skewness 0.784528, kurtosis 80.7638 ) 
[2] diff-output of <Sigmoid> ( min -1.47908, max 2.53115, mean 0.000341975, stddev 0.0691308, skewness 0.728706, kurtosis 40.3122 ) 
[3] diff-output of <AffineTransform> ( min -0.295762, max 0.488255, mean 1.41767e-05, stddev 0.00841999, skewness 1.69455, kurtosis 173.651 ) 
[4] diff-output of <Sigmoid> ( min -1.53316, max 2.28671, mean -0.000176481, stddev 0.0848584, skewness 0.110604, kurtosis 16.8954 ) 
[5] diff-output of <AffineTransform> ( min -0.241052, max 0.526782, mean 3.19399e-05, stddev 0.00858306, skewness 1.67641, kurtosis 155.289 ) 
[6] diff-output of <Sigmoid> ( min -1.13763, max 2.1283, mean 0.00023081, stddev 0.0752314, skewness 0.236442, kurtosis 16.738 ) 
[7] diff-output of <AffineTransform> ( min -0.160995, max 0.338928, mean 9.86044e-06, stddev 0.00760547, skewness 0.94391, kurtosis 82.7672 ) 
[8] diff-output of <Sigmoid> ( min -1.09126, max 1.38003, mean 2.53822e-05, stddev 0.0607978, skewness 0.0744927, kurtosis 14.5605 ) 
[9] diff-output of <AffineTransform> ( min -0.162349, max 0.224573, mean 1.02834e-05, stddev 0.00623758, skewness 0.444709, kurtosis 60.8452 ) 
[10] diff-output of <Sigmoid> ( min -0.740271, max 0.986508, mean -8.90497e-05, stddev 0.0482948, skewness 0.0102201, kurtosis 13.7675 ) 
[11] diff-output of <AffineTransform> ( min -0.341083, max 0.201433, mean 2.17445e-05, stddev 0.00746032, skewness -0.306033, kurtosis 67.9955 ) 
[12] diff-output of <Sigmoid> ( min -1.36735, max 1.05001, mean 0.000418133, stddev 0.081782, skewness -0.0998643, kurtosis 5.3829 ) 
[13] diff-output of <AffineTransform> ( min -0.999992, max 0.923322, mean -1.01963e-08, stddev 0.018132, skewness -26.5982, kurtosis 1811.65 ) 
[14] diff-output of <Softmax> ( min -0.999992, max 0.923322, mean -1.01963e-08, stddev 0.018132, skewness -26.5982, kurtosis 1811.65 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.51732, max 1.25072, mean 0.00103686, stddev 0.126464, skewness 0.013831, kurtosis 2.37655 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.565823, max 0.596399, mean 0.0131642, stddev 0.127029, skewness -0.00580685, kurtosis 1.43274 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.492213, max 0.859551, mean 0.000409688, stddev 0.0458583, skewness 0.60713, kurtosis 11.7575 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.399489, max 0.810127, mean 0.00362926, stddev 0.136311, skewness 0.464638, kurtosis 2.45534 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.473783, max 1.03981, mean 0.000621385, stddev 0.0300739, skewness 0.810827, kurtosis 23.2877 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.564596, max 1.01865, mean 0.00817662, stddev 0.137955, skewness 0.609307, kurtosis 4.29527 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.390137, max 0.695794, mean 4.45419e-05, stddev 0.0266046, skewness 0.438402, kurtosis 14.2483 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.402502, max 0.655312, mean 0.00252427, stddev 0.120323, skewness 0.312575, kurtosis 1.73103 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.336017, max 0.518281, mean 8.35521e-05, stddev 0.0258653, skewness 0.299365, kurtosis 9.76851 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.376175, max 0.577904, mean 0.00263254, stddev 0.101751, skewness 0.362886, kurtosis 2.40872 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.631671, max 0.483493, mean 0.000619477, stddev 0.0383536, skewness 0.200652, kurtosis 9.27825 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.628454, max 0.551665, mean 0.00556659, stddev 0.123078, skewness 0.186629, kurtosis 2.77629 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.69747, max 2.12971, mean -4.85623e-08, stddev 0.0946998, skewness -5.15787, kurtosis 102.765 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.66719, max 2.13882, mean 0, stddev 0.303357, skewness -1.93494, kurtosis 15.4824 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0762823 min, processing 72432.7 frames per sec; i/o time 5.03846%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 12529 82 168 15 39 90 125 14 160 949 326 163 664 119 473 184 201 211 193 569 325 158 270 55 263 76 470 288 269 203 80 65 33 45 448 78 546 224 339 87 41 297 220 92 457 158 159 130 5856 862 179 17467 15 263 124 345 325 302 31 186 53 1047 72 114 389 21 23 419 1069 180 214 154 271 105 32 194 124 783 354 176 83 31 186 287 234 208 522 218 96 210 382 201 298 644 47 277 116 333 115 258 97 191 173 96 181 409 120 133 163 726 178 139 96 129 226 307 166 16 24 18 1329 98 244 90 176 53 288 200 54 100 123 272 117 15 41 21 21 91 60 126 197 51 96 82 224 194 191 50 223 160 89 169 118 146 105 70 169 132 174 243 95 138 65 27 97 248 159 113 303 171 151 133 105 77 297 99 319 34 122 282 178 379 148 336 54 208 100 220 133 84 0 247 47 103 145 242 114 216 104 255 48 166 433 153 128 171 581 195 185 145 265 92 119 238 74 15 103 342 96 132 301 367 241 102 18 97 54 169 50 92 213 98 90 124 291 101 304 146 431 115 261 157 246 195 51 13 17 244 135 169 227 123 218 412 126 192 391 18 262 155 102 86 146 8 84 265 167 112 230 95 30 117 236 201 158 427 18 339 60 93 79 7 556 136 131 62 108 182 86 236 115 179 279 93 212 288 133 159 416 105 190 73 14 212 282 219 234 242 140 32 460 138 190 86 26 79 90 133 144 126 140 151 182 229 202 329 98 70 41 56 66 175 96 203 78 340 96 213 364 337 325 81 226 93 176 268 122 33 145 322 416 116 17 201 122 526 15 186 115 516 185 57 164 61 172 568 94 119 42 316 216 137 148 261 176 117 134 69 63 77 237 114 511 347 33 67 214 40 90 96 17 96 188 154 191 78 226 224 143 56 66 20 116 235 10 59 112 20 925 112 101 64 330 173 189 119 264 24 289 498 201 200 288 170 100 111 51 116 255 69 154 98 113 61 112 148 150 296 169 111 187 529 47 97 193 170 112 19 19 198 265 44 73 167 148 25 129 100 34 156 24 99 180 54 118 142 115 354 173 25 22 70 541 199 244 461 412 310 188 49 50 53 42 349 163 110 334 142 37 16 58 279 22 113 151 223 463 86 147 708 197 88 176 144 118 78 283 134 124 217 134 136 164 82 86 87 59 265 197 244 476 106 97 76 428 30 80 60 182 25 346 68 102 346 99 294 462 91 115 92 282 167 22 13 218 76 128 496 74 214 223 237 61 292 81 254 250 237 71 176 480 458 121 230 29 67 142 49 178 161 191 106 62 106 85 203 120 293 684 40 382 61 138 263 77 746 294 86 85 192 116 95 405 107 330 128 134 151 98 16 275 229 196 131 254 150 387 109 172 188 121 314 56 46 176 49 272 684 10 53 150 105 527 176 13 56 136 138 15 203 67 121 317 127 199 225 89 151 283 188 68 23 181 366 147 424 193 84 127 27 157 150 384 28 128 25 70 176 306 125 178 127 77 84 206 199 46 321 126 161 65 130 315 216 31 106 136 438 132 119 33 47 84 167 570 193 84 23 80 162 274 207 95 133 408 298 83 33 214 590 5 107 61 368 62 130 8 166 7 331 177 265 261 63 20 208 156 71 281 350 223 399 79 147 167 122 501 519 24 221 65 212 266 290 284 114 166 555 0 197 293 81 799 7 124 220 234 54 12 165 33 91 209 98 17 81 480 178 1029 328 182 84 777 104 282 346 109 171 187 35 132 213 88 226 373 76 50 15 1407 121 29 82 258 203 262 69 149 103 244 58 68 77 122 372 192 157 96 225 24 194 317 140 92 200 122 18 14 131 429 169 92 176 412 72 47 39 185 6 2 100 21 100 153 121 450 92 21 119 261 149 152 112 131 91 28 78 119 300 289 229 134 97 534 32 172 152 261 70 244 148 87 89 345 141 217 58 4 469 407 196 138 141 72 190 55 228 321 238 558 473 261 26 370 14 772 305 191 0 87 240 80 132 38 97 159 476 170 46 29 147 294 121 307 12 196 119 224 139 174 28 112 256 242 131 46 117 110 266 491 265 0 123 173 382 15 363 1014 217 48 39 221 167 289 113 288 267 18 127 145 12 122 108 276 36 147 206 496 88 137 277 16 124 87 332 137 130 140 48 103 153 92 165 219 108 176 304 117 25 176 240 50 79 258 173 192 204 136 37 159 88 122 73 129 201 727 213 578 202 494 508 120 108 98 101 62 177 243 378 312 54 37 94 141 440 91 318 143 302 161 165 118 54 243 130 127 81 137 52 190 117 433 158 270 167 51 261 82 116 130 171 109 146 87 135 147 186 228 139 499 43 521 263 266 332 317 25 207 207 79 20 226 288 259 312 198 426 119 230 582 55 205 344 192 80 133 126 73 83 241 211 147 108 566 589 163 160 199 175 91 80 271 125 142 301 218 115 155 204 205 162 293 140 63 294 129 120 270 522 103 106 28 11 143 131 119 209 153 133 177 102 13 40 170 103 136 233 65 89 174 12 173 124 65 70 493 135 108 232 152 104 134 856 498 405 419 152 23 265 332 423 180 491 63 418 219 46 263 257 105 341 170 75 318 453 595 40 175 71 387 283 82 58 59 500 149 267 232 219 277 19 116 0 11 237 64 116 236 549 160 54 547 261 243 277 165 12 320 111 196 275 87 85 197 83 102 156 321 22 145 132 38 352 178 409 280 217 274 140 353 528 110 278 303 459 391 184 266 329 55 698 165 186 118 381 146 206 29 257 153 84 198 1839 150 182 52 338 190 18 149 310 251 217 30 198 32 118 98 310 397 155 203 200 194 117 185 30 54 142 216 418 307 24 310 404 261 80 86 75 110 107 267 270 210 75 145 72 17 79 146 426 254 173 297 0 266 293 146 127 15 350 792 493 238 123 210 143 211 231 401 70 142 356 154 467 53 190 145 53 249 853 435 197 236 79 218 507 193 37 354 137 162 30 239 118 564 275 121 253 272 250 20 277 14 167 136 256 458 143 149 177 162 35 13 64 201 104 168 192 199 350 685 54 302 286 244 24 337 239 332 277 180 79 131 169 105 488 264 274 214 278 59 136 46 42 16 94 267 496 588 255 297 248 339 100 228 27 119 137 18 130 118 232 213 701 153 185 276 129 123 110 271 84 569 175 70 130 71 69 37 334 114 11 371 284 42 101 82 308 262 561 147 349 94 213 117 213 383 44 497 95 25 15 310 439 202 94 32 317 393 337 159 467 35 238 143 86 85 120 347 1105 163 193 304 151 134 141 88 1025 80 82 30 140 112 165 87 123 228 102 55 87 73 180 169 37 85 193 460 98 137 241 214 338 149 142 511 327 81 345 73 43 70 0 414 85 226 75 96 112 170 534 77 223 400 137 510 324 32 115 174 153 89 196 149 237 225 389 131 139 154 202 113 45 140 205 332 128 299 193 357 66 364 450 118 171 200 126 154 143 124 68 334 83 85 81 68 253 210 53 109 186 113 286 166 1445 ]
@@@ Loss per-class: [ 0.736687 1.72833 1.43774 2.94147 2.14064 1.89161 1.97681 4.493 1.62746 0.98734 0.675569 2.10308 0.865462 1.40144 1.97384 1.76664 1.48465 1.66699 1.63872 1.08907 0.766132 1.62413 0.666379 1.77414 1.61883 2.76489 1.13055 1.13065 1.46314 1.14437 2.95648 2.27059 1.43599 2.36174 1.05881 1.69591 0.951234 0.434511 1.28885 2.5818 2.5737 1.53265 2.75272 1.87254 0.633544 0.888435 1.48316 1.87855 1.13368 1.11783 1.26812 0.437474 4.96263 1.03346 2.19653 0.860171 1.24504 0.976424 3.02937 2.1083 2.16646 1.30636 2.40282 1.04161 0.73936 2.52037 3.469 1.2933 1.02603 1.39252 1.10505 1.70866 1.3998 3.54812 2.72491 1.85338 1.21617 0.437586 1.08487 1.13806 2.72025 3.30708 1.47706 2.29028 1.20022 1.81105 1.00507 1.14874 1.92307 2.32904 1.04315 1.58911 1.06888 1.20025 2.79726 0.815416 1.71454 1.58772 2.75685 1.37396 2.55797 1.61946 0.950018 1.53886 1.55179 0.823758 2.35452 1.68233 1.47263 0.707239 1.06598 2.99945 1.61931 1.31452 0.84205 2.11873 1.17634 3.37276 3.23926 5.00451 1.05661 1.96963 1.2746 2.94372 1.09588 3.66102 1.85469 1.4328 2.39169 1.64676 2.06753 1.36625 1.78316 3.81861 1.7714 2.94369 3.70942 1.60138 2.31677 1.79134 1.43218 1.86395 1.68333 3.11569 1.27521 2.39168 1.37427 2.49869 1.8386 1.64341 2.10844 2.04925 1.50677 2.25349 2.17023 1.45377 1.5079 1.72278 1.57222 0.891056 2.39503 1.36987 2.99979 4.15742 1.54982 1.30175 1.95522 2.44232 1.07413 1.79995 1.28598 1.65714 2.88145 1.34166 1.74293 1.41154 1.65478 2.37437 1.50293 0.986493 1.73629 1.69747 1.83014 2.16742 2.41041 2.63908 1.33262 1.51017 1.41784 1.85495 0 1.28964 2.37699 1.5683 2.75104 1.71344 2.14234 0.957162 1.7435 1.76046 2.34093 2.00938 1.0759 1.03371 1.58687 0.936236 1.29009 1.41446 1.30378 2.78386 1.60919 1.85717 2.09096 2.48695 2.3823 5.77918 3.17655 1.68167 1.48259 1.62476 1.01139 1.42077 2.434 2.18173 3.93764 2.66681 1.59879 2.12948 2.52777 3.02324 0.818936 2.49643 1.62964 2.1406 1.48792 1.71391 2.22401 1.4756 0.709653 1.35193 1.0797 2.07157 1.22998 1.07332 3.32075 4.66619 4.27928 2.27174 1.07354 0.94878 1.78554 1.19616 1.46177 1.1089 2.14442 2.01064 1.19298 2.59911 1.42835 2.30299 2.47244 1.56883 1.20059 7.98078 1.82665 0.924043 1.20196 2.05371 1.04963 2.49806 4.51863 2.00494 1.58975 0.885716 3.86951 1.12751 3.40959 2.75765 1.64388 2.31256 2.12982 7.0989 0.942487 2.45275 2.46438 1.65796 1.75692 1.7098 1.5925 1.57956 1.89915 2.48892 2.05558 2.83002 2.48742 0.948283 1.2778 2.41073 1.92376 1.86734 1.86925 3.63253 5.48313 2.05122 1.54801 1.8313 2.2296 1.50395 1.02127 3.33499 0.975894 2.62566 1.18332 1.08618 2.01229 1.35901 2.81783 3.55733 1.46345 1.59163 1.30585 1.66385 2.06112 2.01066 1.21403 2.62794 2.81452 1.98012 2.7023 3.73735 2.37249 1.21458 1.61237 1.64598 1.43176 1.15342 1.42045 2.64178 1.66937 1.66572 1.06431 2.14564 1.48882 2.21026 1.86241 1.10122 2.68835 2.94856 1.71034 2.04357 1.533 2.69856 3.75403 1.89297 2.58827 1.10915 3.27259 1.40999 1.91371 1.20396 2.32479 2.91409 2.2168 1.87772 1.7811 0.806267 2.83197 2.16511 2.94577 1.42679 2.41974 1.46484 1.55604 1.33754 2.07642 2.02918 1.99711 2.491 2.44149 2.009 1.06296 2.96092 1.48547 1.75296 1.88658 1.22986 1.46357 2.61496 1.76582 1.86359 4.99479 1.72875 2.0678 1.12883 1.35167 2.13337 1.14022 0.853826 1.39575 3.74049 1.98554 2.84827 1.83518 1.32406 5.12902 2.52628 3.48835 3.33641 0.947427 1.81421 2.63933 1.78852 1.39122 1.48363 1.14178 1.33376 1.67095 2.72939 2.27978 1.62531 1.53188 1.824 0.89795 2.09511 0.835675 3.05856 2.26291 1.64117 1.95074 2.69962 1.1605 1.73578 2.1523 1.59773 1.30496 2.11111 1.42749 2.21021 1.33846 2.22318 1.32857 1.27397 2.31535 2.35811 2.28205 2.3072 1.75154 4.81709 4.47825 0.948029 1.49995 1.98727 2.42053 1.67516 2.16197 5.25202 1.84067 1.91962 4.12311 0.907759 2.64021 1.53391 1.52122 1.56902 1.7576 2.54158 1.71825 0.829748 2.16156 3.46322 3.0599 1.27391 0.910738 2.20275 1.33558 1.66482 1.17931 2.40349 1.98204 2.94602 2.61716 1.74606 3.31465 1.87021 1.95158 1.73583 1.54954 2.7726 2.4245 2.87937 1.86983 2.13279 3.01846 2.77983 2.55565 1.5748 0.95513 1.55532 1.61624 0.859454 2.03045 3.14602 1.21851 1.49522 1.30489 2.83906 1.51639 1.40203 2.35483 1.16903 1.69373 2.1048 1.69011 1.27653 2.62303 1.54746 2.5321 1.99754 1.91318 1.86326 1.51844 2.32103 2.82777 1.97992 0.970141 2.44092 2.09153 3.11671 1.90778 3.16197 1.58918 1.4651 1.86704 1.15165 1.23165 2.85879 1.2342 1.81507 3.13663 2.36814 1.15992 2.01689 4.15696 4.65893 2.83739 1.92947 1.45441 1.24061 1.78663 1.96929 1.53931 1.70001 3.94364 1.6572 2.4182 1.92475 2.22479 1.63744 2.20308 1.39675 2.32446 1.25559 1.67887 1.49598 4.04905 2.55652 1.74688 3.80374 1.74962 1.20525 1.43142 1.58702 2.04657 3.84671 2.30775 2.04127 1.67127 1.88417 1.81798 2.61498 1.61836 4.56118 1.76567 1.82143 3.22207 0.87165 1.34431 2.33681 2.59927 1.52383 1.47167 2.73383 1.47409 2.45973 1.34728 2.59233 2.22994 2.07759 2.93786 5.43552 1.62026 2.17068 2.20001 1.47839 1.43371 1.76552 1.13551 2.31021 1.46724 1.57894 1.71536 2.10197 2.75025 1.62141 1.67953 3.50214 0.924427 1.08296 6.5401 1.50534 1.87246 2.23426 1.32989 1.86476 5.25362 2.00328 3.01623 1.07192 3.83642 1.98364 4.26317 1.63618 1.38229 2.44425 2.2091 3.00159 2.20631 1.30243 1.75937 1.88397 4.6703 3.93561 3.59058 1.51082 1.84232 1.29526 1.82624 2.20197 3.17874 3.75326 2.43227 1.16751 1.38326 3.60883 2.23442 3.43837 2.47103 1.77131 0.890872 1.63187 1.38245 3.17946 4.43705 2.4792 2.33296 1.22182 4.10543 1.62392 1.75331 1.63785 2.13602 2.22501 1.90564 0.787373 3.3132 2.00928 2.16778 0.86999 1.78621 1.45695 2.72182 2.2327 1.50182 1.70011 1.07372 1.87978 1.63209 3.34123 2.3111 2.28481 1.51618 2.03987 4.01227 1.69805 1.66012 1.69369 2.82822 5.16529 2.63755 1.67625 9.89367 2.26577 1.92474 1.36478 2.79277 1.39762 7.6441 1.91703 7.95483 1.19202 2.01438 0.927899 1.84943 1.79068 1.89913 1.3859 2.1249 2.10665 2.18014 1.45915 1.46514 1.94767 2.12596 1.39232 1.56897 1.60905 0.908513 1.51023 3.15707 1.84764 2.88037 1.72342 2.11357 1.61974 1.73166 2.28266 1.47549 1.35798 0 1.26985 2.08315 1.69245 1.2543 7.86218 1.64048 1.39 1.58144 3.18575 3.71462 1.49741 3.95341 2.63947 2.7737 1.88291 4.15118 1.86814 1.51878 1.94635 0.921273 1.82608 2.70039 2.68623 1.08428 1.57782 1.81066 2.09885 3.38638 1.1241 2.01961 3.08005 1.6141 1.46172 2.34112 1.46408 2.1095 1.6204 2.78036 3.53604 0.944014 2.80533 2.64828 2.26811 1.94259 1.65258 1.69455 2.57453 2.19428 1.76688 1.41927 2.85849 2.2654 2.25859 1.48658 1.81827 1.92833 1.82873 2.83804 2.04728 3.29423 1.29404 1.24067 1.89772 2.08621 1.63777 2.61037 3.22678 3.13895 2.87738 1.22498 2.96994 2.20211 2.35343 1.89864 2.18106 2.43494 3.18236 1.25307 10.8006 10.4498 2.01536 3.35656 2.24623 1.88463 1.24243 1.21558 1.93077 4.47274 3.51305 1.26865 1.47408 1.4981 2.46543 2.62295 2.24606 3.54599 3.8935 2.75559 1.34769 1.94845 1.40916 1.96785 1.83609 0.752628 3.2747 1.82483 1.61479 0.999365 2.05878 2.20977 1.37287 3.50567 1.38314 1.86763 1.5125 1.18527 1.84756 9.49018 1.10519 1.85892 1.35505 2.17765 2.64107 1.9513 2.01964 1.76887 2.71531 0.856665 1.72014 0.950947 1.51598 1.9006 4.45926 1.36757 5.04396 1.69756 1.09367 2.08244 0 2.50824 1.80914 1.88715 1.35964 2.09769 1.81882 1.56935 1.27986 2.72309 3.29173 2.43218 2.8921 2.34216 2.89365 2.35427 6.51892 1.99597 1.06122 2.07985 2.56293 2.27066 3.09169 2.57873 1.8218 3.27053 1.754 3.03759 3.06905 4.45287 1.63824 1.79158 2.09619 0 1.77071 3.78865 1.87503 3.35367 1.1558 1.23086 2.37104 2.63523 3.95232 1.51503 1.96168 1.93016 1.72376 1.44976 1.03711 3.11129 1.70346 1.55956 5.17121 2.61233 2.05046 1.64979 3.59501 1.84945 1.42289 1.93066 1.67443 2.67468 1.31193 4.79666 2.13173 2.74611 0.828832 1.24896 1.65902 1.73918 3.04321 1.97615 1.7014 1.17847 1.69028 1.74302 1.91662 1.96786 1.81364 2.49601 4.71222 2.31848 1.31314 3.60445 1.72518 1.8154 2.19405 1.83345 1.80324 2.19349 4.63494 1.94779 2.72157 2.2154 2.16656 3.22069 3.42078 1.84249 2.67696 1.005 1.3707 1.43637 1.52419 1.90897 1.45783 2.21105 2.04014 2.41777 2.51482 1.32748 1.83262 1.69494 2.53899 2.24699 2.04398 1.88169 1.2169 2.48784 2.32724 2.30212 2.45359 1.42304 1.41158 2.32302 1.7272 2.08981 1.8831 2.94284 4.18281 3.184 3.77763 2.32942 3.03364 1.10965 1.32211 1.41581 2.2303 1.80948 2.15129 3.32871 2.16994 1.5471 1.66261 1.83536 1.97751 2.52968 2.01316 1.58325 2.35145 1.30216 2.80548 1.24485 3.03838 1.15015 1.51757 1.47218 2.60754 2.53384 4.09541 2.34725 2.67021 1.31979 3.99957 1.16675 1.78303 1.50961 1.357 1.9959 0.819126 2.32368 1.68981 1.73641 2.88129 1.35987 1.33813 2.77728 1.89466 1.33548 2.34857 2.58302 2.31737 1.62033 1.4213 1.35094 1.90312 1.3969 1.73488 2.22458 1.52464 1.65571 1.5072 2.27493 2.38679 2.62984 2.2584 3.05764 1.20531 1.98314 2.24713 2.70435 2.44321 3.4255 1.07309 2.4007 2.32958 2.15697 2.14407 1.92068 1.98025 2.48911 0.858253 2.29479 1.74502 5.69941 7.17897 1.76355 1.78518 2.17128 1.89132 1.91669 2.32088 1.56639 1.55886 7.19199 3.01447 1.69105 1.80045 2.41036 1.90286 2.31216 2.50063 3.01704 5.99353 2.20828 2.31993 3.24684 3.85068 1.58084 2.48585 3.02222 1.06121 1.9982 1.89585 2.02096 1.14675 2.04456 1.52955 1.10788 2.56892 2.94322 1.12692 1.21349 2.06118 1.63327 1.36638 1.70206 1.84489 2.14239 3.3228 2.15906 2.23342 1.33971 1.22239 1.55508 1.16573 1.88268 1.67535 2.078 3.71504 1.41305 2.20417 1.55569 1.59161 1.79865 2.60751 2.65346 2.03737 2.1752 2.46303 2.07938 1.29268 1.64348 5.38653 1.731 0 5.98884 1.32152 2.95048 1.95782 1.75489 1.59277 2.51398 2.74616 1.63837 2.60766 1.10351 1.78221 2.0064 2.93161 1.6793 4.23916 1.96486 1.56529 2.1993 2.38225 3.19049 2.47839 2.70842 2.79976 1.90681 3.9121 2.4547 2.74841 2.54223 2.07727 2.12138 1.54521 1.13243 1.08276 2.12321 2.22471 1.43065 1.55059 3.51121 1.25566 1.36689 1.38087 1.3796 1.10812 2.39596 1.70187 1.7849 1.54355 2.52374 1.83138 2.14847 1.9931 3.0874 1.54101 3.32725 1.55288 2.18246 3.03903 1.91603 1.16417 2.22635 1.21714 2.4797 0.98523 2.0246 2.76263 2.15696 1.70749 2.17032 1.6492 4.27237 3.01877 4.73659 2.32854 2.08603 1.77049 1.82441 1.51154 0.999413 1.76589 1.36629 2.82534 1.42172 2.59281 2.88325 1.64824 1.7881 1.56448 2.20125 3.87547 2.01651 1.67181 1.37035 1.90316 4.0872 4.47921 1.66803 2.10071 1.03201 1.91725 2.58907 2.39166 2.70328 2.7482 2.62928 2.14108 2.22517 0.969184 2.15334 2.14254 1.01095 0 2.01597 1.62166 1.73722 3.6771 5.53374 1.58985 1.32508 1.67937 1.76664 2.65959 2.37435 2.04434 1.65382 1.8155 1.61816 2.02493 1.22863 0.960706 2.70643 1.22849 2.31609 2.34479 2.65864 1.15578 1.66741 1.03679 2.0159 4.14249 2.12701 1.7493 1.71132 1.87294 2.01036 3.12215 1.65461 2.56504 2.0638 3.61977 1.61768 2.71723 1.58229 1.27018 3.09512 1.73108 2.38665 1.20344 4.06559 1.35393 4.30259 2.21991 3.24012 2.04538 1.12261 1.86691 1.83486 2.29588 2.15296 2.1947 5.48214 2.90449 1.35138 2.829 2.5508 1.86181 1.3477 1.77168 1.73574 2.73432 1.47689 2.40997 2.98292 3.35974 1.66047 1.48397 2.15889 2.23868 1.73047 2.571 3.37743 1.46194 2.54581 1.26903 1.29679 1.75088 1.73201 1.99924 2.51944 3.0941 2.13199 4.00108 2.50559 2.34317 2.01969 1.36118 1.11591 2.67507 1.87908 2.07231 1.46579 2.26063 2.41976 3.52587 2.49712 2.00253 3.57851 2.78497 2.37064 2.2132 1.07961 1.51588 1.62 2.08549 2.10353 1.68012 2.38006 2.16397 2.26309 2.07763 1.23123 1.97193 2.49643 3.45588 2.02327 2.15779 3.6533 2.85725 1.84993 7.26841 1.67785 2.73464 3.2627 1.7751 1.72573 1.88636 3.2023 1.51211 2.03385 1.67638 2.07752 0.906245 4.09443 2.32025 0.7957 4.32622 1.40318 3.0725 2.78178 5.23722 1.22364 1.4758 1.3081 2.23245 4.08649 2.73759 1.67006 2.15221 1.62048 2.05604 2.90826 2.08825 2.64636 2.13111 4.14905 1.70559 2.22675 1.08282 2.54715 1.73473 1.86412 1.96227 1.31735 1.98885 1.7628 1.08989 2.83045 3.33244 2.67058 1.57005 2.22869 2.28632 2.33436 1.56591 2.18535 2.86849 3.71155 2.30022 2.77529 1.75441 2.90564 1.59772 2.59939 2.08608 1.33019 2.39192 1.84516 1.82754 1.76543 1.76686 1.80438 1.61287 1.28676 1.58013 2.39486 1.83692 2.41387 2.81539 2.65909 0 1.7462 2.17614 1.82718 3.37281 2.36895 2.89583 2.82919 1.38624 3.00069 1.9153 2.10722 2.29121 0.942568 1.41363 2.65931 1.5821 2.48684 1.10101 2.61462 2.61864 2.24786 1.92076 1.68424 1.60861 2.98249 2.12406 1.6586 2.51821 2.10393 3.7366 2.07887 1.81792 1.67311 2.02971 1.09026 2.12385 1.28295 2.74465 1.43051 1.4854 2.17671 1.44387 2.3339 1.79358 1.79822 1.61262 2.38902 1.74155 1.01189 3.5989 1.85442 2.09669 2.32991 1.86567 2.52354 4.15907 2.1659 3.4134 2.46616 1.34123 1.80246 0.479043 ]
@@@ Frame-accuracy per-class: [ 72.9239 54.5455 59.3472 32.2581 37.9747 47.5138 45.4183 20.6897 52.9595 71.406 80.245 31.8043 74.4921 61.9247 41.6051 50.4065 57.5682 53.9007 55.814 70.5882 82.3349 54.2587 79.4824 54.0541 56.167 23.5294 65.0372 67.9376 60.4824 62.4079 14.9068 33.5878 53.7313 32.967 71.5719 49.6815 75.0229 87.7506 64.5066 25.1429 33.7349 61.1765 27.6644 34.5946 79.7814 77.6025 57.6803 52.1073 57.6966 66.3188 65.7382 86.9901 0 72.1063 30.5221 78.7265 61.7512 69.7521 22.2222 46.1126 42.9907 42.7685 42.7586 69.869 80.1027 32.5581 4.25532 65.5542 59.841 54.2936 63.8695 45.3074 57.0902 11.3744 21.5385 42.6735 56.2249 84.2374 66.0085 70.255 31.1377 15.873 61.6622 26.4348 66.0981 50.3597 67.3684 69.5652 42.487 30.8789 65.6209 45.6576 72.0268 60.2017 40 75.3153 49.7854 52.4738 24.2424 61.1219 25.641 61.6188 70.317 47.6684 59.5041 74.7253 31.5353 53.1835 56.8807 80.3854 68.3473 24.3728 54.9223 61.7761 84.3267 38.0488 69.6697 12.1212 24.4898 0 69.1237 36.5482 71.9836 19.8895 64.5892 13.0841 41.2478 58.3541 33.0275 51.7413 46.1538 54.6789 50.2128 19.3548 45.7831 27.907 37.2093 49.1803 34.7107 47.4308 58.7342 36.8932 53.886 23.0303 65.9243 18.509 61.6188 31.6832 40.7159 60.4361 31.2849 41.2979 55.6962 43.0034 29.3839 63.8298 58.4071 59.6226 52.7221 78.4394 38.7435 66.426 12.2137 3.63636 57.4359 64.7887 43.8871 44.9339 69.1928 54.2274 61.3861 62.9213 25.5924 61.9355 58.1513 63.3166 52.2692 40.5797 66.1224 74.3363 56.5826 49.0119 48.4848 39.8217 23.8532 27.3381 61.6915 63.4921 58.427 52.071 0 67.0707 21.0526 64.7343 24.055 58.1443 38.4279 75.7506 44.9761 51.272 30.9278 43.8438 69.8962 68.4039 51.3619 72.3032 69.1316 63.9386 66.8464 13.7457 42.9379 25.9459 41.0042 22.6415 29.5302 0 28.0193 51.9708 64.2487 52.8302 72.6368 56.8707 40.9938 37.0732 32.4324 45.1282 55.0459 44.2478 47.5248 19.4595 76.3466 32.4873 51.9337 36.9478 60.3774 42.3645 39.4089 53.9249 80.8806 59.7403 78.3939 50.7937 60.8519 68.0307 25.2427 7.40741 5.71429 37.6278 70.1107 74.9263 50.989 63.1579 56.7506 69.0909 39.5257 45.1948 69.9872 43.2432 61.3333 29.582 28.2927 55.4913 68.942 0 41.4201 71.5631 62.6866 36.4444 72.885 28.2723 6.55738 42.5532 54.9683 77.4194 12.6183 63.6257 37.8378 30.3387 47.9339 37.4332 37.7358 0 74.9326 32.2344 31.9392 64 42.3963 60.8219 53.1792 60.0423 42.4242 30.0836 42.576 24.5989 37.6471 75.9099 63.6704 25.7053 46.0984 42.654 42.5197 5.44218 0 49.8824 62.6549 46.9248 40.5117 59.7938 71.1744 9.23077 74.4843 34.657 55.643 68.2081 52.8302 54.0881 38.674 11.985 60.2076 56.1265 62.6335 58.7459 40.5479 40.9586 67.1605 27.9211 28.4264 39.7163 24.0964 19.469 43.609 66.0969 54.9223 57.4939 61.1465 64.6109 60.1036 38.8759 54.321 54.8148 70.6605 45.3988 48.1236 28.877 51.5581 64.8045 31.8367 20.8955 57.0447 36.8992 59.5438 28.3262 22.8571 48.6352 24.4898 71.7949 19.3548 60.5898 48.4848 69.6999 37.1968 22.6087 31.6109 53.6585 52.1739 75.1099 15.873 37.6569 37.6471 64.139 37.4134 56 58.5859 65.7744 33.4278 43.4043 47.5836 28.777 31.4961 45.1613 69.8947 20.0873 50.6354 49.7842 53.7313 68.1481 59.2075 17.284 56.3536 44.5596 11.4286 55.9585 42.9708 65.3722 65.7963 45.8599 66.2252 78.8419 62.7178 19.469 52.6316 39.0244 54.0773 63.6943 0 26.8908 15.1111 19.5122 69.8001 52.4444 24.6305 44.9612 59.0015 52.4496 67.0185 63.5983 47.6371 53.0612 40.0691 51.5547 58.0645 49.8753 76.6031 43.4018 82.5871 25.1121 27.1845 61.8026 50.4892 18.705 62.1359 49.7462 37.8855 52.0325 63.1111 30.9764 57.8073 37.0995 65.4867 33.1839 63.4667 61.7564 18.9474 38.9744 29.4574 31.085 51.5556 15.3846 5.12821 73.5516 58.3804 42.6966 42.1769 48.9552 44.4444 7.84314 54.8263 46.7662 8.69565 77.9553 53.0612 52.2613 58.1717 55.0459 42.1941 30.1754 54.5455 78.4203 36.3112 39.2157 40 65.2482 74.6076 40.1003 69.1207 51.3543 66.9091 32.5282 30.7692 22.2222 23.7624 42.9907 16.4706 54.0773 55.6575 48.8688 51.42 23.8596 34.6667 36.3636 46.1538 43.2916 31.1111 14.0969 31.0231 55.9284 72.0604 61.2717 56.9492 78.4757 47.0886 19.209 58.9235 58.1315 62.4473 17.8344 58.5538 62.4535 44.1767 62.069 55.7621 52.0147 49.848 66.6667 20.8092 56 38.6555 44.4444 50.1266 51.1247 55.8237 14.0845 21.5385 56.2092 77.9463 36.0656 38.5093 24.7934 49.3151 31.3725 58.8745 52.5547 49.7561 66.6667 75.3769 34.635 65.0811 46.9945 24.2424 32.4324 67.6106 26.2687 13.3333 7.40741 23.7986 49.6732 61.4786 65.6596 37.5839 48.4848 54.1387 53.4737 4.87805 52.9915 38.0368 40.8644 45.1098 59.7895 43.3566 57.7904 30.1769 69.1385 51.0288 58.1345 6.77966 20.7407 51.2281 20.202 56.0224 66.2539 55.8747 60.0939 43.2 17.8404 45.614 43.2432 56.4315 42.5894 31.8481 27.1605 62.4837 4.87805 54.1516 49.3359 23.2258 77.562 68.2513 40.4624 40.9357 61.8182 48.927 29.3194 57.9531 38.1395 58.6989 31.1284 37.9182 41.5842 17.2589 0 56.9873 51.4161 46.3104 63.8783 58.9391 35.8804 72 36.5297 59.7101 55.1724 51.0288 41.6534 24.7788 55.914 49.2918 38.3838 76.6972 71.1468 0 56.0748 44.5183 33.1754 63.8863 51.5581 7.40741 60.177 27.8388 68.5921 32.2581 46.683 10.3704 59.2593 59.8425 32.9412 38.5965 27.051 40.2235 65.3465 49.7354 44.5623 14.5985 42.5532 19.2837 55.9345 48.1356 58.6572 45.9948 28.4024 19.6078 3.63636 32.381 71.7608 65.2796 21.0526 41.2451 31.3725 35.461 43.6261 72.7569 54.1833 61.6246 29.0196 5.16129 39.0533 34.3826 68.1704 10.7527 47.2784 45.8498 58.2043 36.6412 44.4444 44.374 75.2887 28.5714 42.2535 37.3626 77.081 51.3208 60.251 17.9104 25.2632 52.071 49.5522 72.0421 51.6796 57.9882 34.0426 31.0559 32.6154 52.8233 50.6024 9.42408 59.9251 58.2619 50.9213 13.1737 2.98507 19.5804 56.3929 0 33.4884 45.5285 57.8019 12.8 63.6015 0 48.6486 0 62.4434 46.1972 73.823 51.2428 47.2441 58.5366 61.8705 35.1438 37.7622 49.7336 47.0756 62.6398 42.5532 41.5094 52.2034 45.3731 59.5918 71.7846 58.3253 24.4898 50.1129 19.8473 50.8235 33.7711 56.1102 56.5905 31.441 59.4595 64.4464 0 67.8481 42.2487 40.4908 65.0407 0 49.7992 54.4218 63.113 12.844 24 54.9849 2.98507 43.7158 21.4797 54.8223 0 53.9877 59.5213 46.4986 70.7139 53.5769 36.1644 33.1361 66.4952 53.5885 42.8319 35.2092 18.2648 67.6385 48.5333 28.169 45.283 64.1686 38.4181 60.9272 49.5315 57.5163 33.6634 45.1613 76.2345 23.0453 44.0678 43.6364 41.3926 53.5627 49.9048 34.5324 30.1003 47.343 47.4438 22.2222 45.2555 37.4194 65.3061 51.8121 48.3117 45.7143 18.6528 41.2417 16.3265 63.2391 70.5512 43.4164 44.3243 49.8753 28.5714 48.6486 41.3793 16.73 69.383 22.4189 22.7027 30.0283 44.3636 31.7241 40 22.7848 61.9946 0 0 43.7811 32.5581 34.8259 52.7687 58.4362 65.7048 45.4054 0 15.0628 68.0688 60.2007 59.6721 25.7778 29.6578 48.0874 3.50877 11.465 33.4728 54.5757 48.0138 64.488 43.8662 47.1795 81.1974 24.6154 51.0145 58.3607 75.717 39.7163 44.9898 65.9933 6.85714 62.5698 46.8886 53.7102 68.046 39.3162 0 65.6017 46.135 58.5242 44.7653 34.629 49.6552 51.4436 66.6667 27.1335 72.1617 46.1216 73.9481 62.7244 46.2715 7.54717 63.1579 6.89655 45.178 74.3044 42.2977 0 14.8571 53.6383 55.9006 58.8679 51.9481 50.2564 50.1567 65.6873 38.7097 12.9032 44.0678 15.5932 39.7284 25.5144 40.9756 0 47.8372 69.4561 39.1982 37.276 32.0917 31.5789 25.7778 53.0214 21.8557 46.3878 30.1075 30.6383 10.8597 52.9081 51.882 41.8079 0 51.8219 9.79827 50.719 45.1613 59.6974 67.2252 32.6437 28.866 2.53165 60.9481 48.9552 37.3057 46.696 57.8856 68.0374 37.8378 55.6863 54.2955 0 32.6531 45.1613 58.9512 8.21918 48.1356 59.5642 40.4834 49.7175 38.5455 58.3784 6.06061 40.1606 36.5714 76.9925 80.7273 55.1724 59.7865 22.6804 40.5797 51.4658 70.2703 59.8187 53.303 35.9447 50.4249 49.2611 34.8936 0 37.9603 67.3597 7.92079 57.8616 51.0638 53.6023 55.0649 47.4328 41.0256 8 40.1254 24.8588 35.102 39.4558 17.7606 18.8586 50.7216 33.7237 68.9715 63.7037 61.8807 58.8004 53.112 62.6728 42.6396 49.2611 33.6 21.4085 68.5832 48.3487 54.08 40.367 45.3333 45.5026 45.2297 65.3802 32.7869 39.8744 31.3589 32.3967 61.9195 65.861 35.443 40.367 49.692 52.8736 16.4706 4.90798 18.9091 11.4286 37.7953 22.1277 73.8178 57.4132 63.586 45.3731 36.8932 42.065 14.5455 40.3433 57.4713 48.3965 51.1416 47.099 35.4286 37.6384 56.9492 33.7802 65.6455 24.3728 67.4675 6.89655 66.7306 61.8596 57.4109 30.0752 33.0709 0 33.253 14.9398 62.8931 9.7561 71.9647 57.1924 59.7303 67.84 49.3703 79.7186 31.7992 56.3991 38.6266 18.018 57.9075 61.5385 27.013 48.4472 62.9213 33.9921 42.1769 37.1257 53.8302 66.1939 65.7627 44.2396 55.075 53.0958 37.9205 56.6978 54.6366 57.5499 41.5301 33.5404 26.151 46.2151 21.7544 65.34 53.0892 39.8268 30.8682 29.3399 23.3577 62.1538 35.0937 31.3167 40.9449 38.7097 57.9151 61.4108 33.2717 77.1292 44.4444 46.0094 0 0 58.5366 53.2319 34.3096 41.5274 50.1629 31.4607 54.6479 58.5366 0 24.6914 55.132 56.0386 39.5604 53.9615 32.0611 37.9888 19.4842 0 43.2277 39.3574 13.7405 5.67376 54.9139 22.8782 28.5714 69.6774 52.459 49.7608 32.7138 67.6007 45.1354 60.6658 71.5137 19.6721 34.0426 68.9266 68.5714 47.4616 61.4958 62.6653 48.8189 48.9845 36.4465 15.0538 42.8843 36.1165 59.7156 66.4714 60.4106 63.5762 44.584 59.0959 36.1041 9.87654 59.2593 34.965 59.0968 53.2628 47.2727 27.3504 30.2521 42.5574 38.1271 31.7757 43.871 67.426 51.8919 10.2564 51.5021 0 0 61.8947 23.2558 40.3433 57.0825 54.2311 23.676 20.1835 56.2557 27.9159 67.3511 49.009 56.7976 32 52.1061 3.58744 51.9084 52.2686 46.8571 35.0877 15.6962 34.7305 32.1951 24.9201 48.5226 13.3333 20.6186 30.1887 38.961 34.3262 49.8599 57.1429 64.5276 68.5057 35.337 38.4342 64.4979 60.9272 19.0045 62.4776 66.5568 65.506 64.8787 72.0867 43.9024 57.6631 52.2523 52.9707 25.3776 49.3298 36.2869 45.8716 21.843 50.3632 3.38983 58.2524 39.7394 23.6686 41.3098 62.6257 44.5183 70.6849 45.7143 75.6278 52.4934 48.6486 38.796 55.7166 38.171 56.5517 3.27869 24.6851 0 27.8481 39.5939 49.2754 53.0818 57.8778 73.7101 46.384 64.2674 20.4255 65.2291 22.9508 29.3578 52.6316 48.4988 64.5161 42.2764 24.4898 45.4106 54.3881 63.4799 65.8385 11.5607 0 46.1538 43.7209 69.9065 48.7985 27.5534 26.4901 36.4261 28.9655 40 44.0252 47.099 74.3259 42.0432 43.2277 69.916 0 51.4071 61.3288 51.1945 17.2549 0 54.2083 61.3249 54.9139 60.3774 27.5304 38.9549 45.993 57.2104 51.8359 54.5455 49.6454 72.9825 73.4923 25.2427 60.3209 46.729 42.5197 31.6151 69.1589 52.505 76.0398 45.6946 7.59494 41.0148 50.3145 54.0046 49.4581 45.9948 26.6667 49.3653 29.0909 41.2308 26.2295 60.1253 32.9114 56.333 65.6987 20.5761 49.7041 34.4954 68.6627 19.5122 58.018 13.7931 47.1642 31.5018 42.885 71.7557 42.5087 49.4983 44.507 38.1538 45.0704 7.40741 27.907 67.4938 38.2775 28.4866 50.9091 58.1454 47.9315 51.4953 18.3486 59.5041 36.3002 24.1309 20.4082 56.5926 61.7954 32.4812 32.4324 58.7258 40.2516 18.251 66.0767 38.8626 65.5067 64.6503 53.5519 55.4779 45.9605 28.5714 12.4542 43.0108 7.05882 48.4848 35.9788 48.972 66.8681 69.4987 31.3112 50.4202 49.8994 61.2666 38.806 39.8249 29.0909 42.6778 38.5455 37.8378 28.3525 39.6624 49.0323 74.9415 60.0143 61.2378 36.6577 46.2929 54.0541 28.3401 38.009 43.8306 30.7692 66.7252 39.886 26.9504 9.1954 44.7552 33.0935 8 27.5037 47.1616 0 49.7981 34.7979 9.41176 49.2611 59.3939 49.919 20.1905 50.5788 44.7458 57.5107 46.5608 72.1311 8.51064 35.1288 79.2699 11.236 67.5377 8.37696 35.2941 6.45161 65.3784 56.2002 64.6914 40.2116 3.07692 29.9213 50.8259 40.2963 49.5298 40.8556 16.9014 47.3795 31.3589 39.3064 4.67836 48.1328 42.3022 68.114 34.2508 58.3979 45.6486 40.9241 67.658 49.47 47.4576 70.3072 29.8137 24.2424 42.623 54.8043 29.3333 42.2961 44.5714 58.2996 49.0153 37.0732 10.8108 49.1429 39.4558 53.7396 23.5988 56 25.731 51.1628 60.5863 42.6396 47.2727 56.7288 54.0793 54.062 49.4983 61.0526 61.7791 58.626 33.1288 49.4935 39.4558 29.8851 25.5319 0 55.971 37.4269 50.7726 10.596 40.4145 19.5556 22.2874 59.1207 30.9677 43.8479 44.9438 38.5455 74.8286 62.5578 43.0769 58.0087 45.8453 66.4495 21.2291 32.0611 35.4515 53.0526 59.867 57.5096 18.251 44.4444 58.2524 34.5679 43.1718 4.3956 42.7046 54.9878 56.8421 27.2374 72.4541 29.4574 62.9371 13.5338 65.0206 56.8257 42.1941 55.9767 38.9027 56.1265 56.9579 53.6585 33.7349 55.4745 75.9342 17.9641 53.8012 34.3558 29.1971 42.2091 27.0784 3.73832 43.8356 18.7668 29.0749 57.2426 64.8649 87.8589 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 1.61697 (Xent), [AvgXent: 1.61697, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 55.5472% <<

