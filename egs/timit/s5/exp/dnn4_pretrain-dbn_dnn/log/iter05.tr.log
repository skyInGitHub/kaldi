nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.004 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter04_learnrate0.008_tr1.1154_cv2.1606 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter05 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975016
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.86424, max 7.06273, mean -0.000964877, stddev 0.993005, skewness 0.0133901, kurtosis 2.03207 ) 
[1] output of <AffineTransform> ( min -29.7293, max 22.0605, mean -3.28948, stddev 3.99879, skewness 0.127768, kurtosis 1.41945 ) 
[2] output of <Sigmoid> ( min 1.22662e-13, max 1, mean 0.205688, stddev 0.313025, skewness 1.50354, kurtosis 0.804406 ) 
[3] output of <AffineTransform> ( min -29.4691, max 18.9191, mean -4.11344, stddev 2.8728, skewness -0.00803131, kurtosis 2.75127 ) 
[4] output of <Sigmoid> ( min 1.59125e-13, max 1, mean 0.0978437, stddev 0.197582, skewness 2.91368, kurtosis 8.25654 ) 
[5] output of <AffineTransform> ( min -15.035, max 12.7245, mean -3.20879, stddev 2.0369, skewness 0.599548, kurtosis 2.42948 ) 
[6] output of <Sigmoid> ( min 2.95383e-07, max 0.999997, mean 0.110666, stddev 0.190468, skewness 2.79216, kurtosis 7.84503 ) 
[7] output of <AffineTransform> ( min -22.289, max 14.311, mean -2.87627, stddev 2.27804, skewness 0.575605, kurtosis 2.83372 ) 
[8] output of <Sigmoid> ( min 2.08943e-10, max 0.999999, mean 0.146624, stddev 0.230045, skewness 2.18346, kurtosis 4.07541 ) 
[9] output of <AffineTransform> ( min -16.5666, max 16.0839, mean -2.92639, stddev 2.82049, skewness 1.33817, kurtosis 2.73866 ) 
[10] output of <Sigmoid> ( min 6.38575e-08, max 1, mean 0.169639, stddev 0.28616, skewness 1.85396, kurtosis 2.09313 ) 
[11] output of <AffineTransform> ( min -27.7981, max 17.7302, mean -3.78234, stddev 3.53616, skewness 0.969247, kurtosis 3.36325 ) 
[12] output of <Sigmoid> ( min 8.46098e-13, max 1, mean 0.140455, stddev 0.286291, skewness 2.15783, kurtosis 3.16304 ) 
[13] output of <AffineTransform> ( min -13.409, max 22.721, mean -0.00165188, stddev 3.3956, skewness 0.572318, kurtosis 1.0566 ) 
[14] output of <Softmax> ( min 4.78631e-15, max 0.999147, mean 0.000647587, stddev 0.0175031, skewness 40.0688, kurtosis 1790.06 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.89799, max 1.02499, mean 1.14635e-05, stddev 0.058291, skewness -0.468581, kurtosis 29.4599 ) 
[1] diff-output of <AffineTransform> ( min -0.328587, max 0.384364, mean -3.90833e-05, stddev 0.0102293, skewness -0.283504, kurtosis 67.6667 ) 
[2] diff-output of <Sigmoid> ( min -1.76434, max 2.20981, mean -9.06607e-05, stddev 0.0919299, skewness -0.0816674, kurtosis 16.0365 ) 
[3] diff-output of <AffineTransform> ( min -0.366322, max 0.429885, mean -3.71775e-05, stddev 0.0113765, skewness -0.112314, kurtosis 83.3636 ) 
[4] diff-output of <Sigmoid> ( min -1.47752, max 1.85032, mean 4.48198e-06, stddev 0.118068, skewness -0.00311526, kurtosis 8.88442 ) 
[5] diff-output of <AffineTransform> ( min -0.336317, max 0.280285, mean 1.85285e-05, stddev 0.0117298, skewness -0.562018, kurtosis 57.8614 ) 
[6] diff-output of <Sigmoid> ( min -1.37917, max 1.29522, mean 0.000115691, stddev 0.100733, skewness -0.0484027, kurtosis 9.14395 ) 
[7] diff-output of <AffineTransform> ( min -0.220912, max 0.241283, mean 4.46049e-05, stddev 0.00984352, skewness -0.250654, kurtosis 38.9113 ) 
[8] diff-output of <Sigmoid> ( min -0.937596, max 1.01471, mean 0.000270898, stddev 0.0748492, skewness -0.0602523, kurtosis 9.11252 ) 
[9] diff-output of <AffineTransform> ( min -0.188737, max 0.161858, mean 2.31592e-05, stddev 0.0075792, skewness -0.461253, kurtosis 39.4634 ) 
[10] diff-output of <Sigmoid> ( min -0.838389, max 0.733482, mean -1.68363e-05, stddev 0.0588267, skewness -0.158312, kurtosis 11.0616 ) 
[11] diff-output of <AffineTransform> ( min -0.218581, max 0.387152, mean 7.93786e-05, stddev 0.00874102, skewness 0.359121, kurtosis 66.0931 ) 
[12] diff-output of <Sigmoid> ( min -1.36149, max 2.77171, mean 0.000878208, stddev 0.0948731, skewness 0.19936, kurtosis 10.995 ) 
[13] diff-output of <AffineTransform> ( min -0.999883, max 0.984229, mean -1.1323e-08, stddev 0.018814, skewness -24.4836, kurtosis 1718.98 ) 
[14] diff-output of <Softmax> ( min -0.999883, max 0.984229, mean -1.1323e-08, stddev 0.018814, skewness -24.4836, kurtosis 1718.98 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.84121, max 2.27581, mean -0.000785533, stddev 0.165933, skewness 0.0149951, kurtosis 2.30361 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.593596, max 0.650409, mean -0.0100053, stddev 0.171206, skewness 0.0119982, kurtosis 0.517549 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -1.13396, max 0.934756, mean -0.00148715, stddev 0.0726286, skewness -0.121115, kurtosis 7.33067 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.10938, max 0.884066, mean -0.00951746, stddev 0.202085, skewness -0.0246039, kurtosis 2.37108 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -1.19737, max 0.767057, mean 0.000665898, stddev 0.0442784, skewness -0.280627, kurtosis 17.3467 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.30165, max 1.01998, mean 0.0047433, stddev 0.217263, skewness -0.169736, kurtosis 3.46284 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.969552, max 0.559821, mean 0.001388, stddev 0.0380598, skewness 0.0278388, kurtosis 12.9914 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.983848, max 0.800209, mean 0.0114189, stddev 0.188649, skewness 0.164392, kurtosis 2.48854 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.607179, max 0.483377, mean 0.00106479, stddev 0.03594, skewness 0.0119383, kurtosis 8.99058 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.734065, max 0.666997, mean 0.00592878, stddev 0.140634, skewness 0.00898459, kurtosis 3.22867 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.905601, max 0.81417, mean 0.00370381, stddev 0.0494508, skewness 0.322137, kurtosis 10.8714 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.924615, max 0.74183, mean 0.0203209, stddev 0.157638, skewness -0.0710945, kurtosis 3.75389 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.84311, max 3.83185, mean -3.29211e-08, stddev 0.100834, skewness -3.26712, kurtosis 80.7188 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.67377, max 3.57331, mean -8.64731e-09, stddev 0.325981, skewness -0.599173, kurtosis 17.8148 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 331520 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.8171, max 6.44093, mean -0.00429144, stddev 1.00295, skewness -0.0631885, kurtosis 1.97814 ) 
[1] output of <AffineTransform> ( min -29.2536, max 22.2616, mean -3.31585, stddev 4.09399, skewness 0.118894, kurtosis 1.32404 ) 
[2] output of <Sigmoid> ( min 1.97394e-13, max 1, mean 0.2089, stddev 0.316268, skewness 1.47599, kurtosis 0.707028 ) 
[3] output of <AffineTransform> ( min -27.1334, max 17.8434, mean -4.08468, stddev 2.86418, skewness 0.0092754, kurtosis 2.58378 ) 
[4] output of <Sigmoid> ( min 1.64484e-12, max 1, mean 0.0993163, stddev 0.198449, skewness 2.87797, kurtosis 8.05058 ) 
[5] output of <AffineTransform> ( min -14.5361, max 14.8245, mean -3.16463, stddev 2.04154, skewness 0.587329, kurtosis 2.47876 ) 
[6] output of <Sigmoid> ( min 4.8646e-07, max 1, mean 0.113636, stddev 0.191937, skewness 2.73434, kurtosis 7.49897 ) 
[7] output of <AffineTransform> ( min -22.7953, max 14.5218, mean -2.79873, stddev 2.30501, skewness 0.556094, kurtosis 2.66683 ) 
[8] output of <Sigmoid> ( min 1.25927e-10, max 1, mean 0.15446, stddev 0.235487, skewness 2.07943, kurtosis 3.57103 ) 
[9] output of <AffineTransform> ( min -15.8758, max 17.218, mean -2.86233, stddev 2.89948, skewness 1.32469, kurtosis 2.65432 ) 
[10] output of <Sigmoid> ( min 1.2742e-07, max 1, mean 0.177739, stddev 0.292823, skewness 1.76751, kurtosis 1.74991 ) 
[11] output of <AffineTransform> ( min -27.8123, max 19.9764, mean -3.72869, stddev 3.64194, skewness 0.97616, kurtosis 3.20908 ) 
[12] output of <Sigmoid> ( min 8.34182e-13, max 1, mean 0.147199, stddev 0.293947, skewness 2.07086, kurtosis 2.7599 ) 
[13] output of <AffineTransform> ( min -16.2838, max 22.4776, mean -0.00370644, stddev 3.54534, skewness 0.532696, kurtosis 1.00458 ) 
[14] output of <Softmax> ( min 5.08818e-16, max 0.999368, mean 0.000647602, stddev 0.0188939, skewness 40.2524, kurtosis 1757.24 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.769304, max 1.2424, mean 0.000183022, stddev 0.0417418, skewness 0.252136, kurtosis 24.7524 ) 
[1] diff-output of <AffineTransform> ( min -0.198119, max 0.303962, mean 5.55808e-05, stddev 0.00782206, skewness 0.819687, kurtosis 74.0808 ) 
[2] diff-output of <Sigmoid> ( min -1.49779, max 2.567, mean 0.000269437, stddev 0.0710666, skewness 0.69844, kurtosis 34.4615 ) 
[3] diff-output of <AffineTransform> ( min -0.222942, max 0.494884, mean 3.72528e-05, stddev 0.00879729, skewness 1.49866, kurtosis 140.76 ) 
[4] diff-output of <Sigmoid> ( min -1.44244, max 2.50282, mean 8.97493e-05, stddev 0.0934464, skewness 0.121213, kurtosis 16.5439 ) 
[5] diff-output of <AffineTransform> ( min -0.263823, max 0.600116, mean 4.74552e-05, stddev 0.0092803, skewness 1.50507, kurtosis 142.871 ) 
[6] diff-output of <Sigmoid> ( min -1.11283, max 2.41455, mean 0.000263201, stddev 0.0807551, skewness 0.309004, kurtosis 18.2994 ) 
[7] diff-output of <AffineTransform> ( min -0.150209, max 0.336125, mean 2.41159e-05, stddev 0.00776557, skewness 1.08496, kurtosis 74.7472 ) 
[8] diff-output of <Sigmoid> ( min -0.866139, max 1.42423, mean 0.00013343, stddev 0.0583494, skewness 0.137115, kurtosis 15.5801 ) 
[9] diff-output of <AffineTransform> ( min -0.155485, max 0.218506, mean 1.05919e-05, stddev 0.00590978, skewness 0.406733, kurtosis 60.1845 ) 
[10] diff-output of <Sigmoid> ( min -0.780078, max 0.97387, mean -4.71525e-05, stddev 0.0454726, skewness -0.0374582, kurtosis 17.0231 ) 
[11] diff-output of <AffineTransform> ( min -0.284903, max 0.23014, mean 6.48649e-06, stddev 0.00665827, skewness -0.215624, kurtosis 85.0432 ) 
[12] diff-output of <Sigmoid> ( min -1.3234, max 1.88452, mean 0.000171996, stddev 0.0717359, skewness -0.0645304, kurtosis 12.3024 ) 
[13] diff-output of <AffineTransform> ( min -0.999997, max 0.850081, mean -7.61465e-09, stddev 0.0139472, skewness -29.4916, kurtosis 2402.68 ) 
[14] diff-output of <Softmax> ( min -0.999997, max 0.850081, mean -7.61465e-09, stddev 0.0139472, skewness -29.4916, kurtosis 2402.68 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.11916, max 1.13045, mean 0.00156647, stddev 0.124154, skewness 0.0312881, kurtosis 1.6462 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.430033, max 0.520813, mean 0.0142286, stddev 0.130448, skewness 0.108212, kurtosis 0.818512 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.654714, max 1.08639, mean 0.00162117, stddev 0.0548358, skewness 0.613842, kurtosis 9.66055 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.506107, max 0.861929, mean 0.00953671, stddev 0.152254, skewness 0.554639, kurtosis 2.42386 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.555792, max 1.55727, mean 0.000983056, stddev 0.0343329, skewness 1.30703, kurtosis 40.0555 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.563067, max 1.47755, mean 0.0121485, stddev 0.16611, skewness 1.09549, kurtosis 7.89182 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.406167, max 0.974214, mean 0.000426905, stddev 0.0282729, skewness 0.79152, kurtosis 19.0856 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.526247, max 0.915964, mean 0.00617368, stddev 0.135844, skewness 0.63635, kurtosis 3.382 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.310245, max 0.679443, mean 0.000119675, stddev 0.0274843, skewness 0.3822, kurtosis 9.41846 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.43136, max 0.660445, mean 0.00271156, stddev 0.105008, skewness 0.531411, kurtosis 3.46678 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.733511, max 0.387473, mean 9.96261e-05, stddev 0.0365774, skewness 0.0221611, kurtosis 10.3109 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.733347, max 0.45208, mean 0.00166055, stddev 0.110063, skewness -0.0410981, kurtosis 3.65483 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.07299, max 1.59947, mean -4.42084e-08, stddev 0.0748734, skewness -5.03377, kurtosis 99.6455 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.0667, max 1.45436, mean -1.05003e-08, stddev 0.224358, skewness -1.86707, kurtosis 15.405 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0763523 min, processing 72366.3 frames per sec; i/o time 5.0691%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 12529 82 168 15 39 90 125 14 160 949 326 163 664 119 473 184 201 211 193 569 325 158 270 55 263 76 470 288 269 203 80 65 33 45 448 78 546 224 339 87 41 297 220 92 457 158 159 130 5856 862 179 17467 15 263 124 345 325 302 31 186 53 1047 72 114 389 21 23 419 1069 180 214 154 271 105 32 194 124 783 354 176 83 31 186 287 234 208 522 218 96 210 382 201 298 644 47 277 116 333 115 258 97 191 173 96 181 409 120 133 163 726 178 139 96 129 226 307 166 16 24 18 1329 98 244 90 176 53 288 200 54 100 123 272 117 15 41 21 21 91 60 126 197 51 96 82 224 194 191 50 223 160 89 169 118 146 105 70 169 132 174 243 95 138 65 27 97 248 159 113 303 171 151 133 105 77 297 99 319 34 122 282 178 379 148 336 54 208 100 220 133 84 0 247 47 103 145 242 114 216 104 255 48 166 433 153 128 171 581 195 185 145 265 92 119 238 74 15 103 342 96 132 301 367 241 102 18 97 54 169 50 92 213 98 90 124 291 101 304 146 431 115 261 157 246 195 51 13 17 244 135 169 227 123 218 412 126 192 391 18 262 155 102 86 146 8 84 265 167 112 230 95 30 117 236 201 158 427 18 339 60 93 79 7 556 136 131 62 108 182 86 236 115 179 279 93 212 288 133 159 416 105 190 73 14 212 282 219 234 242 140 32 460 138 190 86 26 79 90 133 144 126 140 151 182 229 202 329 98 70 41 56 66 175 96 203 78 340 96 213 364 337 325 81 226 93 176 268 122 33 145 322 416 116 17 201 122 526 15 186 115 516 185 57 164 61 172 568 94 119 42 316 216 137 148 261 176 117 134 69 63 77 237 114 511 347 33 67 214 40 90 96 17 96 188 154 191 78 226 224 143 56 66 20 116 235 10 59 112 20 925 112 101 64 330 173 189 119 264 24 289 498 201 200 288 170 100 111 51 116 255 69 154 98 113 61 112 148 150 296 169 111 187 529 47 97 193 170 112 19 19 198 265 44 73 167 148 25 129 100 34 156 24 99 180 54 118 142 115 354 173 25 22 70 541 199 244 461 412 310 188 49 50 53 42 349 163 110 334 142 37 16 58 279 22 113 151 223 463 86 147 708 197 88 176 144 118 78 283 134 124 217 134 136 164 82 86 87 59 265 197 244 476 106 97 76 428 30 80 60 182 25 346 68 102 346 99 294 462 91 115 92 282 167 22 13 218 76 128 496 74 214 223 237 61 292 81 254 250 237 71 176 480 458 121 230 29 67 142 49 178 161 191 106 62 106 85 203 120 293 684 40 382 61 138 263 77 746 294 86 85 192 116 95 405 107 330 128 134 151 98 16 275 229 196 131 254 150 387 109 172 188 121 314 56 46 176 49 272 684 10 53 150 105 527 176 13 56 136 138 15 203 67 121 317 127 199 225 89 151 283 188 68 23 181 366 147 424 193 84 127 27 157 150 384 28 128 25 70 176 306 125 178 127 77 84 206 199 46 321 126 161 65 130 315 216 31 106 136 438 132 119 33 47 84 167 570 193 84 23 80 162 274 207 95 133 408 298 83 33 214 590 5 107 61 368 62 130 8 166 7 331 177 265 261 63 20 208 156 71 281 350 223 399 79 147 167 122 501 519 24 221 65 212 266 290 284 114 166 555 0 197 293 81 799 7 124 220 234 54 12 165 33 91 209 98 17 81 480 178 1029 328 182 84 777 104 282 346 109 171 187 35 132 213 88 226 373 76 50 15 1407 121 29 82 258 203 262 69 149 103 244 58 68 77 122 372 192 157 96 225 24 194 317 140 92 200 122 18 14 131 429 169 92 176 412 72 47 39 185 6 2 100 21 100 153 121 450 92 21 119 261 149 152 112 131 91 28 78 119 300 289 229 134 97 534 32 172 152 261 70 244 148 87 89 345 141 217 58 4 469 407 196 138 141 72 190 55 228 321 238 558 473 261 26 370 14 772 305 191 0 87 240 80 132 38 97 159 476 170 46 29 147 294 121 307 12 196 119 224 139 174 28 112 256 242 131 46 117 110 266 491 265 0 123 173 382 15 363 1014 217 48 39 221 167 289 113 288 267 18 127 145 12 122 108 276 36 147 206 496 88 137 277 16 124 87 332 137 130 140 48 103 153 92 165 219 108 176 304 117 25 176 240 50 79 258 173 192 204 136 37 159 88 122 73 129 201 727 213 578 202 494 508 120 108 98 101 62 177 243 378 312 54 37 94 141 440 91 318 143 302 161 165 118 54 243 130 127 81 137 52 190 117 433 158 270 167 51 261 82 116 130 171 109 146 87 135 147 186 228 139 499 43 521 263 266 332 317 25 207 207 79 20 226 288 259 312 198 426 119 230 582 55 205 344 192 80 133 126 73 83 241 211 147 108 566 589 163 160 199 175 91 80 271 125 142 301 218 115 155 204 205 162 293 140 63 294 129 120 270 522 103 106 28 11 143 131 119 209 153 133 177 102 13 40 170 103 136 233 65 89 174 12 173 124 65 70 493 135 108 232 152 104 134 856 498 405 419 152 23 265 332 423 180 491 63 418 219 46 263 257 105 341 170 75 318 453 595 40 175 71 387 283 82 58 59 500 149 267 232 219 277 19 116 0 11 237 64 116 236 549 160 54 547 261 243 277 165 12 320 111 196 275 87 85 197 83 102 156 321 22 145 132 38 352 178 409 280 217 274 140 353 528 110 278 303 459 391 184 266 329 55 698 165 186 118 381 146 206 29 257 153 84 198 1839 150 182 52 338 190 18 149 310 251 217 30 198 32 118 98 310 397 155 203 200 194 117 185 30 54 142 216 418 307 24 310 404 261 80 86 75 110 107 267 270 210 75 145 72 17 79 146 426 254 173 297 0 266 293 146 127 15 350 792 493 238 123 210 143 211 231 401 70 142 356 154 467 53 190 145 53 249 853 435 197 236 79 218 507 193 37 354 137 162 30 239 118 564 275 121 253 272 250 20 277 14 167 136 256 458 143 149 177 162 35 13 64 201 104 168 192 199 350 685 54 302 286 244 24 337 239 332 277 180 79 131 169 105 488 264 274 214 278 59 136 46 42 16 94 267 496 588 255 297 248 339 100 228 27 119 137 18 130 118 232 213 701 153 185 276 129 123 110 271 84 569 175 70 130 71 69 37 334 114 11 371 284 42 101 82 308 262 561 147 349 94 213 117 213 383 44 497 95 25 15 310 439 202 94 32 317 393 337 159 467 35 238 143 86 85 120 347 1105 163 193 304 151 134 141 88 1025 80 82 30 140 112 165 87 123 228 102 55 87 73 180 169 37 85 193 460 98 137 241 214 338 149 142 511 327 81 345 73 43 70 0 414 85 226 75 96 112 170 534 77 223 400 137 510 324 32 115 174 153 89 196 149 237 225 389 131 139 154 202 113 45 140 205 332 128 299 193 357 66 364 450 118 171 200 126 154 143 124 68 334 83 85 81 68 253 210 53 109 186 113 286 166 1445 ]
@@@ Loss per-class: [ 0.422161 0.709497 0.775899 0.824386 1.22875 0.786278 1.04639 1.03301 0.912736 0.569588 0.323077 1.12018 0.422555 0.823467 1.25674 1.02655 0.875982 1.04808 0.811271 0.613096 0.410465 0.774448 0.271463 0.760254 0.861183 1.3411 0.583759 0.539177 0.808915 0.585897 1.8232 1.02719 0.592916 0.887321 0.499785 0.914757 0.524492 0.185971 0.633984 1.14001 0.854418 0.884045 1.56604 1.09623 0.293891 0.44126 0.862299 1.04283 0.561975 0.760457 0.60578 0.281599 2.18741 0.559796 1.16357 0.467968 0.69563 0.474712 1.23391 1.31219 1.19388 0.948577 1.27424 0.470543 0.400869 0.683513 1.47192 0.703128 0.7522 0.686676 0.601701 0.824062 0.752311 1.94909 1.37645 1.09786 0.565833 0.250791 0.548511 0.45127 1.57884 1.02013 0.843399 1.41086 0.70405 1.08188 0.575817 0.695705 1.11357 1.46912 0.642779 0.992219 0.59861 0.723776 1.42547 0.413031 0.930987 0.96177 1.62219 0.786609 1.59638 0.924277 0.468133 0.713584 0.736169 0.506377 1.23998 0.983903 0.741399 0.372737 0.614135 1.78323 0.78016 0.709612 0.400109 1.42317 0.57728 1.05806 0.960787 1.90477 0.667258 1.08021 0.651758 1.9366 0.633362 2.00926 1.13894 0.664253 1.12751 0.855438 1.28691 0.786492 0.880779 0.619203 0.810225 1.0031 1.69662 0.744964 1.2125 1.06218 0.820829 0.985379 0.867197 1.66383 0.70919 1.59557 0.61868 1.13475 1.19777 0.859861 0.891393 1.25646 0.73557 1.2053 1.03865 0.688596 0.757841 0.766128 0.893292 0.481932 1.20466 0.627179 1.64064 2.30175 0.918201 0.804462 1.10078 1.57744 0.548955 0.966456 0.610075 0.987977 1.69813 0.591657 0.936506 0.749051 1.00803 1.27457 0.688282 0.521228 0.895616 0.919895 1.10131 1.363 1.46203 1.58462 0.676314 0.754635 0.823232 0.992012 0 0.620558 1.44446 0.862899 1.80502 1.03952 0.902552 0.507702 0.755196 1.08562 0.991325 1.09508 0.657071 0.527434 0.799415 0.497311 0.818725 0.769876 0.657302 1.84634 0.890193 0.772299 1.26197 1.32195 1.3586 1.93564 1.69297 0.935734 0.886454 0.735476 0.557785 0.831127 1.3882 0.938538 1.50831 1.61464 0.729059 1.0752 0.799487 2.02171 0.458551 1.37209 0.936361 1.14181 0.825499 1.05893 1.40366 0.841879 0.398365 0.766202 0.62834 1.09445 0.768189 0.452315 1.94012 1.4926 1.37431 1.27806 0.576842 0.55816 0.960895 0.647206 0.551624 0.548088 0.980936 1.2098 0.611922 0.533178 0.933337 1.50937 1.3 0.607801 0.57226 3.35949 0.75246 0.400973 0.587408 1.01636 0.589035 1.32222 2.11896 0.977831 0.843314 0.491182 2.60325 0.662799 0.84884 1.76133 0.830744 1.16764 0.748994 1.22013 0.613192 0.920348 1.48501 0.734146 0.822573 0.929847 0.620809 0.68695 0.852058 1.47282 1.28033 1.62473 1.38744 0.481081 0.585631 1.38348 1.22734 0.956113 1.10563 2.47337 1.84414 1.01434 0.859075 1.07225 1.33361 0.728759 0.505376 1.14552 0.533993 1.63216 0.726965 0.557899 0.667085 0.54016 1.44509 2.11728 0.688922 0.853811 0.656921 0.954252 0.985436 1.19836 0.536752 1.75698 1.70375 0.95049 1.31166 2.04571 1.19011 0.676225 0.897507 1.02519 0.72751 0.670724 0.587375 1.71762 0.893458 0.950988 0.620064 0.88006 0.738309 1.07501 0.910486 0.473116 1.46851 1.13052 1.07811 1.2631 0.890878 1.54849 1.09348 0.926374 1.47886 0.69829 0.592174 0.843777 0.954737 0.73118 1.44943 1.35077 1.30025 0.824336 0.871988 0.380562 1.70144 1.27232 1.71781 0.747191 1.576 0.776702 0.773518 0.526847 1.13598 1.04645 0.948609 1.35101 1.08736 1.11979 0.550681 1.87592 0.904485 1.01088 0.63401 0.484657 0.897118 1.18239 0.892657 1.14484 1.91143 0.897959 1.1974 0.534524 0.825188 1.04548 0.584687 0.448422 0.571108 2.22854 0.988255 0.704184 0.873485 0.65134 1.11119 1.32231 2.23692 1.05462 0.59012 1.03597 1.22332 1.04427 0.894624 0.761177 0.508539 0.592262 0.857438 1.4778 1.24993 1.07561 0.672261 0.941758 0.464443 1.21415 0.37694 1.75345 1.09951 1.08091 1.16291 1.77918 0.613873 0.866631 1.24621 0.708028 0.659452 1.42316 0.802026 1.44252 0.582189 1.01972 0.53993 0.755387 1.28808 1.32051 1.3055 1.31009 0.851885 1.66856 1.43125 0.494657 0.860036 0.580808 1.09507 0.993545 1.2251 2.64918 1.22141 1.1691 1.75861 0.409705 1.15205 0.660551 0.805104 0.547761 0.955589 1.59445 0.90708 0.322015 1.22727 1.17954 0.814141 0.541543 0.481027 1.22787 0.783584 0.975839 0.628928 1.36239 1.0873 1.2033 1.3571 0.719589 1.63002 1.03851 0.986831 0.982176 0.887569 1.77785 1.11009 1.32737 1.02757 1.19768 1.28131 1.97505 1.50052 0.838872 0.556247 0.668658 0.96126 0.51137 1.12535 1.59995 0.581071 0.809875 0.553654 1.68531 0.810252 0.691923 1.33939 0.591779 0.796054 1.13226 0.883572 0.613032 1.47151 0.74958 0.952063 1.16107 0.992789 1.04093 1.00848 1.44134 1.65316 1.19569 0.493662 0.888021 0.921782 1.65074 0.936746 1.15797 0.861964 0.517139 1.13818 0.536575 0.511148 1.71893 0.727302 0.776834 1.86814 1.3074 0.662152 1.19455 1.738 1.72861 1.78045 0.923647 0.780764 0.731444 0.795506 1.12568 0.788197 0.819057 2.11695 0.829625 1.08631 1.21325 1.26066 0.808365 1.05885 0.824434 1.65429 0.638816 0.887259 0.960983 1.49136 1.39191 0.956304 2.02796 0.890569 0.684641 0.770969 0.830276 0.919281 2.18697 1.01098 1.1578 0.856551 1.14267 1.16792 1.27232 0.956292 2.68682 0.985718 1.07407 1.90562 0.467261 0.736271 1.20605 1.19136 0.790395 0.63939 1.55535 0.94229 1.28137 0.687447 1.47666 1.23811 1.42706 1.84535 3.09285 0.85438 1.31799 1.49583 0.594591 0.881683 0.945628 0.62459 1.36401 0.752657 0.789836 0.950673 1.2078 1.14227 0.705036 0.929895 1.73428 0.375058 0.642969 3.3871 0.646008 1.0206 1.13484 0.76791 1.07296 1.97683 0.851367 1.92067 0.50614 1.13525 1.11661 2.41379 0.895938 0.750865 1.33147 1.352 1.7658 1.27723 0.703914 0.903322 0.970664 3.35572 1.41383 2.21049 0.96145 1.00491 0.754165 0.830197 1.17234 1.88914 1.61119 1.42871 0.688412 0.772859 1.06006 1.10912 1.26245 1.22585 0.871536 0.382336 0.987497 0.768544 1.88844 2.77759 1.43688 1.23932 0.668306 2.23203 0.941766 0.850539 0.798959 0.871308 1.20617 1.0817 0.420171 1.86083 1.10651 1.00302 0.409718 0.953764 0.715894 0.99228 1.10646 0.619494 0.911939 0.589077 0.906522 0.737882 1.50073 1.01242 1.31563 0.930374 1.15289 2.15693 0.773403 0.8647 0.877696 1.46868 2.89957 1.61461 0.995003 1.99959 1.37705 0.913305 0.826751 1.68558 0.752808 2.7692 1.14211 1.04392 0.694916 1.22581 0.489385 1.16058 0.857848 0.494437 0.624175 1.28561 1.06031 1.37413 0.843961 0.774461 1.21098 1.19568 0.63286 0.892804 0.842842 0.446247 0.919941 1.02376 1.00168 1.18155 0.937866 1.31378 0.821146 1.01091 1.3969 0.857234 0.762887 0 0.608757 1.19411 1.03616 0.678535 2.42739 0.829164 0.825315 0.818862 1.51138 0.815287 0.841912 1.90112 1.53141 1.92221 0.839802 0.865292 0.932619 0.922087 1.23881 0.538478 1.14338 1.3821 1.29546 0.612083 0.946227 1.01944 1.41042 2.35353 0.542389 1.09974 1.18399 0.721328 0.659385 0.955838 0.890488 1.39584 0.865277 1.37231 1.25345 0.539839 1.81699 0.641809 1.02562 1.1582 0.8496 0.909592 1.13808 1.26579 0.871162 0.859068 1.34084 1.09682 1.11414 0.620733 1.03147 1.2208 1.00879 1.74236 1.19758 0.965955 0.684447 0.612905 1.00349 1.18402 0.958557 1.36048 0.846189 1.08696 1.50355 0.679014 1.79125 1.30081 1.43596 1.20743 1.09477 0.571262 1.37108 0.724103 5.92089 8.51911 1.00488 1.10775 1.32427 0.816603 0.612242 0.759719 0.957363 1.44308 2.02928 0.660234 0.751 0.644934 1.3308 1.55446 1.10682 1.59105 2.14331 1.5605 0.651395 1.11377 0.819824 0.972586 0.9907 0.420134 1.29019 0.916705 0.914521 0.603976 1.06691 1.31369 0.779963 2.1176 0.693759 1.17514 0.890534 0.662561 0.908189 5.07334 0.692602 1.1587 0.825327 1.08755 1.50757 0.926574 1.07057 0.711915 1.66787 0.421396 0.94019 0.515291 0.844552 1.18028 2.05964 0.855948 1.37804 1.1045 0.613992 1.17627 0 1.22961 1.05638 0.80066 0.644944 0.755719 0.92139 0.882439 0.747988 1.39004 1.81051 0.832418 1.48424 1.33802 1.43587 1.50337 2.06583 1.20209 0.542139 1.48379 1.48944 1.47057 1.34399 1.53794 1.00316 2.22137 0.868772 1.52823 1.96865 2.70682 0.766255 1.12115 1.26137 0 0.892217 2.18024 1.18879 0.902162 0.613522 0.664021 1.46532 1.00419 1.6121 0.839172 1.25808 1.21568 0.867399 0.816513 0.643998 1.28211 0.912682 0.901447 1.7784 1.56073 1.22834 1.02361 1.7243 1.10912 0.846109 1.15387 0.988286 1.52612 0.723867 1.70672 1.21163 1.65076 0.365194 0.469358 0.599452 0.867738 1.10709 0.959763 1.02304 0.515107 0.877335 1.08078 1.08952 1.21684 0.974186 1.17863 2.38005 1.15188 0.743281 1.63317 0.72611 1.03715 1.18649 1.08498 1.07721 1.12669 2.53783 1.05912 1.18531 1.25388 1.09294 1.96644 1.9326 1.11846 1.55571 0.522187 0.770162 0.708314 0.884076 0.929766 0.674371 1.27208 1.21871 1.35693 1.22534 0.569414 1.16983 0.932523 1.43973 0.944591 1.09225 0.852425 0.691136 1.46394 1.4769 1.4158 1.56584 0.613731 0.688037 1.22419 0.736047 1.0262 1.01709 1.79455 2.57212 1.9372 1.63823 1.11733 1.84518 0.551418 0.728791 0.679656 1.47118 0.921724 1.31394 1.64014 0.908734 0.768324 0.812377 0.880185 1.15224 0.980633 1.19855 0.815913 1.40442 0.736625 1.48737 0.750314 1.82985 0.680794 0.894714 0.785963 1.72442 1.60285 1.22845 1.24287 1.70015 0.750083 1.75025 0.542556 0.993779 0.826836 0.774598 1.30266 0.3921 1.32753 1.03798 0.995287 1.66087 0.672679 0.674788 1.58544 0.999965 0.667443 1.12321 1.2091 1.2446 0.732207 0.91134 0.753237 1.10177 0.806545 1.08061 1.34467 0.74485 1.00347 0.890659 1.13806 1.1745 1.65693 1.21037 1.9359 0.688686 1.0896 1.35295 1.52738 1.58896 2.13156 0.490816 1.43408 1.56975 1.06073 1.18452 1.02177 0.951415 1.64342 0.477748 1.13199 0.853211 3.2803 2.90781 1.06236 0.787575 1.03916 1.12199 1.03249 1.22085 0.784689 0.921761 2.15389 1.60409 1.07221 0.999493 1.31968 1.0936 1.19726 1.13995 1.78318 2.10809 1.15042 1.3763 2.2399 2.04175 1.0532 1.61124 1.78385 0.622226 1.08183 0.961636 1.23714 0.66321 1.23965 0.81911 0.579215 1.60719 0.730876 0.632308 0.626999 1.26675 0.770463 0.730752 0.75009 1.11246 1.02582 1.32837 1.24451 1.33156 0.641493 0.670348 0.729239 0.471346 1.16847 1.05823 1.31517 1.8154 0.754441 1.08439 0.947235 0.991144 0.843649 1.26394 1.07536 1.36 1.21909 1.61819 1.12575 0.715146 0.985402 2.13007 0.843542 0 2.08863 0.652332 1.636 0.958148 0.903813 0.923676 1.47289 1.39265 0.996805 1.72408 0.546038 1.00213 0.94227 0.603252 0.874898 2.77801 1.14042 0.849675 0.908738 1.33517 1.96945 1.15216 1.46838 1.56886 1.03065 1.76872 1.53508 1.50373 1.26612 1.31823 1.18314 0.887065 0.606635 0.579065 1.15014 1.33034 0.808993 0.875244 1.86174 0.68103 0.655163 0.740161 0.704524 0.520282 1.25597 1.07462 0.740866 0.917371 1.54497 1.11603 1.02589 1.1339 1.77318 0.828667 1.21578 0.818008 1.25402 1.30515 0.911074 0.745855 1.00587 0.621393 1.21852 0.528975 1.07435 1.12768 1.09027 0.918432 1.38372 0.925513 1.48435 1.67758 3.05332 1.18154 1.20045 0.90952 1.01227 0.664613 0.51778 1.08872 0.730089 1.30538 0.661743 0.652533 1.16254 0.799734 1.11184 0.883597 1.39939 1.76725 1.19806 0.865121 0.70856 0.889762 2.50254 2.94284 0.914787 1.04772 0.448588 1.10148 1.62446 1.49265 1.73557 1.41354 0.466586 1.11561 1.24658 0.514277 1.34202 1.38798 0.569412 0 1.20727 0.844769 0.92306 2.52395 1.8454 0.876222 0.753965 1.05077 0.856924 1.3838 1.47367 0.89811 0.903798 1.09829 1.03002 1.20072 0.575412 0.463403 1.65512 0.655978 1.08644 1.18541 1.47236 0.444625 0.993339 0.610102 1.13626 2.75993 1.09849 0.742381 1.04934 1.22519 0.99517 1.33961 1.08768 1.50244 0.841384 1.55216 0.935655 1.39042 1.00681 0.639137 1.77293 1.01279 1.60385 0.709813 1.50263 0.750294 1.38579 1.04402 1.80133 1.27995 0.657269 1.0945 1.01416 1.48329 1.24981 1.03862 1.40009 1.42687 0.594362 1.39522 1.58813 1.11315 0.773992 1.04828 0.941249 1.25731 0.838832 1.60343 1.78235 1.47477 0.988986 0.898304 1.25691 1.40386 0.993698 1.54889 1.99897 0.80984 1.26213 0.743076 0.735072 0.975205 1.08009 1.2087 1.32849 1.66787 1.04803 1.84334 0.638413 1.09976 1.20608 0.791687 0.616195 1.56078 1.08383 1.14892 0.79553 1.07187 1.69958 1.32109 1.18284 0.872784 0.994587 1.42444 1.42671 1.303 0.578421 0.984266 0.857859 1.11671 1.11283 0.77168 1.09959 1.15649 1.3986 1.1629 0.725317 1.04654 0.973266 2.14495 0.876447 0.957742 1.43752 1.89315 0.895199 2.07382 0.954648 1.89365 1.70028 0.967459 0.710895 0.978373 2.02171 0.970524 0.997278 0.922792 0.97063 0.399375 2.76838 1.30114 0.422638 2.60153 0.798836 1.564 0.600183 2.28259 0.617769 0.891915 0.714307 1.19043 2.19173 1.76086 0.885676 1.33887 0.802293 1.37756 1.10357 0.980495 1.50458 1.05844 2.42874 0.852717 1.19842 0.682848 1.65172 0.985077 0.977475 1.13598 0.700618 0.893992 0.89863 0.597345 1.52897 1.80333 0.699606 0.919947 1.36809 1.37144 1.06948 0.750049 1.2582 1.38087 2.10343 1.19032 1.32115 1.01669 1.78763 0.479812 1.21784 1.26815 0.691236 1.22452 0.87908 1.11298 1.07712 1.04135 1.00383 0.82019 0.739689 0.809226 1.26887 1.01648 1.00455 1.02989 1.33161 0 1.06392 1.17507 0.973914 1.7932 1.04046 1.96148 1.92129 0.781092 1.58176 0.903768 1.1962 1.27012 0.481546 0.795417 1.04114 0.795121 1.28251 0.520246 1.35839 1.45203 1.36208 1.22663 0.916727 0.830579 1.99594 1.20666 0.812029 1.61642 0.942033 1.81237 1.22364 1.06564 1.00874 0.934695 0.668931 1.36983 0.814766 1.46412 0.696955 0.826754 1.343 0.616482 1.35968 1.05921 1.08821 0.750876 1.23511 0.841356 0.485765 2.10836 0.941479 1.12197 0.896421 1.05445 1.39644 1.88926 0.936148 2.13812 1.7168 0.740021 1.06036 0.250626 ]
@@@ Frame-accuracy per-class: [ 83.9219 83.6364 78.9318 83.871 60.7595 74.0331 70.1195 68.9655 71.028 85.4134 92.1899 65.4434 87.8856 82.0084 61.246 72.0867 70.4715 70.922 78.553 83.0553 88.4793 81.388 92.4214 79.2793 76.2808 60.1307 83.1031 82.149 77.551 85.9951 38.5093 59.542 83.5821 74.7253 86.5106 76.4331 85.8188 95.3229 81.8851 65.1429 74.6988 74.958 52.6077 64.8649 91.5847 87.6972 75.2351 73.5632 81.004 76.8696 83.5655 90.9289 32.2581 83.871 61.0442 88.2779 77.1121 86.9421 66.6667 63.807 69.1589 57.1838 66.2069 85.5895 90.8858 83.7209 63.8298 81.764 71.9963 78.6704 80.1865 73.7864 79.1897 48.3412 58.4615 66.838 81.9277 91.8953 82.0874 87.8187 55.0898 73.0159 72.9223 49.3913 80.597 64.7482 81.1483 80.5492 68.3938 59.8575 81.8301 65.0124 84.7571 78.2002 71.5789 88.6486 75.5365 70.7646 49.3506 79.3037 47.1795 79.3734 87.0317 76.6839 79.3388 84.9817 69.7095 71.161 79.5107 89.7454 81.2325 40.8602 79.7927 75.6757 92.7152 56.5854 84.6847 72.7273 85.7143 48.6486 80.331 63.9594 82.2086 37.5691 81.5864 44.8598 61.6984 83.2918 69.7248 71.6418 68.0162 75.5963 74.0426 90.3226 79.5181 79.0698 55.814 78.6885 67.7686 69.5652 74.9367 67.9612 82.9016 54.5455 80.1782 36.5039 83.5509 57.4257 59.5078 74.7664 73.743 64.8968 75.9494 70.3072 67.2986 80.8511 79.056 83.0189 73.9255 89.117 62.8272 81.5884 53.4351 21.8182 72.8205 77.2636 68.3386 63.4361 85.0082 74.0525 79.868 77.9026 46.4455 85.1613 72.605 78.392 69.1706 66.6667 86.5306 84.6018 77.8711 72.9908 65.9933 61.5156 55.0459 50.8393 81.592 78.0045 74.9064 73.3728 0 84.0404 63.1579 78.2609 48.7973 70.1031 68.9956 90.5312 80.3828 66.9276 57.732 65.4655 83.2757 84.0391 73.93 85.1312 79.7936 83.376 85.1752 38.488 69.3032 69.1892 58.5774 57.8616 57.7181 51.6129 54.1063 76.2044 73.5751 77.7358 83.5821 72.9252 63.354 67.3171 70.2703 69.7436 73.3945 70.2065 83.1683 40 86.6511 65.9898 74.0331 68.2731 75.1286 69.9507 57.4713 73.7201 89.2236 77.0563 83.3652 72.381 75.8621 87.9795 50.4854 44.4444 68.5714 63.8037 81.9188 84.3658 72.5275 78.5425 85.1259 85.3333 75.8893 64.4156 83.2695 81.0811 74.2857 48.2315 57.561 85.5491 83.959 0 78.1065 89.6422 82.9851 72.8889 83.731 57.5916 52.459 74.0426 75.6871 86.8486 30.2839 78.5965 86.4865 53.3137 74.3802 65.2406 79.2453 80 83.558 71.7949 57.0342 81.6 70.0461 78.3562 84.3931 81.1839 77.9221 57.9387 62.6118 50.2674 63.0588 89.4281 80.8989 58.3072 61.9448 68.2464 61.9423 19.0476 55.1724 70.5882 77.5221 67.426 62.2601 80.8247 85.4093 73.8462 85.342 57.7617 72.9659 82.0809 86.7925 84.2767 62.9834 39.7004 80.2768 72.7273 79.7153 69.3069 68.4932 65.7952 85.9259 45.22 44.6701 68.0851 65.0602 51.3274 66.1654 78.0627 72.5389 75.6757 73.8854 79.0015 86.0104 53.3958 74.6228 71.1111 84.1782 77.3006 74.6137 62.0321 74.221 85.6611 54.6939 74.6269 68.7285 61.0853 77.7911 60.0858 68.5714 71.9603 47.3469 81.4815 96.7742 76.1394 73.5931 79.7677 57.6819 67.8261 62.0061 78.0488 83.4783 90.0616 44.4444 55.2301 63.5294 80.5687 54.0416 77.8182 73.4007 86.0421 61.1898 65.5319 74.3494 60.4317 67.7165 65.8065 82.9474 43.6681 69.4037 68.4892 83.5821 84.4444 73.6597 59.2593 70.7182 68.3938 51.4286 70.4663 67.9045 84.1424 76.7624 68.7898 85.6512 88.6414 83.6237 37.1681 72.1805 82.9268 78.1116 83.6518 57.1429 62.1849 44.4444 63.4146 81.9017 68.4444 64.0394 63.5659 70.4992 77.2334 85.4881 87.0293 73.724 69.3878 67.3575 64.995 80.8933 71.8204 88.3882 65.1026 91.5423 49.3274 54.3689 71.2446 67.319 47.482 80.2589 72.0812 54.6256 82.9268 80.8889 52.5253 77.0764 58.0101 80.826 67.2646 85.8667 74.7875 56.8421 66.6667 59.4315 60.9971 74.6667 56.4103 61.5385 83.1234 76.8362 87.6404 68.0272 72.8358 64.6465 39.2157 67.1815 63.6816 55.0725 87.5399 81.6327 82.4121 75.9003 91.7431 71.73 48.4211 76.1905 91.9605 65.1297 70.5882 66.6667 85.1064 87.35 67.1679 80.1636 68.6891 81.4545 58.6151 59.4164 68.6869 55.4455 82.243 54.1176 72.9614 78.2875 71.4932 69.3572 50.5263 69.3333 60.6061 64.9573 65.1163 71.1111 34.3612 52.8053 75.1678 84.7896 85.5491 72.5424 85.674 71.3924 59.887 81.5864 78.2007 88.6076 48.4076 76.8959 77.3234 71.4859 80.9195 81.0409 76.1905 71.1246 81.2121 49.711 75.4286 82.3529 65.9134 70.8861 73.6196 69.6747 45.0704 51.2821 74.5098 87.5146 72.1311 77.0186 56.1983 75.0685 62.7451 75.9019 89.0511 65.3659 86.8687 88.4422 57.3854 80.2162 80.8743 52.8139 61.6216 80.354 54.9254 40 37.037 46.6819 75.817 77.0428 76.9386 73.8255 69.9301 75.1678 77.8947 37.3984 74.5299 69.9387 63.6542 65.4691 77.8947 74.1259 75.3541 47.4506 82.879 74.0741 74.6204 57.6271 48.8889 77.8947 54.5455 74.5098 81.1146 80.4178 79.8122 70.4 49.7653 73.6842 66.8305 76.3485 62.6917 56.0993 81.4815 75.817 42.2764 71.4801 70.2087 42.5806 89.3503 81.1545 72.8324 69.0058 79.4805 82.4034 58.6387 71.7633 66.0465 77.4584 53.6965 65.4275 60.066 45.6853 24.2424 74.7731 65.7952 61.0687 87.4525 71.5128 65.1163 84.3871 57.5342 81.1594 79.0451 65.8436 62.9571 61.9469 86.0215 67.9887 56.5657 92.1101 81.5194 9.52381 87.8505 71.0963 62.5592 78.1043 67.9887 44.4444 81.4159 45.4212 86.6426 70.9677 67.8133 45.9259 79.0123 80.9449 60.3922 60.6516 49.2239 63.6872 82.5083 74.4268 73.2095 26.2774 72.3404 39.1185 69.8499 71.8644 73.7338 79.5866 63.9053 39.2157 50.9091 55.2381 83.7209 80.8843 63.1579 69.2607 78.4314 66.6667 70.255 91.354 73.3068 78.9916 46.2745 32.2581 63.9053 67.3123 84.7118 38.7097 70.2955 79.0514 79.8762 68.7023 65.9004 68.1458 86.836 57.1429 70.4225 76.1905 89.6237 71.6981 81.1715 80.597 71.5789 84.0237 70.4478 83.6109 74.4186 78.1065 68.0851 68.323 56.6154 69.2168 67.9518 45.0262 77.9026 74.9082 74.0369 56.2874 35.8209 41.4918 72.6503 18.1818 59.5349 78.0488 75.441 46.4 78.1609 23.5294 66.6667 66.6667 79.3363 63.662 86.2524 65.7744 74.0157 92.6829 81.5348 57.508 68.5315 60.746 71.0414 79.6421 64.3304 66.6667 80 68.6567 76.7347 85.7428 73.7247 77.551 72.2348 64.1221 72 60.788 79.1738 73.1107 56.7686 75.6757 79.3879 0 84.0506 64.7359 65.0307 80.1751 13.3333 75.502 73.4694 79.3177 64.2202 80 73.716 26.8657 67.7596 45.3461 78.1726 74.2857 72.3926 76.1707 63.3053 83.1472 68.7976 63.0137 61.5385 82.4437 73.6842 65.8407 53.1025 31.9635 84.5481 72.5333 61.9718 80.7547 86.6511 74.5763 73.2892 60.7764 77.1242 61.3861 77.4194 86.4654 47.7366 81.3559 73.9394 66.9246 77.6413 74.2857 67.6259 56.1873 79.2271 72.8016 68.3761 74.4526 68.3871 84.898 75.7047 67.013 70.4762 43.5233 68.2927 77.551 80.2057 84.7244 66.1922 68.1081 67.8304 59.5918 81.0811 62.069 53.9924 81.4901 51.3274 50.8108 52.1246 66.1818 59.3103 90.5263 65.8228 79.2453 0 0 76.6169 74.4186 61.6915 78.8274 81.4815 77.9134 72.4324 55.814 47.6987 82.6004 80.2676 82.623 59.5556 53.9924 68.8525 52.6316 40.7643 56.0669 76.8719 68.7392 77.5599 71.3755 67.6923 91.4874 55.3846 77.6812 76.7213 86.8069 60.9929 64.6217 78.7879 35.4286 77.095 65.4124 74.2049 79.0805 73.5043 0 78.1683 67.4847 76.3359 67.148 60.0707 75.8621 72.9659 84.6847 56.4551 86.7807 73.3753 85.0492 78.1415 61.9503 45.283 75.0337 55.1724 64.3366 86.0884 65.2742 0 52.5714 72.7651 78.2609 76.2264 80.5195 71.7949 70.2194 78.0693 67.4487 47.3118 74.5763 56.9492 63.837 69.1358 57.2358 24 63.6132 87.0293 49.8886 59.4982 50.4298 59.6491 52.4444 69.7856 42.4742 69.2015 64.5161 45.9574 31.6742 77.6735 69.3795 64.4068 0 78.5425 43.2277 65.098 77.4194 80.8803 82.0108 56.5517 78.3505 60.7595 75.8465 68.6567 58.3765 75.7709 77.643 80.7477 54.0541 76.0784 73.5395 24 55.5102 67.2811 75.226 41.0959 69.8305 75.0605 64.6526 67.7966 58.1818 75.3153 42.4242 65.8635 60.5714 89.6241 93.8182 82.7586 78.2918 70.1031 72.4638 71.0098 86.4865 76.7372 69.2483 65.4378 70.255 75.5337 66.383 23.5294 65.7224 79.0021 45.5446 80.5031 72.7273 69.1643 73.7662 64.5477 65.2015 34.6667 63.3229 67.7966 57.9592 68.0272 38.61 42.6799 69.6907 57.1429 84.7018 78.0247 80.2831 73.5497 73.8589 83.871 61.9289 68.9655 64 60.2817 87.4743 66.5786 71.04 58.7156 77.3333 71.9577 73.4982 80.1362 61.2022 58.7127 57.1429 57.5207 84.8297 79.7583 64.135 77.0642 70.2259 75.0958 41.5686 29.4479 46.5455 62.8571 74.0157 43.4043 87.4279 76.3407 80.2218 60.8955 75.7282 61.9503 52.1212 73.8197 78.9272 75.8017 73.9726 67.5768 76.5714 68.6347 80 57.3727 80.9628 58.0645 79.2793 36.7816 79.7699 75.5218 78.0488 51.7293 54.8031 66.6667 58.7952 43.8554 76.7296 53.6585 86.0927 75.2166 76.6859 80.64 64.4836 90.973 61.0879 71.1497 66.9528 36.036 80.7786 80.9869 50.9091 72.0497 81.6479 67.9842 68.0272 68.2635 77.8468 75.6501 80 67.2811 71.8447 68.0237 65.4434 79.1277 72.1805 76.3533 64.4809 72.0497 44.5672 65.3386 44.2105 79.2703 70.9382 63.2035 53.3762 50.8557 46.2287 86.7692 60.9881 50.5338 70.8661 64.5161 73.3591 70.5394 52.1257 88.2297 63.7681 76.9953 17.5439 26.087 71.0801 79.8479 62.7615 63.0072 69.7068 65.9176 75.493 72.1951 44.4444 46.9136 70.9677 73.43 63.0037 73.2334 61.0687 72.6257 45.8453 40 63.9769 61.0442 27.4809 34.0426 70.3141 50.9225 45.1613 82.1505 71.4754 78.4689 64.684 79.9766 63.5908 80.8878 83.9094 43.9344 89.3617 83.6158 84.2105 64.2267 82.5485 81.1801 86.6142 66.9056 73.3485 55.914 63.3776 62.9126 81.5166 80.8199 82.6979 83.4437 68.4458 71.2238 57.2628 51.8519 76.3533 62.9371 70.7097 71.6049 80 71.7949 67.2269 60.5395 59.5318 54.9533 68.3871 78.8155 70.2703 51.2821 77.2532 0 34.7826 82.9474 58.9147 70.3863 78.2241 75.1592 53.5826 62.3853 72.1461 47.8011 83.3676 68.4685 80.9668 80 74.883 25.1121 65.1399 74.7731 81.1429 67.8363 38.481 64.6707 59.5122 50.4792 71.8507 48.8889 46.0481 64.1509 70.1299 54.1844 71.7087 74.2369 82.7094 84.1379 64.4809 65.4804 80.9052 75.8751 58.8235 78.6355 84.0198 84.0044 79.4381 87.8049 71.6698 71.0167 77.4775 70.723 50.7553 68.0965 75.1055 67.8899 48.4642 71.1864 64.4068 79.6117 61.8893 59.1716 73.5516 75.2922 75.7475 87.1233 64.7619 88.6263 71.916 81.0811 65.5518 75.6844 60.0398 71.2644 59.0164 58.9421 9.23077 64.135 72.0812 75.0403 75.7233 84.8875 87.4693 67.3317 82.2622 60.4255 82.4798 78.6885 73.3945 79.2982 68.8222 79.3309 61.4634 53.0612 61.1916 80.3461 80.3059 81.9876 36.9942 17.2185 72.3982 70.6977 86.729 69.8706 52.7316 46.3576 52.2337 63.4483 97.1429 66.6667 68.2594 84.8769 58.9391 58.2133 84.7059 0 69.7936 78.3646 75.7679 32.9412 58.0645 75.0357 78.8644 71.9352 80.9224 57.4899 58.9074 76.6551 78.487 71.2743 69.7385 68.0851 87.0175 87.798 53.0744 79.1444 72.8972 68.7664 63.9175 87.8505 68.9379 84.9443 68.6567 24.8101 71.4588 83.0189 71.3959 65.4187 72.3514 66.6667 66.8547 53.0909 80 49.1803 73.4864 60.7595 71.9221 82.7586 47.7366 69.428 52.844 79.0419 58.5366 75.6757 62.069 72.2388 63.0037 61.2086 82.2246 68.2927 72.2408 64.2254 62.7692 76.0563 44.4444 62.0155 85.8561 62.201 53.4125 65.974 80.2005 64.7646 73.2312 47.7064 76.0331 53.4031 49.4888 53.0612 72.5926 77.6618 63.4586 57.6577 75.3463 62.8931 51.711 77.8761 70.1422 80.6551 78.6389 72.8597 73.1935 63.1957 52.1008 41.0256 73.1183 40 90.9091 68.7831 67.2897 78.3484 81.9031 56.7515 71.2605 71.6298 79.5287 68.6567 58.6433 58.1818 68.6192 68.3636 75.6757 63.6015 59.0717 68.3871 85.7143 72.8439 79.4788 65.2291 70.5244 81.8533 70.4453 64.2534 62.6151 61.5385 81.475 70.0855 70.922 39.8467 75.5245 73.3813 58.6667 46.3378 72.4891 34.7826 72.14 47.1002 47.0588 69.9507 80 70.0162 43.0476 71.4159 74.5763 72.6753 75.1323 89.9297 34.0426 58.548 87.8748 38.2022 80 49.2147 86.2745 19.3548 81.1594 72.5825 80.4938 64.5503 30.7692 46.9291 73.6976 61.3333 73.3542 58.6096 61.9718 76.3103 55.7491 69.3642 29.2398 77.1784 67.6259 79.2402 48.9297 76.4858 72.578 66.0066 80.2974 72.0848 73.4463 83.6665 64.5963 53.3333 85.2459 74.0214 56 61.6314 77.7143 82.5911 69.1466 65.3659 43.2432 64 65.3061 69.2521 50.1475 88 69.0058 69.2506 78.8274 70.0508 77.8182 72.8778 73.1935 72.3781 68.8963 75.0877 79.5699 77.2519 65.0307 71.4906 80.2721 71.2644 59.5745 0 70.4463 66.6667 75.0552 46.3576 75.6477 37.3333 45.1613 73.7138 60.6452 76.9575 68.4145 61.0909 87.1694 77.3498 83.0769 81.3853 68.7679 83.3876 63.6872 60.5598 60.2007 69.4737 75.388 80.8729 41.8251 66.6667 80.9061 52.3457 75.7709 39.5604 68.3274 70.5596 69.4737 70.0389 85.1419 56.8475 73.2867 57.1429 83.9506 75.0277 54.0084 84.5481 61.8454 70.3557 72.4919 73.8676 68.2731 74.4526 88.7892 44.3114 74.8538 65.0307 75.9124 70.6114 54.1568 44.8598 71.2329 39.1421 44.9339 77.1379 78.0781 94.2235 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 0.906896 (Xent), [AvgXent: 0.906896, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 74.0441% <<

