nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.002 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter05_learnrate0.004_tr0.9069_cv2.0296 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter06 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975016
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.86424, max 7.06273, mean -0.000964877, stddev 0.993005, skewness 0.0133901, kurtosis 2.03207 ) 
[1] output of <AffineTransform> ( min -29.4337, max 22.1275, mean -3.30921, stddev 4.0532, skewness 0.12397, kurtosis 1.36538 ) 
[2] output of <Sigmoid> ( min 1.6486e-13, max 1, mean 0.207411, stddev 0.315016, skewness 1.48722, kurtosis 0.74447 ) 
[3] output of <AffineTransform> ( min -29.0353, max 19.721, mean -4.08663, stddev 2.84906, skewness -0.0148935, kurtosis 2.72555 ) 
[4] output of <Sigmoid> ( min 2.45548e-13, max 1, mean 0.0980917, stddev 0.196469, skewness 2.9067, kurtosis 8.25207 ) 
[5] output of <AffineTransform> ( min -15.0974, max 13.5236, mean -3.16368, stddev 2.02099, skewness 0.565002, kurtosis 2.37314 ) 
[6] output of <Sigmoid> ( min 2.77521e-07, max 0.999999, mean 0.112784, stddev 0.189965, skewness 2.74679, kurtosis 7.62093 ) 
[7] output of <AffineTransform> ( min -22.1863, max 14.6767, mean -2.80161, stddev 2.28481, skewness 0.53556, kurtosis 2.68178 ) 
[8] output of <Sigmoid> ( min 2.3153e-10, max 1, mean 0.153417, stddev 0.233604, skewness 2.0874, kurtosis 3.62807 ) 
[9] output of <AffineTransform> ( min -16.854, max 16.4027, mean -2.87139, stddev 2.87453, skewness 1.30585, kurtosis 2.56964 ) 
[10] output of <Sigmoid> ( min 4.79079e-08, max 1, mean 0.176811, stddev 0.291857, skewness 1.77581, kurtosis 1.78151 ) 
[11] output of <AffineTransform> ( min -28.079, max 17.9856, mean -3.72122, stddev 3.62981, skewness 0.976254, kurtosis 3.22248 ) 
[12] output of <Sigmoid> ( min 6.38936e-13, max 1, mean 0.147219, stddev 0.293622, skewness 2.07044, kurtosis 2.76197 ) 
[13] output of <AffineTransform> ( min -14.6445, max 22.8327, mean -0.00286854, stddev 3.55195, skewness 0.538598, kurtosis 0.971987 ) 
[14] output of <Softmax> ( min 2.73492e-15, max 0.999618, mean 0.000647599, stddev 0.0182261, skewness 40.2031, kurtosis 1779.3 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.00497, max 1.09451, mean 0.000360425, stddev 0.0563184, skewness 0.122932, kurtosis 20.1987 ) 
[1] diff-output of <AffineTransform> ( min -0.598917, max 0.255804, mean -5.36236e-05, stddev 0.0102983, skewness -1.55376, kurtosis 109.528 ) 
[2] diff-output of <Sigmoid> ( min -3.24084, max 1.93409, mean -0.000119856, stddev 0.0939474, skewness -0.682184, kurtosis 35.9524 ) 
[3] diff-output of <AffineTransform> ( min -0.785107, max 0.431643, mean -5.38182e-05, stddev 0.0116029, skewness -1.42886, kurtosis 171.628 ) 
[4] diff-output of <Sigmoid> ( min -3.14054, max 2.01463, mean -1.61427e-05, stddev 0.121676, skewness -0.118172, kurtosis 15.7236 ) 
[5] diff-output of <AffineTransform> ( min -0.588542, max 0.366016, mean 1.24259e-06, stddev 0.0119511, skewness -1.12259, kurtosis 109.116 ) 
[6] diff-output of <Sigmoid> ( min -2.86102, max 1.84225, mean 5.25191e-06, stddev 0.101512, skewness -0.25373, kurtosis 18.1388 ) 
[7] diff-output of <AffineTransform> ( min -0.483667, max 0.256798, mean 1.87651e-05, stddev 0.0097815, skewness -0.918812, kurtosis 89.8558 ) 
[8] diff-output of <Sigmoid> ( min -1.97316, max 1.31291, mean 0.000145385, stddev 0.0724591, skewness -0.139536, kurtosis 16.2925 ) 
[9] diff-output of <AffineTransform> ( min -0.301485, max 0.189724, mean 6.52363e-06, stddev 0.00729516, skewness -0.917108, kurtosis 69.0351 ) 
[10] diff-output of <Sigmoid> ( min -1.26356, max 0.905626, mean -6.57692e-05, stddev 0.0555964, skewness -0.26354, kurtosis 16.2003 ) 
[11] diff-output of <AffineTransform> ( min -0.218096, max 0.607626, mean 5.46076e-05, stddev 0.0081887, skewness 1.59403, kurtosis 170.635 ) 
[12] diff-output of <Sigmoid> ( min -1.20308, max 2.50726, mean 0.000502355, stddev 0.0865799, skewness 0.22213, kurtosis 13.3051 ) 
[13] diff-output of <AffineTransform> ( min -0.999559, max 0.968342, mean -1.10914e-08, stddev 0.0170053, skewness -25.0555, kurtosis 1993.61 ) 
[14] diff-output of <Softmax> ( min -0.999559, max 0.968342, mean -1.10914e-08, stddev 0.0170053, skewness -25.0555, kurtosis 1993.61 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.60901, max 1.68909, mean -0.000536833, stddev 0.163986, skewness 0.0314602, kurtosis 1.82243 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.520709, max 0.621037, mean -0.0137277, stddev 0.162326, skewness 0.0274461, kurtosis 0.325086 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -1.1463, max 0.930324, mean -0.00226849, stddev 0.0725656, skewness -0.185281, kurtosis 7.2973 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.944901, max 0.813669, mean -0.0137774, stddev 0.197122, skewness 0.0248635, kurtosis 1.911 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.955403, max 0.623822, mean 0.000283546, stddev 0.0431781, skewness -0.055761, kurtosis 13.9728 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.01034, max 0.94724, mean 0.000318142, stddev 0.201806, skewness 0.12393, kurtosis 2.45451 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.771096, max 0.571279, mean 0.000658913, stddev 0.036357, skewness 0.0467696, kurtosis 11.47 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.741291, max 0.670807, mean 0.00480387, stddev 0.172142, skewness 0.182355, kurtosis 2.12091 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.472856, max 0.458331, mean 0.000433604, stddev 0.033649, skewness 0.0347239, kurtosis 7.81321 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.537053, max 0.61128, mean 0.00167004, stddev 0.122931, skewness 0.0746059, kurtosis 3.00931 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.563629, max 0.688886, mean 0.00264084, stddev 0.0458514, skewness 0.340456, kurtosis 8.86603 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.61084, max 0.650204, mean 0.0139795, stddev 0.136645, skewness 0.042323, kurtosis 2.74236 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -1.81141, max 2.10082, mean -1.64613e-08, stddev 0.0920224, skewness -3.25563, kurtosis 65.8999 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.71689, max 1.85267, mean -1.2971e-08, stddev 0.278307, skewness -0.993083, kurtosis 8.62356 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 331520 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.8171, max 6.44093, mean -0.00429144, stddev 1.00295, skewness -0.0631885, kurtosis 1.97814 ) 
[1] output of <AffineTransform> ( min -29.3319, max 22.1024, mean -3.32464, stddev 4.11281, skewness 0.11719, kurtosis 1.28982 ) 
[2] output of <Sigmoid> ( min 1.82526e-13, max 1, mean 0.209588, stddev 0.317018, skewness 1.46905, kurtosis 0.682928 ) 
[3] output of <AffineTransform> ( min -26.8062, max 17.5884, mean -4.0566, stddev 2.83968, skewness 0.00227712, kurtosis 2.53742 ) 
[4] output of <Sigmoid> ( min 2.28144e-12, max 1, mean 0.0996763, stddev 0.197572, skewness 2.869, kurtosis 8.0279 ) 
[5] output of <AffineTransform> ( min -14.165, max 14.9497, mean -3.14132, stddev 2.03463, skewness 0.565364, kurtosis 2.4148 ) 
[6] output of <Sigmoid> ( min 7.05059e-07, max 1, mean 0.114881, stddev 0.191744, skewness 2.70662, kurtosis 7.36246 ) 
[7] output of <AffineTransform> ( min -23.4957, max 14.4298, mean -2.76096, stddev 2.30848, skewness 0.531091, kurtosis 2.58971 ) 
[8] output of <Sigmoid> ( min 6.25075e-11, max 0.999999, mean 0.158053, stddev 0.237192, skewness 2.03084, kurtosis 3.35781 ) 
[9] output of <AffineTransform> ( min -16.0179, max 17.5697, mean -2.83986, stddev 2.92269, skewness 1.30972, kurtosis 2.57611 ) 
[10] output of <Sigmoid> ( min 1.10537e-07, max 1, mean 0.180899, stddev 0.295249, skewness 1.73373, kurtosis 1.62047 ) 
[11] output of <AffineTransform> ( min -28.2323, max 19.9683, mean -3.70075, stddev 3.67733, skewness 0.975611, kurtosis 3.15254 ) 
[12] output of <Sigmoid> ( min 5.48123e-13, max 1, mean 0.150073, stddev 0.296834, skewness 2.03522, kurtosis 2.6022 ) 
[13] output of <AffineTransform> ( min -16.425, max 22.6629, mean -0.00414573, stddev 3.61143, skewness 0.520195, kurtosis 0.963359 ) 
[14] output of <Softmax> ( min 6.06684e-16, max 0.999392, mean 0.000647603, stddev 0.0189486, skewness 40.2081, kurtosis 1747.95 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.511011, max 0.687731, mean 0.000265134, stddev 0.0423215, skewness 0.224917, kurtosis 17.2778 ) 
[1] diff-output of <AffineTransform> ( min -0.178626, max 0.295196, mean 5.37012e-05, stddev 0.00808921, skewness 0.675571, kurtosis 66.9458 ) 
[2] diff-output of <Sigmoid> ( min -1.28503, max 1.97746, mean 0.000245014, stddev 0.0731199, skewness 0.315766, kurtosis 21.8009 ) 
[3] diff-output of <AffineTransform> ( min -0.277042, max 0.423518, mean 3.92829e-05, stddev 0.00905718, skewness 0.398805, kurtosis 101.895 ) 
[4] diff-output of <Sigmoid> ( min -1.63652, max 1.99529, mean 4.40197e-05, stddev 0.0969169, skewness 0.0107944, kurtosis 13.3371 ) 
[5] diff-output of <AffineTransform> ( min -0.254305, max 0.476289, mean 4.91848e-05, stddev 0.00952449, skewness 0.669028, kurtosis 87.6951 ) 
[6] diff-output of <Sigmoid> ( min -1.07484, max 1.90962, mean 0.000185326, stddev 0.082582, skewness 0.119906, kurtosis 14.3406 ) 
[7] diff-output of <AffineTransform> ( min -0.167669, max 0.257477, mean 2.05024e-05, stddev 0.00785521, skewness 0.506861, kurtosis 52.1901 ) 
[8] diff-output of <Sigmoid> ( min -0.7765, max 1.05057, mean 0.000146611, stddev 0.0585544, skewness 0.0753335, kurtosis 13.7124 ) 
[9] diff-output of <AffineTransform> ( min -0.132229, max 0.168901, mean 8.6853e-06, stddev 0.00589554, skewness 0.12879, kurtosis 49.566 ) 
[10] diff-output of <Sigmoid> ( min -0.760903, max 0.721498, mean -7.15377e-05, stddev 0.0452372, skewness -0.0955687, kurtosis 16.4277 ) 
[11] diff-output of <AffineTransform> ( min -0.189794, max 0.204792, mean -1.27506e-06, stddev 0.00659249, skewness -0.229478, kurtosis 74.0203 ) 
[12] diff-output of <Sigmoid> ( min -0.948484, max 1.71585, mean 0.000131869, stddev 0.0705109, skewness -0.0964202, kurtosis 11.8769 ) 
[13] diff-output of <AffineTransform> ( min -0.999995, max 0.792219, mean -7.57363e-09, stddev 0.0135801, skewness -30.1231, kurtosis 2485.73 ) 
[14] diff-output of <Softmax> ( min -0.999995, max 0.792219, mean -7.57363e-09, stddev 0.0135801, skewness -30.1231, kurtosis 2485.73 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.01387, max 0.973473, mean 0.00192434, stddev 0.128527, skewness 0.0251592, kurtosis 1.46582 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.493866, max 0.53009, mean 0.0137475, stddev 0.135898, skewness 0.092624, kurtosis 0.70606 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.658409, max 0.939085, mean 0.00178626, stddev 0.0566621, skewness 0.240167, kurtosis 6.7587 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.562414, max 0.781895, mean 0.0100564, stddev 0.156008, skewness 0.269594, kurtosis 1.53334 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.78942, max 1.40655, mean 0.00104233, stddev 0.0350849, skewness 0.786825, kurtosis 25.9506 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.689051, max 1.27654, mean 0.0125913, stddev 0.166945, skewness 0.724546, kurtosis 5.75094 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.332291, max 0.845248, mean 0.000364061, stddev 0.028473, skewness 0.402332, kurtosis 12.1866 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.483419, max 0.718662, mean 0.00524861, stddev 0.131246, skewness 0.322929, kurtosis 2.07386 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.285676, max 0.577872, mean 8.38633e-05, stddev 0.0275924, skewness 0.241647, kurtosis 7.94494 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.395208, max 0.532117, mean 0.00222346, stddev 0.100777, skewness 0.394709, kurtosis 3.10177 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.525489, max 0.379788, mean -0.000213177, stddev 0.0367761, skewness -0.0369036, kurtosis 8.32952 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.536995, max 0.455522, mean -0.000326411, stddev 0.108379, skewness -0.0242087, kurtosis 2.59772 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -1.87511, max 1.40629, mean -2.03151e-08, stddev 0.0738539, skewness -5.22728, kurtosis 96.5497 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.8719, max 1.28388, mean -4.32365e-09, stddev 0.219087, skewness -2.05412, kurtosis 14.7852 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0765744 min, processing 72156.4 frames per sec; i/o time 5.15847%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 12529 82 168 15 39 90 125 14 160 949 326 163 664 119 473 184 201 211 193 569 325 158 270 55 263 76 470 288 269 203 80 65 33 45 448 78 546 224 339 87 41 297 220 92 457 158 159 130 5856 862 179 17467 15 263 124 345 325 302 31 186 53 1047 72 114 389 21 23 419 1069 180 214 154 271 105 32 194 124 783 354 176 83 31 186 287 234 208 522 218 96 210 382 201 298 644 47 277 116 333 115 258 97 191 173 96 181 409 120 133 163 726 178 139 96 129 226 307 166 16 24 18 1329 98 244 90 176 53 288 200 54 100 123 272 117 15 41 21 21 91 60 126 197 51 96 82 224 194 191 50 223 160 89 169 118 146 105 70 169 132 174 243 95 138 65 27 97 248 159 113 303 171 151 133 105 77 297 99 319 34 122 282 178 379 148 336 54 208 100 220 133 84 0 247 47 103 145 242 114 216 104 255 48 166 433 153 128 171 581 195 185 145 265 92 119 238 74 15 103 342 96 132 301 367 241 102 18 97 54 169 50 92 213 98 90 124 291 101 304 146 431 115 261 157 246 195 51 13 17 244 135 169 227 123 218 412 126 192 391 18 262 155 102 86 146 8 84 265 167 112 230 95 30 117 236 201 158 427 18 339 60 93 79 7 556 136 131 62 108 182 86 236 115 179 279 93 212 288 133 159 416 105 190 73 14 212 282 219 234 242 140 32 460 138 190 86 26 79 90 133 144 126 140 151 182 229 202 329 98 70 41 56 66 175 96 203 78 340 96 213 364 337 325 81 226 93 176 268 122 33 145 322 416 116 17 201 122 526 15 186 115 516 185 57 164 61 172 568 94 119 42 316 216 137 148 261 176 117 134 69 63 77 237 114 511 347 33 67 214 40 90 96 17 96 188 154 191 78 226 224 143 56 66 20 116 235 10 59 112 20 925 112 101 64 330 173 189 119 264 24 289 498 201 200 288 170 100 111 51 116 255 69 154 98 113 61 112 148 150 296 169 111 187 529 47 97 193 170 112 19 19 198 265 44 73 167 148 25 129 100 34 156 24 99 180 54 118 142 115 354 173 25 22 70 541 199 244 461 412 310 188 49 50 53 42 349 163 110 334 142 37 16 58 279 22 113 151 223 463 86 147 708 197 88 176 144 118 78 283 134 124 217 134 136 164 82 86 87 59 265 197 244 476 106 97 76 428 30 80 60 182 25 346 68 102 346 99 294 462 91 115 92 282 167 22 13 218 76 128 496 74 214 223 237 61 292 81 254 250 237 71 176 480 458 121 230 29 67 142 49 178 161 191 106 62 106 85 203 120 293 684 40 382 61 138 263 77 746 294 86 85 192 116 95 405 107 330 128 134 151 98 16 275 229 196 131 254 150 387 109 172 188 121 314 56 46 176 49 272 684 10 53 150 105 527 176 13 56 136 138 15 203 67 121 317 127 199 225 89 151 283 188 68 23 181 366 147 424 193 84 127 27 157 150 384 28 128 25 70 176 306 125 178 127 77 84 206 199 46 321 126 161 65 130 315 216 31 106 136 438 132 119 33 47 84 167 570 193 84 23 80 162 274 207 95 133 408 298 83 33 214 590 5 107 61 368 62 130 8 166 7 331 177 265 261 63 20 208 156 71 281 350 223 399 79 147 167 122 501 519 24 221 65 212 266 290 284 114 166 555 0 197 293 81 799 7 124 220 234 54 12 165 33 91 209 98 17 81 480 178 1029 328 182 84 777 104 282 346 109 171 187 35 132 213 88 226 373 76 50 15 1407 121 29 82 258 203 262 69 149 103 244 58 68 77 122 372 192 157 96 225 24 194 317 140 92 200 122 18 14 131 429 169 92 176 412 72 47 39 185 6 2 100 21 100 153 121 450 92 21 119 261 149 152 112 131 91 28 78 119 300 289 229 134 97 534 32 172 152 261 70 244 148 87 89 345 141 217 58 4 469 407 196 138 141 72 190 55 228 321 238 558 473 261 26 370 14 772 305 191 0 87 240 80 132 38 97 159 476 170 46 29 147 294 121 307 12 196 119 224 139 174 28 112 256 242 131 46 117 110 266 491 265 0 123 173 382 15 363 1014 217 48 39 221 167 289 113 288 267 18 127 145 12 122 108 276 36 147 206 496 88 137 277 16 124 87 332 137 130 140 48 103 153 92 165 219 108 176 304 117 25 176 240 50 79 258 173 192 204 136 37 159 88 122 73 129 201 727 213 578 202 494 508 120 108 98 101 62 177 243 378 312 54 37 94 141 440 91 318 143 302 161 165 118 54 243 130 127 81 137 52 190 117 433 158 270 167 51 261 82 116 130 171 109 146 87 135 147 186 228 139 499 43 521 263 266 332 317 25 207 207 79 20 226 288 259 312 198 426 119 230 582 55 205 344 192 80 133 126 73 83 241 211 147 108 566 589 163 160 199 175 91 80 271 125 142 301 218 115 155 204 205 162 293 140 63 294 129 120 270 522 103 106 28 11 143 131 119 209 153 133 177 102 13 40 170 103 136 233 65 89 174 12 173 124 65 70 493 135 108 232 152 104 134 856 498 405 419 152 23 265 332 423 180 491 63 418 219 46 263 257 105 341 170 75 318 453 595 40 175 71 387 283 82 58 59 500 149 267 232 219 277 19 116 0 11 237 64 116 236 549 160 54 547 261 243 277 165 12 320 111 196 275 87 85 197 83 102 156 321 22 145 132 38 352 178 409 280 217 274 140 353 528 110 278 303 459 391 184 266 329 55 698 165 186 118 381 146 206 29 257 153 84 198 1839 150 182 52 338 190 18 149 310 251 217 30 198 32 118 98 310 397 155 203 200 194 117 185 30 54 142 216 418 307 24 310 404 261 80 86 75 110 107 267 270 210 75 145 72 17 79 146 426 254 173 297 0 266 293 146 127 15 350 792 493 238 123 210 143 211 231 401 70 142 356 154 467 53 190 145 53 249 853 435 197 236 79 218 507 193 37 354 137 162 30 239 118 564 275 121 253 272 250 20 277 14 167 136 256 458 143 149 177 162 35 13 64 201 104 168 192 199 350 685 54 302 286 244 24 337 239 332 277 180 79 131 169 105 488 264 274 214 278 59 136 46 42 16 94 267 496 588 255 297 248 339 100 228 27 119 137 18 130 118 232 213 701 153 185 276 129 123 110 271 84 569 175 70 130 71 69 37 334 114 11 371 284 42 101 82 308 262 561 147 349 94 213 117 213 383 44 497 95 25 15 310 439 202 94 32 317 393 337 159 467 35 238 143 86 85 120 347 1105 163 193 304 151 134 141 88 1025 80 82 30 140 112 165 87 123 228 102 55 87 73 180 169 37 85 193 460 98 137 241 214 338 149 142 511 327 81 345 73 43 70 0 414 85 226 75 96 112 170 534 77 223 400 137 510 324 32 115 174 153 89 196 149 237 225 389 131 139 154 202 113 45 140 205 332 128 299 193 357 66 364 450 118 171 200 126 154 143 124 68 334 83 85 81 68 253 210 53 109 186 113 286 166 1445 ]
@@@ Loss per-class: [ 0.370485 0.633879 0.670061 0.649159 1.13987 0.642797 0.931821 0.913947 0.796928 0.50992 0.279631 1.00251 0.35295 0.748049 1.1476 0.903748 0.783831 0.948093 0.706118 0.533028 0.363125 0.662405 0.233638 0.662514 0.767792 1.2476 0.506873 0.453192 0.711119 0.518887 1.66044 0.919738 0.50051 0.806948 0.431473 0.812347 0.460837 0.152413 0.535169 0.981459 0.733616 0.776593 1.35086 0.964325 0.256359 0.391965 0.762294 0.923145 0.478554 0.687842 0.545451 0.250444 1.91618 0.470832 1.02621 0.418649 0.599315 0.407283 1.05873 1.20044 1.0632 0.874664 1.1374 0.415572 0.355449 0.615527 1.25625 0.613109 0.6826 0.55416 0.523891 0.707318 0.661751 1.75934 1.32167 0.961034 0.494264 0.219507 0.485955 0.396411 1.42792 0.850247 0.755585 1.25275 0.635088 0.946755 0.510941 0.601992 0.982674 1.32678 0.575667 0.887582 0.522002 0.658695 1.27632 0.357173 0.818981 0.855116 1.46448 0.708038 1.42553 0.802117 0.395185 0.642371 0.643518 0.462615 1.08644 0.87094 0.664611 0.331066 0.537831 1.58671 0.642933 0.6241 0.373812 1.26527 0.496632 0.986812 0.849779 1.82225 0.592359 0.973386 0.571206 1.78279 0.573236 1.80149 1.01109 0.578606 1.0279 0.769032 1.13946 0.679587 0.763664 0.490908 0.699137 0.895562 1.56597 0.64248 1.05312 0.95688 0.719871 0.874683 0.778392 1.4622 0.631121 1.41327 0.545517 1.02191 1.05787 0.775379 0.781735 1.14797 0.619475 1.08421 0.933947 0.582534 0.642423 0.701767 0.79278 0.428916 1.0414 0.547858 1.49513 2.15139 0.840872 0.725862 0.996566 1.47193 0.479569 0.822252 0.530198 0.934444 1.54137 0.508219 0.821173 0.620941 0.888433 1.2352 0.592096 0.465366 0.793895 0.793874 1.00769 1.22153 1.2901 1.42227 0.636806 0.651401 0.738304 0.910289 0 0.51209 1.4147 0.762518 1.62766 0.939103 0.823398 0.450095 0.643562 0.960672 0.854192 0.973098 0.58167 0.461789 0.693459 0.425189 0.740359 0.679841 0.574489 1.66582 0.813302 0.68399 1.11219 1.14366 1.23328 1.65272 1.53867 0.821836 0.782651 0.624428 0.476404 0.729338 1.2064 0.800007 1.33356 1.51978 0.63383 0.954143 0.704305 1.81508 0.406069 1.22589 0.834828 0.992388 0.733984 0.962502 1.25349 0.744668 0.364423 0.682221 0.555508 0.990364 0.684752 0.402258 1.72206 1.35798 1.22411 1.16095 0.490006 0.500107 0.853428 0.54804 0.443194 0.467552 0.84939 1.08868 0.505227 0.461494 0.843711 1.35888 1.10144 0.532468 0.511854 2.88176 0.674725 0.339946 0.485308 0.920006 0.537119 1.20024 1.91534 0.869067 0.779838 0.411099 2.35645 0.595028 0.709878 1.55523 0.728721 1.08078 0.642783 1.09889 0.553106 0.791544 1.31228 0.691378 0.751629 0.821979 0.55039 0.577183 0.731413 1.30441 1.12545 1.50709 1.23532 0.426128 0.473435 1.19921 1.07879 0.883107 0.963986 2.33586 1.65293 0.871332 0.752257 0.969714 1.18145 0.628388 0.448233 1.01539 0.458483 1.50963 0.647641 0.505665 0.624399 0.468874 1.26092 1.90753 0.603376 0.724791 0.567367 0.862199 0.86953 1.08289 0.438412 1.60192 1.48831 0.862811 1.19789 1.94578 1.01154 0.596652 0.796331 0.934084 0.625741 0.594111 0.544842 1.58212 0.761714 0.834645 0.552772 0.774049 0.632142 0.895863 0.778505 0.385925 1.3312 1.0862 0.991855 1.10388 0.782793 1.41184 0.927158 0.841991 1.31142 0.625473 0.511027 0.761401 0.853749 0.650528 1.29237 1.16062 1.13957 0.727966 0.806922 0.324212 1.43968 1.11645 1.68057 0.657806 1.41956 0.664421 0.66098 0.433536 0.980412 0.904453 0.821224 1.1733 0.953672 0.980656 0.495834 1.67761 0.791742 0.886842 0.536753 0.427378 0.791913 1.01991 0.774477 1.04769 1.77221 0.78592 1.04852 0.457786 0.748102 0.927976 0.519022 0.373597 0.474068 2.12854 0.844842 0.630639 0.775733 0.558432 0.870838 1.13468 2.02427 0.930513 0.53071 0.927247 1.05536 0.961074 0.806593 0.677371 0.442049 0.553908 0.759426 1.38906 1.10601 0.980389 0.59336 0.828018 0.397934 1.09436 0.32986 1.5536 0.925601 0.951775 1.02873 1.59727 0.527495 0.752021 1.1491 0.660385 0.591755 1.30213 0.735331 1.29749 0.502522 0.847071 0.45359 0.669091 1.14834 1.25222 1.15413 1.22201 0.732631 1.33073 1.28089 0.459303 0.755922 0.487666 0.987677 0.888763 1.09028 2.38604 1.13928 1.07985 1.6203 0.392506 1.08151 0.633523 0.721078 0.48661 0.828381 1.4945 0.810954 0.267175 1.0984 1.0789 0.770203 0.5057 0.42269 1.11566 0.7028 0.840279 0.548554 1.20325 0.964952 1.08147 1.20396 0.605209 1.42867 0.90457 0.851888 0.843917 0.794556 1.60152 0.993426 1.28844 0.908942 1.05513 1.29573 1.81497 1.34908 0.721952 0.494732 0.588976 0.837591 0.457258 1.03812 1.4468 0.506345 0.750088 0.485861 1.54533 0.698309 0.630829 1.21382 0.536044 0.741481 1.03682 0.781731 0.538889 1.32436 0.658153 0.899214 1.04571 0.854492 0.951955 0.907459 1.26995 1.51051 1.10224 0.438856 0.788683 0.804915 1.57363 0.815398 1.03832 0.746584 0.478018 1.00567 0.472588 0.447445 1.54242 0.628072 0.685751 1.71773 1.15859 0.582603 1.02945 1.50855 1.59373 1.58192 0.824554 0.672164 0.641718 0.715692 0.993264 0.675812 0.717467 1.87995 0.709854 0.975638 1.08444 1.12197 0.72345 0.940055 0.742498 1.51744 0.559186 0.788285 0.845802 1.23838 1.26644 0.848825 1.73567 0.784058 0.610174 0.657537 0.726557 0.824172 1.98435 0.910212 1.02581 0.761591 0.999811 1.04818 1.1903 0.85404 2.50252 0.887257 0.948947 1.77552 0.405206 0.655674 1.08607 1.12406 0.691405 0.517374 1.3793 0.827842 1.15763 0.607455 1.29036 1.12228 1.30437 1.69613 2.81136 0.745137 1.1884 1.36795 0.563892 0.778678 0.821909 0.557124 1.20575 0.662304 0.678994 0.865587 1.05259 0.998337 0.644013 0.812865 1.64078 0.335937 0.563267 3.10135 0.564761 0.905289 1.0116 0.674045 0.951029 1.64228 0.787958 1.69178 0.432774 0.988156 0.997244 2.18884 0.81214 0.664836 1.18281 1.18809 1.57421 1.15663 0.647436 0.786588 0.838705 3.21388 1.26612 1.99602 0.872313 0.879476 0.659063 0.747002 1.03073 1.74179 1.39201 1.27871 0.633338 0.676813 0.945289 0.998095 1.0971 1.0924 0.818719 0.317036 0.905194 0.666554 1.75797 2.59728 1.32997 1.06964 0.582061 2.04132 0.843593 0.755862 0.690536 0.764246 1.06135 0.941998 0.348924 1.73489 0.961825 0.876437 0.341796 0.827021 0.596917 0.885213 1.00675 0.562973 0.816733 0.512638 0.77987 0.66537 1.36414 0.822056 1.17647 0.81891 1.00438 2.00523 0.697655 0.739215 0.75901 1.29239 2.58517 1.41216 0.887183 1.43252 1.25258 0.800238 0.737252 1.57752 0.675295 2.17884 1.01696 0.807806 0.629166 1.1067 0.433064 1.02593 0.839824 0.464983 0.521298 1.17483 0.939284 1.24205 0.73717 0.693968 1.09277 1.03666 0.539117 0.812224 0.733149 0.391728 0.821968 0.872512 0.884242 1.05753 0.843269 1.16548 0.700119 0.917171 1.24521 0.732384 0.659061 0 0.536877 1.06711 0.915459 0.604127 1.92288 0.71808 0.740662 0.718547 1.42059 0.78444 0.721823 1.71933 1.40859 1.72928 0.731047 0.908868 0.838612 0.809594 1.11904 0.464047 1.02973 1.24943 1.13038 0.540684 0.863174 0.903246 1.26145 2.16604 0.486411 0.963016 0.990584 0.63003 0.576985 0.866091 0.792391 1.26638 0.761518 1.26667 1.15388 0.46569 1.6549 0.562718 0.929476 1.02447 0.739672 0.80011 1.04362 1.11479 0.75466 0.784238 1.17212 1.0312 1.02744 0.567231 0.90052 1.10708 0.88485 1.603 1.0787 0.957553 0.597053 0.541544 0.872596 1.06358 0.869765 1.19662 0.75646 0.95294 1.35705 0.598937 1.5727 1.21031 1.27568 1.06661 1.00081 0.493358 1.20715 0.638511 5.51089 8.13902 0.871906 0.965224 1.21939 0.705259 0.5624 0.66771 0.842452 1.20659 1.78399 0.570008 0.661296 0.579693 1.18415 1.38766 0.990432 1.48679 1.96209 1.41616 0.549104 0.991626 0.734758 0.855035 0.871123 0.372518 1.24891 0.830152 0.805783 0.536047 0.955488 1.18273 0.713401 1.93043 0.594673 1.03067 0.78244 0.579092 0.748966 4.20954 0.62625 1.02479 0.738044 0.968874 1.35308 0.826216 0.932395 0.661639 1.49345 0.362259 0.801562 0.453181 0.757141 1.05059 1.81607 0.764831 1.13082 0.994191 0.546536 1.04729 0 1.05559 0.937941 0.740491 0.606275 0.668925 0.870703 0.767187 0.659808 1.22956 1.71122 0.677233 1.33443 1.19953 1.29938 1.37704 1.84822 1.06167 0.49852 1.35856 1.33194 1.32615 1.28824 1.40607 0.860122 2.03012 0.77549 1.43969 1.85376 2.4742 0.652152 0.994835 1.12328 0 0.755171 1.92037 1.07533 0.786643 0.540741 0.578398 1.31847 0.964737 1.51868 0.753526 1.13651 1.05903 0.742029 0.73111 0.583487 1.22493 0.784216 0.824783 1.46713 1.4039 1.11898 0.931932 1.47521 1.0028 0.761294 1.03077 0.904255 1.36259 0.608635 1.38675 1.08186 1.5135 0.303249 0.441106 0.519944 0.770858 0.9886 0.874758 0.939075 0.46614 0.747097 0.989256 0.976063 1.08618 0.843455 1.06661 2.2108 0.998002 0.660638 1.48523 0.608531 0.911897 1.06061 0.995621 0.943166 1.00191 2.37799 0.962091 0.985183 1.13506 0.983511 1.79401 1.70834 1.00443 1.41855 0.438277 0.71061 0.597681 0.779794 0.807351 0.590421 1.22143 1.13778 1.2782 1.06258 0.487309 1.04297 0.828858 1.25723 0.869045 0.992718 0.741493 0.620717 1.30573 1.3331 1.25725 1.45322 0.526489 0.607906 1.12332 0.609955 0.906936 0.90615 1.58776 2.3475 1.7369 1.3978 1.00033 1.6422 0.475335 0.660212 0.583769 1.31352 0.826435 1.18256 1.43542 0.814465 0.669877 0.695676 0.778759 1.01191 0.85367 1.07507 0.72676 1.28974 0.67395 1.33989 0.679645 1.6528 0.581378 0.799034 0.687228 1.5631 1.46432 1.11659 1.10088 1.53128 0.666789 1.74419 0.468271 0.89678 0.737821 0.698512 1.19524 0.338362 1.22953 0.943121 0.872274 1.48116 0.564171 0.582832 1.43261 0.883124 0.582668 1.04164 1.08191 1.12882 0.608374 0.814821 0.656283 1.00125 0.697457 0.957766 1.19592 0.654775 0.885245 0.774474 1.0008 1.03637 1.48609 1.05414 1.69722 0.609435 0.981922 1.19691 1.43157 1.43577 1.90489 0.411124 1.30653 1.42859 0.94348 1.04372 0.894991 0.848529 1.49853 0.426989 0.987583 0.719708 3.0954 2.48463 0.94994 0.706872 0.877233 0.994287 0.908494 1.10305 0.679922 0.798697 1.88652 1.49812 0.985117 0.876112 1.15908 0.997737 1.06135 1.01603 1.60082 1.7555 1.05822 1.22427 2.05744 1.77773 0.94106 1.4435 1.64296 0.566514 0.970975 0.862971 1.12953 0.573093 1.09515 0.728094 0.50572 1.45129 0.658456 0.561512 0.536113 1.11834 0.679585 0.627556 0.669539 0.979072 0.878457 1.05303 1.10126 1.20867 0.552886 0.597875 0.623093 0.427607 1.04183 0.962948 1.1741 1.57717 0.628864 0.944107 0.836207 0.894416 0.725445 1.17914 0.985807 1.23079 1.07834 1.45275 0.999165 0.624166 0.872191 1.95277 0.789724 0 1.80135 0.562595 1.45153 0.844424 0.80159 0.815873 1.3493 1.23946 0.881011 1.55829 0.489631 0.882628 0.825315 0.548127 0.749363 2.50017 1.00866 0.759061 0.812497 1.20623 1.75297 1.08679 1.30834 1.38779 0.8997 1.50165 1.37548 1.33682 1.09341 1.19704 1.04827 0.772122 0.538184 0.501323 0.985097 1.17297 0.713481 0.758072 1.69931 0.602629 0.565618 0.648839 0.604502 0.443302 1.1057 0.993172 0.660008 0.823207 1.39657 0.99722 0.941524 1.00252 1.57726 0.710941 1.06435 0.71111 1.11826 1.17148 0.779222 0.662591 0.881481 0.547571 1.09636 0.455185 0.968174 1.01574 0.958827 0.83087 1.25247 0.80536 1.32964 1.5258 2.78107 1.0317 1.09001 0.784537 0.917766 0.592373 0.4586 0.963052 0.656689 1.17018 0.607519 0.588763 1.1175 0.721368 0.986929 0.795536 1.26244 1.46792 1.07177 0.780986 0.635858 0.82742 2.25075 2.71935 0.833128 0.913413 0.377562 0.981023 1.50714 1.33142 1.51667 1.36905 0.437302 1.06583 1.08956 0.450796 1.20327 1.25808 0.518845 0 1.08553 0.751717 0.824666 2.29088 1.51829 0.794184 0.639708 0.925074 0.750596 1.20122 1.3309 0.779835 0.829211 0.986978 0.923794 1.07702 0.514016 0.406177 1.47691 0.578106 1.061 1.0414 1.31412 0.379005 0.933812 0.553486 1.01277 2.565 0.976524 0.649806 0.937073 1.10735 0.880139 1.21764 1.014 1.33277 0.727728 1.45146 0.824609 1.24302 0.902033 0.557957 1.64831 0.894431 1.44887 0.647327 1.32214 0.650608 1.21794 0.914993 1.62939 1.16665 0.57741 0.962423 0.924776 1.34745 1.10437 1.01009 1.17214 1.26221 0.553783 1.24933 1.45158 1.00014 0.695767 0.915769 0.810264 1.09289 0.766596 1.43962 1.57422 1.36 0.907617 0.810352 1.12893 1.24032 0.877165 1.43113 1.82207 0.745063 1.1613 0.663414 0.682427 0.849699 0.963945 1.08941 1.21253 1.49813 0.953742 1.65766 0.602012 0.961109 1.08289 0.671897 0.530178 1.37501 1.00078 1.02499 0.694133 0.952655 1.58026 1.1877 1.06913 0.753074 0.852773 1.31755 1.28009 1.19647 0.512093 0.892359 0.806881 0.997172 0.963108 0.720485 0.983922 1.06585 1.25141 1.03962 0.645633 0.948656 0.927282 1.95523 0.733153 0.852615 1.19876 1.70682 0.795766 1.67923 0.848491 1.71255 1.52015 0.867403 0.642411 0.851151 1.84607 0.86329 0.868585 0.819536 0.87981 0.342374 2.58537 1.14817 0.38367 2.44901 0.70845 1.40816 0.500477 2.03022 0.527834 0.784962 0.616362 1.06125 1.97234 1.62315 0.772725 1.20737 0.708153 1.25237 1.00513 0.864497 1.32158 0.956888 2.17066 0.737401 1.07295 0.606477 1.50252 0.875741 0.874998 1.0259 0.621333 0.755647 0.784088 0.511263 1.38509 1.63064 0.586373 0.820391 1.26717 1.2304 0.992724 0.645199 1.12346 1.19882 1.79503 1.09522 1.19437 0.881052 1.57205 0.421059 1.12485 1.14399 0.614321 1.09019 0.806936 0.987538 0.997108 0.944645 0.922569 0.751904 0.642789 0.712789 1.15426 0.922499 0.879127 0.894693 1.18462 0 0.957052 1.03939 0.857928 1.60877 0.85469 1.79193 1.72549 0.662391 1.36843 0.827618 1.07103 1.14174 0.419345 0.708186 0.937941 0.702046 1.15295 0.453239 1.19051 1.24059 1.26085 1.11187 0.822791 0.721812 1.80292 1.08223 0.765296 1.46273 0.828105 1.65884 1.10629 0.935889 0.882882 0.828306 0.621055 1.23015 0.734353 1.34603 0.627247 0.721203 1.22324 0.505678 1.21629 0.948415 0.992205 0.625922 1.08587 0.794203 0.437329 1.94043 0.837162 0.984196 0.795151 0.940033 1.23007 1.66851 0.822056 1.91867 1.57162 0.637029 0.968711 0.224623 ]
@@@ Frame-accuracy per-class: [ 86.4041 86.0606 81.3056 90.3226 58.2278 80.663 74.1036 75.8621 74.1433 86.3612 92.8025 69.1131 88.9391 83.682 64.8363 76.4228 70.9677 75.1773 83.2041 86.5672 90.0154 87.0662 95.0092 82.8829 77.0398 62.7451 85.441 87.3484 82.3748 87.9607 38.5093 67.1756 89.5522 79.1209 88.7402 81.5287 86.7338 97.1047 84.2415 76.5714 77.1084 78.6555 59.8639 68.1081 93.3333 92.7445 75.2351 75.0958 85.0849 79.0725 86.9081 91.7075 32.2581 88.425 64.257 90.0145 80.7988 90.2479 73.0159 64.8794 69.1589 59.9523 70.3448 86.4629 91.1425 88.3721 72.3404 84.3862 75.6428 81.9945 80.1865 79.6117 82.8729 54.0284 55.3846 73.0077 81.9277 92.5335 85.4725 89.5184 61.0778 82.5397 76.6756 54.6087 82.3028 70.5036 85.3589 84.6682 70.4663 63.1829 83.9216 68.4864 86.4322 80.6827 75.7895 90.0901 81.5451 73.1634 52.8139 81.6248 52.3077 83.0287 90.4899 80.829 82.6446 86.2027 73.8589 75.6554 82.5688 90.4336 84.0336 48.7455 80.829 75.6757 93.1567 61.4634 86.4865 78.7879 81.6327 48.6486 83.49 64.9746 84.6626 41.989 83.2861 50.4673 68.2842 87.2818 77.0642 78.607 69.6356 78.8991 78.2979 96.7742 79.5181 79.0698 60.4651 78.6885 69.4215 73.5178 80 69.9029 87.0466 60.6061 82.4053 40.1028 86.6841 59.4059 63.5347 75.3894 75.9777 63.1268 81.8565 75.7679 72.0379 82.2695 85.5457 85.283 79.6562 89.9384 64.9215 83.7545 61.0687 21.8182 73.8462 78.4708 75.2351 65.1982 86.9852 78.1341 83.8284 79.4007 53.0806 85.1613 78.3193 79.397 72.9264 66.6667 89.7959 86.3717 79.5518 76.4163 68.6869 63.893 62.3853 56.5947 83.5821 83.4467 80.1498 78.1065 0 87.2727 54.7368 81.1594 54.2955 72.5773 73.3624 91.9169 80.3828 70.8415 72.1649 68.4685 85.5825 83.3876 76.2646 88.6297 82.2012 85.422 86.2534 41.9244 72.3164 73.5135 67.7824 65.4088 64.4295 51.6129 52.1739 77.0803 78.7565 84.5283 87.5622 76.7347 66.2526 76.0976 70.2703 72.8205 82.5688 72.5664 85.1485 43.2432 90.8665 71.066 78.453 73.8956 79.2453 71.9212 63.3826 77.1331 90.6141 79.6537 85.2772 74.2857 80.3245 88.491 54.3689 29.6296 74.2857 66.2577 84.8708 87.3156 76.4835 82.5911 88.3295 88.4848 77.4704 68.5714 85.5683 91.8919 76.1905 52.09 65.3659 86.7052 86.0068 0 81.6568 92.6554 88.9552 78.2222 85.9002 64.9215 52.459 75.7447 76.1099 90.8189 37.224 79.5322 81.0811 60.0884 77.686 71.6578 84.2767 80 83.9173 76.1905 65.3992 81.6 70.0461 82.7397 89.0173 85.4123 79.6537 64.0669 66.9052 51.3369 65.4118 89.7747 84.6442 65.2038 67.467 68.2464 66.1417 27.2109 55.1724 80.4706 79.646 69.7039 66.951 84.1237 88.968 76.9231 88.165 56.3177 77.6903 86.7052 86.7925 84.2767 64.0884 48.6891 85.8131 77.4704 81.8505 76.5677 72.8767 65.7952 86.9136 52.5038 49.7462 70.922 67.4699 53.0973 73.6842 80.3419 75.6477 78.6241 75.1592 82.8194 84.9741 57.6112 79.0123 75.8519 83.871 78.5276 78.1457 65.2406 81.0198 88.2682 58.7755 65.6716 70.7904 66.0465 79.4718 60.0858 74.2857 76.4268 52.2449 83.3808 96.7742 77.2118 76.1905 83.8335 63.0728 71.3043 66.2614 79.6748 84.058 91.4688 52.9101 60.251 63.5294 84.3602 58.1986 79.2727 79.4613 87.1893 66.8555 70.6383 80.2974 64.7482 66.1417 68.3871 86.3158 50.655 74.2913 72.8058 89.5522 85.9259 79.2541 61.7284 76.2431 69.4301 57.1429 73.5751 72.679 88.6731 77.8068 76.4331 87.4172 90.4232 87.108 44.2478 75.188 82.9268 78.1116 86.6242 76.1905 68.9076 46.2222 73.1707 85.4673 76.4444 71.9212 68.2171 74.7352 78.9625 87.0712 87.8661 78.6389 73.4694 70.1209 69.4082 81.8859 76.808 91.1612 68.6217 92.5373 55.6054 64.0777 70.3863 72.0157 53.2374 80.9061 77.1574 59.9119 76.4228 83.5556 57.2391 79.0698 63.0691 84.9558 72.6457 86.4 78.187 61.0526 69.7436 68.7339 66.2757 79.1111 66.6667 71.7949 85.6423 79.4727 87.6404 76.1905 76.4179 67.3401 39.2157 68.7259 64.6766 60.8696 90.7348 85.7143 81.407 78.6704 88.0734 75.1055 53.3333 76.1905 93.3709 68.0115 74.5098 80 83.6879 89.7507 73.183 81.3906 74.3229 85.0909 66.9887 65.252 70.7071 61.3861 84.1121 63.5294 79.5422 84.4037 75.1131 72.3468 54.0351 69.3333 42.4242 68.3761 70.8408 66.6667 35.2423 60.066 77.8523 86.9471 89.0173 73.2203 88.2145 73.4177 65.5367 83.8527 81.6609 89.4515 52.2293 82.1869 78.8104 72.2892 85.977 80.2974 77.6557 74.1641 82.4242 55.4913 82.2857 84.0336 68.1733 75.443 74.8466 74.2917 53.5211 49.2308 73.2026 90.0817 75.4098 79.5031 54.5455 76.1644 74.5098 79.3651 90.5109 70.2439 88.3117 92.4623 60.781 83.2432 80.8743 52.8139 62.7027 82.8319 59.1045 44.4444 22.2222 51.7162 82.3529 82.4903 80.1611 80.5369 72.2611 81.4318 79.1579 45.5285 77.9487 72.3926 65.6189 67.4651 81.6842 76.9231 78.7535 50.3642 85.7143 74.0741 77.2234 64.4068 51.8519 77.8947 58.5859 78.4314 83.5913 82.5065 80.7512 81.6 57.277 73.6842 66.8305 82.1577 67.121 59.8977 81.4815 79.2157 42.2764 73.6462 70.2087 43.871 91.3597 83.1919 72.8324 70.1754 82.0779 84.9785 60.733 75.4624 71.6279 82.9047 59.9222 69.145 62.7063 48.731 54.5455 80.2178 69.7168 64.631 90.4943 77.4067 68.4385 86.1935 59.3607 81.1594 82.2281 74.8971 66.4547 63.7168 88.172 74.7875 60.6061 93.945 83.1264 19.0476 89.7196 73.7542 69.1943 83.4123 73.6544 51.8519 84.9558 52.0147 89.5307 70.9677 69.7789 51.8519 78.1893 82.5197 64.3137 65.6642 53.6585 73.743 83.8284 76.1905 75.8621 30.6569 76.5957 45.73 74.7613 75.2542 78.9164 82.6873 72.1893 43.9216 58.1818 61.5873 82.392 83.225 70.1754 76.2646 82.3529 69.5035 73.0878 93.3116 77.2908 80.6723 47.8431 33.5484 65.0888 69.7337 87.7193 43.0108 76.8274 80.6324 85.4489 77.8626 72.7969 70.9984 88.6836 60.3175 76.0563 80.5861 92.3603 78.4906 85.3556 89.5522 69.4737 87.574 74.0299 86.5907 81.6537 81.6568 72.3404 78.2609 61.5385 75.0455 70.3614 47.1204 83.8951 79.3146 78.727 63.4731 41.791 48.4848 74.8518 36.3636 62.3256 82.9268 80.0543 51.2 81.2261 47.0588 72.0721 80 82.0513 67.0423 89.6422 71.8929 74.0157 97.561 86.3309 60.0639 74.1259 66.0746 74.1797 79.1946 68.5857 71.6981 83.3898 70.4478 81.6327 87.338 76.2271 77.551 74.9436 65.6489 75.2941 65.666 80.895 73.8137 65.5022 79.2793 82.0882 0 87.5949 68.1431 67.4847 82.8018 26.6667 78.7149 80.2721 81.8763 62.3853 88 75.5287 32.8358 71.0383 49.642 83.2487 74.2857 76.0736 80.7492 68.3473 85.9641 73.3638 66.8493 68.6391 83.8585 80.3828 69.0265 57.4315 34.7032 88.0466 74.6667 59.1549 81.5094 87.5878 73.4463 77.7042 66.6667 79.7386 67.3267 77.4194 87.8863 52.6749 88.1356 73.9394 70.4062 79.1155 77.3333 69.0647 59.5318 84.058 71.1656 73.5043 77.3723 68.3871 87.3469 77.3154 72.7273 73.0159 45.5959 70.51 81.6327 81.7481 89.4488 70.4626 69.1892 70.8229 65.3061 81.0811 62.069 57.0342 84.7497 57.8171 51.8919 58.9235 69.8182 62.069 92.6316 68.3544 81.9407 0 0 81.592 79.0698 63.6816 84.0391 87.2428 80.5771 72.4324 74.4186 56.0669 85.6597 82.2742 83.2787 64.8889 57.0342 73.224 52.6316 39.4904 57.7406 81.5308 72.8843 78.4314 75.8364 72.8205 91.6745 58.4615 84.6377 78.0328 87.5717 68.0851 69.5297 81.4815 38.8571 80.4469 69.754 78.4452 81.8391 76.9231 0 81.1502 69.6933 78.3715 65.704 61.4841 77.2414 77.1654 84.6847 59.9562 90.8243 79.2453 88.0931 81.5206 68.8337 37.7358 77.7328 68.9655 67.1845 88.3797 69.9739 0 59.4286 78.5863 80.7453 76.9811 80.5195 71.7949 75.2351 81.2172 72.7273 51.6129 84.7458 60.339 66.893 71.6049 61.1382 32 69.2112 89.5397 54.343 63.0824 58.4527 66.6667 57.7778 75.6335 48.2474 73.7643 62.3656 51.9149 38.009 81.4259 73.8555 67.7966 0 83.4008 48.415 68.4967 90.3226 82.5309 84.8694 62.5287 80.4124 63.2911 80.8126 72.2388 64.2487 76.652 80.7626 82.9907 43.2432 79.2157 76.2887 32 60.4082 71.8894 77.0344 57.5342 67.7966 76.0291 68.4794 67.7966 64 82.5225 48.4848 69.8795 62.8571 91.7293 94.5455 85.0575 82.5623 78.3505 77.2947 71.6612 89.7297 80.9668 71.9818 74.6544 71.9547 79.1461 74.0426 35.2941 70.8215 84.4075 55.4455 85.5346 77.3694 73.1988 76.3636 66.5037 68.8645 34.6667 68.9655 71.1864 64.4898 70.7483 50.1931 48.6352 72.8522 58.0796 87.9862 80.4938 84.7321 77.4828 78.8382 86.6359 61.9289 71.9212 64 61.9718 91.1704 71.07 74.56 66.055 82.6667 74.0741 77.0318 81.0443 69.9454 60.9105 62.0209 61.4876 87.3065 81.571 64.135 86.2385 71.4579 78.1609 50.1961 33.1288 48.7273 64.7619 76.6404 49.3617 89.504 78.8644 85.0277 63.8806 75.7282 66.1568 54.5455 77.2532 81.2261 79.8834 77.6256 73.0375 78.8571 69.3727 81.3559 62.1984 82.7133 62.3656 82.0821 41.3793 83.0297 79.3169 80.3002 56.5414 59.8425 78.4314 62.6506 46.747 83.0189 53.6585 88.3002 78.6828 79.7688 83.84 65.4912 93.3177 61.0879 72.4512 71.9313 37.8378 84.1849 83.5994 57.6623 72.0497 83.8951 72.7273 73.4694 69.4611 82.8157 78.487 83.3898 73.7327 76.4342 70.9075 68.5015 81.6199 77.6942 78.0627 76.5027 75.7764 51.1971 66.1355 48.4211 84.5771 71.3959 64.9351 58.5209 60.1467 49.635 88.6154 65.4174 54.8043 70.8661 68.2513 78.7645 73.8589 54.3438 88.6124 69.5652 83.5681 10.5263 34.7826 73.1707 85.1711 71.1297 67.3031 76.2215 70.412 76.0563 74.1463 44.4444 56.7901 74.4868 73.43 68.8645 75.803 62.5954 73.743 50.4298 56 69.1643 69.8795 29.0076 41.1348 72.9483 51.6605 53.4562 87.3118 72.7869 77.512 66.9145 84.1798 68.8064 84.0937 88.677 49.8361 89.3617 87.3823 86.3158 69.8937 85.8726 85.4527 85.0394 71.2067 79.2711 66.6667 67.5522 67.5728 86.2559 83.1625 84.4575 84.7682 70.9576 72.7674 61.293 54.321 80.9117 67.1329 74.0645 74.0741 84.8485 76.9231 68.9076 65.1349 68.2274 57.9439 71.3978 82.0046 73.8739 56.4103 78.97 0 43.4783 85.0526 65.1163 72.103 82.0296 80.6187 54.8287 64.2202 75.2511 54.3021 87.4743 70.991 82.7795 88 78.6271 31.3901 70.7379 80.9437 84.5714 72.5146 42.0253 63.4731 68.2927 62.6198 78.6936 57.7778 50.8591 66.4151 77.9221 59.0071 74.5098 78.1441 85.918 86.4368 69.2168 70.4626 83.1683 80.9839 57.9186 82.5853 86.6557 87.2688 83.2695 90.5149 74.6717 73.1411 81.0811 74.5884 51.3595 70.7775 75.9494 72.0839 49.1468 78.4504 71.1864 83.1068 64.4951 67.4556 81.1083 78.4996 82.392 88.7671 70.4762 90.3988 75.0656 81.0811 73.5786 80.1932 62.8231 75.8621 68.8525 59.9496 9.23077 64.9789 70.0508 77.9388 78.239 86.8167 87.9607 69.3267 85.8612 65.5319 85.1752 88.5246 75.2294 81.4035 72.9792 81.4815 65.6911 57.1429 67.3108 80.5933 82.6004 81.9876 40.4624 22.5166 77.8281 75.3488 91.215 72.0887 53.6817 55.6291 59.7938 60.6897 97.1429 70.4403 75.0853 87.925 65.2259 62.2478 87.7311 0 74.6717 79.046 79.8635 42.3529 58.0645 79.8859 82.776 76.5957 84.696 64.7773 64.133 79.4425 81.7967 72.5702 72.9763 66.6667 89.8246 89.7616 57.6052 81.7112 76.6355 71.3911 64.6048 93.4579 72.9459 86.5847 73.2491 24.8101 74.4186 84.2767 76.8879 67.9803 75.969 69.3333 70.8039 60.3636 85.5385 52.459 76.4092 64.9789 75.8193 85.2995 51.0288 73.7673 58.7156 80.6387 68.2927 77.8378 68.9655 78.806 65.2015 64.3275 86.3686 71.777 76.2542 68.7324 65.8462 76.0563 51.8519 62.0155 84.3672 66.9856 58.1602 73.2468 80.7018 70.4708 77.1699 56.8807 78.3471 59.3368 56.0327 57.1429 76.1481 80.5846 65.8647 63.4234 78.1163 65.4088 50.9506 79.646 72.0379 82.7021 82.4197 75.4098 76.4569 66.4273 55.4622 43.956 81.7204 49.4118 90.9091 73.0159 69.9065 80.5639 84.1121 61.8395 73.6134 74.4467 83.6524 78.607 61.2691 61.8182 72.8033 69.8182 81.0811 65.1341 64.9789 70.9677 86.1827 74.9822 82.0847 66.8464 74.141 85.7143 72.0648 66.0633 67.035 68.6391 83.5821 71.7949 78.0142 43.6782 78.3217 76.259 74.6667 50.5232 77.7293 52.1739 75.1009 47.8032 47.0588 71.9212 80 76.8233 49.9048 74.9777 77.9661 76.681 81.4815 91.8033 33.1915 67.4473 90.2216 33.7079 82.8141 53.4031 90.1961 32.2581 85.9903 78.4983 81.9753 71.9577 36.9231 49.7638 76.493 64 76.489 62.6738 73.2394 80.9224 57.8397 75.1445 31.5789 82.1577 72.8058 82.3157 54.4343 76.4858 74.5484 68.6469 82.5279 75.6184 76.8362 86.5919 67.0807 58.1818 85.2459 79.0036 57.7778 66.4653 77.7143 87.4494 73.523 70.2439 54.0541 69.7143 65.3061 75.9003 57.8171 93.3333 69.0058 71.3178 82.7362 72.0812 78.5455 77.0186 71.3287 74.1507 74.9164 79.2982 82.3069 80.3053 66.2577 75.8321 78.9116 73.5632 62.4113 0 73.1001 66.6667 79.0287 52.9801 79.7927 44.4444 49.8534 79.5136 68.3871 78.2998 73.6579 66.1818 89.3242 78.5824 86.1538 86.5801 72.2063 86.645 65.9218 62.0865 64.214 72.8421 79.3792 83.697 45.6274 69.5341 84.1424 57.7778 81.9383 46.1538 66.1922 72.9927 74.2857 76.2646 87.1452 60.9819 75.8042 54.1353 84.225 79.0233 60.7595 86.8805 65.8354 72.7273 73.1392 78.7456 69.0763 77.3723 90.284 45.509 74.8538 68.7117 75.9124 73.7673 59.8575 54.2056 78.5388 41.8231 44.9339 79.2321 80.4805 94.8461 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 0.806629 (Xent), [AvgXent: 0.806629, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 77.2517% <<

