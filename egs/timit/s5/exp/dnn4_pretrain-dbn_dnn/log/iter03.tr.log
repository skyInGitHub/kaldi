nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.008 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter02_learnrate0.008_tr1.6170_cv2.2188 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter03 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975016
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.86424, max 7.06273, mean -0.000964877, stddev 0.993005, skewness 0.0133901, kurtosis 2.03207 ) 
[1] output of <AffineTransform> ( min -26.3859, max 18.066, mean -3.19379, stddev 3.34604, skewness 0.129973, kurtosis 1.67987 ) 
[2] output of <Sigmoid> ( min 3.47319e-12, max 1, mean 0.18094, stddev 0.283198, skewness 1.7371, kurtosis 1.74881 ) 
[3] output of <AffineTransform> ( min -30.0898, max 18.2089, mean -3.91837, stddev 2.68496, skewness 0.0184698, kurtosis 3.30721 ) 
[4] output of <Sigmoid> ( min 8.55372e-14, max 1, mean 0.0973993, stddev 0.192715, skewness 2.97155, kurtosis 8.73812 ) 
[5] output of <AffineTransform> ( min -14.3971, max 12.4129, mean -3.22361, stddev 2.02245, skewness 0.701654, kurtosis 2.88002 ) 
[6] output of <Sigmoid> ( min 5.59034e-07, max 0.999996, mean 0.107944, stddev 0.189812, skewness 2.88514, kurtosis 8.38485 ) 
[7] output of <AffineTransform> ( min -23.9634, max 14.3415, mean -3.04947, stddev 2.2529, skewness 0.608307, kurtosis 3.31372 ) 
[8] output of <Sigmoid> ( min 3.9158e-11, max 0.999999, mean 0.131331, stddev 0.21982, skewness 2.41735, kurtosis 5.27658 ) 
[9] output of <AffineTransform> ( min -16.3749, max 15.1843, mean -3.00667, stddev 2.66944, skewness 1.37349, kurtosis 3.02556 ) 
[10] output of <Sigmoid> ( min 7.73554e-08, max 1, mean 0.156565, stddev 0.272562, skewness 2.00967, kurtosis 2.78427 ) 
[11] output of <AffineTransform> ( min -28.2214, max 18.0529, mean -3.61838, stddev 3.25343, skewness 1.05945, kurtosis 3.70562 ) 
[12] output of <Sigmoid> ( min 5.54091e-13, max 1, mean 0.138384, stddev 0.278557, skewness 2.20142, kurtosis 3.41988 ) 
[13] output of <AffineTransform> ( min -11.7916, max 19.4576, mean -0.00197571, stddev 2.87238, skewness 0.644709, kurtosis 1.26606 ) 
[14] output of <Softmax> ( min 7.11711e-13, max 0.996429, mean 0.00064755, stddev 0.015925, skewness 40.5887, kurtosis 1888.04 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.19828, max 0.755338, mean -3.46002e-05, stddev 0.0475915, skewness -0.40261, kurtosis 21.9315 ) 
[1] diff-output of <AffineTransform> ( min -0.268335, max 0.208368, mean 4.32534e-06, stddev 0.00941562, skewness -0.291662, kurtosis 48.7057 ) 
[2] diff-output of <Sigmoid> ( min -1.47394, max 1.14975, mean -8.2246e-06, stddev 0.0792315, skewness -0.0362605, kurtosis 10.8313 ) 
[3] diff-output of <AffineTransform> ( min -0.258929, max 0.26585, mean 2.5536e-05, stddev 0.00972, skewness -0.266575, kurtosis 61.3427 ) 
[4] diff-output of <Sigmoid> ( min -1.27595, max 1.48321, mean -4.60367e-05, stddev 0.0985491, skewness 0.00297401, kurtosis 7.6223 ) 
[5] diff-output of <AffineTransform> ( min -0.300164, max 0.226784, mean 7.43435e-05, stddev 0.0098723, skewness -0.313186, kurtosis 50.8237 ) 
[6] diff-output of <Sigmoid> ( min -1.26575, max 1.09046, mean 0.000281241, stddev 0.0854624, skewness -0.030023, kurtosis 7.73529 ) 
[7] diff-output of <AffineTransform> ( min -0.183933, max 0.213794, mean 9.83764e-05, stddev 0.00862099, skewness 0.0666094, kurtosis 33.1606 ) 
[8] diff-output of <Sigmoid> ( min -0.744213, max 0.856814, mean 0.000356412, stddev 0.0688044, skewness -0.0125227, kurtosis 7.01551 ) 
[9] diff-output of <AffineTransform> ( min -0.138762, max 0.122365, mean 6.34116e-05, stddev 0.00703834, skewness -0.206774, kurtosis 31.6706 ) 
[10] diff-output of <Sigmoid> ( min -0.692321, max 0.604962, mean 0.000160083, stddev 0.0548562, skewness -0.0752667, kurtosis 8.25543 ) 
[11] diff-output of <AffineTransform> ( min -0.146801, max 0.187872, mean 0.000125159, stddev 0.00861433, skewness 0.181003, kurtosis 33.3506 ) 
[12] diff-output of <Sigmoid> ( min -1.55499, max 1.47991, mean 0.000899959, stddev 0.0953924, skewness -0.0272364, kurtosis 3.71097 ) 
[13] diff-output of <AffineTransform> ( min -0.99996, max 0.96196, mean -1.55791e-08, stddev 0.0210313, skewness -25.2261, kurtosis 1489.59 ) 
[14] diff-output of <Softmax> ( min -0.99996, max 0.96196, mean -1.55791e-08, stddev 0.0210313, skewness -25.2261, kurtosis 1489.59 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.33349, max 1.36704, mean -0.000235071, stddev 0.155397, skewness 0.0160828, kurtosis 2.27919 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.722987, max 0.791944, mean 0.00110728, stddev 0.167495, skewness 0.0405723, kurtosis 1.67373 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.783848, max 0.771407, mean 0.00155064, stddev 0.057625, skewness 0.210053, kurtosis 8.06461 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.7444, max 1.04173, mean 0.00653721, stddev 0.182912, skewness 0.349513, kurtosis 3.31692 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.595684, max 0.622903, mean 0.00207411, stddev 0.0375055, skewness 0.396778, kurtosis 13.3974 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.789699, max 0.920657, mean 0.019032, stddev 0.191421, skewness 0.236131, kurtosis 2.47082 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.506241, max 0.655061, mean 0.00279442, stddev 0.0337556, skewness 0.709423, kurtosis 11.7408 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.686568, max 0.770136, mean 0.0251845, stddev 0.170404, skewness 0.511781, kurtosis 2.27751 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.457943, max 0.505761, mean 0.00222726, stddev 0.0325832, skewness 0.428457, kurtosis 8.96627 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.631124, max 0.688025, mean 0.0162332, stddev 0.139131, skewness 0.364472, kurtosis 2.70596 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.473078, max 0.512346, mean 0.00524919, stddev 0.0463369, skewness 0.85667, kurtosis 8.50775 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.541971, max 0.616685, mean 0.0320407, stddev 0.152495, skewness 0.545532, kurtosis 1.90471 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -3.69522, max 2.68322, mean -1.99553e-08, stddev 0.109533, skewness -3.92981, kurtosis 73.1575 ) , lr-coef 1, max-norm 0
  bias_grad ( min -3.57649, max 1.93412, mean -3.70599e-09, stddev 0.361575, skewness -1.55415, kurtosis 12.869 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 331520 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.8171, max 6.44093, mean -0.00429144, stddev 1.00295, skewness -0.0631885, kurtosis 1.97814 ) 
[1] output of <AffineTransform> ( min -28.2204, max 20.2351, mean -3.24324, stddev 3.74023, skewness 0.125002, kurtosis 1.48464 ) 
[2] output of <Sigmoid> ( min 5.54698e-13, max 1, mean 0.196848, stddev 0.301873, skewness 1.58331, kurtosis 1.11797 ) 
[3] output of <AffineTransform> ( min -26.9823, max 18.0394, mean -4.01629, stddev 2.79787, skewness 0.0338889, kurtosis 2.87458 ) 
[4] output of <Sigmoid> ( min 1.91302e-12, max 1, mean 0.0987655, stddev 0.197138, skewness 2.91516, kurtosis 8.30082 ) 
[5] output of <AffineTransform> ( min -14.5164, max 14.4312, mean -3.22174, stddev 2.04707, skewness 0.664953, kurtosis 2.72473 ) 
[6] output of <Sigmoid> ( min 4.9612e-07, max 0.999999, mean 0.109811, stddev 0.191589, skewness 2.82761, kurtosis 8.00115 ) 
[7] output of <AffineTransform> ( min -22.024, max 14.7075, mean -2.94703, stddev 2.28269, skewness 0.617444, kurtosis 3.02134 ) 
[8] output of <Sigmoid> ( min 2.72335e-10, max 1, mean 0.140715, stddev 0.227301, skewness 2.27552, kurtosis 4.51125 ) 
[9] output of <AffineTransform> ( min -15.3765, max 16.1136, mean -2.94355, stddev 2.77435, skewness 1.37168, kurtosis 2.95271 ) 
[10] output of <Sigmoid> ( min 2.09919e-07, max 1, mean 0.165301, stddev 0.281125, skewness 1.90723, kurtosis 2.33284 ) 
[11] output of <AffineTransform> ( min -27.1459, max 19.0126, mean -3.71953, stddev 3.41064, skewness 1.01213, kurtosis 3.49772 ) 
[12] output of <Sigmoid> ( min 1.62431e-12, max 1, mean 0.139064, stddev 0.282869, skewness 2.18262, kurtosis 3.29627 ) 
[13] output of <AffineTransform> ( min -13.972, max 20.8577, mean -0.00286288, stddev 3.159, skewness 0.602742, kurtosis 1.19554 ) 
[14] output of <Softmax> ( min 1.75866e-14, max 0.997963, mean 0.000647576, stddev 0.0180927, skewness 41.0216, kurtosis 1851.35 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.785285, max 0.641683, mean 0.000121562, stddev 0.0418543, skewness -0.0707055, kurtosis 19.9927 ) 
[1] diff-output of <AffineTransform> ( min -0.282162, max 0.414724, mean 6.76551e-05, stddev 0.00813617, skewness 1.50764, kurtosis 107.051 ) 
[2] diff-output of <Sigmoid> ( min -1.78668, max 3.23965, mean 0.000487465, stddev 0.0734313, skewness 1.56715, kurtosis 80.9055 ) 
[3] diff-output of <AffineTransform> ( min -0.297952, max 0.622251, mean 1.91885e-05, stddev 0.00902099, skewness 3.69861, kurtosis 309.378 ) 
[4] diff-output of <Sigmoid> ( min -1.52734, max 2.92676, mean -5.20946e-05, stddev 0.0913164, skewness 0.301047, kurtosis 24.5703 ) 
[5] diff-output of <AffineTransform> ( min -0.243737, max 0.672164, mean 3.84609e-05, stddev 0.00927557, skewness 3.08287, kurtosis 249.953 ) 
[6] diff-output of <Sigmoid> ( min -1.35581, max 2.76697, mean 0.000360466, stddev 0.081446, skewness 0.546583, kurtosis 26.5328 ) 
[7] diff-output of <AffineTransform> ( min -0.1855, max 0.417302, mean 1.67317e-05, stddev 0.00811397, skewness 2.0439, kurtosis 131.302 ) 
[8] diff-output of <Sigmoid> ( min -1.12362, max 1.83341, mean 7.89461e-05, stddev 0.0630229, skewness 0.253274, kurtosis 21.4865 ) 
[9] diff-output of <AffineTransform> ( min -0.234984, max 0.278784, mean 1.33802e-05, stddev 0.00646205, skewness 0.853199, kurtosis 91.438 ) 
[10] diff-output of <Sigmoid> ( min -0.988783, max 1.22695, mean -1.42155e-05, stddev 0.0495097, skewness 0.157787, kurtosis 18.6697 ) 
[11] diff-output of <AffineTransform> ( min -0.422927, max 0.261425, mean 2.07319e-05, stddev 0.00745638, skewness -0.558407, kurtosis 121.848 ) 
[12] diff-output of <Sigmoid> ( min -1.74572, max 1.33157, mean 0.000345611, stddev 0.0814146, skewness -0.120951, kurtosis 8.82284 ) 
[13] diff-output of <AffineTransform> ( min -0.999997, max 0.932943, mean -9.85368e-09, stddev 0.0170336, skewness -25.56, kurtosis 1945.43 ) 
[14] diff-output of <Softmax> ( min -0.999997, max 0.932943, mean -9.85368e-09, stddev 0.0170336, skewness -25.56, kurtosis 1945.43 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.19483, max 1.57812, mean 0.00167419, stddev 0.128561, skewness 0.090828, kurtosis 2.55923 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.53599, max 0.83193, mean 0.0173197, stddev 0.13715, skewness 0.164629, kurtosis 1.88687 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.470791, max 1.29429, mean 0.000528058, stddev 0.0535628, skewness 1.40107, kurtosis 23.8043 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.514023, max 0.992043, mean 0.00491228, stddev 0.157097, skewness 0.984049, kurtosis 5.3333 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.50695, max 1.46077, mean 0.000718615, stddev 0.0334781, skewness 1.62713, kurtosis 48.6126 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.500353, max 1.37982, mean 0.00984594, stddev 0.158554, skewness 1.20826, kurtosis 8.33947 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.391975, max 1.01392, mean 0.000163355, stddev 0.0288211, skewness 1.0459, kurtosis 27.1926 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.434232, max 0.837521, mean 0.00428333, stddev 0.136609, skewness 0.66892, kurtosis 3.37224 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.456408, max 0.613136, mean 0.000143626, stddev 0.027954, skewness 0.414762, kurtosis 13.5739 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.42422, max 0.678754, mean 0.00342538, stddev 0.111447, skewness 0.584935, kurtosis 3.53375 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.892454, max 0.514886, mean 0.000575923, stddev 0.0391973, skewness 0.0574424, kurtosis 12.5411 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.891556, max 0.566427, mean 0.00530738, stddev 0.125059, skewness -0.0639032, kurtosis 4.49727 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.54699, max 2.14952, mean -7.22779e-08, stddev 0.0894721, skewness -4.85459, kurtosis 102.417 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.52312, max 2.03654, mean -1.17356e-08, stddev 0.28349, skewness -1.7357, kurtosis 15.1044 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0762981 min, processing 72417.7 frames per sec; i/o time 5.09028%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 12529 82 168 15 39 90 125 14 160 949 326 163 664 119 473 184 201 211 193 569 325 158 270 55 263 76 470 288 269 203 80 65 33 45 448 78 546 224 339 87 41 297 220 92 457 158 159 130 5856 862 179 17467 15 263 124 345 325 302 31 186 53 1047 72 114 389 21 23 419 1069 180 214 154 271 105 32 194 124 783 354 176 83 31 186 287 234 208 522 218 96 210 382 201 298 644 47 277 116 333 115 258 97 191 173 96 181 409 120 133 163 726 178 139 96 129 226 307 166 16 24 18 1329 98 244 90 176 53 288 200 54 100 123 272 117 15 41 21 21 91 60 126 197 51 96 82 224 194 191 50 223 160 89 169 118 146 105 70 169 132 174 243 95 138 65 27 97 248 159 113 303 171 151 133 105 77 297 99 319 34 122 282 178 379 148 336 54 208 100 220 133 84 0 247 47 103 145 242 114 216 104 255 48 166 433 153 128 171 581 195 185 145 265 92 119 238 74 15 103 342 96 132 301 367 241 102 18 97 54 169 50 92 213 98 90 124 291 101 304 146 431 115 261 157 246 195 51 13 17 244 135 169 227 123 218 412 126 192 391 18 262 155 102 86 146 8 84 265 167 112 230 95 30 117 236 201 158 427 18 339 60 93 79 7 556 136 131 62 108 182 86 236 115 179 279 93 212 288 133 159 416 105 190 73 14 212 282 219 234 242 140 32 460 138 190 86 26 79 90 133 144 126 140 151 182 229 202 329 98 70 41 56 66 175 96 203 78 340 96 213 364 337 325 81 226 93 176 268 122 33 145 322 416 116 17 201 122 526 15 186 115 516 185 57 164 61 172 568 94 119 42 316 216 137 148 261 176 117 134 69 63 77 237 114 511 347 33 67 214 40 90 96 17 96 188 154 191 78 226 224 143 56 66 20 116 235 10 59 112 20 925 112 101 64 330 173 189 119 264 24 289 498 201 200 288 170 100 111 51 116 255 69 154 98 113 61 112 148 150 296 169 111 187 529 47 97 193 170 112 19 19 198 265 44 73 167 148 25 129 100 34 156 24 99 180 54 118 142 115 354 173 25 22 70 541 199 244 461 412 310 188 49 50 53 42 349 163 110 334 142 37 16 58 279 22 113 151 223 463 86 147 708 197 88 176 144 118 78 283 134 124 217 134 136 164 82 86 87 59 265 197 244 476 106 97 76 428 30 80 60 182 25 346 68 102 346 99 294 462 91 115 92 282 167 22 13 218 76 128 496 74 214 223 237 61 292 81 254 250 237 71 176 480 458 121 230 29 67 142 49 178 161 191 106 62 106 85 203 120 293 684 40 382 61 138 263 77 746 294 86 85 192 116 95 405 107 330 128 134 151 98 16 275 229 196 131 254 150 387 109 172 188 121 314 56 46 176 49 272 684 10 53 150 105 527 176 13 56 136 138 15 203 67 121 317 127 199 225 89 151 283 188 68 23 181 366 147 424 193 84 127 27 157 150 384 28 128 25 70 176 306 125 178 127 77 84 206 199 46 321 126 161 65 130 315 216 31 106 136 438 132 119 33 47 84 167 570 193 84 23 80 162 274 207 95 133 408 298 83 33 214 590 5 107 61 368 62 130 8 166 7 331 177 265 261 63 20 208 156 71 281 350 223 399 79 147 167 122 501 519 24 221 65 212 266 290 284 114 166 555 0 197 293 81 799 7 124 220 234 54 12 165 33 91 209 98 17 81 480 178 1029 328 182 84 777 104 282 346 109 171 187 35 132 213 88 226 373 76 50 15 1407 121 29 82 258 203 262 69 149 103 244 58 68 77 122 372 192 157 96 225 24 194 317 140 92 200 122 18 14 131 429 169 92 176 412 72 47 39 185 6 2 100 21 100 153 121 450 92 21 119 261 149 152 112 131 91 28 78 119 300 289 229 134 97 534 32 172 152 261 70 244 148 87 89 345 141 217 58 4 469 407 196 138 141 72 190 55 228 321 238 558 473 261 26 370 14 772 305 191 0 87 240 80 132 38 97 159 476 170 46 29 147 294 121 307 12 196 119 224 139 174 28 112 256 242 131 46 117 110 266 491 265 0 123 173 382 15 363 1014 217 48 39 221 167 289 113 288 267 18 127 145 12 122 108 276 36 147 206 496 88 137 277 16 124 87 332 137 130 140 48 103 153 92 165 219 108 176 304 117 25 176 240 50 79 258 173 192 204 136 37 159 88 122 73 129 201 727 213 578 202 494 508 120 108 98 101 62 177 243 378 312 54 37 94 141 440 91 318 143 302 161 165 118 54 243 130 127 81 137 52 190 117 433 158 270 167 51 261 82 116 130 171 109 146 87 135 147 186 228 139 499 43 521 263 266 332 317 25 207 207 79 20 226 288 259 312 198 426 119 230 582 55 205 344 192 80 133 126 73 83 241 211 147 108 566 589 163 160 199 175 91 80 271 125 142 301 218 115 155 204 205 162 293 140 63 294 129 120 270 522 103 106 28 11 143 131 119 209 153 133 177 102 13 40 170 103 136 233 65 89 174 12 173 124 65 70 493 135 108 232 152 104 134 856 498 405 419 152 23 265 332 423 180 491 63 418 219 46 263 257 105 341 170 75 318 453 595 40 175 71 387 283 82 58 59 500 149 267 232 219 277 19 116 0 11 237 64 116 236 549 160 54 547 261 243 277 165 12 320 111 196 275 87 85 197 83 102 156 321 22 145 132 38 352 178 409 280 217 274 140 353 528 110 278 303 459 391 184 266 329 55 698 165 186 118 381 146 206 29 257 153 84 198 1839 150 182 52 338 190 18 149 310 251 217 30 198 32 118 98 310 397 155 203 200 194 117 185 30 54 142 216 418 307 24 310 404 261 80 86 75 110 107 267 270 210 75 145 72 17 79 146 426 254 173 297 0 266 293 146 127 15 350 792 493 238 123 210 143 211 231 401 70 142 356 154 467 53 190 145 53 249 853 435 197 236 79 218 507 193 37 354 137 162 30 239 118 564 275 121 253 272 250 20 277 14 167 136 256 458 143 149 177 162 35 13 64 201 104 168 192 199 350 685 54 302 286 244 24 337 239 332 277 180 79 131 169 105 488 264 274 214 278 59 136 46 42 16 94 267 496 588 255 297 248 339 100 228 27 119 137 18 130 118 232 213 701 153 185 276 129 123 110 271 84 569 175 70 130 71 69 37 334 114 11 371 284 42 101 82 308 262 561 147 349 94 213 117 213 383 44 497 95 25 15 310 439 202 94 32 317 393 337 159 467 35 238 143 86 85 120 347 1105 163 193 304 151 134 141 88 1025 80 82 30 140 112 165 87 123 228 102 55 87 73 180 169 37 85 193 460 98 137 241 214 338 149 142 511 327 81 345 73 43 70 0 414 85 226 75 96 112 170 534 77 223 400 137 510 324 32 115 174 153 89 196 149 237 225 389 131 139 154 202 113 45 140 205 332 128 299 193 357 66 364 450 118 171 200 126 154 143 124 68 334 83 85 81 68 253 210 53 109 186 113 286 166 1445 ]
@@@ Loss per-class: [ 0.628515 1.19792 1.17012 1.57915 1.66079 1.38206 1.50675 2.18294 1.3479 0.83172 0.525321 1.64949 0.696514 1.18533 1.69922 1.48755 1.26418 1.41353 1.27786 0.907238 0.597186 1.25723 0.488329 1.27027 1.29057 2.06033 0.939888 0.887081 1.21419 0.912586 2.49129 1.61056 0.964617 1.57216 0.799893 1.3424 0.789705 0.328748 1.01192 1.86592 1.40811 1.27196 2.32497 1.52452 0.473473 0.666598 1.2022 1.51214 0.905817 0.983592 0.952129 0.389613 3.40444 0.864931 1.78989 0.697751 1.02501 0.773995 2.04028 1.80255 1.67835 1.17802 1.87054 0.775488 0.607634 1.33931 2.41817 1.04831 0.942224 1.10643 0.913987 1.32223 1.11805 2.90685 1.98256 1.54711 0.915978 0.357715 0.877138 0.796395 2.22182 1.87296 1.22476 1.98399 0.998359 1.51839 0.837533 0.966433 1.5929 2.00891 0.879092 1.36092 0.88241 0.997332 2.03489 0.658375 1.39693 1.35299 2.29189 1.1361 2.16401 1.32267 0.736394 1.10761 1.21887 0.697948 1.92449 1.37155 1.12359 0.561662 0.914177 2.50668 1.18274 1.04296 0.615527 1.88766 0.905613 1.86998 1.94086 3.28578 0.926063 1.58869 1.00274 2.55269 0.887722 2.90696 1.58352 1.05945 1.78089 1.30208 1.79019 1.14495 1.32305 1.74721 1.18224 1.72397 2.10608 1.18704 1.82217 1.47486 1.18308 1.43176 1.32486 2.4641 1.04569 2.11638 1.03432 1.76774 1.62778 1.29442 1.50731 1.73294 1.15118 1.77693 1.68363 1.11753 1.18935 1.27379 1.3049 0.703766 1.88725 1.05607 2.37014 3.0588 1.24703 1.10321 1.60263 2.06357 0.847181 1.47217 1.00198 1.34346 2.37085 0.964061 1.40764 1.14278 1.41953 1.68796 1.11644 0.791343 1.35476 1.39693 1.53797 1.86049 2.08418 2.21626 1.04688 1.19828 1.19206 1.43438 0 1.0136 1.87724 1.26349 2.36934 1.45325 1.46173 0.763541 1.27457 1.51475 1.59056 1.61423 0.918472 0.80453 1.21958 0.765945 1.10113 1.1501 1.02207 2.40444 1.27908 1.32172 1.81772 2.00065 1.90438 3.3143 2.429 1.38783 1.23169 1.22305 0.816374 1.18196 1.99035 1.55407 2.18864 2.22431 1.17023 1.67777 1.49121 2.6349 0.677431 1.92384 1.35269 1.77269 1.19402 1.4854 1.95109 1.21241 0.571419 1.10939 0.899319 1.60382 1.08406 0.75086 2.7702 2.74439 2.39398 1.8029 0.837845 0.785272 1.46084 0.974857 1.04738 0.879022 1.60678 1.70318 0.974016 1.16099 1.23143 1.99261 2.00958 1.02997 0.912313 5.49868 1.20118 0.663652 0.951415 1.58564 0.863163 1.94005 3.27877 1.5359 1.2585 0.737606 3.39495 0.930255 1.58214 2.38809 1.28945 1.75622 1.32272 3.72602 0.820266 1.65615 2.07098 1.09474 1.31755 1.36057 1.08873 1.19166 1.33582 2.04791 1.77812 2.30602 1.99768 0.725069 0.961172 1.94894 1.68835 1.418 1.55738 3.13191 3.10459 1.55955 1.26361 1.49865 1.88718 1.12171 0.800703 2.18164 0.804785 2.20476 1.00515 0.843465 1.17688 0.932298 2.23758 2.97533 1.12526 1.30855 1.04654 1.35574 1.59663 1.68501 0.87337 2.31117 2.37883 1.48639 2.05371 2.92228 1.8728 0.997984 1.2869 1.38944 1.11668 0.953904 1.00137 2.27301 1.36654 1.39865 0.888528 1.55534 1.18146 1.72568 1.45375 0.814858 2.15888 1.87529 1.44615 1.76818 1.29162 2.1732 2.03779 1.46696 2.10536 0.95967 1.63314 1.13473 1.43621 1.0209 2.01498 2.12228 1.87163 1.34718 1.34006 0.636272 2.45724 1.79806 2.2434 1.14824 2.13129 1.16431 1.22404 0.960318 1.70101 1.61173 1.51139 1.97673 1.753 1.67676 0.843171 2.51801 1.2857 1.41373 1.14095 0.798765 1.24538 1.95519 1.3802 1.55562 3.10836 1.39918 1.74773 0.848862 1.1558 1.55124 0.900252 0.69749 1.02729 2.98053 1.55891 1.48744 1.36082 1.05092 2.73665 1.98339 2.95695 1.95579 0.81681 1.45837 2.01187 1.43507 1.20815 1.17219 0.862846 0.943094 1.31646 1.92331 1.85308 1.42643 1.11443 1.44056 0.707142 1.75047 0.601323 2.50947 1.71736 1.40746 1.63152 2.34448 0.965122 1.37548 1.75937 1.13722 0.964843 1.85569 1.14138 1.94316 1.01279 1.70434 0.951261 1.07527 1.85758 1.86266 1.88043 1.85899 1.3736 3.29207 2.55003 0.74086 1.25132 1.23543 1.76011 1.41237 1.80183 3.98111 1.60084 1.61111 2.82841 0.636239 1.66343 1.0851 1.18772 0.967288 1.4489 2.1501 1.33186 0.568728 1.76964 2.03516 1.32553 0.836115 0.728248 1.7695 1.12029 1.39691 0.934787 2.02271 1.62235 1.99492 2.02537 1.26593 2.37504 1.56469 1.54526 1.42304 1.24338 2.43913 1.70063 1.66386 1.45508 1.73734 1.71727 2.46976 2.1534 1.27311 0.80761 1.08571 1.38296 0.75028 1.62093 2.42364 0.950218 1.18782 0.939149 2.32495 1.20424 1.07031 1.89074 0.940881 1.23777 1.63051 1.35545 0.972986 2.13088 1.16201 1.63286 1.66731 1.53864 1.51782 1.31931 1.96536 2.30052 1.65291 0.76363 1.42166 1.53212 2.36687 1.44043 2.06458 1.30985 0.92435 1.56041 0.866271 0.808731 2.4036 1.05125 1.30809 2.60757 1.90067 0.965795 1.68563 2.78714 2.71615 2.43569 1.44194 1.17978 1.04736 1.32024 1.59191 1.23248 1.30284 3.16903 1.30956 1.68877 1.65795 1.81439 1.26721 1.62879 1.16696 2.09135 0.984327 1.30004 1.29645 2.7467 2.00905 1.40832 3.03974 1.37273 0.949555 1.18973 1.24526 1.49241 3.08646 1.5977 1.67193 1.28989 1.59894 1.58777 1.95121 1.35783 3.76812 1.41195 1.51388 2.65695 0.712831 1.09635 1.78668 1.85598 1.18293 1.09586 2.22189 1.29016 1.94032 1.07421 2.18208 1.73625 1.82911 2.51695 4.10176 1.30919 1.82391 1.90481 0.98496 1.24264 1.43986 0.935824 1.99662 1.13251 1.2704 1.38117 1.73418 1.93345 1.13661 1.36204 2.5499 0.655755 0.927538 4.82216 1.06492 1.51623 1.74622 1.0924 1.55075 3.35677 1.28791 2.63444 0.815266 1.95641 1.61863 3.34087 1.30255 1.10796 1.92093 1.89886 2.46959 1.85946 1.03392 1.37265 1.53801 4.07218 2.32867 3.05853 1.31106 1.47323 1.10362 1.36263 1.72348 2.61045 2.62333 2.0448 0.970161 1.16071 1.96472 1.69258 2.2289 1.89232 1.31582 0.672684 1.37956 1.13495 2.64491 3.71957 1.9353 1.88151 1.01991 3.229 1.34164 1.28976 1.26216 1.45534 1.84833 1.59466 0.616391 2.53443 1.63297 1.67609 0.682161 1.45606 1.12588 1.60193 1.67468 1.03254 1.32939 0.882126 1.4506 1.22018 2.24532 1.63717 1.89392 1.27458 1.6744 3.15152 1.24277 1.32476 1.34808 2.22209 4.15277 2.26066 1.41207 7.10843 1.91434 1.42722 1.16758 2.28787 1.13334 4.97849 1.62244 4.36579 0.962089 1.72477 0.745055 1.61051 1.2431 0.986699 1.04943 1.76088 1.66875 1.87646 1.23915 1.15636 1.65959 1.7186 1.06263 1.30261 1.27503 0.722298 1.29113 1.85851 1.49905 1.98254 1.38458 1.8249 1.28106 1.44834 1.92121 1.22272 1.13313 0 0.984692 1.72865 1.40477 1.01381 5.42473 1.32894 1.16989 1.28758 2.36701 1.61553 1.18072 2.97491 2.12326 2.47051 1.31731 1.68699 1.44843 1.2936 1.70202 0.778696 1.57966 2.01658 2.05043 0.889729 1.29425 1.49371 1.86208 3.00934 0.845872 1.63432 2.09559 1.19584 1.0748 1.51949 1.24155 1.83147 1.27643 2.06688 2.1233 0.791273 2.405 1.2711 1.65121 1.62203 1.29002 1.39259 1.75611 1.83603 1.35627 1.2107 2.06188 1.66793 1.68878 0.992794 1.50162 1.65187 1.50089 2.4135 1.66179 1.82372 1.04993 0.966123 1.48981 1.64333 1.34756 2.07739 1.49628 1.94482 2.2877 1.00756 2.5075 1.79647 2.0263 1.65836 1.62504 1.40637 2.22613 1.04814 8.82874 10.0734 1.53114 1.81281 1.79861 1.36564 0.966336 1.04542 1.46585 2.87893 2.86142 1.03601 1.16332 1.0639 2.00376 2.19102 1.74214 2.53645 3.09731 2.25131 1.0287 1.61047 1.16238 1.5744 1.43121 0.61247 1.96824 1.44955 1.32474 0.820949 1.58694 1.87476 1.10646 2.87533 1.11896 1.61985 1.24583 0.955618 1.41886 8.25607 0.953809 1.60345 1.1453 1.72468 2.19571 1.45486 1.65195 1.20662 2.33476 0.668544 1.42752 0.776337 1.24883 1.6165 3.12149 1.17065 2.89281 1.4704 0.871831 1.71765 0 1.89833 1.48304 1.10527 1.05484 1.322 1.40072 1.32214 1.07122 2.15186 2.58632 1.46119 2.27082 1.92423 2.15558 2.00123 4.05956 1.67308 0.810557 1.8794 2.09004 1.93937 2.18548 2.0653 1.47915 2.87979 1.35893 2.2572 2.64779 3.72168 1.2427 1.53476 1.77341 0 1.37141 3.16009 1.62883 1.77868 0.936505 1.01121 2.02003 1.7415 2.6119 1.2211 1.68055 1.67618 1.28923 1.1565 0.888803 2.00077 1.40191 1.22842 3.32265 2.23035 1.68097 1.37922 2.72818 1.58427 1.16172 1.61285 1.38365 2.21068 1.11714 2.48497 1.70926 2.29303 0.614777 0.826616 1.14033 1.32568 1.97376 1.46051 1.39791 0.851823 1.31217 1.48287 1.5753 1.60175 1.4917 1.82912 3.49967 1.78341 1.07665 2.76018 1.24817 1.51552 1.75069 1.52063 1.54518 1.72152 3.64214 1.55418 2.05281 1.79274 1.64089 2.7247 2.85671 1.56793 2.20985 0.822054 1.14285 1.13146 1.2844 1.45154 1.09308 1.74956 1.62523 1.92158 1.96045 0.999396 1.58986 1.3937 2.04681 1.53898 1.57887 1.41973 0.989498 2.06792 2.01642 1.97929 2.13961 1.0978 1.06776 1.81619 1.16695 1.66712 1.51125 2.48081 3.44718 2.69309 2.69828 1.77457 2.59969 0.855592 1.0432 1.0963 1.97213 1.40549 1.8487 2.55825 1.55283 1.16518 1.30535 1.3998 1.64871 1.67781 1.66906 1.24336 1.96754 1.04458 2.26573 1.03932 2.48317 0.98343 1.27212 1.18481 2.28328 2.16687 2.18478 1.83538 2.27798 1.02306 2.56639 0.897956 1.44429 1.20734 1.09011 1.68473 0.623876 1.89595 1.42343 1.45706 2.27918 1.04562 1.03428 2.24062 1.46145 1.04067 1.69275 1.95007 1.77861 1.24497 1.24568 1.11317 1.57389 1.18549 1.49463 1.86156 1.17042 1.39398 1.27009 1.74197 1.7829 2.27918 1.83068 2.66246 1.00974 1.60434 1.9145 2.16746 2.12107 2.93149 0.835855 2.00527 2.06586 1.63469 1.74878 1.52043 1.46558 2.15193 0.709102 1.80058 1.36656 4.60078 4.4909 1.4785 1.25739 1.70052 1.57899 1.56477 1.83939 1.19368 1.28561 3.9053 2.32041 1.40635 1.46502 1.87117 1.54126 1.78326 1.84542 2.52581 3.32697 1.73124 1.94241 2.8622 3.04797 1.40361 2.1226 2.48434 0.881412 1.61979 1.43449 1.72264 0.978021 1.72336 1.21568 0.888621 2.19648 1.71035 0.932009 0.951494 1.78038 1.22834 1.11691 1.19772 1.5663 1.63614 2.39105 1.77396 1.88537 0.989873 0.989758 1.23408 0.795589 1.59228 1.42241 1.80234 2.68326 1.14811 1.712 1.31284 1.35211 1.34593 1.87171 1.86343 1.8159 1.80345 2.16502 1.67263 1.03587 1.38991 3.31781 1.31639 0 3.82538 0.998238 2.33429 1.47523 1.42041 1.34638 2.07277 1.99287 1.39418 2.29036 0.854373 1.48148 1.50947 1.3864 1.3706 3.64531 1.65371 1.25457 1.54741 1.95263 2.73567 1.86534 2.17309 2.35875 1.52741 2.3154 2.10849 2.20729 1.94199 1.79273 1.72518 1.30445 0.9101 0.87036 1.76457 1.84159 1.18264 1.26435 2.76141 1.0204 1.02888 1.10265 1.08217 0.831365 1.88308 1.45773 1.22305 1.29504 2.13724 1.55065 1.67259 1.61943 2.55477 1.25769 2.22617 1.24275 1.81161 2.2311 1.4461 1.01399 1.61144 0.948708 1.80001 0.795455 1.60351 1.7183 1.66801 1.3716 1.85393 1.35646 2.8157 2.37007 4.02554 1.84898 1.73844 1.41962 1.4659 1.06972 0.787766 1.50184 1.10785 2.17125 1.05007 1.49401 1.93809 1.21305 1.55898 1.27174 1.85769 2.71196 1.69157 1.32191 1.07989 1.30903 3.44005 3.8403 1.31661 1.56835 0.765408 1.55999 2.19174 2.01947 2.40884 2.07057 1.14799 1.63917 1.84559 0.782364 1.84259 1.85438 0.827315 0 1.66634 1.24171 1.34762 3.26282 3.56423 1.28706 1.12008 1.43694 1.38209 2.12673 2.01871 1.51726 1.32466 1.51403 1.4041 1.61601 0.909404 0.737191 2.32712 0.98969 1.61356 1.84351 2.14472 0.719276 1.40592 0.870609 1.66304 3.58312 1.63187 1.21018 1.47083 1.63876 1.54931 2.20202 1.43717 2.13691 1.4567 2.47126 1.34783 2.07646 1.38726 0.987335 2.48718 1.45151 2.10629 0.982467 2.79963 1.09148 2.60789 1.7204 2.59221 1.75418 0.963065 1.54253 1.44329 1.95538 1.74699 1.60916 2.82786 2.19157 0.974787 2.21548 2.14238 1.57715 1.1151 1.51199 1.40396 2.00894 1.1827 2.13525 2.51191 2.17577 1.36927 1.21567 1.7998 1.92067 1.43098 2.03744 2.75388 1.18931 1.93091 1.06983 1.02829 1.42856 1.47701 1.72109 1.91376 2.46078 1.56065 2.98852 1.29838 1.79306 1.67904 1.15233 0.921201 2.256 1.57038 1.69483 1.18132 1.69138 2.14023 2.01821 1.90462 1.49289 1.74649 2.09546 1.98349 1.82871 0.85678 1.32308 1.26617 1.6705 1.70721 1.18343 1.73652 1.68605 1.92966 1.675 1.03488 1.534 1.53221 2.9149 1.4757 1.50133 2.53821 2.51532 1.4186 4.40016 1.38166 2.43889 2.56076 1.34885 1.19904 1.5235 2.74751 1.30952 1.62262 1.37281 1.54231 0.684379 3.54844 1.91836 0.638838 3.5473 1.15872 2.42169 1.39519 3.26711 0.952985 1.25802 1.07097 1.69424 3.21286 2.34227 1.34778 1.84004 1.26568 1.804 1.92272 1.55908 2.18048 1.525 3.48573 1.32447 1.78433 0.940016 2.20039 1.44263 1.50136 1.60793 1.0261 1.51711 1.30673 0.895711 2.22084 2.62798 1.49326 1.27034 1.8561 1.87651 1.68466 1.17922 1.78345 2.15542 3.03975 1.79741 2.00967 1.47394 2.47479 0.930284 1.92796 1.75095 1.04917 1.8762 1.37782 1.54265 1.48169 1.45271 1.48317 1.21931 1.0952 1.25996 1.87748 1.48838 1.72232 1.80958 2.08821 0 1.51536 1.73102 1.43967 2.7093 1.7834 2.54081 2.52377 1.15869 2.38698 1.47513 1.74409 1.85949 0.737965 1.17042 1.70748 1.20848 1.90308 0.834992 2.06871 2.18671 1.86825 1.64816 1.32989 1.27902 2.59527 1.722 1.24839 2.15642 1.56686 2.77817 1.71788 1.53766 1.44823 1.51381 0.908624 1.83738 1.1137 2.11589 1.10435 1.22214 1.85218 1.06221 1.96147 1.4694 1.46962 1.24982 1.87725 1.21835 0.76462 2.93075 1.39683 1.65454 1.57439 1.54982 2.06789 2.99517 1.55136 2.90523 2.225 1.09885 1.43264 0.391942 ]
@@@ Frame-accuracy per-class: [ 76.1722 67.8788 67.0623 58.0645 40.5063 56.3536 54.9801 48.2759 59.19 76.1453 84.2266 48.318 78.1038 67.7824 45.8289 60.1626 59.5533 60.9929 66.1499 74.8025 83.871 60.5678 86.5065 68.4685 62.6186 40.5229 70.5632 75.2166 66.0482 69.7789 22.3602 50.3817 74.6269 54.9451 77.592 57.3248 77.9506 90.8686 70.1031 43.4286 65.0602 63.5294 33.5601 46.4865 83.0601 82.0189 63.3229 57.4713 66.1829 71.3043 72.4234 87.4538 25.8065 75.1423 42.5703 80.7525 69.4316 76.0331 47.619 52.0107 54.2056 48.21 55.1724 75.9825 83.4403 60.4651 38.2979 70.3218 63.0201 63.1579 71.3287 58.8997 67.4033 22.7488 43.0769 53.4704 62.6506 86.6624 71.3681 78.7535 39.521 57.1429 65.9517 34.4348 72.0682 58.0336 72.9187 71.3959 50.7772 39.4299 70.3268 53.598 73.3668 67.9597 50.5263 79.2793 60.9442 55.1724 32.0346 68.472 32.8205 68.9295 77.8098 67.3575 62.8099 78.8767 44.8133 59.176 67.8899 82.4501 72.2689 30.1075 66.3212 64.8649 89.1832 48.1301 74.4745 42.4242 53.0612 16.2162 73.1102 46.7005 74.8466 30.9392 74.7875 24.2991 49.9133 67.8304 47.7064 60.6965 50.2024 61.6514 63.8298 58.0645 69.8795 60.4651 51.1628 62.2951 51.2397 60.0791 65.8228 48.5437 63.2124 41.2121 67.2606 22.108 73.107 43.5644 44.2953 65.4206 52.514 49.5575 63.2911 55.9727 42.654 72.3404 65.4867 67.9245 62.4642 82.1355 51.3089 74.3682 25.9542 10.9091 63.5897 68.4105 54.5455 53.7445 74.7941 62.3907 66.0066 68.9139 32.2275 73.5484 62.521 69.3467 55.7121 49.2754 72.6531 78.2301 65.5462 56.6535 55.2189 45.4681 34.8624 35.9712 73.6318 68.9342 62.1723 63.9053 0 68.6869 40 68.599 32.3024 61.4433 52.4017 82.679 57.4163 54.7945 45.3608 54.0541 76.3552 76.873 63.8132 74.0525 72.399 68.5422 73.3154 21.9931 56.4972 40 49.3724 39.413 42.953 12.9032 37.6812 60.438 69.4301 64.1509 76.6169 63.9456 48.4472 51.7073 59.4595 54.359 58.7156 51.3274 65.3465 29.1892 80.0937 52.7919 60.7735 44.1767 67.5815 48.2759 44.0066 60.7509 84.5886 65.8009 79.1587 60.9524 63.286 79.7954 27.1845 29.6296 40 49.4888 78.9668 79.646 55.3846 70.4453 66.3616 76.3636 54.5455 52.987 75.0958 70.2703 67.4286 35.3698 37.0732 73.9884 75.0853 0 72.1893 82.1092 69.8507 52.4444 76.3557 39.7906 32.7869 56.1702 65.1163 80.397 18.9274 70.8772 70.2703 38.2916 62.8099 54.5455 65.4088 13.3333 76.3702 52.0147 41.0646 73.6 57.1429 64.1096 72.8324 67.6533 64.0693 42.8969 48.3005 32.0856 46.5882 80.7626 72.6592 39.4984 49.2197 57.8199 53.0184 10.8844 13.7931 59.2941 67.9646 54.6697 44.3497 67.2165 74.0214 40 77.3073 44.0433 62.9921 73.9884 75.4717 72.956 47.5138 26.9663 67.8201 59.2885 69.7509 64.0264 49.863 47.9303 74.5679 34.2944 34.5178 58.156 43.3735 40.708 51.1278 69.5157 65.285 63.8821 62.4204 68.1351 75.6477 43.0913 61.7284 60.4444 74.3472 50.3067 58.7196 47.0588 60.0567 75.2328 40 50.7463 63.9175 44.6512 64.8259 39.485 51.4286 59.0571 31.0204 75.4036 38.7097 69.1689 56.2771 73.7657 43.6658 46.9565 41.3374 61.7886 65.5072 79.6834 22.2222 41.0042 51.7647 67.6145 42.4942 61.8182 65.3199 73.4226 45.8924 47.6596 56.5056 44.6043 48.8189 55.4839 75.3684 29.6943 58.0645 56.9784 71.6418 78.5185 61.0723 17.284 59.6685 51.8135 40 65.285 48.8064 75.0809 69.4517 54.7771 74.6137 79.2873 71.777 30.0885 57.1429 58.5366 58.3691 71.3376 28.5714 45.3782 34.6667 48.7805 73.6899 57.7778 34.4828 54.2636 63.2375 64.5533 71.7678 74.477 58.2231 73.4694 49.0501 54.7643 65.0124 59.8504 81.1092 48.0938 86.5672 34.9776 36.8932 67.8112 54.7945 30.2158 68.6084 60.9137 45.815 66.6667 70.2222 37.7104 67.7741 45.5312 70.2065 43.0493 70.4 65.5335 33.6842 52.3077 41.8605 45.7478 62.2222 25.641 41.0256 78.0856 64.4068 67.4157 54.4218 62.6866 51.8519 23.5294 54.8263 53.7313 34.7826 83.7061 69.3878 70.3518 64.8199 78.8991 50.6329 37.193 61.4719 86.3188 44.9568 58.8235 75.5556 79.4326 77.747 49.6241 73.2106 57.2048 74.9091 41.5459 42.4403 44.4444 37.6238 59.8131 40 58.6552 62.9969 57.0136 58.5949 28.7719 42.6667 54.5455 59.8291 50.4472 62.2222 23.7885 34.3234 62.1924 74.8652 73.9884 59.661 79.0402 57.7215 37.2881 68.5552 65.0519 74.2616 30.5732 64.1975 69.8885 57.0281 66.6667 66.171 67.3993 59.5745 70.303 26.5896 68.5714 55.4622 53.1073 57.2152 60.5317 62.1196 29.108 33.8462 65.3595 81.9137 65.5738 62.1118 46.281 63.0137 54.902 64.3579 70.073 53.6585 77.0563 81.407 41.0866 69.1892 65.5738 38.0952 45.4054 71.1504 35.2239 22.2222 37.037 30.6636 61.4379 66.9261 69.8892 49.6644 58.2751 62.6398 64.4211 14.6341 63.2479 49.0798 47.1513 51.0978 66.9474 55.9441 61.7564 36.2123 73.7186 63.3745 62.4729 20.339 28.1481 63.8596 26.2626 60.5042 73.065 62.6632 63.8498 57.6 31.9249 59.6491 54.5455 63.9004 49.4037 39.5909 46.9136 66.9281 13.0081 62.0939 54.2694 30.9677 81.3128 74.3633 58.9595 56.1404 67.5325 64.3777 41.8848 63.1319 52.093 65.053 37.3541 52.0446 49.505 28.4264 24.2424 60.98 57.0806 49.8728 77.5665 62.4754 45.1827 74.8387 43.8356 66.087 65.252 55.144 50.5564 47.7876 68.8172 60.6232 48.4848 84.0367 75.0913 0 76.6355 52.4917 49.2891 68.6256 56.6572 7.40741 65.4867 29.304 77.9783 58.0645 55.0369 19.2593 65.8436 67.4016 51.7647 44.1103 34.5898 50.2793 67.9868 60.3175 54.6419 17.5182 55.3191 26.4463 57.8445 58.9831 62.1908 65.6331 46.1538 30.5882 29.0909 42.5397 77.0764 67.6203 52.6316 52.1401 58.8235 46.8085 58.3569 80.261 61.3546 68.3473 40.7843 12.9032 53.2544 48.9104 71.6792 25.8065 58.1649 62.4506 69.969 61.0687 54.4061 51.3471 83.6028 38.0952 52.5822 54.2125 80.0456 57.3585 66.9456 65.6716 42.1053 67.4556 57.9104 74.4961 62.0155 66.2722 59.5745 53.4161 40 62.2951 57.3494 17.801 68.1648 64.8715 59.6315 28.7425 17.9104 26.1072 60.4572 0 40 61.7886 63.5007 22.4 67.433 0 56.4565 0 70.2866 54.0845 78.7194 54.6845 62.9921 78.0488 68.5851 46.0064 50.3497 54.3517 55.6348 69.3512 49.3116 55.3459 65.7627 54.9254 67.7551 75.9721 63.1376 57.1429 60.0451 39.6947 56.4706 44.6529 66.0929 61.8629 39.3013 66.6667 67.5068 0 71.8987 47.0187 55.2147 70.7942 0 55.4217 63.9456 68.2303 36.6972 56 62.8399 11.9403 56.8306 27.685 71.066 57.1429 56.4417 66.5973 53.2213 75.7649 59.3607 49.3151 46.1538 71.254 64.1148 49.9115 41.847 22.8311 74.0525 53.8667 39.4366 59.6226 72.5995 57.6271 65.3422 51.4056 61.4379 43.5644 64.5161 80.5684 32.0988 57.6271 54.5455 51.8375 65.3563 57.9048 53.2374 42.1405 61.8357 53.9877 49.5726 61.3139 50.3226 73.4694 59.0604 52.987 52.6984 24.8705 54.9889 48.9796 67.8663 78.4252 54.8043 52.973 55.3616 43.2653 64.8649 62.069 31.1787 73.3411 29.4985 34.5946 36.2606 50.6667 46.8966 54.7368 35.443 71.159 0 0 64.6766 60.4651 48.7562 63.8436 65.0206 69.2564 57.2973 18.6047 33.4728 73.4226 68.8963 68.1967 39.1111 37.2624 54.6448 28.0702 22.9299 44.3515 62.8952 55.6131 69.7168 56.5056 55.3846 84.7521 43.0769 58.5507 64.2623 79.5411 51.0638 50.7157 69.3603 18.2857 68.1564 53.2562 58.6572 71.7241 52.9915 0 69.8616 52.5153 63.1043 51.9856 45.2297 60.6897 59.8425 70.2703 38.0744 78.0715 56.6038 78.2453 66.1035 49.7132 26.4151 66.9366 27.5862 51.7799 76.5957 49.0862 0 33.1429 60.7069 73.2919 67.9245 77.9221 58.4615 57.6803 70.5142 48.0938 23.6559 67.7966 31.8644 46.8591 46.9136 47.1545 0 52.9262 79.4979 43.6526 45.8781 38.9685 49.1228 33.7778 55.3606 29.6907 57.0342 47.3118 35.7447 22.6244 62.6642 57.3754 50.0942 0 61.5385 18.4438 55.4248 51.6129 66.8501 71.9566 38.6207 51.5464 25.3165 69.0745 57.3134 44.5596 62.5551 65.8579 72.8972 37.8378 61.9608 62.543 8 40.8163 53.4562 66.5461 19.1781 53.5593 66.3438 49.3454 57.6271 48 60.9009 36.3636 48.996 43.4286 80.9023 84.3636 67.433 64.7687 51.5464 52.1739 58.6319 77.8378 67.0695 57.8588 49.7696 63.4561 58.4565 51.0638 0 49.2918 72.7651 23.7624 62.8931 58.0271 61.6715 60.2597 52.3227 52.7473 21.3333 45.768 40.678 44.898 50.3401 27.027 24.8139 57.5945 44.0281 74.6759 68.1481 67.7452 63.3235 64.7303 71.8894 53.8071 63.0542 48 36.0563 72.6899 53.897 60.48 55.0459 61.3333 51.8519 57.9505 71.9637 46.9945 44.584 40.4181 40.3306 68.7307 72.5076 43.8819 60.5505 53.7988 62.8352 26.6667 13.4969 27.6364 43.8095 52.4934 29.7872 78.4314 64.3533 70.61 50.1493 50.4854 48.566 31.5152 55.794 64.3678 57.1429 59.3607 52.5597 60.5714 50.9225 64.4068 47.7212 70.0219 35.8423 72.8729 18.3908 70.5657 66.4137 66.4165 37.2932 43.7795 39.2157 41.4458 26.988 72.956 29.2683 76.3797 64.818 67.052 71.04 55.9194 81.8288 42.6778 59.8698 48.7554 28.8288 68.1265 67.6343 35.3247 57.1429 68.1648 52.9644 57.1429 53.8922 61.2836 68.0851 67.7966 58.9862 60.1942 56.4885 50.1529 66.6667 64.6617 65.5271 53.5519 44.7205 33.8858 53.3865 29.4737 68.6567 58.5812 49.3506 39.2283 37.6528 31.1436 72 47.3595 36.2989 55.1181 48.2173 63.3205 68.8797 35.8595 79.8086 48.3092 60.0939 3.50877 0 62.0209 63.8783 43.5146 51.5513 57.9805 48.6891 63.662 66.3415 7.40741 32.0988 62.1701 57.0048 49.8168 59.5289 39.6947 51.3966 31.5186 16 52.4496 45.7831 16.7939 12.766 56.9402 33.9483 35.9447 74.8387 60.3279 63.1579 40.8922 70.8698 53.9619 68.0641 76.9964 30.8197 59.5745 72.3164 74.5865 52.6564 70.9141 67.9552 69.2913 55.4361 51.0251 23.6559 53.1309 46.2136 69.1943 72.6208 68.0352 72.8477 51.4914 62.8445 43.4929 34.5679 64.9573 47.5524 64.2581 58.5538 64.2424 54.7009 45.3782 48.951 46.1538 39.6262 52.043 72.8929 58.018 20.5128 59.2275 0 17.3913 72.4211 38.7597 61.8026 62.5793 61.6924 38.0062 42.2018 62.1005 31.74 75.154 58.7387 65.861 64 61.1544 11.6592 53.4351 62.069 59.4286 44.4444 26.8354 45.509 37.0732 37.6997 55.9876 40 27.4914 43.0189 54.5455 39.1489 54.3417 60.8059 70.9447 74.023 45.5373 49.1103 70.7214 66.6036 32.5792 68.5817 77.1005 71.1643 72.2861 76.9648 51.7824 58.5736 68.4685 59.413 35.6495 55.2279 54.0084 52.6868 31.3993 58.5956 27.1186 67.5728 48.2085 41.4201 56.4232 66.8116 61.1296 75.0685 49.5238 76.8095 62.4672 54.0541 52.1739 62.1578 44.9304 61.1494 19.6721 39.2947 3.07692 43.038 46.7005 58.9372 60.1258 72.0257 79.1155 52.8678 72.4936 38.2979 74.3935 59.0164 44.0367 65.9649 58.1986 70.7288 47.4797 36.7347 50.5636 63.0408 69.5985 77.0186 21.9653 7.94702 60.6335 58.6047 72.8972 58.4104 37.5297 45.0331 41.2371 45.5172 62.8571 52.8302 58.0205 78.0774 46.7583 50.1441 78.6555 0 57.7861 70.8688 62.7986 21.9608 12.9032 63.3381 67.1293 60.5876 66.6667 34.8178 46.0808 60.6272 62.8842 60.9071 59.2777 58.156 78.5965 79.9439 29.7735 67.3797 61.6822 56.168 44.6735 82.243 57.3146 79.3204 54.6498 11.6456 52.4313 69.1824 59.4966 53.5961 57.8811 56 54.1608 39.2727 57.2308 36.0656 65.1357 44.7257 61.4703 71.1434 34.5679 55.6213 39.2661 71.4571 29.2683 67.3874 34.4828 56.1194 43.956 50.2924 75.4635 55.7491 58.194 52.3944 50.4615 64.7887 22.2222 40.3101 74.938 46.89 39.1691 54.5455 67.6692 53.6377 61.415 34.8624 67.1074 44.6771 33.5378 40.8163 62.2222 67.6409 45.1128 42.8829 68.144 54.0881 30.4183 71.9764 53.0806 69.8055 70.6994 60.1093 62.0047 48.474 47.0588 20.5128 58.0645 23.5294 60.6061 49.7354 56.4486 68.8822 73.7468 41.4873 56.4706 55.5332 68.9249 56.7164 45.0766 50.9091 54.3933 50.1818 59.4595 47.5096 46.4135 53.7634 79.6253 63.7206 68.4039 48.5175 53.1646 68.7259 50.2024 51.5837 52.302 44.9704 71.2906 52.4217 45.3901 19.9234 64.3357 60.4317 24 31.0912 57.6419 8.69565 61.1036 40.0703 18.8235 55.1724 71.5152 57.3744 28.5714 59.1273 51.5254 61.8026 58.2011 77.7518 20.4255 42.623 82.399 17.9775 71.3568 20.9424 70.5882 6.45161 71.1755 62.3436 68.642 50.7937 9.23077 36.8504 61.4994 45.037 61.442 45.1337 47.8873 56.6038 39.7213 58.9595 12.8655 59.751 52.6619 71.28 35.474 63.5659 53.5304 51.4851 71.3755 57.9505 61.0169 74.6953 44.7205 37.5758 62.2951 65.4804 36.4444 50.1511 56 67.2065 57.3304 45.8537 28.8288 60.5714 48.9796 57.0637 35.9882 74.6667 44.4444 58.3979 68.6211 54.8223 58.1818 62.94 60.6061 60.2659 56.8562 68.7719 66.8622 64.4275 40.4908 58.466 58.5034 50.5747 39.7163 0 57.6598 51.462 58.7196 23.8411 50.7772 25.7778 29.912 63.0496 43.871 57.2707 51.9351 45.8182 79.1381 68.4129 67.6923 71.8615 57.8797 74.9186 39.1061 40.2036 44.1472 58.1053 64.745 65.2118 27.3764 51.6129 68.6084 40 61.674 17.5824 51.9573 57.4209 61.6541 46.6926 77.7963 41.8605 64.3357 36.0902 70.5075 61.7092 43.8819 69.9708 45.3865 64.0316 62.7832 63.4146 45.7831 62.7737 80.1196 29.9401 64.3275 45.3988 52.5547 52.4655 36.1045 16.8224 53.8813 26.8097 36.1233 62.8272 69.6697 89.6576 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 1.31746 (Xent), [AvgXent: 1.31746, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 62.4183% <<

