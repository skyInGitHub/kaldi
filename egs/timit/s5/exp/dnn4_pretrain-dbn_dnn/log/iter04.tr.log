nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.008 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter03_learnrate0.008_tr1.3175_cv2.1652 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter04 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975016
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.86424, max 7.06273, mean -0.000964877, stddev 0.993005, skewness 0.0133901, kurtosis 2.03207 ) 
[1] output of <AffineTransform> ( min -27.552, max 20.3016, mean -3.23802, stddev 3.70334, skewness 0.129504, kurtosis 1.52118 ) 
[2] output of <Sigmoid> ( min 1.08227e-12, max 1, mean 0.195379, stddev 0.300598, skewness 1.59599, kurtosis 1.16439 ) 
[3] output of <AffineTransform> ( min -29.728, max 17.7615, mean -4.01747, stddev 2.78103, skewness -0.00216087, kurtosis 2.99484 ) 
[4] output of <Sigmoid> ( min 1.22832e-13, max 1, mean 0.0976347, stddev 0.195031, skewness 2.93911, kurtosis 8.47858 ) 
[5] output of <AffineTransform> ( min -14.7662, max 12.4589, mean -3.22137, stddev 2.02733, skewness 0.643538, kurtosis 2.61588 ) 
[6] output of <Sigmoid> ( min 3.86481e-07, max 0.999996, mean 0.10896, stddev 0.189599, skewness 2.84205, kurtosis 8.14608 ) 
[7] output of <AffineTransform> ( min -23.0815, max 14.3425, mean -2.94761, stddev 2.26109, skewness 0.591427, kurtosis 3.03237 ) 
[8] output of <Sigmoid> ( min 9.4591e-11, max 0.999999, mean 0.139846, stddev 0.225215, skewness 2.28257, kurtosis 4.57899 ) 
[9] output of <AffineTransform> ( min -16.5543, max 15.6578, mean -2.95253, stddev 2.75081, skewness 1.35211, kurtosis 2.8504 ) 
[10] output of <Sigmoid> ( min 6.465e-08, max 1, mean 0.164483, stddev 0.280414, skewness 1.91396, kurtosis 2.35698 ) 
[11] output of <AffineTransform> ( min -27.6436, max 17.8559, mean -3.71242, stddev 3.40201, skewness 1.00755, kurtosis 3.51295 ) 
[12] output of <Sigmoid> ( min 9.87533e-13, max 1, mean 0.139283, stddev 0.2826, skewness 2.1792, kurtosis 3.28591 ) 
[13] output of <AffineTransform> ( min -12.1703, max 21.1693, mean -0.00171271, stddev 3.16427, skewness 0.603643, kurtosis 1.13671 ) 
[14] output of <Softmax> ( min 9.10194e-14, max 0.998191, mean 0.00064757, stddev 0.0167895, skewness 40.1741, kurtosis 1821.78 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.80598, max 0.89628, mean 1.1531e-05, stddev 0.0538942, skewness -0.568888, kurtosis 32.1922 ) 
[1] diff-output of <AffineTransform> ( min -0.339766, max 0.281407, mean -2.69328e-05, stddev 0.00993373, skewness -0.136085, kurtosis 59.1737 ) 
[2] diff-output of <Sigmoid> ( min -1.36547, max 1.38231, mean -0.000169817, stddev 0.0861307, skewness -0.0619617, kurtosis 11.7802 ) 
[3] diff-output of <AffineTransform> ( min -0.289374, max 0.251869, mean -1.94189e-05, stddev 0.0106446, skewness -0.333049, kurtosis 63.371 ) 
[4] diff-output of <Sigmoid> ( min -2.68029, max 1.8057, mean 5.35733e-05, stddev 0.109348, skewness -0.0444843, kurtosis 9.61813 ) 
[5] diff-output of <AffineTransform> ( min -0.497388, max 0.256102, mean 3.37902e-05, stddev 0.0109553, skewness -0.774239, kurtosis 68.4292 ) 
[6] diff-output of <Sigmoid> ( min -1.99112, max 1.32316, mean 0.000123093, stddev 0.094347, skewness -0.111999, kurtosis 9.50289 ) 
[7] diff-output of <AffineTransform> ( min -0.288067, max 0.247896, mean 6.52966e-05, stddev 0.0093669, skewness -0.305137, kurtosis 39.7527 ) 
[8] diff-output of <Sigmoid> ( min -1.38817, max 1.06947, mean 0.000331806, stddev 0.0725205, skewness -0.082294, kurtosis 8.70797 ) 
[9] diff-output of <AffineTransform> ( min -0.192586, max 0.124176, mean 3.76467e-05, stddev 0.00738105, skewness -0.562747, kurtosis 36.9869 ) 
[10] diff-output of <Sigmoid> ( min -0.82879, max 0.690796, mean 7.69474e-05, stddev 0.057302, skewness -0.16417, kurtosis 9.90092 ) 
[11] diff-output of <AffineTransform> ( min -0.17701, max 0.291696, mean 9.93101e-05, stddev 0.00872576, skewness 0.117899, kurtosis 45.9989 ) 
[12] diff-output of <Sigmoid> ( min -1.17384, max 2.008, mean 0.000907505, stddev 0.0954452, skewness 0.0936622, kurtosis 6.59934 ) 
[13] diff-output of <AffineTransform> ( min -0.99994, max 0.981161, mean -1.26452e-08, stddev 0.0198999, skewness -24.674, kurtosis 1594.03 ) 
[14] diff-output of <Softmax> ( min -0.99994, max 0.981161, mean -1.26452e-08, stddev 0.0198999, skewness -24.674, kurtosis 1594.03 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.84474, max 1.71347, mean -0.000246394, stddev 0.162686, skewness 0.028237, kurtosis 2.34913 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.60246, max 0.675347, mean -0.00689482, stddev 0.169787, skewness 0.000740708, kurtosis 0.732205 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -1.07916, max 0.788601, mean -0.000472311, stddev 0.0662844, skewness -0.179614, kurtosis 8.10281 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.00008, max 0.985266, mean -0.00497124, stddev 0.195221, skewness -0.064116, kurtosis 2.76617 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -1.09136, max 0.657625, mean 0.00110156, stddev 0.0415903, skewness -0.200149, kurtosis 17.0256 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.18271, max 0.891888, mean 0.00865029, stddev 0.209395, skewness -0.0756352, kurtosis 2.92483 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.958665, max 0.55042, mean 0.00194205, stddev 0.0364655, skewness 0.151541, kurtosis 13.7473 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.960366, max 0.738221, mean 0.0167159, stddev 0.184486, skewness 0.202238, kurtosis 2.45437 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.613761, max 0.501886, mean 0.00152913, stddev 0.0348414, skewness 0.103961, kurtosis 9.37826 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.712502, max 0.695086, mean 0.0096376, stddev 0.142808, skewness 0.0967099, kurtosis 3.15036 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.817356, max 0.723448, mean 0.00444613, stddev 0.0487475, skewness 0.475361, kurtosis 9.97924 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.837366, max 0.634441, mean 0.0254234, stddev 0.158596, skewness 0.0999608, kurtosis 3.31906 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -3.61272, max 3.75068, mean -5.10318e-09, stddev 0.105744, skewness -3.72708, kurtosis 83.3801 ) , lr-coef 1, max-norm 0
  bias_grad ( min -3.44155, max 3.32429, mean -1.17356e-08, stddev 0.347113, skewness -1.18137, kurtosis 17.4613 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 331520 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.8171, max 6.44093, mean -0.00429144, stddev 1.00295, skewness -0.0631885, kurtosis 1.97814 ) 
[1] output of <AffineTransform> ( min -28.8602, max 21.8891, mean -3.29571, stddev 4.03774, skewness 0.123464, kurtosis 1.38501 ) 
[2] output of <Sigmoid> ( min 2.92543e-13, max 1, mean 0.207093, stddev 0.31421, skewness 1.4924, kurtosis 0.766597 ) 
[3] output of <AffineTransform> ( min -27.5674, max 17.9724, mean -4.11063, stddev 2.88859, skewness 0.020483, kurtosis 2.64477 ) 
[4] output of <Sigmoid> ( min 1.06566e-12, max 1, mean 0.0990202, stddev 0.199571, skewness 2.8868, kurtosis 8.06793 ) 
[5] output of <AffineTransform> ( min -14.7896, max 14.4789, mean -3.20963, stddev 2.05634, skewness 0.624193, kurtosis 2.55461 ) 
[6] output of <Sigmoid> ( min 3.77539e-07, max 0.999999, mean 0.111456, stddev 0.192374, skewness 2.78031, kurtosis 7.72303 ) 
[7] output of <AffineTransform> ( min -21.8837, max 14.5203, mean -2.87469, stddev 2.29822, skewness 0.600168, kurtosis 2.83447 ) 
[8] output of <Sigmoid> ( min 3.13357e-10, max 1, mean 0.147494, stddev 0.231925, skewness 2.17699, kurtosis 4.01965 ) 
[9] output of <AffineTransform> ( min -15.7935, max 16.6029, mean -2.91731, stddev 2.84294, skewness 1.36026, kurtosis 2.84536 ) 
[10] output of <Sigmoid> ( min 1.38345e-07, max 1, mean 0.170405, stddev 0.286881, skewness 1.84753, kurtosis 2.0689 ) 
[11] output of <AffineTransform> ( min -27.4813, max 19.3669, mean -3.79048, stddev 3.54434, skewness 0.972182, kurtosis 3.35506 ) 
[12] output of <Sigmoid> ( min 1.16153e-12, max 1, mean 0.140207, stddev 0.286527, skewness 2.16151, kurtosis 3.17427 ) 
[13] output of <AffineTransform> ( min -15.2526, max 22.3592, mean -0.00278418, stddev 3.39022, skewness 0.570933, kurtosis 1.1126 ) 
[14] output of <Softmax> ( min 1.38168e-15, max 0.999161, mean 0.000647594, stddev 0.0187849, skewness 40.5513, kurtosis 1788.07 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.943491, max 0.8031, mean 0.00015302, stddev 0.0451401, skewness 0.0125446, kurtosis 22.0039 ) 
[1] diff-output of <AffineTransform> ( min -0.235272, max 0.517429, mean 7.52541e-05, stddev 0.00835701, skewness 2.15621, kurtosis 138.302 ) 
[2] diff-output of <Sigmoid> ( min -2.11541, max 3.60849, mean 0.000479108, stddev 0.0768387, skewness 1.90973, kurtosis 96.3905 ) 
[3] diff-output of <AffineTransform> ( min -0.260618, max 0.789755, mean 2.75027e-05, stddev 0.00948886, skewness 4.9448, kurtosis 394.121 ) 
[4] diff-output of <Sigmoid> ( min -2.06054, max 3.26296, mean 4.49681e-05, stddev 0.0972098, skewness 0.45424, kurtosis 31.6112 ) 
[5] diff-output of <AffineTransform> ( min -0.325763, max 0.687554, mean 4.56748e-05, stddev 0.00983631, skewness 3.99565, kurtosis 305.962 ) 
[6] diff-output of <Sigmoid> ( min -1.64081, max 3.35827, mean 0.000359741, stddev 0.0858518, skewness 0.901327, kurtosis 38.8375 ) 
[7] diff-output of <AffineTransform> ( min -0.163059, max 0.562028, mean 2.55676e-05, stddev 0.00844051, skewness 3.36432, kurtosis 216.139 ) 
[8] diff-output of <Sigmoid> ( min -1.35778, max 2.36259, mean 0.00010636, stddev 0.0641294, skewness 0.456554, kurtosis 30.2235 ) 
[9] diff-output of <AffineTransform> ( min -0.281083, max 0.359621, mean 1.51187e-05, stddev 0.00656523, skewness 1.44713, kurtosis 138.032 ) 
[10] diff-output of <Sigmoid> ( min -1.19253, max 1.44069, mean 1.31983e-05, stddev 0.0503915, skewness 0.295215, kurtosis 24.3353 ) 
[11] diff-output of <AffineTransform> ( min -0.500885, max 0.330834, mean 1.93178e-05, stddev 0.00741609, skewness -0.752967, kurtosis 181.746 ) 
[12] diff-output of <Sigmoid> ( min -2.01627, max 1.32341, mean 0.000298774, stddev 0.0803781, skewness -0.143875, kurtosis 11.8629 ) 
[13] diff-output of <AffineTransform> ( min -0.999999, max 0.922574, mean -8.5508e-09, stddev 0.0159496, skewness -24.931, kurtosis 2113.45 ) 
[14] diff-output of <Softmax> ( min -0.999999, max 0.922574, mean -8.5508e-09, stddev 0.0159496, skewness -24.931, kurtosis 2113.45 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.23658, max 1.6224, mean 0.00144972, stddev 0.131133, skewness 0.113056, kurtosis 2.60183 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.519669, max 0.85333, mean 0.019265, stddev 0.140229, skewness 0.154494, kurtosis 1.59805 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.542913, max 1.52851, mean 0.000913849, stddev 0.0591869, skewness 1.65171, kurtosis 26.5478 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.623987, max 1.29314, mean 0.00704067, stddev 0.16874, skewness 1.27675, kurtosis 7.37798 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.619214, max 1.79307, mean 0.000874413, stddev 0.0362878, skewness 2.2912, kurtosis 73.5474 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.602965, max 1.73528, mean 0.0116928, stddev 0.174135, skewness 1.62546, kurtosis 13.1576 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.407721, max 1.15506, mean 0.000395573, stddev 0.0304989, skewness 1.66845, kurtosis 43.6383 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.426007, max 1.00666, mean 0.00654531, stddev 0.147892, skewness 1.03434, kurtosis 5.83791 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.505479, max 0.696743, mean 0.00019133, stddev 0.029402, skewness 0.577414, kurtosis 16.429 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.470632, max 0.718619, mean 0.0038704, stddev 0.116931, skewness 0.731952, kurtosis 4.50603 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -1.09985, max 0.592586, mean 0.000533291, stddev 0.0397324, skewness -0.0976647, kurtosis 17.9592 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.09917, max 0.521508, mean 0.00494535, stddev 0.126571, skewness -0.34194, kurtosis 7.23654 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -2.38756, max 2.06971, mean -9.54847e-08, stddev 0.0843874, skewness -4.53546, kurtosis 103.189 ) , lr-coef 1, max-norm 0
  bias_grad ( min -2.36779, max 1.93733, mean -1.1118e-08, stddev 0.26546, skewness -1.54388, kurtosis 14.9693 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0762632 min, processing 72450.8 frames per sec; i/o time 4.97553%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 12529 82 168 15 39 90 125 14 160 949 326 163 664 119 473 184 201 211 193 569 325 158 270 55 263 76 470 288 269 203 80 65 33 45 448 78 546 224 339 87 41 297 220 92 457 158 159 130 5856 862 179 17467 15 263 124 345 325 302 31 186 53 1047 72 114 389 21 23 419 1069 180 214 154 271 105 32 194 124 783 354 176 83 31 186 287 234 208 522 218 96 210 382 201 298 644 47 277 116 333 115 258 97 191 173 96 181 409 120 133 163 726 178 139 96 129 226 307 166 16 24 18 1329 98 244 90 176 53 288 200 54 100 123 272 117 15 41 21 21 91 60 126 197 51 96 82 224 194 191 50 223 160 89 169 118 146 105 70 169 132 174 243 95 138 65 27 97 248 159 113 303 171 151 133 105 77 297 99 319 34 122 282 178 379 148 336 54 208 100 220 133 84 0 247 47 103 145 242 114 216 104 255 48 166 433 153 128 171 581 195 185 145 265 92 119 238 74 15 103 342 96 132 301 367 241 102 18 97 54 169 50 92 213 98 90 124 291 101 304 146 431 115 261 157 246 195 51 13 17 244 135 169 227 123 218 412 126 192 391 18 262 155 102 86 146 8 84 265 167 112 230 95 30 117 236 201 158 427 18 339 60 93 79 7 556 136 131 62 108 182 86 236 115 179 279 93 212 288 133 159 416 105 190 73 14 212 282 219 234 242 140 32 460 138 190 86 26 79 90 133 144 126 140 151 182 229 202 329 98 70 41 56 66 175 96 203 78 340 96 213 364 337 325 81 226 93 176 268 122 33 145 322 416 116 17 201 122 526 15 186 115 516 185 57 164 61 172 568 94 119 42 316 216 137 148 261 176 117 134 69 63 77 237 114 511 347 33 67 214 40 90 96 17 96 188 154 191 78 226 224 143 56 66 20 116 235 10 59 112 20 925 112 101 64 330 173 189 119 264 24 289 498 201 200 288 170 100 111 51 116 255 69 154 98 113 61 112 148 150 296 169 111 187 529 47 97 193 170 112 19 19 198 265 44 73 167 148 25 129 100 34 156 24 99 180 54 118 142 115 354 173 25 22 70 541 199 244 461 412 310 188 49 50 53 42 349 163 110 334 142 37 16 58 279 22 113 151 223 463 86 147 708 197 88 176 144 118 78 283 134 124 217 134 136 164 82 86 87 59 265 197 244 476 106 97 76 428 30 80 60 182 25 346 68 102 346 99 294 462 91 115 92 282 167 22 13 218 76 128 496 74 214 223 237 61 292 81 254 250 237 71 176 480 458 121 230 29 67 142 49 178 161 191 106 62 106 85 203 120 293 684 40 382 61 138 263 77 746 294 86 85 192 116 95 405 107 330 128 134 151 98 16 275 229 196 131 254 150 387 109 172 188 121 314 56 46 176 49 272 684 10 53 150 105 527 176 13 56 136 138 15 203 67 121 317 127 199 225 89 151 283 188 68 23 181 366 147 424 193 84 127 27 157 150 384 28 128 25 70 176 306 125 178 127 77 84 206 199 46 321 126 161 65 130 315 216 31 106 136 438 132 119 33 47 84 167 570 193 84 23 80 162 274 207 95 133 408 298 83 33 214 590 5 107 61 368 62 130 8 166 7 331 177 265 261 63 20 208 156 71 281 350 223 399 79 147 167 122 501 519 24 221 65 212 266 290 284 114 166 555 0 197 293 81 799 7 124 220 234 54 12 165 33 91 209 98 17 81 480 178 1029 328 182 84 777 104 282 346 109 171 187 35 132 213 88 226 373 76 50 15 1407 121 29 82 258 203 262 69 149 103 244 58 68 77 122 372 192 157 96 225 24 194 317 140 92 200 122 18 14 131 429 169 92 176 412 72 47 39 185 6 2 100 21 100 153 121 450 92 21 119 261 149 152 112 131 91 28 78 119 300 289 229 134 97 534 32 172 152 261 70 244 148 87 89 345 141 217 58 4 469 407 196 138 141 72 190 55 228 321 238 558 473 261 26 370 14 772 305 191 0 87 240 80 132 38 97 159 476 170 46 29 147 294 121 307 12 196 119 224 139 174 28 112 256 242 131 46 117 110 266 491 265 0 123 173 382 15 363 1014 217 48 39 221 167 289 113 288 267 18 127 145 12 122 108 276 36 147 206 496 88 137 277 16 124 87 332 137 130 140 48 103 153 92 165 219 108 176 304 117 25 176 240 50 79 258 173 192 204 136 37 159 88 122 73 129 201 727 213 578 202 494 508 120 108 98 101 62 177 243 378 312 54 37 94 141 440 91 318 143 302 161 165 118 54 243 130 127 81 137 52 190 117 433 158 270 167 51 261 82 116 130 171 109 146 87 135 147 186 228 139 499 43 521 263 266 332 317 25 207 207 79 20 226 288 259 312 198 426 119 230 582 55 205 344 192 80 133 126 73 83 241 211 147 108 566 589 163 160 199 175 91 80 271 125 142 301 218 115 155 204 205 162 293 140 63 294 129 120 270 522 103 106 28 11 143 131 119 209 153 133 177 102 13 40 170 103 136 233 65 89 174 12 173 124 65 70 493 135 108 232 152 104 134 856 498 405 419 152 23 265 332 423 180 491 63 418 219 46 263 257 105 341 170 75 318 453 595 40 175 71 387 283 82 58 59 500 149 267 232 219 277 19 116 0 11 237 64 116 236 549 160 54 547 261 243 277 165 12 320 111 196 275 87 85 197 83 102 156 321 22 145 132 38 352 178 409 280 217 274 140 353 528 110 278 303 459 391 184 266 329 55 698 165 186 118 381 146 206 29 257 153 84 198 1839 150 182 52 338 190 18 149 310 251 217 30 198 32 118 98 310 397 155 203 200 194 117 185 30 54 142 216 418 307 24 310 404 261 80 86 75 110 107 267 270 210 75 145 72 17 79 146 426 254 173 297 0 266 293 146 127 15 350 792 493 238 123 210 143 211 231 401 70 142 356 154 467 53 190 145 53 249 853 435 197 236 79 218 507 193 37 354 137 162 30 239 118 564 275 121 253 272 250 20 277 14 167 136 256 458 143 149 177 162 35 13 64 201 104 168 192 199 350 685 54 302 286 244 24 337 239 332 277 180 79 131 169 105 488 264 274 214 278 59 136 46 42 16 94 267 496 588 255 297 248 339 100 228 27 119 137 18 130 118 232 213 701 153 185 276 129 123 110 271 84 569 175 70 130 71 69 37 334 114 11 371 284 42 101 82 308 262 561 147 349 94 213 117 213 383 44 497 95 25 15 310 439 202 94 32 317 393 337 159 467 35 238 143 86 85 120 347 1105 163 193 304 151 134 141 88 1025 80 82 30 140 112 165 87 123 228 102 55 87 73 180 169 37 85 193 460 98 137 241 214 338 149 142 511 327 81 345 73 43 70 0 414 85 226 75 96 112 170 534 77 223 400 137 510 324 32 115 174 153 89 196 149 237 225 389 131 139 154 202 113 45 140 205 332 128 299 193 357 66 364 450 118 171 200 126 154 143 124 68 334 83 85 81 68 253 210 53 109 186 113 286 166 1445 ]
@@@ Loss per-class: [ 0.543027 0.898361 0.97186 1.06865 1.36539 1.07912 1.24513 1.24853 1.15829 0.722528 0.439029 1.37512 0.57365 1.0253 1.48866 1.27538 1.09424 1.24087 1.04058 0.771589 0.505356 1.02485 0.366645 1.00105 1.076 1.58733 0.784683 0.71636 1.01467 0.760998 2.15626 1.25494 0.775674 1.18226 0.643524 1.13469 0.665953 0.266914 0.834488 1.46408 0.981898 1.09144 1.98595 1.33324 0.377281 0.557474 1.03233 1.27947 0.755036 0.880096 0.755422 0.350046 2.60589 0.738214 1.46628 0.584032 0.861064 0.634816 1.61296 1.54912 1.39355 1.07944 1.54961 0.61524 0.516174 0.892483 1.86643 0.885969 0.863485 0.931986 0.774954 1.09942 0.939462 2.42199 1.59047 1.35489 0.736682 0.305729 0.701751 0.617651 1.90874 1.22809 1.04765 1.73096 0.868674 1.31003 0.726131 0.85142 1.38044 1.77104 0.779465 1.16618 0.74914 0.846136 1.66548 0.549441 1.17495 1.18127 1.96415 0.967094 1.89241 1.1286 0.607515 0.899119 0.999184 0.598222 1.59187 1.20967 0.901695 0.453449 0.794329 2.15847 0.97451 0.88582 0.477095 1.6855 0.756186 1.35534 1.35981 2.47571 0.820489 1.33563 0.816349 2.27567 0.741004 2.44813 1.39054 0.848937 1.40868 1.05431 1.57213 0.987502 1.03851 0.999022 0.933719 1.23926 1.61832 0.954187 1.49113 1.28852 1.01223 1.18796 1.09466 2.07724 0.896472 1.91484 0.820691 1.39433 1.45049 1.05781 1.16739 1.49865 0.952819 1.44582 1.36604 0.930441 0.992802 0.98176 1.12421 0.59845 1.50169 0.837988 1.94922 2.49049 1.08122 0.942264 1.34575 1.81346 0.694764 1.23289 0.788601 1.14009 2.05522 0.779412 1.18092 0.95936 1.23564 1.40491 0.872 0.662688 1.10976 1.16115 1.32016 1.62775 1.81569 1.91691 0.860498 0.971086 1.03322 1.22843 0 0.830419 1.63456 1.06707 2.10616 1.24348 1.0944 0.63525 0.98048 1.33469 1.24599 1.35806 0.804509 0.671727 1.00929 0.648058 0.968644 0.979542 0.825923 2.15436 1.06823 1.01309 1.59899 1.66947 1.61136 2.28403 1.93383 1.16289 1.0747 0.991609 0.697881 1.03014 1.68512 1.2258 1.54873 1.90564 0.97585 1.36984 1.01633 2.3693 0.591577 1.6071 1.17074 1.46884 1.00683 1.29506 1.72391 1.03463 0.475282 0.945728 0.7752 1.30923 0.946939 0.568146 2.4053 1.85108 1.55537 1.51087 0.725656 0.674337 1.22608 0.823691 0.805011 0.720006 1.2726 1.48834 0.802078 0.688018 1.09715 1.76464 1.68502 0.784712 0.739423 3.93589 0.938219 0.530723 0.781612 1.28709 0.721686 1.63193 2.59571 1.21801 1.03802 0.632892 3.00693 0.797363 0.933178 2.09981 1.0681 1.4454 0.910768 1.79579 0.733389 1.23833 1.787 0.83203 1.07501 1.12369 0.812886 0.93658 1.03721 1.75626 1.55939 1.94886 1.68478 0.599144 0.779172 1.68406 1.50388 1.15464 1.339 2.80484 2.06318 1.2679 1.07288 1.29817 1.63863 0.906164 0.631013 1.59412 0.676837 1.9153 0.864399 0.70075 0.792471 0.746059 1.86337 2.55084 0.907875 1.11091 0.859696 1.16218 1.29416 1.46402 0.701492 2.0671 2.05951 1.20922 1.67054 2.39827 1.5683 0.838796 1.07233 1.17923 0.919598 0.822419 0.758157 1.99043 1.1493 1.20558 0.769548 1.17819 0.972355 1.41721 1.18037 0.631777 1.80578 1.30686 1.26967 1.56352 1.10681 1.84075 1.33081 1.17842 1.80113 0.845208 0.914252 0.972294 1.16181 0.882001 1.78093 1.67394 1.64066 1.07769 1.0621 0.517156 2.17324 1.52679 1.84752 0.940554 1.88989 0.967409 1.02179 0.73575 1.44705 1.33979 1.22864 1.64813 1.38171 1.43522 0.690716 2.25007 1.12935 1.20797 0.831028 0.60891 1.1004 1.55724 1.14178 1.38554 2.19898 1.16562 1.50657 0.690651 0.998067 1.24696 0.760647 0.58001 0.792111 2.54866 1.28254 0.901194 1.09881 0.864455 1.51175 1.65301 2.59259 1.3499 0.716448 1.23479 1.58205 1.21543 1.05706 0.957261 0.692211 0.743462 1.07936 1.61213 1.55861 1.28445 0.858294 1.20888 0.594004 1.52945 0.485362 2.15669 1.39945 1.28336 1.39594 2.12929 0.820889 1.13032 1.49556 0.914742 0.806522 1.64686 0.983121 1.7212 0.804035 1.37235 0.747057 0.930072 1.55065 1.53182 1.61516 1.55279 1.09562 2.38876 1.63693 0.606754 1.07315 0.873593 1.41634 1.22181 1.53721 3.18616 1.39586 1.40945 2.15752 0.500073 1.26915 0.829934 0.988496 0.711199 1.23391 1.88543 1.1022 0.443589 1.49652 1.33869 0.876363 0.643689 0.600775 1.45296 0.95749 1.19398 0.780287 1.73046 1.40079 1.55221 1.66582 0.981497 1.93781 1.34133 1.27373 1.24205 1.04629 2.13501 1.33576 1.24759 1.26076 1.46673 1.24908 2.22056 1.84512 1.06417 0.703397 0.858231 1.20577 0.646149 1.35107 1.94632 0.781812 0.979013 0.716981 2.05384 1.01665 0.86347 1.61779 0.775859 0.959752 1.31357 1.12613 0.787413 1.82222 0.94682 1.17653 1.41661 1.27778 1.25137 1.17654 1.73702 1.9726 1.44482 0.629222 1.04361 1.16286 1.92056 1.1711 1.44371 1.11383 0.675219 1.35688 0.6932 0.603499 2.0475 0.920145 1.02018 2.22056 1.61123 0.831191 1.47444 2.12211 1.81182 2.14002 1.17293 1.01051 0.908476 1.02172 1.35309 1.02521 1.02949 2.69537 1.09068 1.31638 1.45622 1.54986 1.03378 1.30607 1.01819 1.89919 0.809552 1.08488 1.1694 2.00416 1.66693 1.17639 2.52396 1.10601 0.810229 1.01928 1.02451 1.14626 2.57531 1.24871 1.41753 1.05857 1.39082 1.40443 1.57618 1.16724 3.21383 1.20514 1.28817 2.23214 0.599556 0.916076 1.44376 1.41278 0.988134 0.877253 1.88088 1.14757 1.60146 0.885027 1.85653 1.46062 1.65398 2.19692 3.48248 1.09839 1.56315 1.72503 0.731558 1.08376 1.22245 0.790628 1.72476 0.947638 1.03793 1.1553 1.47039 1.46308 0.866688 1.16365 2.0018 0.500266 0.809483 3.92521 0.820694 1.25349 1.46179 0.942114 1.32663 2.39621 1.00872 2.35113 0.655828 1.29377 1.37548 2.7733 1.07574 0.94316 1.59459 1.66972 2.10596 1.60294 0.883547 1.14296 1.29162 3.60735 1.62271 2.62823 1.15305 1.22108 0.956813 1.07033 1.43694 2.19982 2.07175 1.74035 0.836169 0.980464 1.42916 1.35716 1.6491 1.51898 1.04865 0.527472 1.18184 0.972842 2.21492 3.18095 1.63718 1.59065 0.852465 2.56797 1.15487 1.04307 1.04232 1.14042 1.54023 1.36434 0.513704 2.09793 1.38654 1.336 0.556789 1.19798 0.93423 1.12823 1.37559 0.760786 1.1243 0.731784 1.17579 0.988993 1.69283 1.30857 1.61009 1.12366 1.43267 2.51544 0.959985 1.09088 1.10186 1.83373 3.44269 1.9751 1.21444 4.24997 1.67334 1.16977 1.02099 1.95199 0.957463 3.26335 1.40827 1.96189 0.81977 1.47758 0.612649 1.42964 0.972173 0.634548 0.849997 1.52361 1.35444 1.63796 1.0731 0.954482 1.45189 1.49684 0.867492 1.11746 1.07057 0.594735 1.12433 1.30054 1.25577 1.45472 1.14574 1.59769 1.05727 1.24612 1.69542 1.06691 0.96488 0 0.818245 1.47009 1.23145 0.825747 3.42826 1.0758 1.01208 1.06345 1.79574 1.00951 0.993665 2.37475 1.77892 2.24412 1.00185 1.07657 1.14817 1.12123 1.50915 0.675682 1.3739 1.63849 1.64758 0.756516 1.11265 1.23945 1.67879 2.70025 0.690286 1.36464 1.59019 0.941855 0.840684 1.12115 1.08595 1.62638 1.08632 1.62565 1.49162 0.688209 2.12928 0.747235 1.29324 1.41319 1.06087 1.17522 1.30449 1.56829 1.09228 1.03939 1.68125 1.33886 1.34606 0.782363 1.26708 1.44925 1.27187 2.08564 1.41577 1.21485 0.884468 0.791029 1.22314 1.40089 1.14828 1.73956 0.972576 1.42136 1.84669 0.857239 2.18686 1.54534 1.78229 1.46793 1.33473 0.879217 1.67835 0.90277 6.75109 9.37673 1.24939 1.24798 1.53793 1.04084 0.765815 0.920158 1.20347 1.8875 2.43313 0.860615 0.958993 0.821645 1.65397 1.89459 1.40405 1.98584 2.55773 1.87308 0.842444 1.34628 0.99773 1.27192 1.20621 0.519949 1.35035 1.1674 1.12918 0.714098 1.3161 1.62525 0.940665 2.405 0.929233 1.43053 1.08118 0.810692 1.20029 6.61522 0.840211 1.40033 1.00233 1.40408 1.82699 1.18733 1.396 0.890459 2.00969 0.557366 1.21305 0.648472 1.04522 1.39652 2.23615 1.03379 1.7696 1.31344 0.732824 1.47245 0 1.57677 1.26259 0.83685 0.821834 0.957989 1.13231 1.11801 0.916109 1.75763 2.14876 1.06671 1.81974 1.63596 1.69794 1.72984 2.5644 1.44363 0.682864 1.71223 1.76968 1.73173 1.6536 1.76365 1.25683 2.56889 1.11669 1.75171 2.28838 3.2118 1.00049 1.34137 1.531 0 1.15044 2.69833 1.42901 1.11355 0.769758 0.856673 1.75552 1.26088 1.87164 1.03606 1.49056 1.48022 1.11254 0.98819 0.771168 1.45464 1.16789 1.0523 2.36312 1.90277 1.43258 1.22155 2.21764 1.32715 1.00438 1.39103 1.16597 1.87927 0.96358 1.63877 1.4329 1.98241 0.496481 0.598928 0.839342 1.09215 1.42962 1.16454 1.22196 0.67735 1.09741 1.30429 1.34929 1.4009 1.25168 1.40493 2.80408 1.4785 0.923816 2.11013 0.977918 1.2867 1.43589 1.29282 1.35601 1.41151 2.9576 1.31031 1.61958 1.51284 1.35033 2.34599 2.40298 1.34974 1.86535 0.690828 0.954495 0.916861 1.10406 1.16438 0.885568 1.48086 1.40603 1.64395 1.54646 0.771068 1.39432 1.18303 1.7614 1.1434 1.31095 1.12489 0.839039 1.79017 1.77512 1.73156 1.87082 0.855843 0.872412 1.50738 0.92408 1.33829 1.23262 2.15081 2.99218 2.3203 2.14107 1.3789 2.26707 0.697943 0.891612 0.889439 1.76269 1.1435 1.61251 2.05677 1.19954 0.971788 1.07721 1.09546 1.42241 1.26885 1.45232 1.02744 1.68519 0.894133 1.87732 0.891202 2.17908 0.838437 1.08945 0.981235 2.03702 1.91505 1.54897 1.49212 2.01323 0.876609 1.85722 0.712943 1.2014 1.00872 0.933881 1.50229 0.509946 1.59563 1.23415 1.25013 1.93164 0.877304 0.864569 1.90341 1.1991 0.863246 1.30969 1.5465 1.463 1.00865 1.11317 0.954087 1.34299 1.03069 1.31073 1.62619 0.958868 1.21408 1.1183 1.42505 1.43023 2.00014 1.52523 2.35122 0.855279 1.34505 1.66386 1.82183 1.85803 2.55415 0.673115 1.68519 1.85348 1.34093 1.46678 1.28489 1.16777 1.89937 0.597472 1.45098 1.10721 3.77745 2.98474 1.28655 0.972989 1.40179 1.36321 1.3128 1.5094 0.993756 1.12234 2.33884 1.84961 1.21684 1.25078 1.57637 1.30758 1.45252 1.39482 2.15023 2.29722 1.38026 1.6664 2.60337 2.52517 1.253 1.86864 2.13189 0.76427 1.34402 1.17523 1.4916 0.849494 1.49144 1.01215 0.741173 1.92381 1.06276 0.792162 0.796001 1.55494 0.968464 0.946619 0.956112 1.3706 1.3378 1.85094 1.53173 1.61708 0.796641 0.832418 0.981695 0.641828 1.39191 1.23711 1.58415 2.0723 0.971589 1.38466 1.14526 1.17137 1.07788 1.47548 1.40214 1.63216 1.53854 1.91748 1.38813 0.855274 1.19568 2.48769 1.05904 0 2.77754 0.820887 2.01187 1.18885 1.17016 1.15067 1.73 1.62253 1.20249 2.03806 0.696487 1.24598 1.17938 0.87832 1.13782 3.22519 1.41233 1.04231 1.17598 1.66235 2.37324 1.43523 1.79636 2.01218 1.28501 1.77321 1.86771 1.88454 1.56325 1.56318 1.44312 1.11542 0.758381 0.73213 1.5058 1.60196 0.992663 1.08007 2.24529 0.853533 0.836794 0.917962 0.897166 0.656991 1.55677 1.26462 0.963569 1.11862 1.86323 1.35173 1.31665 1.38417 2.14568 1.05913 1.6579 1.0323 1.52918 1.67229 1.15194 0.906144 1.27171 0.792104 1.41581 0.681201 1.31663 1.29112 1.34961 1.141 1.60263 1.13816 1.85059 1.96975 3.53733 1.5108 1.4782 1.17018 1.21995 0.81443 0.644855 1.32554 0.916292 1.66485 0.841079 1.03852 1.40956 0.988405 1.3741 1.06463 1.62337 2.0111 1.46957 1.06203 0.901227 1.01666 2.96469 3.36606 1.12577 1.27602 0.613729 1.32646 1.90777 1.80325 2.16197 1.65561 0.623767 1.32835 1.56155 0.65353 1.60593 1.66505 0.701228 0 1.44367 1.02616 1.12414 2.93934 2.51854 1.05584 0.970237 1.25742 1.10505 1.72811 1.76025 1.17548 1.09054 1.31442 1.23914 1.40561 0.729615 0.601436 2.0436 0.833276 1.27413 1.49799 1.79935 0.534056 1.19681 0.744073 1.38727 3.13234 1.33685 0.94726 1.2894 1.45535 1.22998 1.62862 1.25883 1.83765 1.11833 1.7584 1.14346 1.71172 1.23293 0.815417 2.07526 1.24148 1.88243 0.833876 2.02962 0.943339 1.81624 1.35599 2.16161 1.53238 0.843144 1.3546 1.18915 1.72016 1.50039 1.31229 1.68477 1.75064 0.741325 1.7792 1.87674 1.36505 0.954143 1.31755 1.17048 1.59202 0.973456 1.91148 2.14246 1.63656 1.17628 1.04118 1.51368 1.69768 1.23251 1.72954 2.33961 0.995978 1.53485 0.91952 0.885795 1.19923 1.30443 1.47945 1.56919 2.04318 1.22245 2.28279 0.818746 1.44384 1.43732 0.998986 0.783626 1.93523 1.31664 1.41004 1.00813 1.33234 1.93304 1.42201 1.47298 1.15724 1.05228 1.65164 1.71083 1.52008 0.721356 1.16471 1.04162 1.37833 1.40769 0.935592 1.36382 1.39448 1.68186 1.42046 0.886615 1.26444 1.10259 2.51941 1.17235 1.22566 1.87087 2.24696 1.15601 2.56157 1.16537 2.19617 2.13241 1.1197 0.914854 1.23754 2.3975 1.14651 1.31294 1.16092 1.19759 0.542762 3.13912 1.60784 0.526826 3.03631 0.972106 1.93976 0.829485 2.42908 0.796528 1.10473 0.923881 1.40402 2.70952 2.03396 1.13894 1.59688 1.04361 1.61658 1.3958 1.22651 1.82494 1.23383 2.99588 1.10924 1.48243 0.834555 1.88847 1.23194 1.23432 1.37077 0.861329 1.20531 1.07671 0.762312 1.81083 2.18354 0.955121 1.07989 1.59068 1.57802 1.31352 0.953812 1.53288 1.71198 2.59196 1.45551 1.56347 1.26695 2.13596 0.643336 1.47546 1.5069 0.86727 1.54117 1.10078 1.33289 1.25679 1.25888 1.21813 0.992422 0.947659 1.01948 1.53264 1.23814 1.2822 1.32374 1.67693 0 1.31725 1.48329 1.16998 2.21616 1.35615 2.30816 2.2645 1.00189 1.92949 1.15481 1.45182 1.55138 0.607494 0.992856 1.27167 0.997997 1.54549 0.689328 1.69804 1.82569 1.57032 1.45632 1.09831 1.06573 2.32353 1.43908 1.02081 1.88882 1.22236 2.16058 1.46887 1.33356 1.25707 1.19347 0.793217 1.62361 0.988551 1.71308 0.880282 1.04524 1.62198 0.853401 1.6956 1.26454 1.26036 1.02025 1.53687 0.950487 0.61414 2.46937 1.14266 1.41009 1.17678 1.31793 1.71154 2.2402 1.20321 2.52705 2.01572 0.94168 1.22452 0.325862 ]
@@@ Frame-accuracy per-class: [ 79.3567 78.7879 71.8101 77.4194 53.1646 62.9834 62.9482 68.9655 64.7975 78.7783 86.6769 59.3272 81.2641 73.6402 53.6431 66.1247 63.0273 65.2482 73.9018 77.4363 85.7143 67.5079 89.8336 73.8739 70.5882 56.2092 73.7513 79.3761 72.3562 73.2187 32.2981 58.0153 77.6119 68.1319 82.2742 66.242 80.6953 91.314 76.5832 56 77.1084 67.8992 44.898 55.1351 86.776 85.8044 68.9655 66.6667 72.8251 73.971 77.9944 88.3126 45.1613 78.5579 50.6024 84.2258 73.4255 79.6694 57.1429 58.445 56.0748 52.1241 63.4483 82.0961 84.724 74.4186 46.8085 75.5662 66.4797 69.8061 75.5245 64.7249 72.5599 38.8626 49.2308 58.6118 69.8795 89.2151 78.1382 82.7195 45.509 73.0159 70.2413 39.6522 74.6269 62.8297 76.555 77.3455 54.9223 48.9311 76.3399 62.531 75.3769 73.5454 61.0526 81.8018 66.9528 60.2699 39.8268 72.7273 41.0256 72.5849 84.1499 71.5026 69.4215 82.2955 53.9419 62.9213 75.841 86.9924 78.9916 34.4086 76.6839 71.0425 90.0662 52.0325 81.0811 60.6061 65.3061 32.4324 74.2384 52.7919 79.3456 35.3591 75.3541 31.7757 54.0728 76.3092 60.5505 68.6567 56.6802 66.789 69.7872 77.4194 74.6988 69.7674 60.4651 69.9454 57.8512 63.2411 70.8861 62.1359 69.4301 44.8485 72.1604 27.2494 79.3734 49.505 50.5593 69.7819 63.6872 57.2271 70.8861 63.4812 49.2891 75.1773 71.3864 73.9623 64.7564 85.0103 61.7801 77.9783 45.8015 21.8182 67.6923 70.8249 59.5611 54.6256 81.3839 68.2216 73.9274 71.161 39.8104 80 67.2269 73.3668 61.6588 60.8696 80 80.708 72.8291 63.2411 59.9327 53.789 40.367 44.1247 77.6119 72.1088 67.4157 66.2722 0 75.1515 52.6316 71.4976 41.9244 63.0928 62.8821 85.9122 66.9856 58.7084 51.5464 58.8589 79.3541 79.4788 70.8171 79.3003 75.1505 72.6343 79.7844 24.055 61.0169 58.3784 50.2092 48.6373 48.3221 38.7097 42.5121 68.0292 72.5389 70.9434 80.597 67.7551 54.6584 61.4634 70.2703 60.5128 69.7248 61.9469 75.2475 33.5135 82.4356 55.8376 67.4033 50.6024 72.3842 63.0542 49.5895 65.529 87.3696 72.7273 78.3939 65.3968 69.3712 84.399 34.9515 37.037 57.1429 54.3967 81.1808 81.4159 63.2967 72.0648 75.5149 79.7576 66.4032 60.2597 78.9272 75.6757 68.9524 41.8006 47.8049 80.9249 78.4983 11.7647 75.7396 86.629 77.0149 63.1111 77.6573 47.1204 42.623 62.1277 70.6131 81.3896 22.082 75.3216 81.0811 47.1281 66.1157 60.9626 71.6981 40 79.9641 67.3993 48.6692 78.4 64.5161 68.4932 75.1445 73.1501 72.7273 49.5822 56.1717 41.7112 54.1176 84.2288 75.6554 50.1567 52.581 65.4028 59.8425 23.1293 55.1724 65.8824 71.8584 61.959 52.0256 74.6392 79.7153 52.3077 80.5646 49.0975 69.8163 78.6127 83.0189 75.4717 53.0387 32.9588 74.0484 64.8221 72.5979 65.3465 60.274 52.7233 79.0123 37.9363 35.533 60.9929 57.8313 44.2478 58.6466 74.0741 70.4663 71.2531 68.7898 71.953 83.9378 50.1171 68.0384 64 78.6482 63.8037 64.4592 57.754 65.7224 79.3296 48.1633 59.7015 65.2921 49.6124 70.108 49.7854 62.8571 66.5012 42.449 76.7331 70.9677 72.9223 69.2641 76.2827 48.5175 57.3913 46.8085 71.5447 73.0435 83.0255 26.455 53.5565 58.8235 73.3017 44.3418 69.0909 67.3401 78.0115 52.6912 57.0213 66.9145 50.3597 61.4173 58.0645 80.4211 34.9345 62.9521 63.8849 80.597 78.5185 68.5315 34.5679 62.9834 58.0311 51.4286 67.3575 54.1114 77.0227 74.6736 64.9682 80.3532 82.8508 77.3519 35.3982 67.6692 73.1707 69.5279 76.8577 66.6667 48.7395 40.8889 53.6585 76.9314 54.2222 50.2463 62.0155 64.4478 67.4352 78.1003 80.3347 67.2968 77.551 56.6494 58.1745 72.9529 63.3416 83.8821 54.5455 90.5473 40.3587 44.6602 66.9528 60.274 38.8489 71.8447 69.0355 50.2203 76.4228 73.7778 46.4646 70.4319 51.2648 73.7463 54.7085 78.9333 69.6884 40 61.5385 50.1292 52.1994 69.3333 35.8974 61.5385 80.1008 69.3032 76.4045 61.2245 66.8657 57.2391 27.451 60.2317 56.7164 43.4783 86.262 85.7143 75.3769 68.144 82.5688 59.9156 46.3158 67.5325 88.8575 55.3314 66.6667 80 85.1064 82.5485 60.1504 75.6646 62.8386 78.7879 49.5974 51.9894 54.5455 43.5644 72.8972 44.7059 63.5193 68.5015 64.2534 64.8729 38.5965 53.3333 66.6667 59.8291 57.6029 75.5556 29.9559 39.604 67.5615 77.4542 76.3006 63.0508 81.5808 68.3544 49.7175 75.9207 74.7405 83.5443 38.2166 71.9577 72.119 65.0602 71.2644 75.0929 72.5275 64.4377 72.7273 38.1503 73.1429 72.2689 58.0038 62.2785 68.7117 65.0577 36.6197 42.0513 67.9739 84.7141 68.8525 70.8075 49.5868 68.4932 58.8235 68.3983 78.8321 60.4878 81.9625 87.4372 50.2547 72.8649 75.4098 46.7532 56.2162 74.6903 44.1791 35.5556 51.8519 40.2746 67.9739 70.8171 71.2991 65.7718 63.8695 67.1141 72 24.3902 68.0342 63.8037 53.831 57.485 70.7368 62.9371 67.9887 39.1259 78.735 68.3128 68.5466 47.4576 35.5556 72.2807 38.3838 69.4678 78.6378 71.5405 71.3615 67.2 39.4366 64.3275 59.9509 70.5394 55.5366 46.6034 64.1975 72.1569 19.5122 67.148 61.4801 38.7097 85.1976 75.382 63.5838 61.9883 71.6883 72.103 46.0733 66.0912 60.4651 71.407 44.358 57.2491 52.1452 38.5787 24.2424 64.6098 60.1307 51.3995 82.1293 66.7976 56.4784 79.7419 48.4018 74.7826 71.0875 63.3745 56.2798 54.8673 79.5699 65.1558 54.5455 88.4404 78.3053 0 84.1121 60.4651 54.9763 72.4171 61.1898 37.037 72.5664 34.4322 84.4765 64.5161 60.9337 34.0741 72.428 73.3858 55.6863 51.1278 41.6851 54.7486 70.6271 66.3139 61.5385 23.3577 80.8511 31.9559 64.3929 65.0847 66.9022 72.3514 59.1716 35.2941 36.3636 48.254 79.7342 73.8622 63.1579 63.035 66.6667 53.9007 66.289 83.8499 66.9323 70.5882 43.9216 20.6452 59.1716 53.2688 73.183 40.8602 61.8974 73.5178 71.8266 65.6489 60.5364 56.4184 84.5266 41.2698 56.338 60.8059 85.7469 65.6604 71.1297 71.6418 54.7368 79.2899 65.6716 77.8265 67.1835 73.3728 59.5745 64.5963 46.1538 64.8452 62.1687 32.4607 76.4045 68.5435 63.9866 37.1257 23.8806 30.303 65.707 0 48.3721 68.2927 68.3853 36.8 70.4981 35.2941 62.4625 40 74.2081 60.8451 82.1092 58.1262 72.4409 87.8049 75.7794 51.7572 64.3357 57.5488 61.9116 73.3781 55.8198 60.3774 67.1186 60.8955 71.8367 79.9601 66.6025 65.3061 66.3657 53.4351 64 51.7824 71.6007 67.4868 46.2882 72.6727 71.6472 0 76.962 55.1959 61.3497 76.2977 0 70.6827 70.7483 72.4947 51.3761 80 70.0906 14.9254 63.388 35.3222 76.1421 62.8571 65.0307 71.5921 57.7031 78.5818 63.6225 59.1781 54.4379 76.1415 67.9426 60.177 45.8874 28.3105 78.7172 62.9333 50.7042 66.4151 80.0937 64.4068 67.5497 54.8862 65.3595 57.4257 77.4194 81.8472 42.7984 77.9661 64.2424 55.706 70.7617 64.381 60.4317 48.8294 72.4638 61.7587 59.8291 64.2336 56.7742 80 66.0403 56.1039 63.4921 35.2332 61.6408 69.3878 74.036 82.2047 64.0569 60.5405 61.8454 49.7959 81.0811 62.069 50.9506 77.0664 40.708 40 43.6261 58.1818 60.6897 77.8947 50.6329 74.3935 0 0 68.6567 69.7674 57.7114 69.7068 71.6049 73.2519 65.9459 41.8605 40.1674 75.3346 74.2475 75.4098 51.5556 43.346 61.2022 42.1053 35.6688 48.5356 68.8852 64.2487 73.6383 63.197 62.5641 87.7456 58.4615 64.9275 68.8525 81.8356 59.5745 55.6237 74.7475 30.8571 74.8603 59.0449 67.1378 77.2414 61.5385 0 73.2694 57.4233 68.1934 55.5957 56.5371 66.2069 62.9921 77.4775 46.3895 81.493 61.2159 80.752 71.8057 55.4493 45.283 69.0958 41.3793 57.6052 80.8511 57.9634 0 42.2857 67.3597 77.0186 76.2264 77.9221 64.6154 62.069 72.6128 55.7185 38.7097 74.5763 46.7797 56.3667 60.9053 51.0569 16 58.5242 82.8452 48.5523 51.6129 42.4069 56.1404 45.3333 64.7173 35.4639 62.3574 58.0645 40 28.0543 70.1689 63.0722 57.2505 0 71.2551 29.3948 58.5621 64.5161 71.2517 76.2937 48.7356 68.0412 43.038 71.7833 61.4925 49.0501 71.3656 70.7106 75.514 54.0541 69.8039 66.6667 24 47.3469 60.8295 67.9928 35.6164 63.0508 70.7022 56.7976 61.0169 52.3636 64.5045 48.4848 61.8474 48 85.4135 88 76.6284 70.4626 68.0412 61.8357 63.8436 80 72.5076 64.2369 60.8295 66.289 64.3678 62.9787 15.6863 56.6572 73.5967 37.6238 70.4403 64.6035 68.0115 67.5325 55.2567 58.6081 32 56.4263 51.9774 50.6122 61.2245 33.2046 36.2283 61.4433 48.2436 78.6517 72.0988 72.5986 64.8968 70.5394 72.8111 60.9137 63.0542 52.8 52.9577 76.7967 59.4452 64.96 55.0459 72 62.4339 69.9647 75.1419 48.0874 49.6075 49.4774 49.2562 74.3034 76.7372 52.3207 71.5596 62.8337 67.433 34.5098 25.7669 37.8182 53.3333 64.042 37.4468 82.5836 70.6625 75.4159 56.1194 62.1359 50.478 46.0606 63.5193 71.2644 62.9738 67.5799 58.7031 69.7143 56.8266 72.5424 54.1555 73.0853 47.3118 76.0761 27.5862 74.976 70.9677 71.6698 42.1053 48.8189 54.902 54.9398 36.1446 72.956 43.9024 82.5607 68.2842 72.0617 75.52 58.9421 84.408 50.2092 63.7744 56.824 34.2342 74.9392 73.4398 41.5584 67.0807 74.9064 62.4506 62.585 59.8802 67.0807 70.922 73.8983 65.4378 65.6664 59.3723 56.2691 68.5358 67.6692 68.3761 61.2022 60.8696 38.674 58.1673 36.4912 73.9635 64.9886 55.4113 47.5884 43.5208 36.983 78.7692 53.1516 44.8399 62.9921 55.348 67.9537 70.5394 42.5139 83.2536 52.1739 68.5446 7.01754 34.7826 66.2021 70.7224 56.9038 57.7566 61.8893 60.6742 70.4225 66.3415 44.4444 41.9753 66.8622 63.7681 57.1429 65.0964 54.9618 64.8045 39.5415 40 58.7896 55.4217 25.9542 22.695 62.2087 39.8524 42.3963 80.8602 64.2623 71.7703 52.0446 74.7227 57.3721 73.7361 80.0954 36.0656 72.3404 76.0829 80 57.379 75.9003 72.6348 77.1654 59.2593 58.7699 47.3118 56.5465 51.6505 76.7773 77.0132 72.7273 75.4967 59.3407 67.2547 50.3778 41.9753 71.2251 58.7413 67.3548 63.4921 72.7273 66.6667 57.1429 51.1489 53.5117 42.9907 60.6452 76.082 63.0631 51.2821 67.8112 0 26.087 76.6316 46.5116 66.9528 68.9218 67.5159 47.352 55.0459 66.6667 39.0057 78.4394 63.0631 73.1118 80 67.7067 17.0404 56.4885 67.8766 76.5714 53.8012 31.3924 58.6826 46.8293 44.0895 61.8974 48.8889 36.4261 52.0755 57.1429 47.0922 63.3053 67.3993 77.3619 80 53.9162 54.0925 76.9448 71.9016 48.8688 73.6086 79.7364 76.1697 75.0958 84.0108 63.0394 64.3399 72.0721 63.8511 41.6918 61.126 63.2911 58.9777 38.9078 62.954 40.678 73.3981 56.6775 52.071 65.995 69.8559 71.7608 78.9041 57.1429 81.8316 66.1417 70.2703 58.194 68.9211 53.2803 67.5862 42.623 51.3854 9.23077 52.3207 55.8376 66.6667 66.9182 78.4566 82.0639 60.8479 77.1208 54.4681 78.1671 65.5738 60.5505 72.9825 63.7413 72.8793 53.6585 48.9796 55.7166 72.1879 73.0402 80.7453 31.2139 17.2185 63.3484 66.0465 80.7477 64.3253 41.8052 50.3311 44.6735 52.4138 85.7143 62.8931 62.116 80.1876 52.2593 54.1787 81.0084 0 62.6642 73.5945 69.6246 25.8824 25.8065 68.1883 71.5457 64.4377 72.956 47.7733 56.057 71.777 69.0307 65.2268 62.7646 59.5745 84.9123 83.31 38.1877 72.9412 67.2897 60.8924 52.921 89.7196 64.9299 81.5466 61.7681 20.7595 60.0423 80.5031 63.1579 57.931 67.1835 66.6667 60.6488 46.5455 67.6923 45.9016 72.2338 54.8523 65.899 77.314 41.9753 59.5661 42.9358 73.4531 39.0244 68.4685 48.2759 62.0896 52.0147 57.3099 77.6445 61.324 67.5585 56.9014 59.6923 78.8732 37.037 51.1628 79.4045 49.7608 45.1039 61.2987 73.6842 58.7732 68.1255 45.8716 72.7273 46.4223 41.3088 57.1429 68.1481 73.904 53.5338 47.2072 73.6842 60.3774 38.7833 74.9263 64.455 72.6714 74.8582 66.3024 65.2681 53.86 50.4202 35.8974 62.3656 32.9412 72.7273 61.3757 58.3178 71.9033 76.1257 48.5323 61.8487 61.5694 72.1649 62.6866 48.14 54.5455 59.4142 60.3636 70.2703 59.0038 54.0084 63.2258 80.5621 68.1397 71.6612 57.6819 63.6528 72.5869 62.3482 57.0136 57.4586 50.8876 75.3292 63.2479 65.2482 29.8851 68.5315 70.5036 42.6667 38.565 65.5022 26.087 66.7564 44.2882 37.6471 65.0246 75.1515 64.1815 35.8095 65.3606 61.0169 66.6667 69.8413 82.4356 26.383 53.8642 85.2673 29.2135 76.1809 34.555 82.3529 19.3548 74.7182 66.4391 72.0988 61.3757 15.3846 44.4094 65.5654 52.1481 69.5925 50.9091 56.338 65.4088 47.3868 64.7399 22.2222 63.0705 59.8561 74.3555 42.2018 67.1835 59.7701 59.4059 75.8364 63.6042 68.9266 78.1082 57.1429 47.2727 72.1311 70.4626 42.6667 59.2145 66.2857 76.9231 62.1444 59.5122 41.4414 64 58.5034 60.3878 41.2979 80 60.8187 63.0491 72.9642 59.8985 70.5455 66.2526 64.8019 67.0606 62.8763 68.0702 70.5767 69.313 50.3067 65.9913 66.6667 66.6667 46.8085 0 62.7262 58.4795 66.6667 34.4371 65.285 29.3333 32.2581 68.101 51.6129 64.4295 60.9238 54.5455 82.6641 72.1109 70.7692 77.0563 64.1834 79.4788 52.514 50.8906 49.4983 62.7368 71.3969 73.6842 36.5019 58.0645 74.4337 46.4198 69.6035 26.3736 61.21 62.7737 64.3609 62.2568 80.1336 49.6124 68.2517 48.1203 74.3484 68.1465 47.2574 73.4694 53.3666 67.1937 67.3139 67.5958 58.6345 74.4526 84.006 35.9281 69.0058 55.2147 64.2336 61.5385 43.2304 33.6449 64.8402 31.0992 37.8855 69.459 72.6727 92.0097 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 1.1154 (Xent), [AvgXent: 1.1154, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 67.6789% <<

