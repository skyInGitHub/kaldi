nsclab-gpu
nnet-train-frmshuff --cross-validate=false --randomize=true --verbose=0 --minibatch-size=256 --randomizer-size=32768 --randomizer-seed=777 --learn-rate=0.000125 --momentum=0 --l1-penalty=0 --l2-penalty=0 --feature-transform=exp/dnn4_pretrain-dbn_dnn/final.feature_transform 'ark:copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- |' 'ark:ali-to-pdf exp/tri3_ali/final.mdl "ark:gunzip -c exp/tri3_ali/ali.*.gz |" ark:- | ali-to-post ark:- ark:- |' exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter09_learnrate0.00025_tr0.7257_cv1.8839 exp/dnn4_pretrain-dbn_dnn/nnet/nnet_dbn_dnn_iter10 
WARNING (nnet-train-frmshuff[5.5.294-06484]:SelectGpuId():cu-device.cc:221) Not in compute-exclusive mode.  Suggestion: use 'nvidia-smi -c 3' to set compute exclusive mode
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:349) Selecting from 2 GPUs
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(0): TITAN Xp	free:12023M, used:173M, total:12196M, free/total:0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:364) cudaSetDevice(1): TITAN Xp	free:11888M, used:304M, total:12192M, free/total:0.975001
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:411) Trying to select device: 0 (automatically), mem_ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:SelectGpuIdAuto():cu-device.cc:430) Success selecting device 0 free mem ratio: 0.985815
LOG (nnet-train-frmshuff[5.5.294-06484]:FinalizeActiveGpu():cu-device.cc:284) The active GPU is [0]: TITAN Xp	free:11957M, used:239M, total:12196M, free/total:0.980403 version 6.1
copy-feats scp:exp/dnn4_pretrain-dbn_dnn/train.scp ark:- 
LOG (nnet-train-frmshuff[5.5.294-06484]:Init():nnet-randomizer.cc:32) Seeding by srand with : 777
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:163) TRAINING STARTED
ali-to-post ark:- ark:- 
ali-to-pdf exp/tri3_ali/final.mdl 'ark:gunzip -c exp/tri3_ali/ali.*.gz |' ark:- 
LOG (ali-to-pdf[5.5.294-06484]:main():ali-to-pdf.cc:68) Converted 1232 alignments to pdf sequences.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:354) ### After 0 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:355) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.86424, max 7.06273, mean -0.000964877, stddev 0.993005, skewness 0.0133901, kurtosis 2.03207 ) 
[1] output of <AffineTransform> ( min -29.2942, max 22.0724, mean -3.32252, stddev 4.08533, skewness 0.120674, kurtosis 1.30151 ) 
[2] output of <Sigmoid> ( min 1.8953e-13, max 1, mean 0.208708, stddev 0.316412, skewness 1.47514, kurtosis 0.701141 ) 
[3] output of <AffineTransform> ( min -28.2349, max 18.762, mean -4.02284, stddev 2.79901, skewness -0.0321237, kurtosis 2.6388 ) 
[4] output of <Sigmoid> ( min 5.46709e-13, max 1, mean 0.0991042, stddev 0.194954, skewness 2.88234, kurtosis 8.16516 ) 
[5] output of <AffineTransform> ( min -15.2239, max 12.7361, mean -3.11954, stddev 2.01155, skewness 0.519395, kurtosis 2.23712 ) 
[6] output of <Sigmoid> ( min 2.44543e-07, max 0.999997, mean 0.115416, stddev 0.190009, skewness 2.68643, kurtosis 7.30541 ) 
[7] output of <AffineTransform> ( min -21.964, max 14.74, mean -2.73186, stddev 2.2972, skewness 0.490297, kurtosis 2.52311 ) 
[8] output of <Sigmoid> ( min 2.89171e-10, max 1, mean 0.160492, stddev 0.237479, skewness 1.99229, kurtosis 3.19981 ) 
[9] output of <AffineTransform> ( min -17.39, max 16.7734, mean -2.83451, stddev 2.92356, skewness 1.28089, kurtosis 2.45143 ) 
[10] output of <Sigmoid> ( min 2.80306e-08, max 1, mean 0.182364, stddev 0.296239, skewness 1.71743, kurtosis 1.55922 ) 
[11] output of <AffineTransform> ( min -28.7882, max 18.5061, mean -3.68429, stddev 3.69379, skewness 0.968207, kurtosis 3.13046 ) 
[12] output of <Sigmoid> ( min 3.14384e-13, max 1, mean 0.151731, stddev 0.298489, skewness 2.0142, kurtosis 2.509 ) 
[13] output of <AffineTransform> ( min -14.8199, max 22.4698, mean -0.00343097, stddev 3.67846, skewness 0.519669, kurtosis 0.920925 ) 
[14] output of <Softmax> ( min 1.04443e-15, max 0.999485, mean 0.000647606, stddev 0.0191146, skewness 40.2175, kurtosis 1746.77 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:357) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -1.26739, max 1.2275, mean 0.000446134, stddev 0.0512777, skewness -0.0614305, kurtosis 26.7163 ) 
[1] diff-output of <AffineTransform> ( min -0.278662, max 0.258637, mean -2.59089e-05, stddev 0.00973378, skewness -0.0474847, kurtosis 63.2714 ) 
[2] diff-output of <Sigmoid> ( min -1.56952, max 2.07183, mean -6.15872e-05, stddev 0.0885074, skewness 0.0941589, kurtosis 15.9968 ) 
[3] diff-output of <AffineTransform> ( min -0.335554, max 0.483827, mean -2.07939e-05, stddev 0.0109937, skewness 0.235806, kurtosis 89.2746 ) 
[4] diff-output of <Sigmoid> ( min -1.77748, max 3.03013, mean -0.000107289, stddev 0.117264, skewness 0.0207656, kurtosis 14.2393 ) 
[5] diff-output of <AffineTransform> ( min -0.311502, max 0.371142, mean 3.42244e-05, stddev 0.0113267, skewness 0.421676, kurtosis 72.5966 ) 
[6] diff-output of <Sigmoid> ( min -1.57572, max 1.64898, mean 0.000185638, stddev 0.095426, skewness 0.13237, kurtosis 13.5361 ) 
[7] diff-output of <AffineTransform> ( min -0.194944, max 0.35252, mean 1.19021e-05, stddev 0.00902343, skewness 0.2745, kurtosis 49.5921 ) 
[8] diff-output of <Sigmoid> ( min -1.17331, max 1.56739, mean 9.54637e-05, stddev 0.0661825, skewness -0.0176936, kurtosis 14.7612 ) 
[9] diff-output of <AffineTransform> ( min -0.154117, max 0.256459, mean 2.55478e-06, stddev 0.00661244, skewness 0.0143059, kurtosis 53.6511 ) 
[10] diff-output of <Sigmoid> ( min -0.672024, max 1.04391, mean -5.42665e-05, stddev 0.0504535, skewness -0.0219904, kurtosis 15.9023 ) 
[11] diff-output of <AffineTransform> ( min -0.193143, max 0.161963, mean 2.87022e-05, stddev 0.00730769, skewness 0.19117, kurtosis 61.2278 ) 
[12] diff-output of <Sigmoid> ( min -0.954962, max 1.69912, mean 0.000151148, stddev 0.0769554, skewness 0.0120353, kurtosis 8.58663 ) 
[13] diff-output of <AffineTransform> ( min -0.998947, max 0.952779, mean -7.92107e-09, stddev 0.0150714, skewness -26.626, kurtosis 2387 ) 
[14] diff-output of <Softmax> ( min -0.998947, max 0.952779, mean -7.92107e-09, stddev 0.0150714, skewness -26.626, kurtosis 2387 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:358) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.71053, max 1.61087, mean 0.000351513, stddev 0.156839, skewness 0.00344309, kurtosis 2.13855 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.535452, max 0.547132, mean -0.00663269, stddev 0.152196, skewness 0.0328233, kurtosis 0.334291 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.62872, max 0.789005, mean -0.00084701, stddev 0.068009, skewness 0.055571, kurtosis 5.278 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.696641, max 0.813271, mean -0.00532322, stddev 0.17683, skewness 0.0100378, kurtosis 1.79766 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.802213, max 0.637497, mean 0.000964388, stddev 0.0397172, skewness 0.235706, kurtosis 12.0286 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.81131, max 0.720043, mean 0.00876147, stddev 0.174857, skewness 0.135818, kurtosis 2.11038 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.464098, max 0.589318, mean 0.000344928, stddev 0.0324882, skewness 0.0962399, kurtosis 9.64148 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.633085, max 0.511434, mean 0.00304693, stddev 0.142753, skewness -0.238049, kurtosis 1.82626 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.365211, max 0.412295, mean 0.000170563, stddev 0.0301385, skewness 0.0852851, kurtosis 7.09303 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.437941, max 0.535435, mean 0.000654029, stddev 0.101018, skewness 0.158998, kurtosis 2.3868 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.394243, max 0.476035, mean 0.00138726, stddev 0.0404978, skewness 0.292871, kurtosis 7.20293 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.401542, max 0.596001, mean 0.00734776, stddev 0.113382, skewness 0.264409, kurtosis 2.33981 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -1.26363, max 1.55034, mean -3.06798e-08, stddev 0.0811905, skewness -3.71744, kurtosis 69.7212 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.24419, max 1.53252, mean -6.79431e-09, stddev 0.234625, skewness -1.28205, kurtosis 8.79642 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (ali-to-post[5.5.294-06484]:main():ali-to-post.cc:73) Converted 1232 alignments.
LOG (copy-feats[5.5.294-06484]:main():copy-feats.cc:143) Copied 1112 feature matrices.
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:384) ### After 331520 frames,
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:385) 
### FORWARD PROPAGATION BUFFER CONTENT :
[0] output of <Input>  ( min -7.8171, max 6.44093, mean -0.00429144, stddev 1.00295, skewness -0.0631885, kurtosis 1.97814 ) 
[1] output of <AffineTransform> ( min -29.3761, max 21.5979, mean -3.33173, stddev 4.12614, skewness 0.116589, kurtosis 1.2536 ) 
[2] output of <Sigmoid> ( min 1.74633e-13, max 1, mean 0.210151, stddev 0.317606, skewness 1.46375, kurtosis 0.664077 ) 
[3] output of <AffineTransform> ( min -26.3448, max 17.1722, mean -4.01982, stddev 2.81002, skewness -0.0106231, kurtosis 2.49187 ) 
[4] output of <Sigmoid> ( min 3.61914e-12, max 1, mean 0.100211, stddev 0.196523, skewness 2.85448, kurtosis 7.97624 ) 
[5] output of <AffineTransform> ( min -14.2155, max 14.9567, mean -3.11823, stddev 2.026, skewness 0.540147, kurtosis 2.3237 ) 
[6] output of <Sigmoid> ( min 6.70311e-07, max 1, mean 0.11611, stddev 0.191381, skewness 2.6773, kurtosis 7.22315 ) 
[7] output of <AffineTransform> ( min -23.7872, max 14.2495, mean -2.72635, stddev 2.31024, skewness 0.504773, kurtosis 2.51478 ) 
[8] output of <Sigmoid> ( min 4.67019e-11, max 0.999999, mean 0.161417, stddev 0.238691, skewness 1.9855, kurtosis 3.16167 ) 
[9] output of <AffineTransform> ( min -16.165, max 17.7836, mean -2.82563, stddev 2.93837, skewness 1.29803, kurtosis 2.51149 ) 
[10] output of <Sigmoid> ( min 9.54141e-08, max 1, mean 0.183079, stddev 0.296878, skewness 1.71081, kurtosis 1.53449 ) 
[11] output of <AffineTransform> ( min -28.6555, max 19.8378, mean -3.68938, stddev 3.70004, skewness 0.963029, kurtosis 3.1086 ) 
[12] output of <Sigmoid> ( min 3.58999e-13, max 1, mean 0.151654, stddev 0.298398, skewness 2.01615, kurtosis 2.519 ) 
[13] output of <AffineTransform> ( min -16.1518, max 23.1943, mean -0.00329994, stddev 3.66518, skewness 0.510856, kurtosis 0.932601 ) 
[14] output of <Softmax> ( min 8.94631e-16, max 0.999613, mean 0.000647606, stddev 0.0189393, skewness 40.3324, kurtosis 1764.63 ) 
### END FORWARD

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:387) 
### BACKWARD PROPAGATION BUFFER CONTENT :
[0] diff of <Input>  ( min -0.783369, max 0.87999, mean 0.000500482, stddev 0.0474605, skewness 0.488082, kurtosis 23.1919 ) 
[1] diff-output of <AffineTransform> ( min -0.266191, max 0.598897, mean 8.29791e-05, stddev 0.00935671, skewness 2.03021, kurtosis 144.667 ) 
[2] diff-output of <Sigmoid> ( min -2.03335, max 3.43741, mean 0.000485764, stddev 0.0852729, skewness 1.28602, kurtosis 64.5894 ) 
[3] diff-output of <AffineTransform> ( min -0.371768, max 0.754563, mean 7.00673e-05, stddev 0.0105016, skewness 2.58943, kurtosis 232.897 ) 
[4] diff-output of <Sigmoid> ( min -2.11271, max 3.28513, mean 0.000194832, stddev 0.110279, skewness 0.22917, kurtosis 22.9581 ) 
[5] diff-output of <AffineTransform> ( min -0.312413, max 0.730867, mean 7.92776e-05, stddev 0.0107627, skewness 2.62042, kurtosis 200.291 ) 
[6] diff-output of <Sigmoid> ( min -1.71495, max 2.93068, mean 0.000427908, stddev 0.0912632, skewness 0.379498, kurtosis 24.097 ) 
[7] diff-output of <AffineTransform> ( min -0.182134, max 0.421137, mean 2.82553e-05, stddev 0.0086059, skewness 1.46011, kurtosis 98.1179 ) 
[8] diff-output of <Sigmoid> ( min -1.34297, max 1.72937, mean 0.000199517, stddev 0.0630152, skewness 0.148223, kurtosis 19.3818 ) 
[9] diff-output of <AffineTransform> ( min -0.175693, max 0.234276, mean 1.5531e-05, stddev 0.00629609, skewness 0.433412, kurtosis 69.6305 ) 
[10] diff-output of <Sigmoid> ( min -0.739459, max 1.03724, mean 3.72241e-05, stddev 0.0475732, skewness -0.0186783, kurtosis 18.0751 ) 
[11] diff-output of <AffineTransform> ( min -0.263027, max 0.203076, mean -1.39232e-05, stddev 0.00692115, skewness -0.64273, kurtosis 78.405 ) 
[12] diff-output of <Sigmoid> ( min -1.72533, max 0.936991, mean 5.67044e-05, stddev 0.0729317, skewness -0.285955, kurtosis 11.6643 ) 
[13] diff-output of <AffineTransform> ( min -0.999967, max 0.717862, mean -7.53261e-09, stddev 0.0138334, skewness -29.9348, kurtosis 2366.1 ) 
[14] diff-output of <Softmax> ( min -0.999967, max 0.717862, mean -7.53261e-09, stddev 0.0138334, skewness -29.9348, kurtosis 2366.1 ) 
### END BACKWARD


LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:388) 
### GRADIENT STATS :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -1.26583, max 1.61561, mean 0.00208576, stddev 0.149554, skewness 0.063055, kurtosis 2.2191 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.517087, max 0.781792, mean 0.0212426, stddev 0.164316, skewness 0.0858948, kurtosis 0.7876 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -0.720414, max 1.48001, mean 0.00330172, stddev 0.0681016, skewness 0.565295, kurtosis 12.3645 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.589183, max 1.21018, mean 0.0179372, stddev 0.189537, skewness 0.230104, kurtosis 1.93669 ) , lr-coef 1
Component 4 : <Sigmoid>, 
Component 5 : <AffineTransform>, 
  linearity_grad ( min -0.730126, max 1.76858, mean 0.00174797, stddev 0.0410208, skewness 1.31103, kurtosis 44.2669 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.842377, max 1.59995, mean 0.020295, stddev 0.19507, skewness 0.582655, kurtosis 6.15168 ) , lr-coef 1
Component 6 : <Sigmoid>, 
Component 7 : <AffineTransform>, 
  linearity_grad ( min -0.428436, max 0.969017, mean 0.000584593, stddev 0.0327721, skewness 0.631385, kurtosis 18.6202 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.577264, max 0.822342, mean 0.00723334, stddev 0.150587, skewness 0.360902, kurtosis 2.03675 ) , lr-coef 1
Component 8 : <Sigmoid>, 
Component 9 : <AffineTransform>, 
  linearity_grad ( min -0.332328, max 0.64175, mean 0.000351875, stddev 0.0311371, skewness 0.174972, kurtosis 9.4151 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.49512, max 0.609182, mean 0.00397594, stddev 0.114003, skewness 0.205113, kurtosis 2.73769 ) , lr-coef 1
Component 10 : <Sigmoid>, 
Component 11 : <AffineTransform>, 
  linearity_grad ( min -0.712525, max 0.540371, mean -0.000812388, stddev 0.0400928, skewness -0.284855, kurtosis 9.33648 ) , lr-coef 1, max-norm 0
  bias_grad ( min -0.708706, max 0.438463, mean -0.00356433, stddev 0.119112, skewness -0.217252, kurtosis 3.15703 ) , lr-coef 1
Component 12 : <Sigmoid>, 
Component 13 : <AffineTransform>, 
  linearity_grad ( min -1.72174, max 1.41222, mean -1.68473e-08, stddev 0.0771195, skewness -5.4718, kurtosis 93.0232 ) , lr-coef 1, max-norm 0
  bias_grad ( min -1.70866, max 1.11919, mean -4.32365e-09, stddev 0.229152, skewness -2.26761, kurtosis 14.0253 ) , lr-coef 1
Component 14 : <Softmax>, 
### END GRADIENT

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:395) Done 1112 files, 0 with no tgt_mats, 0 with other errors. [TRAINING, RANDOMIZED, 0.0763342 min, processing 72383.5 frames per sec; i/o time 5.1206%]
LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:405) PER-CLASS PERFORMANCE:
@@@ Frames per-class: [ 12529 82 168 15 39 90 125 14 160 949 326 163 664 119 473 184 201 211 193 569 325 158 270 55 263 76 470 288 269 203 80 65 33 45 448 78 546 224 339 87 41 297 220 92 457 158 159 130 5856 862 179 17467 15 263 124 345 325 302 31 186 53 1047 72 114 389 21 23 419 1069 180 214 154 271 105 32 194 124 783 354 176 83 31 186 287 234 208 522 218 96 210 382 201 298 644 47 277 116 333 115 258 97 191 173 96 181 409 120 133 163 726 178 139 96 129 226 307 166 16 24 18 1329 98 244 90 176 53 288 200 54 100 123 272 117 15 41 21 21 91 60 126 197 51 96 82 224 194 191 50 223 160 89 169 118 146 105 70 169 132 174 243 95 138 65 27 97 248 159 113 303 171 151 133 105 77 297 99 319 34 122 282 178 379 148 336 54 208 100 220 133 84 0 247 47 103 145 242 114 216 104 255 48 166 433 153 128 171 581 195 185 145 265 92 119 238 74 15 103 342 96 132 301 367 241 102 18 97 54 169 50 92 213 98 90 124 291 101 304 146 431 115 261 157 246 195 51 13 17 244 135 169 227 123 218 412 126 192 391 18 262 155 102 86 146 8 84 265 167 112 230 95 30 117 236 201 158 427 18 339 60 93 79 7 556 136 131 62 108 182 86 236 115 179 279 93 212 288 133 159 416 105 190 73 14 212 282 219 234 242 140 32 460 138 190 86 26 79 90 133 144 126 140 151 182 229 202 329 98 70 41 56 66 175 96 203 78 340 96 213 364 337 325 81 226 93 176 268 122 33 145 322 416 116 17 201 122 526 15 186 115 516 185 57 164 61 172 568 94 119 42 316 216 137 148 261 176 117 134 69 63 77 237 114 511 347 33 67 214 40 90 96 17 96 188 154 191 78 226 224 143 56 66 20 116 235 10 59 112 20 925 112 101 64 330 173 189 119 264 24 289 498 201 200 288 170 100 111 51 116 255 69 154 98 113 61 112 148 150 296 169 111 187 529 47 97 193 170 112 19 19 198 265 44 73 167 148 25 129 100 34 156 24 99 180 54 118 142 115 354 173 25 22 70 541 199 244 461 412 310 188 49 50 53 42 349 163 110 334 142 37 16 58 279 22 113 151 223 463 86 147 708 197 88 176 144 118 78 283 134 124 217 134 136 164 82 86 87 59 265 197 244 476 106 97 76 428 30 80 60 182 25 346 68 102 346 99 294 462 91 115 92 282 167 22 13 218 76 128 496 74 214 223 237 61 292 81 254 250 237 71 176 480 458 121 230 29 67 142 49 178 161 191 106 62 106 85 203 120 293 684 40 382 61 138 263 77 746 294 86 85 192 116 95 405 107 330 128 134 151 98 16 275 229 196 131 254 150 387 109 172 188 121 314 56 46 176 49 272 684 10 53 150 105 527 176 13 56 136 138 15 203 67 121 317 127 199 225 89 151 283 188 68 23 181 366 147 424 193 84 127 27 157 150 384 28 128 25 70 176 306 125 178 127 77 84 206 199 46 321 126 161 65 130 315 216 31 106 136 438 132 119 33 47 84 167 570 193 84 23 80 162 274 207 95 133 408 298 83 33 214 590 5 107 61 368 62 130 8 166 7 331 177 265 261 63 20 208 156 71 281 350 223 399 79 147 167 122 501 519 24 221 65 212 266 290 284 114 166 555 0 197 293 81 799 7 124 220 234 54 12 165 33 91 209 98 17 81 480 178 1029 328 182 84 777 104 282 346 109 171 187 35 132 213 88 226 373 76 50 15 1407 121 29 82 258 203 262 69 149 103 244 58 68 77 122 372 192 157 96 225 24 194 317 140 92 200 122 18 14 131 429 169 92 176 412 72 47 39 185 6 2 100 21 100 153 121 450 92 21 119 261 149 152 112 131 91 28 78 119 300 289 229 134 97 534 32 172 152 261 70 244 148 87 89 345 141 217 58 4 469 407 196 138 141 72 190 55 228 321 238 558 473 261 26 370 14 772 305 191 0 87 240 80 132 38 97 159 476 170 46 29 147 294 121 307 12 196 119 224 139 174 28 112 256 242 131 46 117 110 266 491 265 0 123 173 382 15 363 1014 217 48 39 221 167 289 113 288 267 18 127 145 12 122 108 276 36 147 206 496 88 137 277 16 124 87 332 137 130 140 48 103 153 92 165 219 108 176 304 117 25 176 240 50 79 258 173 192 204 136 37 159 88 122 73 129 201 727 213 578 202 494 508 120 108 98 101 62 177 243 378 312 54 37 94 141 440 91 318 143 302 161 165 118 54 243 130 127 81 137 52 190 117 433 158 270 167 51 261 82 116 130 171 109 146 87 135 147 186 228 139 499 43 521 263 266 332 317 25 207 207 79 20 226 288 259 312 198 426 119 230 582 55 205 344 192 80 133 126 73 83 241 211 147 108 566 589 163 160 199 175 91 80 271 125 142 301 218 115 155 204 205 162 293 140 63 294 129 120 270 522 103 106 28 11 143 131 119 209 153 133 177 102 13 40 170 103 136 233 65 89 174 12 173 124 65 70 493 135 108 232 152 104 134 856 498 405 419 152 23 265 332 423 180 491 63 418 219 46 263 257 105 341 170 75 318 453 595 40 175 71 387 283 82 58 59 500 149 267 232 219 277 19 116 0 11 237 64 116 236 549 160 54 547 261 243 277 165 12 320 111 196 275 87 85 197 83 102 156 321 22 145 132 38 352 178 409 280 217 274 140 353 528 110 278 303 459 391 184 266 329 55 698 165 186 118 381 146 206 29 257 153 84 198 1839 150 182 52 338 190 18 149 310 251 217 30 198 32 118 98 310 397 155 203 200 194 117 185 30 54 142 216 418 307 24 310 404 261 80 86 75 110 107 267 270 210 75 145 72 17 79 146 426 254 173 297 0 266 293 146 127 15 350 792 493 238 123 210 143 211 231 401 70 142 356 154 467 53 190 145 53 249 853 435 197 236 79 218 507 193 37 354 137 162 30 239 118 564 275 121 253 272 250 20 277 14 167 136 256 458 143 149 177 162 35 13 64 201 104 168 192 199 350 685 54 302 286 244 24 337 239 332 277 180 79 131 169 105 488 264 274 214 278 59 136 46 42 16 94 267 496 588 255 297 248 339 100 228 27 119 137 18 130 118 232 213 701 153 185 276 129 123 110 271 84 569 175 70 130 71 69 37 334 114 11 371 284 42 101 82 308 262 561 147 349 94 213 117 213 383 44 497 95 25 15 310 439 202 94 32 317 393 337 159 467 35 238 143 86 85 120 347 1105 163 193 304 151 134 141 88 1025 80 82 30 140 112 165 87 123 228 102 55 87 73 180 169 37 85 193 460 98 137 241 214 338 149 142 511 327 81 345 73 43 70 0 414 85 226 75 96 112 170 534 77 223 400 137 510 324 32 115 174 153 89 196 149 237 225 389 131 139 154 202 113 45 140 205 332 128 299 193 357 66 364 450 118 171 200 126 154 143 124 68 334 83 85 81 68 253 210 53 109 186 113 286 166 1445 ]
@@@ Loss per-class: [ 0.32807 0.545196 0.549379 0.625654 1.09717 0.553894 0.833191 0.778256 0.685916 0.451212 0.233049 0.859465 0.294476 0.663572 1.04543 0.805018 0.688347 0.863337 0.612531 0.430773 0.296263 0.558376 0.208298 0.601518 0.707096 1.07614 0.428755 0.382768 0.643043 0.450878 1.49767 0.854878 0.463734 0.673676 0.377541 0.73679 0.406168 0.143153 0.434571 0.815131 0.647032 0.664993 1.15874 0.829656 0.228771 0.331593 0.674154 0.836726 0.400127 0.613147 0.479166 0.221497 1.83831 0.406653 0.862059 0.370214 0.483039 0.362702 1.02525 1.09682 0.883874 0.818902 0.987314 0.368749 0.324664 0.520396 1.17453 0.535571 0.605942 0.435528 0.472076 0.587422 0.568367 1.57004 1.17934 0.8452 0.44333 0.202881 0.450095 0.384544 1.37489 0.802655 0.676682 1.12838 0.567082 0.801215 0.45074 0.510436 0.935634 1.20578 0.536179 0.792755 0.449527 0.603438 1.12899 0.3089 0.734927 0.74525 1.34855 0.622407 1.22738 0.707585 0.345178 0.562627 0.557963 0.454391 0.974704 0.727035 0.601299 0.280157 0.447326 1.38979 0.50526 0.584605 0.328257 1.10987 0.420567 0.972772 0.840754 1.74605 0.512211 0.855173 0.487058 1.66793 0.48366 1.55796 0.903872 0.518549 0.911854 0.716405 0.969427 0.573062 0.617683 0.448351 0.574046 0.780676 1.42321 0.527966 0.949977 0.813123 0.668118 0.695432 0.69331 1.29855 0.564948 1.26748 0.459574 0.887827 0.962931 0.741345 0.680031 1.08701 0.537345 1.00304 0.909542 0.484765 0.564105 0.643037 0.704648 0.373481 0.875218 0.473483 1.42163 1.89006 0.735854 0.630874 0.981215 1.36557 0.406509 0.74422 0.485624 0.855105 1.37788 0.464564 0.763661 0.52647 0.765184 1.10404 0.527571 0.404253 0.66448 0.644324 0.920755 1.0654 1.20566 1.27019 0.658357 0.572645 0.639715 0.796679 0 0.419455 1.53202 0.682877 1.43397 0.886083 0.776314 0.428663 0.575902 0.862734 0.759956 0.848439 0.526995 0.428892 0.598543 0.357699 0.629647 0.582037 0.503193 1.4592 0.79749 0.589042 0.963629 0.996428 1.11454 1.471 1.39421 0.686886 0.703664 0.555384 0.404576 0.645809 1.08939 0.699192 1.13928 1.4559 0.526944 0.831942 0.621811 1.62649 0.358244 1.04666 0.746838 0.874497 0.620249 0.867235 1.10892 0.729017 0.349011 0.609781 0.475127 0.940981 0.591087 0.360249 1.53354 1.2647 1.06662 1.0179 0.42479 0.451304 0.771929 0.471573 0.383827 0.413904 0.756784 0.970003 0.427657 0.433258 0.74611 1.21299 0.984712 0.474603 0.438681 2.18841 0.684831 0.297706 0.369505 0.834297 0.493313 1.06802 1.74338 0.811469 0.768085 0.352564 2.22041 0.538957 0.540021 1.34964 0.612999 1.09384 0.560145 1.12312 0.481484 0.66493 1.22108 0.595165 0.675107 0.734494 0.481207 0.475801 0.624973 1.12385 0.960328 1.39793 1.0879 0.349695 0.393784 1.08749 0.929862 0.817081 0.862958 2.16182 1.4594 0.761476 0.66016 0.8534 1.04328 0.586696 0.384971 0.87458 0.397302 1.34888 0.550863 0.425688 0.595349 0.428258 1.13575 1.66742 0.540734 0.60823 0.501679 0.797165 0.804181 1.01617 0.374545 1.46694 1.24023 0.846274 1.17339 1.78629 0.990522 0.559888 0.712101 0.779131 0.539044 0.5312 0.478146 1.40433 0.676718 0.717005 0.471486 0.670794 0.520824 0.709503 0.676875 0.322656 1.24701 1.07409 0.883037 0.932997 0.666199 1.20202 0.796363 0.805908 1.17945 0.54219 0.454167 0.733961 0.764938 0.592456 1.16474 1.01846 1.02155 0.651412 0.767041 0.264514 1.26348 0.947623 1.57376 0.605358 1.2639 0.549982 0.551646 0.357464 0.815045 0.781214 0.721248 1.02934 0.825941 0.866641 0.448435 1.52699 0.677318 0.74162 0.443285 0.417805 0.71452 0.874845 0.675177 0.92432 1.58664 0.701995 0.914911 0.394958 0.658936 0.820758 0.466781 0.34186 0.400827 1.98061 0.677059 0.494658 0.712436 0.475988 0.612154 0.912067 1.82504 0.785668 0.465365 0.778421 0.975211 0.862891 0.757554 0.570405 0.393611 0.530867 0.656711 1.30712 1.0063 0.878967 0.516075 0.73711 0.346676 0.999213 0.290119 1.32285 0.795529 0.811446 0.898454 1.39754 0.495879 0.633999 1.0726 0.629717 0.541725 1.24309 0.699808 1.16091 0.423984 0.694074 0.424091 0.604031 0.931267 1.19519 1.01353 1.15873 0.586581 1.26084 1.0824 0.402703 0.691213 0.377029 0.91152 0.779235 0.923554 2.07576 1.03034 1.0077 1.3987 0.354704 0.952412 0.608476 0.615031 0.423008 0.728804 1.38903 0.734891 0.218084 0.968153 0.882845 0.817336 0.472525 0.35218 0.987319 0.659574 0.725601 0.474774 1.05531 0.83016 0.897241 1.0218 0.532779 1.24418 0.772356 0.725912 0.723442 0.6946 1.43215 0.904366 1.24436 0.824233 0.923189 1.11334 1.63744 1.20866 0.613755 0.429931 0.573975 0.79327 0.406049 0.957527 1.30997 0.448785 0.698621 0.445143 1.39157 0.585785 0.540267 1.09568 0.46359 0.711739 0.972186 0.668491 0.430189 1.21659 0.589252 0.947186 0.928584 0.725686 0.866422 0.836453 1.06507 1.36576 0.998758 0.379447 0.800807 0.69827 1.41686 0.755364 0.828701 0.655672 0.464695 0.854739 0.402278 0.329313 1.41019 0.533503 0.629981 1.55185 1.01543 0.500098 0.90014 1.165 1.43145 1.39569 0.683793 0.571991 0.570335 0.611342 0.817708 0.578516 0.59537 1.62132 0.593125 0.862793 0.916216 0.954352 0.624058 0.857129 0.656904 1.38141 0.49346 0.662675 0.744566 1.08712 1.21579 0.752111 1.43526 0.687568 0.527584 0.57713 0.655868 0.792812 1.85233 0.83462 0.902629 0.637464 0.872963 0.919495 1.30757 0.765448 2.25635 0.781324 0.870164 1.69716 0.367312 0.562212 1.07139 1.14024 0.605036 0.41177 1.25713 0.747146 1.00058 0.544554 1.09322 0.972086 1.18148 1.59081 2.51104 0.66591 1.06501 1.2361 0.592454 0.724632 0.680759 0.479068 1.05697 0.576906 0.56916 0.727403 0.972542 0.833402 0.613693 0.695343 1.47654 0.278996 0.508149 2.94993 0.489422 0.857044 0.884909 0.570089 0.820912 1.2472 0.710587 1.44361 0.371103 0.847503 0.852761 1.96491 0.755836 0.566422 1.03356 1.03755 1.35651 1.00341 0.576499 0.686973 0.716803 2.89236 1.23767 1.77565 0.798255 0.739395 0.570024 0.634834 0.878049 1.53051 1.20293 1.14138 0.614443 0.597177 1.09578 0.901039 0.993235 0.976815 0.795199 0.269073 0.863184 0.58728 1.60798 2.34167 1.29405 0.948877 0.492926 1.91313 0.75723 0.663497 0.583192 0.603732 0.895858 0.865533 0.29474 1.54913 0.828649 0.783988 0.293805 0.704761 0.4948 0.743063 0.926714 0.520861 0.724381 0.439664 0.651145 0.559231 1.25139 0.673228 1.02003 0.707648 0.852634 1.89083 0.625916 0.593057 0.68735 1.1176 2.39006 1.24269 0.800373 0.996524 1.13592 0.727172 0.662514 1.34379 0.574336 1.89333 0.911364 0.675983 0.592232 0.983946 0.452839 0.883835 0.824405 0.43095 0.405987 1.03357 0.816187 1.08101 0.676172 0.595659 0.952904 0.868378 0.428318 0.723552 0.645612 0.373951 0.744255 0.71521 0.81964 0.954056 0.79129 1.03437 0.613147 0.818588 1.12877 0.581194 0.566071 0 0.503389 0.942187 0.754157 0.562127 1.42806 0.676488 0.666374 0.623164 1.36703 0.825843 0.633218 1.67059 1.32327 1.53489 0.747305 0.863254 0.717157 0.699118 0.987088 0.403531 0.975032 1.1636 0.991883 0.498559 0.764985 0.814344 1.11305 1.95251 0.421603 0.820676 0.839418 0.522034 0.484069 1.14669 0.675412 1.13435 0.680816 1.2721 0.822727 0.395017 1.4949 0.473769 0.890156 0.917238 0.662158 0.70977 0.907616 0.971617 0.711691 0.7093 0.988632 1.1837 1.06056 0.535245 0.770687 1.03117 0.745612 1.43677 1.00467 1.04301 0.513813 0.460654 0.745155 0.932586 0.807503 1.04092 0.845123 1.03739 1.25818 0.562876 1.39044 1.07749 1.15283 0.891926 0.878514 0.487162 1.05375 0.602177 5.1153 7.82791 0.699649 0.832417 1.0886 0.609336 0.492525 0.602539 0.748759 0.831663 1.59824 0.466033 0.570255 0.507342 1.0822 1.22521 0.858032 1.51768 1.77397 1.2759 0.452433 0.893033 0.641646 0.791838 0.779335 0.342456 1.33784 0.817521 0.659853 0.481223 0.849265 1.03338 0.63596 1.78849 0.488317 0.894069 0.714925 0.496555 0.57482 3.26657 0.569469 0.893328 0.645848 0.946038 1.19901 0.735296 0.825393 0.60161 1.32827 0.322111 0.690896 0.380287 0.693886 0.946248 1.45808 0.728015 0.970895 0.850969 0.527419 0.919768 0 0.942066 0.853357 0.710926 0.57863 0.556844 0.928407 0.645557 0.574668 1.14333 1.5775 0.709307 1.26303 1.07283 1.295 1.26132 1.51225 0.933519 0.421376 1.24959 1.19838 1.18732 1.16356 1.26971 0.723995 1.80921 0.727369 1.30308 1.77342 2.28154 0.551287 0.865427 1.01722 0 0.637555 1.68552 0.973632 0.800847 0.448312 0.503077 1.18439 1.02048 1.34039 0.687973 1.1044 0.928104 0.665191 0.675324 0.532472 1.10429 0.673547 0.820333 1.34255 1.25089 1.07495 0.86487 1.2987 0.881747 0.659336 0.91531 0.841806 1.2349 0.533589 1.10412 0.948113 1.38023 0.255918 0.400334 0.620504 0.727428 0.8412 0.82375 0.865717 0.418309 0.662481 0.889398 0.909399 0.985978 0.741702 0.992867 1.88943 0.868835 0.573984 1.45275 0.537427 0.806148 0.958767 0.933644 0.830276 0.916717 2.35942 0.854104 0.819078 1.01107 0.91663 1.61402 1.54196 0.874404 1.26238 0.357564 0.68341 0.511106 0.669158 0.689527 0.524616 1.12008 1.05444 1.18929 1.01619 0.448921 0.927277 0.751995 1.02847 0.826872 0.84063 0.64326 0.544337 1.1542 1.1925 1.0889 1.30505 0.476528 0.572203 1.00066 0.526435 0.826649 0.824763 1.41459 2.06334 1.49978 1.24657 0.949042 1.45887 0.424213 0.582694 0.531524 1.14646 0.752874 1.04101 1.21067 0.696296 0.577765 0.569269 0.688092 0.868026 0.74577 0.913575 0.667408 1.1516 0.620061 1.28587 0.615536 1.49598 0.52787 0.742134 0.607898 1.36429 1.33403 1.03544 0.984086 1.4035 0.617529 1.78631 0.404487 0.899919 0.693818 0.617232 1.08128 0.342807 1.12173 0.860097 0.770464 1.47514 0.530289 0.529093 1.2645 0.774019 0.500689 0.938561 0.935707 0.999884 0.535155 0.710761 0.551812 0.910809 0.601192 0.876231 1.08057 0.569751 0.770224 0.719473 0.83778 1.00791 1.29354 0.856316 1.49883 0.579886 0.862184 1.04032 1.33225 1.33476 1.67281 0.353959 1.18797 1.24942 0.818034 0.918489 0.812971 0.773573 1.36848 0.365071 0.85027 0.641205 2.78416 2.10144 0.823685 0.631168 0.750153 0.88233 0.877639 1.02507 0.658293 0.702993 1.60977 1.43724 0.883098 0.74076 1.03826 0.905636 0.956851 0.878025 1.40558 1.38418 0.962404 1.11734 1.94191 1.50427 0.847329 1.29556 1.48188 0.552422 0.845917 0.822071 0.998005 0.502084 0.965132 0.666643 0.459043 1.32913 0.609128 0.493972 0.499665 0.989057 0.607694 0.540046 0.618395 0.863318 0.742406 0.870025 0.988242 1.07126 0.502644 0.534177 0.530459 0.401281 0.931225 0.871596 1.02068 1.38713 0.538325 0.835208 0.731191 0.842614 0.691157 1.04707 0.928176 1.10992 0.965273 1.2918 0.878027 0.569671 0.800652 1.82036 0.761925 0 1.47504 0.513094 1.20364 0.733173 0.72416 0.707797 1.20703 1.14793 0.787852 1.43187 0.444715 0.756601 0.738467 0.589785 0.661432 2.28147 0.917323 0.684887 0.746572 1.09093 1.5195 1.03298 1.16679 1.22898 0.778842 1.1403 1.16651 1.1822 0.950409 1.06033 0.998688 0.655408 0.462552 0.428317 0.895472 0.978541 0.646138 0.624128 1.5299 0.532967 0.493864 0.578202 0.519134 0.41598 1.00626 0.950374 0.606137 0.81365 1.26629 0.861003 0.898384 0.862983 1.36631 0.600882 0.908428 0.630829 0.982136 1.02665 0.651326 0.59265 0.782998 0.493212 0.947743 0.391277 0.840473 1.0196 0.932361 0.762742 1.12682 0.661541 1.36022 1.38958 2.51838 0.89414 0.935423 0.65655 0.850418 0.560586 0.406299 0.826626 0.607988 1.15192 0.622794 0.626011 1.02295 0.662288 0.882368 0.701975 1.14269 1.18185 0.975428 0.750556 0.571893 0.792342 2.03197 2.51979 0.735835 0.805921 0.328451 0.848373 1.43736 1.18667 1.32494 1.50835 0.454567 1.01779 1.00814 0.391488 1.09525 1.14355 0.505032 0 0.980454 0.72165 0.736645 2.07174 1.26231 0.76192 0.53207 0.82016 0.64776 1.10225 1.1937 0.670607 0.773845 0.868624 0.84505 0.923884 0.431045 0.362267 1.30423 0.504029 1.00076 0.878949 1.15878 0.347965 0.978753 0.516547 0.926857 2.4479 0.930155 0.634883 0.813626 0.97467 0.811758 1.11901 0.92838 1.14785 0.733246 1.4918 0.7147 1.07015 0.806409 0.45263 1.45955 0.775891 1.27357 0.604576 1.2705 0.592113 1.03898 0.810864 1.44848 1.0581 0.503578 0.791161 0.828447 1.20902 0.980037 0.828159 1.09217 1.10123 0.494128 1.21496 1.31672 0.914423 0.605191 0.775252 0.683 0.92213 0.725282 1.27674 1.35701 1.28209 0.869351 0.730679 1.05823 1.11486 0.779116 1.26727 1.64403 0.650618 1.08747 0.55583 0.629485 0.719755 0.860305 1.05558 1.10753 1.40383 0.863458 1.45822 0.481008 0.831679 0.933812 0.561231 0.441418 1.22245 0.908575 0.950116 0.641961 0.861441 1.41186 1.18687 0.971247 0.684116 0.684722 1.30887 1.07596 1.18998 0.469124 0.80111 0.712309 0.901597 0.75901 0.700318 0.95736 0.968324 1.11189 0.931827 0.547753 0.922505 0.858058 1.7687 0.618646 0.765872 0.989051 1.54012 0.760742 1.44828 0.735267 1.5324 1.39951 0.748373 0.625483 0.717685 1.64661 0.807445 0.772574 0.769691 0.891545 0.292528 2.32688 0.990455 0.325618 2.29268 0.631277 1.3308 0.424199 1.82404 0.439374 0.686791 0.533594 0.94697 1.71809 1.47331 0.664613 1.08704 0.622253 1.09589 0.910672 0.752163 1.18266 0.913673 1.90496 0.638013 0.98294 0.53503 1.39113 0.774704 0.784608 0.896523 0.557609 0.663241 0.681055 0.459786 1.27389 1.55058 0.492578 0.706494 1.11823 1.13524 0.943861 0.578684 0.959414 1.02749 1.53917 0.945582 1.11974 0.740362 1.44985 0.409276 1.20518 1.07262 0.546106 0.986419 0.742829 0.861749 0.917076 0.857923 0.869696 0.671024 0.567359 0.635199 1.0852 0.859766 0.771708 0.821804 1.12498 0 0.86437 0.884599 0.728896 1.40143 0.842502 1.60902 1.53786 0.561744 1.24737 0.774908 0.945709 1.04971 0.375267 0.655667 0.881149 0.651293 1.04618 0.363598 1.0304 1.07301 1.26981 1.00808 0.746044 0.623014 1.55764 1.0232 0.759101 1.34727 0.763579 1.5522 1.03658 0.798195 0.760941 0.705956 0.565107 1.11242 0.671593 1.20538 0.596891 0.632102 1.13868 0.442433 1.08098 0.829376 0.972939 0.535907 0.899174 0.676864 0.369791 1.78153 0.71142 0.846766 0.654518 0.811758 1.05329 1.42371 0.749461 1.66208 1.36463 0.556495 0.874467 0.209855 ]
@@@ Frame-accuracy per-class: [ 88.1839 88.4848 87.2404 90.3226 55.6962 85.0829 80.4781 82.7586 78.5047 88.7836 93.7213 74.0061 91.7983 81.1715 69.905 80.7588 76.9231 76.1229 86.8217 88.4987 93.3948 88.3281 95.0092 88.2883 78.5579 69.281 89.6918 90.1213 83.859 87.9607 45.9627 67.1756 89.5522 85.7143 92.3077 81.5287 88.9296 95.7684 88.0707 81.1429 86.747 81.0084 63.9456 73.5135 93.9891 94.6372 80.2508 80.4598 87.9536 81.5072 89.6936 92.8925 32.2581 89.9431 76.3052 92.0405 84.7926 92.2314 79.3651 70.2413 72.8972 61.1933 78.6207 89.9563 92.6829 88.3721 63.8298 86.77 79.7569 89.1967 82.9837 84.1424 83.9779 58.7678 73.8462 77.635 87.5502 93.8098 84.0621 91.7847 61.0778 88.8889 79.8928 61.5652 85.2878 75.2998 84.9761 88.3295 72.5389 70.7838 84.7059 73.4491 89.4472 80.5275 80 92.6126 87.5536 77.961 58.8745 84.3327 63.5897 85.6397 91.0663 87.0466 85.9504 86.9353 72.1992 79.4007 85.6269 91.6724 89.6359 57.3477 88.0829 81.8533 93.5982 66.0163 90.0901 78.7879 81.6327 32.4324 85.9722 71.066 88.3436 40.884 87.8187 57.9439 66.8977 85.2868 80.7339 79.602 73.6842 84.0367 84.2553 96.7742 79.5181 83.7209 60.4651 84.153 71.0744 76.6798 83.038 71.8447 89.1192 65.4545 84.6325 47.3008 89.8172 57.4257 66.6667 79.7508 81.5642 66.0767 85.2321 78.4983 70.1422 90.7801 86.7257 87.5472 80.8023 90.3491 73.2984 85.9206 59.542 32.7273 80 82.0926 74.6082 67.8414 90.6096 82.7988 87.7888 77.1536 55.9242 89.0323 78.6555 83.4171 77.9343 72.4638 89.7959 87.7876 80.6723 81.4229 69.3603 70.1337 62.3853 58.5132 82.5871 87.0748 83.1461 78.1065 0 90.5051 44.2105 86.9565 61.8557 75.0515 78.6026 90.5312 84.2105 74.364 76.2887 76.2763 86.9666 85.9935 81.7121 93.2945 86.1565 87.468 90.027 43.9863 68.9266 80 72.8033 69.6017 65.7718 64.5161 52.1739 82.0438 83.9378 84.5283 89.2206 80.2721 72.8778 79.0244 75.6757 74.8718 78.8991 76.6962 89.1089 48.6486 91.8033 68.0203 80.663 77.9116 80.6175 75.8621 67.9803 79.1809 90.1506 82.2511 89.1013 73.0159 81.5416 90.5371 62.1359 51.8519 68.5714 73.6196 87.0849 87.9056 78.2418 83.4008 88.3295 89.9394 82.2134 71.6883 90.166 97.2973 81.9048 59.164 74.1463 90.1734 90.785 35.2941 79.2899 93.4087 94.9254 73.7778 87.6356 68.0628 65.5738 74.0426 75.2643 93.7965 34.7003 82.1053 91.8919 63.0339 84.2975 65.2406 89.3082 80 86.7925 82.0513 64.6388 86.4 80.1843 83.2877 92.4855 88.3721 83.9827 69.0808 73.703 57.754 67.2941 91.8544 88.3895 68.3386 70.8283 72.9858 70.8661 25.8503 55.1724 84.2353 82.1239 71.9818 73.3475 85.7732 92.5267 76.9231 89.2508 63.5379 80.8399 90.1734 86.7925 89.3082 70.7182 50.1873 84.4291 87.747 81.8505 81.8482 77.2603 69.281 91.358 56.1457 59.8985 75.1773 67.4699 60.177 78.1955 79.7721 75.6477 81.0811 78.9809 84.5815 89.1192 61.8267 83.1276 78.8148 87.5576 83.4356 82.1192 73.7968 84.9858 89.013 59.5918 53.7313 76.9759 71.3178 82.8331 63.5193 91.4286 79.4045 62.0408 86.0399 96.7742 77.748 76.1905 86.3504 67.9245 81.7391 69.3009 82.9268 83.4783 93.0519 61.3757 67.7824 63.5294 85.624 62.3557 84.3636 86.1953 91.7782 73.0878 80 84.0149 71.9424 70.8661 72.2581 88.4211 59.3886 77.2239 79.4245 89.5522 90.3704 83.9161 66.6667 81.768 72.5389 51.4286 78.7565 76.3926 90.6149 78.8512 73.8854 86.9757 92.6503 90.5923 46.0177 82.7068 82.9268 80.6867 87.0488 95.2381 77.3109 56 78.0488 87.4122 79.1111 68.9655 66.6667 77.4584 84.1499 91.8206 87.8661 84.6881 69.3878 73.9206 72.2166 83.3747 80.798 91.5078 72.1408 93.5323 62.7803 67.9612 75.5365 74.7554 56.1151 84.7896 85.2792 59.0308 81.3008 83.5556 57.2391 83.7209 69.4772 90.2655 76.2332 88 81.0198 69.4737 74.8718 70.2842 65.1026 87.1111 66.6667 82.0513 88.1612 83.2392 92.1348 76.1905 78.209 75.4209 43.1373 71.8147 71.6418 69.5652 92.0128 85.7143 79.397 81.4404 91.7431 77.6371 53.3333 79.6537 95.3456 70.8934 78.4314 80 89.3617 91.5974 75.188 82.2086 80.1733 87.5152 73.43 68.9655 72.7273 65.3465 87.8505 70.5882 82.1173 83.1804 79.638 75.3363 54.0351 72 36.3636 75.2137 73.703 66.6667 46.696 64.0264 80.5369 88.4574 86.7052 75.9322 87.9323 73.4177 67.7966 86.119 84.4291 91.1392 61.1465 83.5979 81.0409 77.1084 90.5747 81.0409 80.5861 77.8116 89.697 62.4277 81.1429 75.6303 71.9397 84.0506 76.8916 75.5509 61.0329 57.4359 73.2026 91.9487 75.4098 84.472 61.157 82.1918 82.3529 81.0967 89.0511 77.0732 90.6205 96.4824 67.5722 86.2703 87.4317 55.4113 71.3514 87.0796 60.8955 53.3333 37.037 54.4622 86.2745 87.1595 86.2034 84.5638 77.8555 83.2215 83.3684 56.9106 84.7863 80.9816 74.2633 69.4611 84.6316 81.1189 82.153 52.0291 88.5496 79.8354 80.6941 71.1864 56.2963 82.807 66.6667 80.112 85.4489 86.1619 82.6291 80 60.0939 83.0409 72.7273 85.4772 72.2317 64.4266 66.6667 79.7386 43.9024 78.7004 75.1423 47.7419 92.6993 85.5688 77.4566 70.1754 86.2338 92.7039 67.0157 79.1615 78.1395 85.0227 61.4786 69.145 62.7063 48.731 48.4848 82.0327 73.2026 67.6845 90.4943 80.1572 73.0897 90.0645 69.4064 85.2174 86.4721 75.7202 69.6343 72.5664 86.0215 80.4533 68.6869 94.3119 85.3178 19.0476 87.8505 78.4053 77.7251 85.4976 77.0538 74.0741 88.4956 61.5385 92.4188 70.9677 76.6585 53.3333 77.3663 84.0945 69.8039 67.1679 60.7539 72.6257 85.1485 81.8342 83.2891 32.1168 76.5957 50.1377 78.3083 81.3559 82.2144 87.3385 78.1065 50.9804 72.7273 64.127 85.7143 85.3056 66.6667 73.93 78.4314 73.7589 72.5212 94.2904 81.2749 81.7927 52.549 33.5484 59.1716 73.6077 86.2155 51.6129 79.6267 85.3755 86.6873 82.4427 74.3295 75.4358 91.9169 76.1905 75.1174 82.7839 94.1847 80 89.5397 86.5672 67.3684 88.7574 78.806 89.22 84.7545 81.6568 72.3404 81.9876 68.9231 80.51 77.5904 49.2147 83.8951 82.7417 81.407 67.0659 38.806 57.8089 76.5453 72.7273 66.9767 82.9268 83.5821 60.8 85.8238 47.0588 72.6727 93.3333 80.8446 70.9859 89.2655 76.4818 72.4409 97.561 88.729 65.1757 76.9231 70.6927 76.4622 82.774 73.3417 77.9874 89.4915 76.4179 82.449 89.332 78.922 89.7959 78.5553 68.7023 74.8235 70.5441 83.6489 79.0861 67.2489 84.0841 85.8686 0 86.0759 73.2538 66.2577 84.0525 53.3333 82.7309 83.4467 83.1557 62.3853 88 79.1541 38.806 73.224 54.8926 87.3096 68.5714 84.6626 82.4142 68.9076 88.5867 73.3638 66.8493 69.8225 85.0161 81.3397 73.6283 64.0693 37.4429 88.6297 78.9333 76.0563 89.8113 91.3349 65.5367 78.5872 72.0214 81.0458 67.3267 83.871 89.7336 58.4362 91.5254 66.6667 72.7273 84.0295 77.7143 70.5036 69.5652 85.9903 75.6646 76.9231 71.5328 69.6774 86.5306 79.4631 74.2857 78.7302 55.9585 73.1707 73.4694 84.3188 90.7087 76.8683 72.4324 74.813 66.9388 86.4865 68.9655 60.8365 87.3108 62.5369 57.2973 58.9235 74.9091 68.9655 88.4211 70.8861 82.4798 0 0 88.5572 74.4186 66.6667 87.9479 87.2428 83.4628 76.7568 88.3721 56.0669 88.7189 85.6187 84.5902 66.6667 64.6388 78.6885 38.5965 47.1338 69.4561 89.5175 74.9568 84.0959 81.0409 75.8974 93.5454 52.3077 80.5797 86.5574 88.3365 69.5035 70.3476 83.5017 45.7143 89.3855 75.8321 81.9788 88.7356 78.6325 0 84.345 72.638 83.4606 63.5379 68.5512 78.6207 82.4147 86.4865 63.4573 91.7574 80.9224 90.4208 82.1542 74.5698 71.6981 80.4318 82.7586 71.4563 87.725 78.329 0 62.8571 79.8337 81.9876 80 85.7143 64.6154 80.2508 84.1553 71.5543 51.6129 84.7458 61.6949 71.6469 68.3128 65.0407 48 74.3003 90.3766 60.1336 69.5341 60.1719 70.1754 59.5556 82.2612 53.1959 76.8061 66.6667 54.4681 45.2489 83.6773 77.5178 69.3032 0 82.5911 52.4496 73.2026 90.3226 87.2077 87.3337 64.8276 76.2887 68.3544 80.8126 71.6418 67.3575 79.2952 81.4558 84.8598 59.4595 84.7059 79.0378 48 63.6735 71.8894 79.9277 63.0137 74.5763 79.4189 71.7019 73.4463 66.9091 84.3243 66.6667 73.0924 67.4286 93.8346 93.8182 79.6935 81.8505 82.4742 76.3285 72.3127 92.973 87.6133 76.9932 72.8111 75.9207 82.1018 77.4468 43.1373 76.4873 89.3971 53.4653 89.3082 77.3694 75.5043 77.4026 69.9267 73.9927 34.6667 66.4577 72.3164 63.6735 70.7483 54.0541 53.1017 76.9759 65.1054 91.6162 81.9753 87.7654 81.2193 76.3485 85.7143 67.0051 73.8916 65.6 64.2254 91.1704 75.8256 76.16 67.8899 82.6667 77.2487 80.5654 84.6765 73.224 67.8179 66.899 67.438 87.9257 84.5921 71.73 88.0734 75.154 79.6935 53.3333 45.3988 58.9091 72.381 78.7402 54.4681 90.8881 79.4953 86.1368 66.2687 85.4369 74.5698 66.6667 84.1202 87.3563 85.1312 78.5388 76.4505 80 72.3247 84.0678 68.6327 84.9015 60.2151 84.2843 48.2759 84.9473 79.3169 84.0525 62.8571 62.3622 70.5882 67.9518 51.0843 83.0189 39.0244 90.9492 76.6031 81.3102 85.76 61.9647 91.6764 64.4351 73.7527 74.6781 52.2523 87.1046 85.6313 67.013 74.5342 86.8914 77.4704 74.8299 75.4491 82.8157 81.7967 84.0678 78.341 80.4943 75.4877 67.8899 86.6044 80.7018 82.6211 84.153 72.0497 57.4586 74.1036 51.2281 85.5721 74.5995 70.9957 61.0932 57.7017 55.9611 92.9231 67.4617 59.7865 83.4646 73.0051 79.5367 78.0083 60.2588 91.6746 71.4976 81.6901 17.5439 34.7826 78.0488 84.4106 71.1297 70.1671 76.873 74.9064 78.3099 78.0488 59.2593 56.7901 78.5924 77.2947 71.0623 75.3747 70.229 77.095 56.1605 56 71.4697 70.6827 33.5878 43.9716 77.001 54.6125 54.3779 86.4516 72.1311 76.555 77.3234 87.6824 70.8124 84.3403 88.2002 51.8033 93.617 90.3955 88.4211 72.0189 83.6565 87.8942 83.4646 77.4194 82.9157 68.8172 74.7628 71.068 89.0995 84.6266 86.217 86.0927 72.5275 75.8545 67.1704 64.1975 83.7607 74.1259 78.1935 77.9541 83.6364 78.6325 75.6303 70.7293 70.2341 61.3084 76.5591 82.9157 78.1982 61.5385 79.8283 0 43.4783 87.5789 69.7674 79.8283 84.1438 82.6206 63.5514 66.055 78.9041 57.7438 87.885 75.6757 83.9879 80 81.1232 35.8744 73.2824 81.3067 85.7143 70.1754 50.1266 68.2635 61.4634 65.8147 81.182 66.6667 59.7938 69.434 85.7143 63.5461 72.8291 82.0513 87.7005 89.1954 71.0383 76.1566 86.2801 86.2819 66.0633 85.4578 88.6326 89.2274 87.1009 91.0569 74.6717 71.0167 82.8829 73.1568 58.6103 75.6032 75.1055 78.637 60.0683 82.8087 84.7458 84.6602 70.3583 74.5562 85.1385 80.1305 83.7209 88.7671 72.381 91.8759 80.315 81.0811 76.2542 79.8712 63.2207 82.7586 68.8525 62.4685 12.3077 75.1055 77.1574 82.1256 79.2453 88.1029 90.4177 76.808 86.3753 64.6809 85.7143 78.6885 78.8991 80.7018 75.2887 84.3489 68.6179 69.3878 71.4976 82.3239 85.2772 81.9876 47.3988 22.5166 80.543 77.2093 90.8411 78.0037 51.3064 55.6291 59.1065 59.3103 97.1429 72.956 77.8157 89.5662 69.1552 65.7061 88.0672 0 76.1726 82.1124 83.2765 48.6275 70.9677 79.03 85.9306 80.4458 86.7925 72.8745 70.3088 80.1394 80.8511 76.8898 75.467 73.7589 91.9298 92.8471 63.4304 84.7059 74.7664 76.1155 72.1649 95.3271 69.7395 87.2876 75.5454 29.3671 76.1099 84.2767 78.7185 73.1034 78.0362 77.3333 72.2144 64.7273 80 59.0164 81.8372 70.8861 78.6537 89.2922 58.4362 78.8955 59.8165 84.2315 73.1707 79.6396 68.9655 81.194 69.5971 66.6667 88.3315 78.7456 74.9164 72.6761 71.3846 81.6901 51.8519 65.1163 88.3375 61.244 58.1602 75.8442 83.208 74.7504 79.9416 64.2202 80.6612 67.0157 62.1677 53.0612 75.5556 83.5073 66.4662 68.4685 80.3324 67.9245 54.7529 84.3658 72.9858 87.2057 83.5539 78.3242 78.7879 67.5045 52.1008 51.2821 73.1183 51.7647 96.9697 80.4233 78.1308 83.3837 87.5106 66.5362 77.9832 75.2515 85.4197 79.602 63.895 47.2727 74.477 74.9091 75.6757 66.6667 68.3544 70.9677 87.5878 78.8311 82.7362 74.9326 78.8427 84.9421 69.6356 67.8733 67.7716 73.3728 87.6207 71.7949 82.2695 48.2759 82.5175 82.0144 80 54.4096 80.3493 60.8696 80.4845 53.0756 49.4118 73.8916 80 79.4165 57.5238 76.0463 81.3559 78.97 78.3069 93.2084 32.3404 74.9415 91.7862 40.4494 85.0251 55.4974 94.1176 38.7097 89.211 81.2287 85.9259 75.1323 46.1538 54.4882 79.5426 66.3704 80.2508 68.2353 76.0563 81.3417 63.4146 70.5202 36.2573 85.4772 75.6835 85.2103 61.1621 78.553 77.8325 72.6073 83.2714 81.2721 81.3559 87.372 60.8696 60.6061 91.8033 82.5623 63.1111 67.6737 75.4286 89.0688 77.4617 76.0976 59.4595 72 66.6667 81.4404 53.6873 96 71.345 72.3514 84.4734 74.1117 81.4545 80.3313 75.0583 79.1728 76.9231 80.7018 86.608 83.6641 67.4847 78.1476 81.6327 78.1609 68.0851 0 78.1665 70.1754 82.1192 52.9801 80.829 48.8889 51.0264 82.1328 70.9677 76.0626 76.9039 68.3636 92.0666 81.6641 89.2308 84.8485 72.2063 92.5081 72.6257 66.6667 58.8629 73.6842 81.153 84.724 56.2738 73.8351 84.7896 64.6914 81.9383 48.3516 69.7509 80.292 76.6917 77.821 88.4808 62.5323 78.3217 66.1654 85.3224 82.5749 59.9156 90.9621 70.3242 71.1462 75.0809 85.7143 72.2892 83.2117 92.6756 49.1018 80.7018 78.5276 78.8321 74.9507 70.3088 59.8131 78.5388 43.9678 58.1498 86.2129 82.8829 95.7454 ]

LOG (nnet-train-frmshuff[5.5.294-06484]:main():nnet-train-frmshuff.cc:406) AvgLoss: 0.718636 (Xent), [AvgXent: 0.718636, AvgTargetEnt: 0]
progress: []
FRAME_ACCURACY >> 80.0748% <<

